{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Quickstart","text":""},{"location":"#install","title":"Install","text":"<pre><code>uv pip install synalinks\n</code></pre> <p>Start your project with</p> <pre><code>uv run synalinks init\n</code></pre>"},{"location":"#programming-your-application-4-ways","title":"Programming your application: 4 ways","text":""},{"location":"#using-the-functional-api","title":"Using the <code>Functional</code> API","text":"<p>You start from <code>Input</code>, you chain modules calls to specify the program's structure,  and finally, you create your program from inputs and outputs:</p> <pre><code>import synalinks\nimport asyncio\n\nasync def main():\n    class Query(synalinks.DataModel):\n        query: str = synalinks.Field(\n            description=\"The user query\",\n        )\n\n    class AnswerWithThinking(synalinks.DataModel):\n        thinking: str = synalinks.Field(\n            description=\"Your step by step thinking process\",\n        )\n        answer: float = synalinks.Field(\n            description=\"The correct numerical answer\",\n        )\n\n    language_model = synalinks.LanguageModel(\n        model=\"ollama_chat/deepseek-r1\",\n    )\n\n    x0 = synalinks.Input(data_model=Query)\n    x1 = await synalinks.Generator(\n        data_model=AnswerWithThinking,\n        language_model=language_model,\n    )(x0)\n\n    program = synalinks.Program(\n        inputs=x0,\n        outputs=x1,\n        name=\"chain_of_thought\",\n        description=\"Useful to answer in a step by step manner.\",\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"#subclassing-the-program-class","title":"Subclassing the <code>Program</code> class","text":"<p>In that case, you should define your modules in <code>__init__()</code> and implement the program's structure in <code>call()</code>.</p> <p>Note: you can optionaly have a <code>training</code> argument (boolean), which you can use to specify a different behavior in training and inference.</p> <pre><code>import synalinks\nimport asyncio\n\nasync def main():\n    class Query(synalinks.DataModel):\n        query: str = synalinks.Field(\n            description=\"The user query\",\n        )\n\n    class AnswerWithThinking(synalinks.DataModel):\n        thinking: str = synalinks.Field(\n            description=\"Your step by step thinking process\",\n        )\n        answer: float = synalinks.Field(\n            description=\"The correct numerical answer\",\n        )\n\n    class ChainOfThought(synalinks.Program):\n        \"\"\"Useful to answer in a step by step manner.\n\n        The first line of the docstring is provided as description\n        for the program if not provided in the `super().__init__()`.\n        In a similar way the name is automatically infered based on\n        the class name if not provided.\n        \"\"\"\n\n        def __init__(\n            self,\n            language_model=None,\n            name=None,\n            description=None,\n            trainable=True,\n        ):\n            super().__init__(\n                name=name,\n                description=description,\n                trainable=trainable,\n            )\n            self.answer = synalinks.Generator(\n                data_model=AnswerWithThinking,\n                language_model=language_model,\n                name=self.name+\"_generator\",\n            )\n\n        async def call(self, inputs, training=False):\n            if not inputs:\n                return None\n            x = await self.answer(inputs, training=training)\n            return x\n\n        def get_config(self):\n            config = {\n                \"name\": self.name,\n                \"description\": self.description,\n                \"trainable\": self.trainable,\n            }\n            language_model_config = \\\n            {\n                \"language_model\": synalinks.saving.serialize_synalinks_object(\n                    self.language_model\n                )\n            }\n            return {**config, **language_model_config}\n\n        @classmethod\n        def from_config(cls, config):\n            language_model = synalinks.saving.deserialize_synalinks_object(\n                config.pop(\"language_model\")\n            )\n            return cls(language_model=language_model, **config)\n\n    language_model = synalinks.LanguageModel(model=\"ollama_chat/deepseek-r1\")\n\n    program = ChainOfThought(language_model=language_model)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"#mixing-the-subclassing-and-the-functional-api","title":"Mixing the subclassing and the <code>Functional</code> API","text":"<p>This way of programming is recommended to encapsulate your application while providing an easy to use setup. It is the recommended way for most users as it avoid making your program/agents from scratch. In that case, you should implement only the <code>__init__()</code> and <code>build()</code> methods.</p> <pre><code>import synalinks\nimport asyncio\n\nasync def main():\n\n    class Query(synalinks.DataModel):\n        query: str = synalinks.Field(\n            description=\"The user query\",\n        )\n\n    class AnswerWithThinking(synalinks.DataModel):\n        thinking: str = synalinks.Field(\n            description=\"Your step by step thinking process\",\n        )\n        answer: float = synalinks.Field(\n            description=\"The correct numerical answer\",\n        )\n\n    class ChainOfThought(synalinks.Program):\n        \"\"\"Useful to answer in a step by step manner.\"\"\"\n\n        def __init__(\n            self,\n            language_model=None,\n            name=None,\n            description=None,\n            trainable=True,\n        ):\n            super().__init__(\n                name=name,\n                description=description,\n                trainable=trainable,\n            )\n\n            self.language_model = language_model\n\n        async def build(self, inputs):\n            outputs = await synalinks.Generator(\n                data_model=AnswerWithThinking,\n                language_model=self.language_model,\n            )(inputs)\n\n            # Create your program using the functional API\n            super().__init__(\n                inputs=inputs,\n                outputs=outputs,\n                name=self.name,\n                description=self.description,\n                trainable=self.trainable,\n            )\n\n    language_model = synalinks.LanguageModel(\n        model=\"ollama_chat/deepseek-r1\",\n    )\n\n    program = ChainOfThought(\n        language_model=language_model,\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>This allows you to not have to implement the <code>call()</code> and serialization methods (<code>get_config()</code> and <code>from_config()</code>). The program will be built for any inputs the first time called.</p>"},{"location":"#using-the-sequential-api","title":"Using the <code>Sequential</code> API","text":"<p>In addition, <code>Sequential</code> is a special case of program where the program is purely a stack of single-input, single-output modules.</p> <pre><code>import synalinks\nimport asyncio\n\nasync def main():\n    class Query(synalinks.DataModel):\n        query: str = synalinks.Field(\n            description=\"The user query\",\n        )\n\n    class AnswerWithThinking(synalinks.DataModel):\n        thinking: str = synalinks.Field(\n            description=\"Your step by step thinking process\",\n        )\n        answer: float = synalinks.Field(\n            description=\"The correct numerical answer\",\n        )\n\n    language_model = synalinks.LanguageModel(\n        model=\"ollama_chat/deepseek-r1\",\n    )\n\n    program = synalinks.Sequential(\n        [\n            synalinks.Input(\n                data_model=Query,\n            ),\n            synalinks.Generator(\n                data_model=AnswerWithThinking,\n                language_model=language_model,\n            ),\n        ],\n        name=\"chain_of_thought\",\n        description=\"Useful to answer in a step by step manner.\",\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"#getting-a-summary-of-your-program","title":"Getting a summary of your program","text":"<p>To print a tabular summary of your program:</p> <pre><code>program.summary()\n</code></pre> <p>Or a plot (Useful to document your system):</p> <pre><code>synalinks.utils.plot_program(\n    program,\n    show_module_names=True,\n    show_trainable=True,\n    show_schemas=True,\n)\n</code></pre> <p></p>"},{"location":"#running-your-program","title":"Running your program","text":"<p>To run your program use the following:</p> <pre><code>result = await program(\n    Query(query=\"What is the French city of aerospace?\"),\n)\n</code></pre>"},{"location":"#training-your-program","title":"Training your program","text":"<pre><code>async def main():\n\n    # ... your program definition\n\n    (x_train, y_train), (x_test, y_test) = synalinks.datasets.gsm8k.load_data()\n\n    program.compile(\n        reward=synalinks.rewards.ExactMatch(in_mask=[\"answer\"]),\n        optimizer=synalinks.optimizers.RandomFewShot()\n    )\n\n    batch_size=32\n    epochs=10\n\n    history = await program.fit(\n        x_train,\n        y_train,\n        validation_data=(x_test, y_test),\n        batch_size=batch_size,\n        epochs=epochs,\n    )\n\n    synalinks.utils.plot_history(history)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"FAQ/","title":"FAQ","text":""},{"location":"FAQ/#general-questions","title":"General questions","text":"<ul> <li>What makes Synalinks revolutionary compared to DSPy?</li> <li>Why do you focus on in-context techniques?</li> <li>I already use structured output, why would I use Synalinks?</li> <li>Can Synalinks be used for non-LMs applications</li> <li>What are my options for saving programs?</li> <li>How to do hyperparameter tuning with Synalinks?</li> <li>Where is the Synalinks configuration file stored?</li> <li>How should I cite Synalinks?</li> <li>Do you provide help or support?</li> </ul>"},{"location":"FAQ/#training-related-questions","title":"Training related questions","text":"<ul> <li>What do \"sample\", \"batch\", and \"epoch\" mean?</li> <li>What's the difference between the <code>training</code> argument in <code>call()</code> and the <code>trainable</code> attribute?</li> <li>In <code>fit()</code>, how is the validation split computed?</li> <li>In <code>fit()</code>, is the data shuffled during training?</li> <li>What's the difference between Program methods <code>predict()</code> and <code>__call__()</code>?</li> </ul>"},{"location":"FAQ/#what-makes-synalinks-revolutionary-compared-to-dspy","title":"What makes Synalinks revolutionary compared to DSPy?","text":"<p>While DSPy wrestles with PyTorch complexity, Synalinks delivers the elegant simplicity of Keras with enterprise-grade power. We're the only framework featuring logical flows inspired by logical circuits and comprehensive Knowledge Graph support. Synalinks transforms AI workflow design into an intuitive, natural process that accelerates development cycles and reduces implementation complexity.</p>"},{"location":"FAQ/#why-do-you-focus-on-in-context-techniques","title":"Why do you focus on in-context techniques?","text":"<p>In the real-world, most problems that companies face, are not labelled in public datasets for ML engineers to train their networks against. Meaning that their is a big discrepency between the results annonced on public benchmarks and real-world problems. Making adoption difficult when companies face the reality and complexity of real-world.</p> <p>Training a whole Language Model (LM) from scratch is out of the reach of most companies, so adapting them to real-world tasks is essential.</p> <p>LMs have the capability to leverage their prompt to mimick the examples given, but it means that one have to update the examples each time you change the pipelines as you experiment. Making it cumberstone, but even with that, their is no guaranty that the examples you gave yield to the best results.</p> <p>To select the best examples and instructions to give to the LMs, it needs a complex system like Synalinks that automate the generation and selection.</p>"},{"location":"FAQ/#i-already-use-structured-output-why-would-i-use-synalinks","title":"I already use structured output, why would I use Synalinks?","text":"<p>While structured output ensure a correct format, ready to parse, it doesn't guaranty the content of the LMs answers. Synalinks use constrained structured output in conjunction with in-context techniques to ensure both format and content correctness.</p>"},{"location":"FAQ/#can-synalinks-be-used-for-non-lms-applications","title":"Can Synalinks be used for non-LMs applications?","text":"<p>While Synalinks provide everything to work with LMs, we emphasize that you can create modules (or entire pipelines) that don't use them. In fact, many neuro-symbolic systems use a conjunction of LMs modules with non-LMs modules. Synalinks backend can suit any algorithm that works with any kind of data-structure as long as they are formalized in JSON.</p>"},{"location":"FAQ/#what-are-my-options-for-saving-programs","title":"What are my options for saving programs?","text":"<p>1. Whole-program saving (configuration + variables)</p> <p>Whole program saving means creating a file that will contain:</p> <ul> <li>The architecture of the program, allowing you to re-create the program.</li> <li>The variables of the program</li> <li>The training configuration (reward, optimizer, metrics)</li> <li>The state of the optimizer, allowing you to resume the training exactly where you left off.</li> </ul> <p>The default and recommended way to save the whole program is to do:</p> <p><code>program.save(\"my_program.json\")</code></p> <p>After saving a program you can re-instanciate it via:</p> <p><code>program = synalinks.Program.load(\"my_program.json\")</code></p> <p>2. Variables-only saving</p> <p>If you need to save the variables of a program, you can it using:</p> <p><code>program.save_variables(\"my_program.variables.json\")</code></p> <p>You can then load the variables into a program with the same architecture:</p> <p><code>program.load_variables(\"my_program.variables.json\")</code></p> <p>Note: All programs and/or variables are saved in JSON format, we removed the pickle format for obvious security concerns.</p>"},{"location":"FAQ/#how-to-do-hyperparameter-tuning-with-synalinks","title":"How to do hyperparameter tuning with Synalinks?","text":"<p>As today, there is no way to perform automatic hyperparameter tuning with Synalinks, we might consider it in the future.</p>"},{"location":"FAQ/#where-is-the-synalinks-configuration-file-stored","title":"Where is the Synalinks configuration file stored?","text":"<p>The default directory where all Synalinks data is stored is:</p> <pre><code>$HOME/.synalinks/\n</code></pre> <p>Note that Windows users should replace <code>$HOME</code> with <code>%USERPROFILE%</code>.</p> <p>In case Synalinks cannot create the above directory (e.g. due to permission issues), <code>/tmp/.synalinks/</code> is used as a backup.</p> <p>The Synalinks configuration file is a JSON file stored at $HOME/.synalinks/synalinks.json. The default configuration file looks like this:</p> <pre><code>{\n    \"backend\": \"pydantic\",\n    \"floatx\": \"float32\",\n    \"epsilon\": 1e-07\n}\n</code></pre> <p>Likewise, cached dataset files, such as those downloaded with <code>get_file()</code>, are stored by default in <code>$HOME/.synalinks/datasets/</code>.</p>"},{"location":"FAQ/#how-should-i-cite-synalinks","title":"How should I cite Synalinks?","text":"<p>Please cite Synalinks if it is useful in your research. Here is the bibtex entry to use:</p> <pre><code>@misc{sallami2025synalinks,\n  title={Synalinks},\n  author={Sallami, Yoan and Chollet, Fran\\c{c}ois},\n  year={2025},\n  howpublished={\\url{https://github.com/SynaLinks/Synalinks}},\n}\n</code></pre>"},{"location":"FAQ/#do-you-provide-help-or-support","title":"Do you provide help or support?","text":"<p>We provide consulting, development and technical support for companies that want to implement any neuro-symbolic systems. Using a framework is one thing, having a complete view of possible neuro-symbolic applications and the knowledge to create such complex systems is another. If you can't afford our services, you can find help in our public Discord channel.</p>"},{"location":"FAQ/#what-do-sample-batch-and-epoch-mean","title":"What do \"sample\", \"batch\", and \"epoch\" mean?","text":"<ul> <li>Sample: A sample is one element of a dataset. For example, one DataModel is one sample.</li> <li>Batch: A batch is a set of N samples. The samples in a batch are processed independently, in parallel. During training, a batch result in only one program update. A batch approximates the input distribution better than a single input. The larger the batch, the better the approximation; however a larger batch will take longer to process and still result in only one update.</li> <li>Epochs: A epochs is an arbitrarly cutoff, generally defined as \"one pass over the entire dataset\", used to separate training into distinct phases, which is useful for logging and periodic evaluation. When using <code>validation_split</code> or <code>validation_data</code> with the <code>fit</code> method of Synalinks programs, evaluation will be run at the end of every epoch.</li> </ul>"},{"location":"FAQ/#whats-the-difference-between-the-training-argument-in-call-and-the-trainable-attribute","title":"What's the difference between the <code>training</code> argument in <code>call()</code> and the <code>trainable</code> attribute?","text":"<p><code>training</code> is a boolean argument in <code>call</code> that determines whether the call should be run in inference mode or training mode. For example, in training mode, a <code>Generator</code> module save each LM prediction for later backpropagation. In inference mode, the <code>Generator</code> doesn't save the predictions.</p> <p><code>trainable</code> is a boolean module attribute that determines the trainable variables of the module should be updated to maximize the reward during training. If <code>module.trainable</code> is set to False, then <code>module.trainable_variables</code> will always be an empty list. </p> <p>Example:</p> <pre><code>import synalinks\nimport asyncio\n\nasync def main():\n    class ThinkingWithAnswer(synalinks.DataModel):\n        thinking: str\n        answer: str\n\n    language_model = synalinks.LanguageModel(\n        \"ollama_chat/deepseek-r1\",\n    )\n\n    program = synalinks.Sequential(\n        [\n            synalinks.Generator(\n                data_model=ThinkingWithAnswer,\n                language_model=language_model,\n            ),\n            synalinks.Generator(\n                data_model=ThinkingWithAnswer,\n                language_model=language_model,\n            ),\n        ]\n    )\n\n    program.modules[0].trainable = False # Freeze the first generator\n\n    assert program.modules[0].trainable_variables == []\n\n    program.compile(...)\n    history = await program.fit(...) # Train only the second generator\n\nif __main__ == \"__name__\":\n    asyncio.run(main())\n</code></pre> <p>In essence, \"inference mode vs training mode\" and \"module variable trainability\" are two very different concepts.</p>"},{"location":"FAQ/#in-fit-how-is-the-validation-split-computed","title":"In <code>fit()</code>, how is the validation split computed?","text":"<p>If you set the <code>validation_split</code> argument in <code>program.fit</code> to e.g. 0.1, then the validation data used will be the last 10% of the data. If you set it to 0.25, it will be the last 25% of the data, etc. Note that the data isn't shuffled before extracting the validation split, so the validation is literally just the last x% of samples in the input you passed.</p> <p>The same validation set is used for all epochs (within the same call to fit).</p> <p>Note that the validation_split option is only available if your data is passed as Numpy arrays.</p>"},{"location":"FAQ/#in-fit-is-the-data-shuffled-during-training","title":"In <code>fit()</code>, is the data shuffled during training?","text":"<p>If you pass your data as NumPy arrays and if the <code>shuffle</code> argument in <code>program.fit()</code> is set to True (which is the default), the training data will be globally randomly shuffled at each epoch.</p> <p>Validation data is never shuffled.</p>"},{"location":"FAQ/#whats-the-difference-between-program-methods-predict-and-__call__","title":"What's the difference between <code>Program</code> methods <code>predict()</code> and <code>__call__()</code>?","text":"<p><code>predict()</code> loops over the data in batches (you can specify the batch size via <code>predict(x, batch_size=64)</code>) and returns a Numpy array of predictions.</p> <p>While <code>program(x)</code> perform a single prediction, and is used to create APIs that process a single user request at a time.</p> <p>This means that <code>predict()</code> calls can perform prediction on a dataset. While <code>program(x)</code> perform a single prediction.</p>"},{"location":"Introduction/","title":"Introduction","text":""},{"location":"Introduction/#what-is-synalinks","title":"What is Synalinks?","text":"<p>Synalinks is an open-source framework that makes it easy to create, evaluate, train, and deploy industry-standard Language Models (LMs) applications. Synalinks follows the principle of progressive disclosure of complexity: meaning that simple workflows should be quick and easy, while arbitrarily advanced ones should be possible via a clear path that builds upon what you've already learned.</p> <p>Synalinks is an adaptation of Keras 3 focused on neuro-symbolic systems and in-context reinforcement learning, an ensemble of techniques that enhance the LMs predictions and accuracy without changing the weights of the model. The goal of Synalinks is to facilitate the rapid setup of simple applications while providing the flexibility for researchers and advanced users to develop sophisticated systems.</p>"},{"location":"Introduction/#who-is-synalinks-for","title":"Who is Synalinks for?","text":"<p>Synalinks is designed for a diverse range of users, from professionals and AI researchers to students, independent developers, and hobbyists. It is suitable for anyone who wants to learn about AI by building/composing blocks or build solid foundations for enterprise-grade products. While a background in Machine Learning and Deep Learning can be advantageous \u2014 as Synalinks leverages design patterns from Keras, one of the most user-friendly and popular Deep Learning frameworks \u2014 it is not a prerequisite. Synalinks is designed to be accessible to anyone with programming skills in Python, making it a versatile and inclusive platform for AI development.</p>"},{"location":"Introduction/#why-use-synalinks","title":"Why use Synalinks?","text":"<p>Developping a successful LM application in a profesional context, beyond stateless chatbots, is difficult and typically include:</p> <ul> <li>Building optimized prompts with examples/instructions at each step: Synalinks uses advanced In-Context Reinforcement Learning techniques to optimize each prompt.</li> <li>Pipelines that change over time: Easily edit your pipelines, re-run your training, and you're good to go.</li> <li>Ensuring the correctness of the LMs output: Synalinks combines constrained structured output with In-Context RL to ensure both format and content correctness.</li> <li>Async Optimization: Synalinks automatically optimizes your pipelines by detecting parallel processes.</li> <li>Assessing the performance of your application: Synalinks provides built-in metrics and rewards to evaluate your workflows.</li> <li>Configuring Language &amp; Embedding Models: Seamlessly integrate multiple LM providers like Ollama, OpenAI, Anthropic, Mistral or Groq.</li> <li>Documenting your ML workflows: Plot your workflows, training history, and evaluations; document everything.</li> <li>Versioning the prompts/pipelines: Each program is serializable into JSON so you can version it with git.</li> <li>Deploying REST APIs: Compatible out-of-the-box with FastAPI so your Data Scientists and Web Developers can stop tearing each other apart.</li> </ul> <p>Synalinks can help you simplify these tasks by leveraging decade old practices in Deep Learning frameworks. We provide a comprehensive suite of tools and features designed to streamline the development process, making it easier to create, evaluate, train, document and deploy robust neuro-symbolic LMs applications.</p>"},{"location":"Code%20Examples/Advanced/First%20Knowledge%20Graph%20Schema/","title":"First Knowledge Graph Schema","text":"<p>A knowledge graph schema is like a blueprint that defines the structure and rules for organizing information in a graph format. Just as a database schema defines tables and their relationships, a knowledge graph schema defines entities (nodes) and relations (edges) that can exist in your graph. This tutorial will teach you how to analyze information domains and translate them into structured schema definitions using the synalinks framework.</p>"},{"location":"Code%20Examples/Advanced/First%20Knowledge%20Graph%20Schema/#entities","title":"Entities","text":"<p>Entities represent the \"things\" in your domain - people, places, objects, concepts, or events.</p> <p>Each entity type has:</p> <ul> <li>A <code>label</code>: A unique identifier that distinguishes this entity type from all others?</li> <li>Properties: Attributes that capture the entity's characteristics.</li> <li>Descriptions: Clear, specific descriptions that guide the LMs for accurate data extraction and understanding.</li> </ul> <p>When designing entities, consider both current needs and future extensibility. Properties should be atomic (single-valued) when possible, but flexible enough to accommodate variations in your data.</p> <p>Example:</p> <pre><code>import synalinks\nfrom typing import Literal, List, Union\n\nclass City(synalinks.Entity):\n    label: Literal[\"City\"]\n    name: str = synalinks.Field(\n        description=\"The name of a city, such as 'Paris' or 'New York'.\",\n    )\n\nclass Country(synalinks.Entity):\n    label: Literal[\"Country\"]\n    name: str = synalinks.Field(\n        description=\"The name of a country, such as 'France' or 'Canada'.\",\n    )\n\nclass Place(synalinks.Entity):\n    label: Literal[\"Place\"]\n    name: str = synalinks.Field(\n        description=\"The name of a specific place, which could be a landmark, building, or any point of interest, such as 'Eiffel Tower' or 'Statue of Liberty'.\",\n    )\n\nclass Event(synalinks.Entity):\n    label: Literal[\"Event\"]\n    name: str = synalinks.Field(\n        description=\"The name of an event, such as 'Summer Olympics 2024' or 'Woodstock 1969'.\",\n    )\n</code></pre>"},{"location":"Code%20Examples/Advanced/First%20Knowledge%20Graph%20Schema/#relations","title":"Relations","text":"<p>Relations are the connective tissue of your knowledge graph, representing how entities interact, depend on, or relate to each other. They transform isolated data points into a rich, interconnected web of knowledge.</p> <p>Each relations has:</p> <ul> <li>A subject (<code>subj</code>): The source entity of the relation.</li> <li>A label (<code>label</code>): The type of relationship.</li> <li>A target (<code>obj</code>): The target entity of the relation.</li> <li>Properties: Attributes that describe/enrich the relation.</li> <li>Descriptions: Clear explanations of what each property represents to help extraction.</li> </ul> <p>Example:</p> <pre><code>class IsCapitalOf(synalinks.Relation):\n    subj: City = synalinks.Field(\n        description=\"The city entity that serves as the capital.\",\n    )\n    label: Literal[\"IsCapitalOf\"]\n    obj: Country = synalinks.Field(\n        description=\"The country entity for which the city is the capital.\",\n    )\n\n\nclass IsCityOf(synalinks.Relation):\n    subj: City = synalinks.Field(\n        description=\"The city entity that is a constituent part of a country.\",\n    )\n    label: Literal[\"IsCityOf\"]\n    obj: Country = synalinks.Field(\n        description=\"The country entity that the city is part of.\",\n    )\n\n\nclass IsLocatedIn(synalinks.Relation):\n    subj: Union[Place] = synalinks.Field(\n        description=\"The place entity that is situated within a larger geographical area.\",\n    )\n    label: Literal[\"IsLocatedIn\"]\n    obj: Union[City, Country] = synalinks.Field(\n        description=\"The city or country entity where the place is geographically located.\",\n    )\n\n\nclass TookPlaceIn(synalinks.Relation):\n    subj: Event = synalinks.Field(\n        description=\"The event entity that occurred in a specific location.\",\n    )\n    label: Literal[\"TookPlaceIn\"]\n    obj: Union[City, Country] = synalinks.Field(\n        description=\"The city or country entity where the event occurred.\",\n    )\n</code></pre>"},{"location":"Code%20Examples/Advanced/First%20Knowledge%20Graph%20Schema/#schema-design-strategy-and-best-practices","title":"Schema Design Strategy and Best Practices","text":"<p>Start with Domain Analysis Before writing any code, invest time in understanding your domain thoroughly:</p> <ol> <li>Identify Core Concepts: List the most important \"things\" in your domain</li> <li>Map Natural Relationships: Observe how these concepts connect in real-world scenarios</li> <li>Consider Use Cases: Think about the questions your knowledge graph should answer</li> <li>Plan for Growth: Design schemas that can evolve with your understanding</li> </ol>"},{"location":"Code%20Examples/Advanced/First%20Knowledge%20Graph%20Schema/#balance-granularity-and-usability","title":"Balance Granularity and Usability","text":"<p>Finding the right level of detail is crucial:</p> <ul> <li>Too Generic: Loses important nuances and becomes less useful</li> <li>Too Specific: Creates maintenance overhead and reduces flexibility</li> <li>Just Right: Captures essential distinctions while remaining manageable</li> </ul>"},{"location":"Code%20Examples/Advanced/First%20Knowledge%20Graph%20Schema/#implement-iterative-refinement","title":"Implement Iterative Refinement","text":"<p>Schema development is rarely a one-shot process, always:</p> <ul> <li>Start Simple: Begin with basic entities and core relationships</li> <li>Test with Real Data: Validate your schema against actual use cases</li> <li>Identify Gaps: Notice what your current schema cannot represent</li> <li>Refine Gradually: Add complexity only when justified by real needs</li> <li>Document Decisions: Keep track of why you made specific design choices</li> </ul>"},{"location":"Code%20Examples/Advanced/First%20Knowledge%20Graph%20Schema/#conclusion","title":"Conclusion","text":"<p>Creating effective knowledge graph schemas is both an art and a science. Success comes from understanding your domain deeply, designing with use-case in mind, and remaining flexible as requirements evolve. Your schema serves as the foundation for all downstream applications\u2014from search and recommendation systems to complex analytics and AI applications.</p> <p>With these foundations in place, your knowledge graph schema will serve as a robust platform for organizing, connecting, and leveraging information in powerful new ways.</p>"},{"location":"Code%20Examples/Advanced/First%20Knowledge%20Graph%20Schema/#key-takeaways","title":"Key Takeaways","text":"<ul> <li> <p>Knowledge Graph Schema Basics: A knowledge graph schema defines the structure and rules for organizing information in a graph format, consisting of entities (nodes) and relations (edges).</p> </li> <li> <p>Entities: Represent \"things\" in your domain such as people, places, objects, concepts, or events. Each entity type has a unique <code>label</code>, properties, and descriptions. Properties should be atomic and flexible to accommodate variations in data.</p> </li> <li> <p>Relations: Represent how entities interact or relate to each other. Each relation has a subject (<code>subj</code>), a label (<code>label</code>), a target (<code>obj</code>), properties, and descriptions.</p> </li> <li> <p>Schema Design Strategy: Start with a thorough domain analysis to identify core concepts and map natural relationships. Consider use cases and plan for future growth.</p> </li> <li> <p>Balance Granularity and Usability: Avoid being too generic or too specific; aim for a balance that captures essential distinctions while remaining manageable.</p> </li> <li> <p>Iterative Refinement: Begin with simple entities and core relationships. Test with real data, identify gaps, and refine gradually. Document design decisions for future reference.</p> </li> </ul>"},{"location":"Code%20Examples/Advanced/Implementing%20Custom%20Modules%20And%20Programs%20Via%20Subclassing/","title":"Implementing custom modules &amp; programs via subclassing","text":"<p>This tutorial, is for more advanced users, it will cover how to  create custom modules/programs via subclassing.</p> <p>In this tutorial, we will cover the following themes:</p> <ul> <li>The <code>Module</code> class</li> <li>The <code>add_variable()</code> method</li> <li>Trainable and non-trainable variables</li> <li>The <code>compute_output_spec()</code> and <code>build()</code> method</li> <li>The training argument in <code>call()</code></li> <li>Making sure your module/program can be serialized</li> </ul> <p>One of the main abstraction of Synalinks is the <code>Module</code> class. A <code>Module</code> encapsulate both a state (the module's variables) and  a transformation from inputs to outputs (the <code>call()</code> method).</p> <p>For this tutorial, we are going to make a simple neuro-symbolic component called <code>BacktrackingOfThought</code>. This component is an adaptation of the  famous backtracking algorithm, used a lot in symbolic planning/reasoning,  combined with chain of thought, nowadays most used technique to enhance the LMs predicitons. </p> <p>The principle is straitforward, the component will have to \"think\" then  we will critique at runtime the thinking and aggregate it to  the current chain of thinking only if it is above the given threshold.  This mechanism will allow the system to discard bad thinking to resume  at the previsous step. Additionally we will add a stop condition.</p> <p>This algorithm a simplified version of the popular <code>TreeOfThought</code> that instead of being a tree strucutre, is only a sequential chain of thinking.</p> <pre><code>import synalinks\nimport asyncio\n\nclass Query(synalinks.DataModel):\n    query: str = synalinks.Field(\n        description=\"The user query\",\n    )\n\nclass Answer(synalinks.DataModel):\n    answer: str = synalinks.Field(\n        description=\"The correct answer\",\n    )\n\nlanguage_model = synalinks.LanguageModel(\n    model=\"ollama/mistral\",\n)\n\nclass BacktrackingOfThought(synalinks.Module):\n    def __init__(\n        self,\n        schema=None,\n        data_model=None,\n        language_model=None,\n        backtracking_threshold=0.5,\n        stop_threshold=0.9,\n        max_iterations=5,\n        return_inputs=False,\n        prompt_template=None,\n        examples=None,\n        instructions=None,\n        use_inputs_schema=False,\n        use_outputs_schema=False,\n        name=None,\n        description=None,\n        trainable=True,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n            trainable=trainable,\n        )\n        if not schema and data_model:\n            schema = data_model.get_schema()\n        self.schema = schema\n        self.language_model = language_model\n        self.backtracking_threshold = backtracking_threshold\n        self.stop_threshold = stop_threshold\n        self.max_iterations = max_iterations\n        self.return_inputs = return_inputs\n        self.prompt_template = prompt_template\n        self.examples = examples\n        self.instructions = instructions\n        self.use_inputs_schema = use_inputs_schema\n        self.use_outputs_schema = use_outputs_schema\n\n        self.thinking = []\n        for i in range(self.max_iterations):\n            self.thinking.append(\n                synalinks.ChainOfThought(\n                    schema=self.schema,\n                    language_model=self.language_model,\n                    prompt_template=self.prompt_template,\n                    examples=self.examples,\n                    return_inputs=False,\n                    instructions=self.instructions,\n                    use_inputs_schema=self.use_inputs_schema,\n                    use_outputs_schema=self.use_outputs_schema,\n                    name=self.name + f\"_thinking_generator_{i}\",\n                )\n            )\n        self.critique = []\n        for i in range(self.max_iterations):\n            self.critique.append(\n                synalinks.SelfCritique(\n                language_model=self.language_model,\n                prompt_template=self.prompt_template,\n                examples=self.examples,\n                return_inputs=True,\n                instructions=self.instructions,\n                use_inputs_schema=self.use_inputs_schema,\n                use_outputs_schema=self.use_outputs_schema,\n                name=self.name + f\"_critique_generator_{i}\",\n            )\n        )\n        # This is going to be the final generator\n        self.generator = synalinks.Generator(\n            schema=self.schema,\n            language_model=self.language_model,\n            prompt_template=self.prompt_template,\n            examples=self.examples,\n            return_inputs=self.return_inputs,\n            instructions=self.instructions,\n            use_inputs_schema=self.use_inputs_schema,\n            use_outputs_schema=self.use_outputs_schema,\n            name=self.name + \"_generator\",\n        )\n\n    async def call(self, inputs, training=False):\n        if not inputs:\n            # This is to allow logical flows\n            # (e.g. don't run the module if no inputs provided)\n            return None\n        for i in range(self.max_iterations):\n            thinking = await self.thinking[i](\n                inputs,\n                training=training,\n            )\n            critique = await self.critique[i](\n                thinking,\n                training=training,\n            )\n            reward = critique.get(\"reward\")\n            if reward &gt; self.backtracking_threshold:\n                inputs = await synalinks.ops.concat(\n                    inputs,\n                    critique,\n                    name=self.name + f\"_inputs_with_thinking_{i}\",\n                )\n                if reward &gt; self.stop_threshold:\n                    break\n        return await self.generator(\n            inputs,\n            training=training,\n        )\n\n    async def compute_output_spec(self, inputs, training=False):\n        for i in range(self.max_iterations):\n            inputs = await self.thinking[i](inputs)\n            inputs = await self.critique[i](inputs)\n        return await self.generator(inputs)\n\n    def get_config(self):\n        config = {\n            \"schema\": self.schema,\n            \"backtracking_threshold\": self.backtracking_threshold,\n            \"stop_threshold\": self.stop_threshold,\n            \"max_iterations\": self.max_iterations,\n            \"return_inputs\": self.return_inputs,\n            \"prompt_template\": self.prompt_template,\n            \"examples\": self.examples,\n            \"instructions\": self.instructions,\n            \"use_inputs_schema\": self.use_inputs_schema,\n            \"use_outputs_schema\": self.use_outputs_schema,\n            \"name\": self.name,\n            \"description\": self.description,\n            \"trainable\": self.trainable,\n        }\n        language_model_config = {\n            \"language_model\": synalinks.saving.serialize_synalinks_object(\n                self.language_model,\n            )\n        }\n        return {**language_model_config, **config}\n\n    @classmethod\n    def from_config(cls, config):\n        language_model = synalinks.saving.deserialize_synalinks_object(\n            config.pop(\"language_model\")\n        )\n        return cls(\n            language_model=language_model,\n            **config,\n        )\n\nasync def main():\n\n    inputs = synalinks.Input(data_model=Query)\n    outputs = await BacktrackingOfThought(\n        language_model=language_model,\n        data_model=Answer,\n        return_inputs=True,\n    )(inputs)\n\n    program = synalinks.Program(\n        inputs=inputs,\n        outputs=outputs,\n        name=\"backtracking_of_thought\",\n        description=\"A Backtracking of Thought algorithm\",\n    )\n\n    synalinks.utils.plot_program(\n        program,\n        to_folder=\"examples/implementing_custom_modules_and_programs_via_subclassing\",\n        show_module_names=True,\n        show_trainable=True,\n        show_schemas=True,\n    )\n\n    result = await program(\n        Query(query=(\n              \"How can we develop a scalable, fault-tolerant, and secure quantum\"\n              \" computing system that can solve problems intractable for classical\"\n              \" computers, and what are the practical implications for cryptography\"\n              \" and data security?\"\n            )\n        )\n    )\n\n    print(result.prettify_json())\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p></p>"},{"location":"Code%20Examples/Advanced/Implementing%20Custom%20Modules%20And%20Programs%20Via%20Subclassing/#result","title":"Result","text":"<pre><code>{\n  \"query\": \"How can we develop a scalable, fault-tolerant, and secure quantum computing system that can solve problems intractable for classical computers, and what are the practical implications for cryptography and data security?\",\n  \"thinking\": \"Thinking...\",\n  \"answer\": \"Developing a scalable, fault-tolerant, and secure quantum computing system is a significant challenge due to the unique properties of quantum mechanics. Here's a simplified approach: First, you would need to establish a robust quantum hardware platform such as qubits (quantum bits) made of superconducting circuits or trapped ions. Next, develop error-correcting codes to mitigate errors that naturally occur in quantum systems. Additionally, implement quantum algorithms suitable for the problem at hand, such as Shor's algorithm for factoring large numbers, which is resistant to classical computers but can be solved quickly on a quantum computer. The practical implications for cryptography and data security are profound. Quantum computing could potentially break many of today's encryption methods based on number factorization (e.g., RSA). Therefore, it's essential to develop post-quantum cryptographic algorithms that are resilient against attacks from both classical and quantum computers.\",\n  \"critique\": \"Your response is detailed, informative, and well-structured. It explains the challenges involved in developing a quantum computing system, provides a simplified approach to solving these challenges, and highlights the potential implications for cryptography and data security. The use of examples such as Shor's algorithm and RSA encryption method adds credibility to your response. However, it might be helpful to break down the process into smaller steps or bullet points for easier comprehension.\",\n  \"reward\": 1.0,\n  \"answer_1\": \"Developing a scalable, fault-tolerant, and secure quantum computing system is indeed a complex task due to the intricacies of quantum mechanics. Here's a simplified roadmap: \\n1. Establishing a robust quantum hardware platform using qubits made from superconducting circuits or trapped ions.\\n2. Developing error-correcting codes to combat errors inherent in quantum systems.\\n3. Implementing suitable quantum algorithms, like Shor's algorithm for factoring large numbers, which are resistant to classical computers but can be solved quickly on a quantum computer.\\nRegarding cryptography and data security, the implications are substantial. Quantum computing could potentially breach many existing encryption methods based on number factorization (such as RSA). Consequently, it's crucial to develop post-quantum cryptographic algorithms that can withstand attacks from both classical and quantum computers.\"\n}\n</code></pre>"},{"location":"Code%20Examples/Advanced/Implementing%20Custom%20Modules%20And%20Programs%20Via%20Subclassing/#the-__init__-function","title":"The <code>__init__()</code> function","text":"<p>First, let's explain the <code>__init__()</code> function. When implementing modules that use a <code>Generator</code>, you want to externalize the generator's parameters  (<code>prompt_template</code>, <code>instructions</code>, <code>examples</code>, <code>use_inputs_schema</code>, <code>use_outputs_schema</code>) to give maximum flexibility to your module when possible. Then, you have to include the default arguments of a module (<code>name</code>, <code>description</code>, <code>trainable</code>) that will be provided to the <code>super().__init__()</code>.  Although the name and description are inferred automatically it is a good practice to let the user personalize them. The <code>trainable</code> argument, will indicate if the module  is frozen or not, meaning that their variables could be updated by the optimizer,  by default, a module should be trainable. </p> <p>And finally, you can add any relevant information, weither for the initialization of  the variables, or a config parameter like here.</p> <p>To add a variable to the module, you have to use the <code>add_variables</code> function, this function can only be used in the <code>__init__()</code> or in the <code>build()</code> function. The build function is useful to create variables, or initialize your module/program  based on the actual inputs, that is not known at this stage, remember the module can accept any inputs.</p>"},{"location":"Code%20Examples/Advanced/Implementing%20Custom%20Modules%20And%20Programs%20Via%20Subclassing/#how-to-know-when-using-a-variable","title":"How to know when using a <code>Variable</code>?","text":"<p>As a rule of thumb, the variables should be anything that evolve over time during inference/training. These variables could be updated by the module itself, or by  the optimizer if you have an optimizer designed for that. They will be serialized when you save your program so you can recover the state of your program by loading a JSON file. In this example, the variables are encapsulated in the <code>Generator</code> module.</p>"},{"location":"Code%20Examples/Advanced/Implementing%20Custom%20Modules%20And%20Programs%20Via%20Subclassing/#the-call-function","title":"The <code>call()</code> function","text":"<p>The <code>call()</code> function is the core of the <code>Module</code> class. It defines the computation  performed at every call of the module. This function takes <code>inputs</code> and an optional <code>training</code> argument, which indicates whether the module is in training mode or not.</p> <p>In the <code>BacktrackingOfThought</code> module, the <code>call()</code> function implements the  backtracking logic:</p> <ul> <li>It iterates up to <code>max_iterations</code> times.</li> <li>In each iteration, it generates a \"thinking\" step using the <code>thinking</code> generator.</li> <li>It then critiques the generated thinking using either a provided critique program or      a reward value embedded in the thinking step.</li> <li>If the reward exceeds the <code>backtracking_threshold</code>, the thinking step is concatenated      with the inputs for the next iteration.</li> <li>If the reward exceeds the <code>stop_threshold</code>, the iteration stops early.</li> <li>Finally, the <code>generator</code> produces the final output based on the accumulated inputs.</li> </ul>"},{"location":"Code%20Examples/Advanced/Implementing%20Custom%20Modules%20And%20Programs%20Via%20Subclassing/#the-compute_output_spec-function","title":"The <code>compute_output_spec()</code> function","text":"<p>The <code>compute_output_spec()</code> function is responsible for defining the output data model of the module/program. It allows the system to understand the structure of the data produced by this module. Its inputs is always a <code>SymbolicDataModel</code>, a placeholder that only contains a JSON schema that serve as data specification.</p> <p>In this example, <code>compute_output_spec()</code> returns a <code>SymbolicDataModel</code> based on the module's  schema by calling the modules sequentially, indicating the expected structure of the output data.</p> <p>As a rule of thumb, if you access a data model field in your call (using <code>get()</code>) you will have to  implement it otherwise, Synalinks will infer the output spec by running the call  function with symbolic data models. If you have any doubt, do not implement it and the system will raise an error if you needs to.</p>"},{"location":"Code%20Examples/Advanced/Implementing%20Custom%20Modules%20And%20Programs%20Via%20Subclassing/#serialization-and-deserialization","title":"Serialization and Deserialization","text":"<p>To ensure that your module can be saved and loaded correctly, you need to implement serialization and deserialization methods. This is crucial for saving the state of your module, including  any trainable variables, and restoring it later.</p> <ul> <li>The <code>get_config()</code> method should return a dictionary containing all the information needed      to recreate the module. This includes the module's configuration and any serialized      sub-components like the language model in this case.</li> <li>The <code>from_config()</code> class method should be able to reconstruct the module from the      configuration dictionary returned by <code>get_config()</code>.</li> </ul>"},{"location":"Code%20Examples/Advanced/Implementing%20Custom%20Modules%20And%20Programs%20Via%20Subclassing/#conclusion","title":"Conclusion","text":"<p>By following these guidelines, you can create custom modules in Synalinks that are flexible,  reusable, and can be integrated into larger programs. The <code>BacktrackingOfThought</code> module  demonstrates how to combine symbolic reasoning with language model predictions to enhance  the decision-making process.</p>"},{"location":"Code%20Examples/Advanced/Implementing%20Custom%20Modules%20And%20Programs%20Via%20Subclassing/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>Module Class: The <code>Module</code> class in Synalinks encapsulates both state (variables)      and transformation logic (<code>call()</code> method), serving as a foundational abstraction for      building custom components.</li> <li>Initialization and Variables: The init() function initializes the module,      externalizing generator parameters for flexibility. Trainable and non-trainable      variables are managed using the add_variables function, ensuring that the      module's state can evolve over time and be serialized.</li> <li>Call Function: The <code>call()</code> function defines the core computation of the module,     handling inputs and producing outputs. In <code>BacktrackingOfThought</code>, it implements      backtracking logic, iteratively generating and critiquing thinking steps to refine     the output.</li> <li>Output Specification: The <code>compute_output_spec()</code> function defines the output data     model, allowing the system to understand the structure of the produced data.     Implementing this function is crucial when accessing data model fields directly.</li> <li>Serialization: Proper serialization and deserialization methods (<code>get_config()</code>      and <code>from_config()</code>) ensure that the module's state can be saved and restored,      facilitating reuse and integration into larger programs.</li> <li>Flexibility and Reusability:  By following these guidelines, you can create      custom modules that are flexible, reusable, and easily integrated into neuro-symbolic      programs. The <code>BacktrackingOfThought</code> module exemplifies how to combine symbolic      reasoning with language models to improve decision-making processes.</li> </ul>"},{"location":"Code%20Examples/Advanced/Knowledge%20Extraction/","title":"Knowledge Extraction","text":"<p>Knowledge extraction from unstructured data is a cornerstone of neuro-symbolic AI applications, enabling systems to transform raw text into structured, logically queryable information. Synalinks provides a sophisticated framework that supports constrained property graph extraction and querying, offering unprecedented flexibility in how you architect your knowledge extraction pipelines.</p> <p>Synalinks leverages constrained property graphs as its foundation, where the schema is rigorously enforced through constrained JSON decoding. This approach ensures data integrity while maintaining the flexibility to store extracted knowledge in dedicated graph databases for efficient querying and retrieval. The framework's modular design allows you to compose extraction pipelines from discrete, reusable components. Each component can be optimized independently, tested in isolation, and combined with others to create sophisticated data processing workflows.</p> <pre><code>import synalinks\nimport asyncio\nfrom typing import Literal\nfrom typing import List\nfrom typing import Union\n\n# We start by defining our input data, in that case a simple Document\n\nclass Document(synalinks.DataModel):\n    filename: str\n    content: str\n</code></pre> <p>For the graph schema, we are going to use the same as presented in the previous lesson.</p>"},{"location":"Code%20Examples/Advanced/Knowledge%20Extraction/#modular-architecture-with-granular-control","title":"Modular Architecture with Granular Control","text":"<p>The true strength of Synalinks emerges from its modular approach to pipeline composition. This foundation allows you to modularize the granularity of your data pipelines and recombine them with precision, adapting to the varying computational requirements of different extraction tasks.</p> <p>In production environments, data models often exhibit vastly different inference complexities. Some entities require sophisticated reasoning and substantial computational resources to extract accurately, while others can be identified through lightweight pattern matching. A rigid, one-size-fits-all approach typically leads to suboptimal resource utilization and compromised accuracy.</p> <p>Synalinks addresses this challenge by enabling you to decompose complex extraction tasks into specialized stages, each optimized for its specific requirements. This granular control allows you to allocate computational resources where they're most needed while maintaining overall pipeline efficiency.</p>"},{"location":"Code%20Examples/Advanced/Knowledge%20Extraction/#one-stage-extraction","title":"One-Stage Extraction","text":"<p>For scenarios where you have access to powerful language models capable of handling complex, multi-faceted extraction tasks, the one-stage approach offers simplicity and directness. This method excels when working with large proprietary models that possess the capacity to simultaneously identify entities, infer relationships, and maintain semantic coherence across the entire knowledge graph.</p> <pre><code># We group the entities and relations in a knowledge graph\n\nclass Knowledge(synalinks.KnowledgeGraph):\n    entities: List[Union[City, Country, Place, Event]]\n    relations: List[Union[IsCapitalOf, IsLocatedIn, IsCityOf, TookPlaceIn]]\n\n\nasync def one_stage_program(\n    language_model: synalinks.LanguageModel,\n    knowledge_base: synalinks.KnowledgeBase,\n):\n    inputs = synalinks.Input(data_model=Document)\n    knowledge_graph = await synalinks.Generator(\n        data_model=Knowledge,\n        language_model=language_model,\n    )(inputs)\n    embedded_knowledge_graph = await synalinks.Embedding(\n        embedding_model=embedding_model,\n    )(knowledge_graph)\n\n    program = synalinks.Program(\n        inputs=inputs,\n        outputs=outputs,\n        name=\"two_stage_extraction\",\n        description=\"A two stage KG extraction pipeline\",\n    )\n\n    synalinks.utils.plot_program(\n        program,\n        to_folder=\"examples/knowledge_extraction\",\n        show_trainable=True,\n    )\n\n    return program\n</code></pre> <p></p> <p>The one-stage approach minimizes latency and reduces the complexity of pipeline orchestration. However, it demands models with substantial reasoning capabilities and may not be effective for scenarios involving smaller, specialized models.</p>"},{"location":"Code%20Examples/Advanced/Knowledge%20Extraction/#two-stage-extraction","title":"Two-Stage Extraction","text":"<p>The two-stage approach represents a strategic decomposition of the extraction process, separating entity identification from relationship inference. This separation allows for specialized optimization at each stage and provides greater control.</p> <pre><code>class MapEntities(synalinks.Entities):\n    entities: List[Union[City, Country, Place, Event]]\n\nclass MapRelations(synalinks.Relations):\n    relations: List[Union[IsCapitalOf, IsLocatedIn, IsCityOf, TookPlaceIn]]\n\n\nasync def two_stage_program(\n    language_model: synalinks.LanguageModel,\n    knowledge_base: synalinks.KnowledgeBase,\n):\n    inputs = synalinks.Input(data_model=Document)\n    entities = await synalinks.Generator(\n        data_model=MapEntities,\n        language_model=language_model,\n    )(inputs)\n\n    # inputs_with_entities = inputs AND entities (See Control Flow tutorial)\n    inputs_with_entities = inputs &amp; entities \n    relations = await synalinks.Generator(\n        data_model=MapRelations,\n        language_model=language_model,\n    )(inputs_with_entities)\n\n    # knowledge_graph = inputs AND entities (See Control Flow tutorial)\n    knowledge_graph = entities &amp; relations\n\n    embedded_knowledge_graph = await synalinks.Embedding(\n        embedding_model=embedding_model,\n    )(knowledge_graph)\n\n    updated_knowledge_graph = await synalinks.UpdateKnowledge(\n        knowledge_base=knowledge_base,\n    )(embedded_knowledge_graph)\n\n    outputs = updated_knowledge_graph\n\n    program = synalinks.Program(\n        inputs=inputs,\n        outputs=outputs,\n        name=\"two_stage_extraction\",\n        description=\"A two stage KG extraction pipeline\",\n    )\n\n    synalinks.utils.plot_program(\n        program,\n        to_folder=\"examples/knowledge_extraction\",\n        show_trainable=True,\n    )\n\n    return program\n</code></pre> <p></p> <p>This staged approach offers several advantages: entities can be extracted using lightweight models optimized for named entity recognition, while relationship inference can leverage more sophisticated reasoning models.</p>"},{"location":"Code%20Examples/Advanced/Knowledge%20Extraction/#multi-stage-extraction","title":"Multi-Stage Extraction","text":"<p>If you have heterogeneous data models, or if you are using small language models (SLMs), you might want to consider using a separate generator for each entity or relation to extract. This approach enhances the predictions of LMs by making one call per entity or relation type, thereby reducing the scope of the task for each call and enhancing accuracy. You can then combine the results of your extraction using logical operators (<code>And</code> or <code>Or</code>), depending on whether you want your aggregation to be robust to failures from the LMs.</p> <pre><code>import synalinks\nimport asyncio\nfrom typing import List\n\nfrom knowledge_graph_schema import City, Country, Place, Event\nfrom knowledge_graph_schema import IsCapitalOf, IsLocatedIn, IsCityOf, TookPlaceIn\nfrom knowledge_dataset import Document, load_data\n\n\nclass Cities(synalinks.Entities):\n    entities: List[City] = synalinks.Field(\n        description=\"A list exclusively containing city entities, such as 'Tokyo' or 'London'.\",\n    )\n\n\nclass Countries(synalinks.Entities):\n    entities: List[Country] = synalinks.Field(\n        description=\"A list exclusively containing country entities, such as 'Japan' or 'United Kingdom'.\",\n    )\n\n\nclass Places(synalinks.Entities):\n    entities: List[Place] = synalinks.Field(\n        description=\"A list exclusively containing place entities, which could be landmarks or points of interest, such as 'Mount Fuji' or 'Big Ben'.\",\n    )\n\n\nclass Events(synalinks.Entities):\n    entities: List[Event] = synalinks.Field(\n        description=\"A list exclusively containing event entities, such as 'Olympic Games' or 'Coachella Festival'.\",\n    )\n\n\nclass IsCapitalOfRelations(synalinks.Relations):\n    relations: List[IsCapitalOf] = synalinks.Field(\n        description=\"A list of relations specifically describing capital-city relationships between city and country entities.\",\n    )\n\n\nclass IsCityOfRelations(synalinks.Relations):\n    relations: List[IsCityOf] = synalinks.Field(\n        description=\"A list of relations specifically describing the association of cities as part of countries.\",\n    )\n\n\nclass IsLocatedInRelations(synalinks.Relations):\n    relations: List[IsLocatedIn] = synalinks.Field(\n        description=\"A list of relations specifically describing the geographical containment of places within cities or countries.\",\n    )\n\n\nclass TookPlaceInRelations(synalinks.Relations):\n    relations: List[TookPlaceIn] = synalinks.Field(\n        description=\"A list of relations specifically describing the occurrence of events within cities or countries.\",\n    )\n\n\nasync def main():\n    language_model = synalinks.LanguageModel(\n        model=\"ollama/mistral\",\n    )\n\n    embedding_model = synalinks.EmbeddingModel(\n        model=\"ollama/mxbai-embed-large\",\n    )\n\n    knowledge_base = synalinks.KnowledgeBase(\n        index_name=\"neo4j://localhost:7687\",\n        entity_models=[City, Country, Place, Event],\n        relation_models=[IsCapitalOf, IsLocatedIn, IsCityOf, TookPlaceIn],\n        embedding_model=embedding_model,\n        metric=\"cosine\",\n        wipe_on_start=True,\n    )\n\n    inputs = synalinks.Input(data_model=Document)\n    cities = await synalinks.Generator(\n        data_model=Cities,\n        language_model=language_model,\n    )(inputs)\n    countries = await synalinks.Generator(\n        data_model=Countries,\n        language_model=language_model,\n    )(inputs)\n    places = await synalinks.Generator(\n        data_model=Places,\n        language_model=language_model,\n    )(inputs)\n    events = await synalinks.Generator(\n        data_model=Events,\n        language_model=language_model,\n    )(inputs)\n\n    is_capital_of_relations = await synalinks.Generator(\n        data_model=IsCapitalOfRelations,\n        language_model=language_model,\n    )(inputs)\n    is_located_in_relations = await synalinks.Generator(\n        data_model=IsLocatedInRelations,\n        language_model=language_model,\n    )(inputs)\n    is_city_of_relations = await synalinks.Generator(\n        data_model=IsCityOfRelations,\n        language_model=language_model,\n    )(inputs)\n    took_place_in_relations = await synalinks.Generator(\n        data_model=TookPlaceInRelations,\n        language_model=language_model,\n    )(inputs)\n\n    entities = await synalinks.And()([cities, countries, places, events])\n\n    entities = entities.factorize()\n\n    relations = await synalinks.And()(\n        [\n            is_capital_of_relations,\n            is_located_in_relations,\n            is_city_of_relations,\n            took_place_in_relations,\n        ]\n    )\n    relations = relations.factorize()\n\n    knowledge_graph = entities &amp; relations\n\n    embedded_knowledge_graph = await synalinks.Embedding(\n        embedding_model=embedding_model,\n        in_mask=[\"name\"],\n    )(knowledge_graph)\n\n    updated_knowledge_graph = await synalinks.UpdateKnowledge(\n        knowledge_base=knowledge_base,\n    )(embedded_knowledge_graph)\n\n    outputs = updated_knowledge_graph\n\n    program = synalinks.Program(\n        inputs=inputs,\n        outputs=outputs,\n        name=\"multi_stage_extraction\",\n        description=\"A multi stage KG extraction pipeline\",\n    )\n\n    synalinks.utils.plot_program(\n        program,\n        to_folder=\"examples/knowledge/extraction\",\n        show_trainable=True,\n    )\n\n    dataset = load_data()\n\n    print(\"Starting KG extraction...\")\n    await program.predict(dataset, batch_size=1)\n    print(\"Done.\")\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p></p>"},{"location":"Code%20Examples/Advanced/Knowledge%20Extraction/#dealing-with-orphan-nodes","title":"Dealing with Orphan Nodes","text":"<p>In some cases, specially if you want to use the <code>KnowledgeRetriever</code> you will have to extract nodes that are connected to each other. If intelligence is connecting the dot between your data, then orphan nodes are problematic.</p> <p>To avoid them in SynaLinks, you only need to infer the relations, as they contains not only the id of subject and object entity, but the entities themselves. This approach make sure that each entity extracted will be connected at least to another.</p> <pre><code>import synalinks\nimport asyncio\nfrom typing import List\n\nfrom knowledge_graph_schema import City, Country, Place, Event\nfrom knowledge_graph_schema import IsCapitalOf, IsLocatedIn, IsCityOf, TookPlaceIn\nfrom knowledge_dataset import Document, load_data\n\n\nclass IsCapitalOfRelations(synalinks.Relations):\n    relations: List[IsCapitalOf] = synalinks.Field(\n        description=\"A list of relations specifically describing capital-city relationships between city and country entities.\",\n    )\n\n\nclass IsCityOfRelations(synalinks.Relations):\n    relations: List[IsCityOf] = synalinks.Field(\n        description=\"A list of relations specifically describing the association of cities as part of countries.\",\n    )\n\n\nclass IsLocatedInRelations(synalinks.Relations):\n    relations: List[IsLocatedIn] = synalinks.Field(\n        description=\"A list of relations specifically describing the geographical containment of places within cities or countries.\",\n    )\n\n\nclass TookPlaceInRelations(synalinks.Relations):\n    relations: List[TookPlaceIn] = synalinks.Field(\n        description=\"A list of relations specifically describing the occurrence of events within cities or countries.\",\n    )\n\n\nasync def main():\n    language_model = synalinks.LanguageModel(\n        model=\"ollama/mistral\",\n    )\n\n    embedding_model = synalinks.EmbeddingModel(\n        model=\"ollama/mxbai-embed-large\",\n    )\n\n    knowledge_base = synalinks.KnowledgeBase(\n        index_name=\"neo4j://localhost:7687\",\n        entity_models=[City, Country, Place, Event],\n        relation_models=[IsCapitalOf, IsLocatedIn, IsCityOf, TookPlaceIn],\n        embedding_model=embedding_model,\n        metric=\"cosine\",\n        wipe_on_start=True,\n    )\n\n    inputs = synalinks.Input(data_model=Document)\n\n    is_capital_of_relations = await synalinks.Generator(\n        data_model=IsCapitalOfRelations,\n        language_model=language_model,\n    )(inputs)\n    is_located_in_relations = await synalinks.Generator(\n        data_model=IsLocatedInRelations,\n        language_model=language_model,\n    )(inputs)\n    is_city_of_relations = await synalinks.Generator(\n        data_model=IsCityOfRelations,\n        language_model=language_model,\n    )(inputs)\n    took_place_in_relations = await synalinks.Generator(\n        data_model=TookPlaceInRelations,\n        language_model=language_model,\n    )(inputs)\n\n    relations = await synalinks.And()(\n        [\n            is_capital_of_relations,\n            is_located_in_relations,\n            is_city_of_relations,\n            took_place_in_relations,\n        ]\n    )\n    relations = relations.factorize()\n\n    embedded_relations = await synalinks.Embedding(\n        embedding_model=embedding_model,\n        in_mask=[\"name\"],\n    )(relations)\n\n    updated_relations = await synalinks.UpdateKnowledge(\n        knowledge_base=knowledge_base,\n    )(embedded_relations)\n\n    outputs = updated_relations\n\n    program = synalinks.Program(\n        inputs=inputs,\n        outputs=outputs,\n        name=\"relations_only_multi_stage_extraction\",\n        description=\"A multi stage KG extraction pipeline that only extract the relations\",\n    )\n\n    synalinks.utils.plot_program(\n        program,\n        to_folder=FOLDER,\n        show_trainable=True,\n    )\n\n    synalinks.utils.plot_program(\n        program,\n        to_folder=\"examples/knowledge/extraction\",\n        show_trainable=True,\n    )\n\n    dataset = load_data()\n\n    print(\"Starting KG extraction...\")\n    await program.predict(dataset, batch_size=1)\n    print(\"Done.\")\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p></p>"},{"location":"Code%20Examples/Advanced/Knowledge%20Extraction/#conclusion","title":"Conclusion","text":"<p>Synalinks represents a paradigm shift in knowledge extraction, moving beyond monolithic, inflexible approaches toward a modular, production-first framework that adapts to the complexities of real-world applications.</p> <p>The modular architecture enables teams to iteratively refine their extraction pipelines, starting with simple one-stage approaches and evolving toward sophisticated multi-stage systems as requirements become more complex. This evolutionary path reduces implementation risk while providing a clear migration strategy for growing applications.</p> <p>By separating concerns across different stages, Synalinks allows for specialized optimization at each level of the extraction hierarchy. Entity extraction can leverage lightweight, fast models, while complex reasoning tasks can utilize more powerful, specialized models. This granular control over computational resources leads to more efficient systems that deliver better results at lower costs.</p> <p>Whether you're building a simple entity extraction system or a comprehensive knowledge discovery platform, Synalinks provides the flexibility, control, and scalability needed to transform unstructured data into actionable insights.</p> <p>In an era where structured data is the new oil, Synalinks provides the refinery that transforms raw information into structured knowledge, enabling organizations to unlock the full potential of their data assets through intelligent, adaptive extraction pipelines.</p>"},{"location":"Code%20Examples/Advanced/Knowledge%20Extraction/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>Schema-First Design: Synalinks enforces structured schemas through constrained JSON decoding, ensuring data integrity and consistency across your entire knowledge extraction pipeline. This contract-based approach prevents schema drift and enables reliable downstream processing.</li> <li>Logical Flow Composition: The framework's mathematical foundation allows for precise pipeline composition using logical operations. This enables sophisticated data flow patterns where outputs from one stage can be combined with inputs using python logical operators, creating complex but maintainable extraction workflows.</li> <li>Modular Components: Each pipeline component can be developed, tested, and optimized independently. This separation of concerns reduces complexity, improves maintainability, and enables teams to specialize in different aspects of the extraction process.</li> <li>One-Stage for Simplicity: Use single-stage extraction when you have access to powerful models capable of handling comprehensive extraction tasks. This approach minimizes latency and orchestration complexity but requires models with substantial reasoning capabilities.</li> <li>Two-Stage for Balance: Implement two-stage pipelines when you need to balance accuracy with computational efficiency. This approach allows specialized optimization for entity extraction and relationship inference while maintaining manageable complexity.</li> <li>Multi-Stage for Sophistication: Deploy multi-stage architectures for complex scenarios requiring diverse extraction types, specialized models for different tasks, and sophisticated reasoning capabilities. This approach maximizes flexibility and performance optimization opportunities.</li> <li>Resource Optimization: Different stages can utilize different models optimized for their specific tasks, leading to better resource utilization and cost efficiency. Lightweight models handle simple tasks while powerful models focus on complex reasoning.</li> <li>Error Isolation: Failures in one stage don't necessarily compromise the entire pipeline depending on the logical operators used. This resilience is crucial for production systems processing large volumes of heterogeneous data.</li> </ul>"},{"location":"Code%20Examples/Advanced/Knowledge%20Extraction/#how-to-go-further","title":"How to go further ?","text":"<p>Synalinks KG data models are compatible with other modules, allowing you to easily enhance pipelines to make the extracted data more robust, depending on the data you want to extract. Ultimately, it is about deeply understanding the limitations of your language models (LMs) and having the ability, thanks to our modular approach, to address them. Keep also in mind, that you can train your generators to enhance their accuracy.</p> <p>One might argue that this is a case-by-case, highly domain-specific development and not as straightforward as a one-size-fits-all solution. However, the reality is that companies want systems tailored to their specific business cases and optimized for them. You don't build defensible intellectual property with an average one-size-fits-all solution.</p>"},{"location":"Code%20Examples/Advanced/Retrieval%20Augmented%20Generation/","title":"Retrieval Augmented Generation","text":"<p>Retrieval Augmented Generation (RAG) represents a significant leap forward in AI system design, combining the creative power of language models with precise information retrieval capabilities. This tutorial will guide you through building sophisticated RAG systems using Synalinks, moving from basic document retrieval to advanced Knowledge Augmented Generation (KAG) architectures.</p>"},{"location":"Code%20Examples/Advanced/Retrieval%20Augmented%20Generation/#understanding-the-foundation","title":"Understanding the Foundation","text":"<p>RAG systems solve a fundamental limitation of traditional language models: their reliance on static training data. While language models excel at generating coherent text, they cannot access information beyond their training cutoff or incorporate real-time data. RAG bridges this gap by dynamically retrieving relevant information and weaving it into the generation process.</p> <p>The architecture follows three core stages. The retrieval stage searches through external knowledge bases to find relevant documents or knowledge fragments. The augmentation stage enhances the original query with this retrieved context, providing the language model with additional information to work with. Finally, the generation stage produces responses that synthesize both the user's query and the retrieved knowledge.</p> <p>Synalinks streamlines this complex process through its modular architecture, allowing you to compose retrieval and generation components with precision while maintaining flexibility for different use cases.</p>"},{"location":"Code%20Examples/Advanced/Retrieval%20Augmented%20Generation/#understanding-rag-architecture","title":"Understanding RAG Architecture","text":"<p>Synalinks streamlines RAG implementation through its modular architecture, allowing you to compose retrieval and generation components with precision and flexibility.</p> <p>The foundation of any RAG system begins with defining your data models. These models structure how information flows through your pipeline and ensure consistency across components. You check the tutorial about knowledge graph schemas to have a description of each data model.</p> <pre><code>import synalinks\nimport asyncio\nfrom typing import Literal\nfrom typing import Union\n\nfrom knowledge_graph_schema import City, Country, Place, Event\nfrom knowledge_graph_schema import IsCapitalOf, IsLocatedIn, IsCityOf, TookPlaceIn\n\n\nclass Query(synalinks.DataModel):\n    query: str = synalinks.Field(\n        description=\"The user query\",\n    )\n\nclass Answer(synalinks.DataModel):\n    answer: str = synalinks.Field(\n        description=\"The answer to the user query\",\n    )\n\nasync def main():\n\n    language_model = synalinks.LanguageModel(\n        model=\"ollama/gemma\",\n    )\n\n    embedding_model = synalinks.EmbeddingModel(\n        model=\"ollama/mxbai-embed-large\",\n    )\n\n    knowledge_base = synalinks.KnowledgeBase(\n        index_name=\"neo4j://localhost:7687\",\n        entity_models=[City, Country, Place, Event],\n        relation_models=[IsCapitalOf, IsLocatedIn, IsCityOf, TookPlaceIn],\n        embedding_model=embedding_model,\n        metric=\"cosine\",\n        wipe_on_start=False,\n    )\n\n    inputs = synalinks.Input(data_model=Query)\n    query_result = await synalinks.EntityRetriever(\n        entity_models=[City, Country, Place, Event],\n        knowledge_base=knowledge_base,\n        language_model=language_model,\n        return_inputs=True,\n        return_query=True,\n    )(inputs)\n    outputs = await synalinks.Generator(\n        data_model=Answer,\n        language_model=language_model,\n        instructions=[\n            \"Your task is to answer in natural language to the query based on the results of the search\",\n            \"If the result of the search is not relevant, just say that you don't know\",\n        ],\n        return_inputs=True,\n    )(query_result)\n\n    program = synalinks.Program(\n        inputs=inputs,\n        outputs=outputs,\n        name=\"simple_rag\",\n        description=\"A simple RAG program\",\n    )\n\n    synalinks.utils.plot_program(\n        program,\n        to_folder=\"examples/knowledge/retrieval\",\n        show_trainable=True,\n        show_schemas=True,\n    )\n\n    result = await program(Query(query=\"What is the French capital?\"))\n\n    print(result.prettify_json())\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p></p> <p>The <code>Query</code> and <code>Answer</code> data models serve as the input and output contracts for your RAG system. The <code>Query</code> model captures user questions, while the <code>Answer</code> model structures the system's responses. This explicit modeling ensures type safety and makes your pipeline's behavior predictable.</p> <p>The language model uses Ollama's Gemma model. The embedding model, <code>mxbai-embed-large</code>, transforms text into numerical vectors that enable semantic similarity calculations during retrieval.</p> <p>The knowledge base represents the heart of your RAG system. By connecting to a Neo4j graph database, it stores and indexes your knowledge using both entity models (City, Country, Place, Event) and relationship models (IsCapitalOf, IsLocatedIn). The cosine metric ensures that semantically similar content receives higher relevance scores during retrieval.</p> <p>The <code>EntityRetriever</code> component searches through your knowledge base to find entities that match the user's query. It returns both the retrieved entities and maintains the original input for downstream processing. The <code>Generator</code> then combines the retrieved context with the original query to produce natural language answers.</p>"},{"location":"Code%20Examples/Advanced/Retrieval%20Augmented%20Generation/#advanced-knowledge-augmented-generation","title":"Advanced Knowledge Augmented Generation","text":"<p>Moving beyond simple entity retrieval, Knowledge Augmented Generation (KAG) architectures unlock more sophisticated reasoning capabilities by leveraging the relationships between entities in your knowledge graph.</p> <pre><code>import synalinks\nimport asyncio\nfrom typing import Literal\nfrom typing import Union\n\nfrom knowledge_graph_schema import City, Country, Place, Event\nfrom knowledge_graph_schema import IsCapitalOf, IsLocatedIn, IsCityOf, TookPlaceIn\n\n\nclass Query(synalinks.DataModel):\n    query: str = synalinks.Field(\n        description=\"The user query\",\n    )\n\nclass Answer(synalinks.DataModel):\n    answer: str = synalinks.Field(\n        description=\"The answer to the user query\",\n    )\n\nasync def main():\n\n    language_model = synalinks.LanguageModel(\n        model=\"ollama/gemma\",\n    )\n\n    embedding_model = synalinks.EmbeddingModel(\n        model=\"ollama/mxbai-embed-large\",\n    )\n\n    knowledge_base = synalinks.KnowledgeBase(\n        index_name=\"neo4j://localhost:7687\",\n        entity_models=[City, Country, Place, Event],\n        relation_models=[IsCapitalOf, IsLocatedIn, IsCityOf, TookPlaceIn],\n        embedding_model=embedding_model,\n        metric=\"cosine\",\n        wipe_on_start=False,\n    )\n\n    inputs = synalinks.Input(data_model=Query)\n    query_result = await synalinks.KnowledgeRetriever(\n        entity_models=[City, Country, Place, Event],\n        relation_models=[IsCapitalOf, IsLocatedIn, IsCityOf, TookPlaceIn],\n        knowledge_base=knowledge_base,\n        language_model=language_model,\n        return_inputs=True,\n        return_query=True,\n    )(inputs)\n    outputs = await synalinks.Generator(\n        data_model=Answer,\n        language_model=language_model,\n        instructions=[\n            \"Your task is to answer in natural language to the query based on the results of the search\",\n            \"If the result of the search is not relevant, just say that you don't know\",\n        ],\n        return_inputs=True,\n    )(query_result)\n\n    program = synalinks.Program(\n        inputs=inputs,\n        outputs=outputs,\n        name=\"simple_kag\",\n        description=\"A simple KAG program\",\n    )\n\n    synalinks.utils.plot_program(\n        program,\n        to_folder=\"examples/knowledge/retrieval\",\n        show_trainable=True,\n        show_schemas=True,\n    )\n\n    result = await program(Query(query=\"What is the French capital?\"))\n\n    print(result.prettify_json())\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>The key difference between the basic RAG and KAG approaches lies in the retriever component. While <code>EntityRetriever</code> focuses on finding individual entities, <code>KnowledgeRetriever</code> explores the rich web of relationships between entities. This enables more sophisticated reasoning patterns.</p> <p>When you ask \"What is the French capital?\", the KAG system doesn't just find entities related to France or capitals. It traverses the IsCapitalOf relationships to understand the specific connection between Paris and France, providing more accurate and contextually rich answers.</p> <p>The relationship models (IsCapitalOf, IsLocatedIn, IsCityOf, TookPlaceIn) define the types of connections your system can reason about. This structured approach enables complex queries like \"What events took place in cities that are capitals of European countries?\" by following chains of relationships across your knowledge graph.</p> <p>The <code>return_inputs=True</code> parameter in both retriever and generator components ensures that information flows through your pipeline without loss. This allows downstream components to access both the original query and any intermediate results, enabling more sophisticated processing strategies. The instruction set for the generator provides crucial guidance for response generation. The instruction to acknowledge when search results aren't relevant prevents hallucination and maintains system reliability. You can customize these instructions based on your specific use case requirements.</p> <p>Don't forget that these instructions can be optimized with Synalinks to enhance the reasoning capabilities of your RAGs.</p>"},{"location":"Code%20Examples/Advanced/Retrieval%20Augmented%20Generation/#key-takeaways","title":"Key Takeaways","text":"<ul> <li> <p>Dynamic Knowledge Integration: RAG systems bridge the gap between static training data and real-time information needs by dynamically retrieving and incorporating external knowledge. This enables AI systems to provide current, accurate responses without requiring model retraining.</p> </li> <li> <p>Three-Stage Architecture: The retrieval-augmentation-generation pipeline creates a clear separation of concerns where each stage can be optimized independently. This modular approach improves maintainability and allows for targeted performance improvements.</p> </li> <li> <p>Entity vs Relationship Retrieval: EntityRetriever focuses on finding individual knowledge components, while KnowledgeRetriever explores the rich web of relationships between entities. This distinction enables different reasoning patterns depending on query complexity.</p> </li> <li> <p>Schema-Driven Pipeline Design: Synalinks enforces structured data flow through explicit Query and Answer models, ensuring type safety and predictable behavior across your entire RAG pipeline. This contract-based approach prevents data inconsistencies and enables reliable processing.</p> </li> <li> <p>Graph-Based Knowledge Representation: Using Neo4j with defined entity and relationship models creates a structured knowledge foundation that supports both simple lookups and complex traversal queries. This approach scales from basic Q&amp;A to sophisticated reasoning tasks.</p> </li> <li> <p>Flexible Component Composition: The modular architecture allows you to compose retrieval and generation components with precision while maintaining flexibility for different use cases. Components can be swapped, optimized, or extended without affecting the entire pipeline.</p> </li> </ul>"},{"location":"Code%20Examples/Basics/Control%20Flow/","title":"Control Flow","text":"<p>Controlling the flow of information in a program is an essential feature of any LM framework. In Synalinks, we implemented it in circuit-like fashion, where the flow of information can be  conditionaly or logically restricted to only flow in a subset of a computation graph.</p>"},{"location":"Code%20Examples/Basics/Control%20Flow/#parallel-branches","title":"Parallel Branches","text":"<p>To create parallel branches, all you need to do is using the same inputs when declaring the modules. Then Synalinks will automatically detect them and run them in parrallel with asyncio.</p> <pre><code>import synalinks\nimport asyncio\n\nclass Query(synalinks.DataModel):\n    query: str = synalinks.Field(\n        description=\"The user query\",\n    )\n\nclass AnswerWithThinking(synalinks.DataModel):\n    thinking: str = synalinks.Field(\n        description=\"Your step by step thinking\",\n    )\n    answer: str = synalinks.Field(\n        description=\"The correct answer\",\n    )\n\nasync def main():\n    inputs = synalinks.Input(data_model=Query)\n    x1 = await synalinks.Generator(\n        data_model=AnswerWithThinking,\n        language_model=language_model,\n    )(inputs)\n    x2 = await synalinks.Generator(\n        data_model=AnswerWithThinking,\n        language_model=language_model,\n    )(inputs)\n    outputs = [x1, x2]\n\n    program = synalinks.Program(\n        inputs=inputs,\n        outputs=outputs,\n        name=\"parallel_branches\",\n        description=\"Illustrate the use of parallel branching\",\n    )\n\n    synalinks.utils.plot_program(\n        program,\n        to_folder=\"examples/control_flow\",\n        show_module_names=True,\n        show_schemas=True,\n        show_trainable=True,\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p></p>"},{"location":"Code%20Examples/Basics/Control%20Flow/#decisions","title":"Decisions","text":"<p>Decisions in Synalinks can be viewed as a single label classification, they allow the system to classify the inputs based on a question and labels to choose from. The labels are used to create on the fly a Enum schema that ensure, thanks to constrained structured output, that the system will answer one of the provided labels.</p> <p>This module is the basis of robust control flow in Synalinks.</p> <pre><code>async def main():\n    inputs = synalinks.Input(data_model=Query)\n    outputs = await synalinks.Decision(\n        question=\"Evaluate the difficulty to answer the provided query\",\n        labels=[\"easy\", \"difficult\"],\n        language_model=language_model,\n    )(inputs)\n\n    program = synalinks.Program(\n        inputs=inputs,\n        outputs=outputs,\n        name=\"decision_making\",\n        description=\"Illustrate the decision making process\",\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p></p>"},{"location":"Code%20Examples/Basics/Control%20Flow/#conditional-branches","title":"Conditional Branches","text":"<p>To make conditional branches, we will need the help of a core module: The Branch module. This module use a decision and route the input data model to the selected branch. When a branch is not selected, that branch output a None.</p> <pre><code>class Answer(synalinks.DataModel):\n    answer: str = synalinks.Field(\n        description=\"The correct answer\",\n    )\n\nasync def main():\n    inputs = synalinks.Input(data_model=Query)\n    (x1, x2) = await synalinks.Branch(\n        question=\"Evaluate the difficulty to answer the provided query\",\n        labels=[\"easy\", \"difficult\"],\n        branches=[\n            synalinks.Generator(\n                data_model=Answer,\n                language_model=language_model,\n            ),\n            synalinks.Generator(\n                data_model=AnswerWithThinking,\n                language_model=language_model,\n            ),\n        ],\n    )(inputs)\n    outputs = [x1, x2]\n\n    program = synalinks.Program(\n        inputs=inputs,\n        outputs=outputs,\n        name=\"conditional_branches\",\n        description=\"Illustrate the conditional branches\",\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p></p>"},{"location":"Code%20Examples/Basics/Control%20Flow/#data-models-operators","title":"Data Models Operators","text":"<p>Synalinks implement Python operators that works with data models, some of them are straightforward, like the concatenation, implemented in the Python <code>+</code> operator.  But others like the <code>logical_and</code> and <code>logical_or</code> implemented respectively  in the <code>&amp;</code> and <code>|</code> operator are more difficult to grasp at first. As explained above, in the conditional branches, the branch not selected will have a <code>None</code>  as output. To account that fact and to implement logical flows, we need operators that can work with them. See the Ops API section for an extensive list of all data model operations.</p>"},{"location":"Code%20Examples/Basics/Control%20Flow/#concatenation","title":"Concatenation","text":"<p>The concatenation, consist in creating a data model that have the fields of both inputs. When one of the input is <code>None</code>, it raise an exception. Note that you can use the concatenation, like any other operator, at a meta-class level, meaning you can actually concatenate data model types.</p>"},{"location":"Code%20Examples/Basics/Control%20Flow/#concatenation-table","title":"Concatenation Table","text":"<code>x1</code> <code>x2</code> Concat (<code>+</code>) <code>x1</code> <code>x2</code> <code>x1 + x2</code> <code>x1</code> <code>None</code> <code>Exception</code> <code>None</code> <code>x2</code> <code>Exception</code> <code>None</code> <code>None</code> <code>Exception</code>"},{"location":"Code%20Examples/Basics/Control%20Flow/#concatenation-example","title":"Concatenation Example","text":"<pre><code>async def main():\n    inputs = synalinks.Input(data_model=Query)\n    x1 = await synalinks.Generator(\n        data_model=AnswerWithThinking,\n        language_model=language_model,\n    )(inputs)\n    x2 = await synalinks.Generator(\n        data_model=AnswerWithThinking,\n        language_model=language_model,\n    )(inputs)\n    outputs = x1 + x2\n\n    program = synalinks.Program(\n        inputs=inputs,\n        outputs=outputs,\n        name=\"concatenation\",\n        description=\"Illustrate the use of concatenate\",\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"Code%20Examples/Basics/Control%20Flow/#logical-and","title":"Logical And","text":"<p>The <code>logical_and</code> is a concatenation that instead of raising an <code>Exception</code>, output a <code>None</code>. This operator should be used, when you have to concatenate a data model with an another one that can be <code>None</code>, like a <code>Branch</code> output.</p>"},{"location":"Code%20Examples/Basics/Control%20Flow/#logical-and-table","title":"Logical And Table","text":"<code>x1</code> <code>x2</code> Logical And (<code>&amp;</code>) <code>x1</code> <code>x2</code> <code>x1 + x2</code> <code>x1</code> <code>None</code> <code>None</code> <code>None</code> <code>x2</code> <code>None</code> <code>None</code> <code>None</code> <code>None</code>"},{"location":"Code%20Examples/Basics/Control%20Flow/#logical-and-example","title":"Logical And Example","text":"<pre><code>class Critique(synalinks.DataModel):\n    critique: str = synalinks.Field(\n        description=\"The critique of the answer\",\n    )\n\nasync def main():\n    inputs = synalinks.Input(data_model=Query)\n    (x1, x2) = await synalinks.Branch(\n        question=\"Evaluate the difficulty to answer the provided query\",\n        labels=[\"easy\", \"difficult\"],\n        branches=[\n            synalinks.Generator(\n                data_model=Answer,\n                language_model=language_model,\n            ),\n            synalinks.Generator(\n                data_model=AnswerWithThinking,\n                language_model=language_model,\n            ),\n        ],\n        return_decision=False,\n    )(inputs)\n    x3 = x0 &amp; x1\n    x4 = x0 &amp; x2\n    x5 = await synalinks.Generator(\n        data_model=Critique,\n        language_model=language_model,\n        return_inputs=True,\n    )(x3)\n    x6 = await synalinks.Generator(\n        data_model=Critique,\n        language_model=language_model,\n        return_inputs=True,\n    )(x4)\n    x7 = x5 | x6\n    outputs = await synalinks.Generator(\n        data_model=Answer,\n        language_model=language_model,\n    )(x7)\n\n    program = synalinks.Program(\n        inputs=inputs,\n        outputs=outputs,\n        name=\"logical_and\",\n        description=\"Illustrate the use of logical and\",\n    )\n</code></pre>"},{"location":"Code%20Examples/Basics/Control%20Flow/#logical-or","title":"Logical Or","text":"<p>The <code>logical_or</code> is used when you want to combine two data models, but you can accomodate that one of them is <code>None</code>. Another use, is to gather the outputs of a <code>Branch</code>, as only one branch is active, it allows you merge the branches outputs  into a unique data model.</p>"},{"location":"Code%20Examples/Basics/Control%20Flow/#logical-or-table","title":"Logical Or Table","text":"<code>x1</code> <code>x2</code> Logical Or (<code>|</code>) <code>x1</code> <code>x2</code> <code>x1 + x2</code> <code>x1</code> <code>None</code> <code>x1</code> <code>None</code> <code>x2</code> <code>x2</code> <code>None</code> <code>None</code> <code>None</code>"},{"location":"Code%20Examples/Basics/Control%20Flow/#logical-or-example","title":"Logical Or Example","text":"<pre><code>async def main():\n    inputs = synalinks.Input(data_model=Query)\n    (x1, x2) = await synalinks.Branch(\n        question=\"Evaluate the difficulty to answer the provided query\",\n        labels=[\"easy\", \"difficult\"],\n        branches=[\n            synalinks.Generator(\n                data_model=Answer,\n                language_model=language_model,\n            ),\n            synalinks.Generator(\n                data_model=AnswerWithThinking,\n                language_model=language_model,\n            ),\n        ],\n        return_decision=False,\n    )(x0)\n    outputs = x1 | x2\n\n    program = synalinks.Program(\n        inputs=inputs,\n        outputs=outputs,\n        name=\"logical_or\",\n        description=\"Illustrate the use of logical or\",\n    )\n</code></pre>"},{"location":"Code%20Examples/Basics/Control%20Flow/#conclusion","title":"Conclusion","text":"<p>In this tutorial, we explored the fundamental concepts of controlling information flow within Synalinks programs. We introduced the creation of parallel branches,  decision-making processes, and conditional branching, all of which are essential  for building dynamic and robust applications.</p>"},{"location":"Code%20Examples/Basics/Control%20Flow/#key-takeaways","title":"Key Takeaways","text":"<ul> <li> <p>Parallel Branches: We demonstrated how to run modules in parallel using      the same inputs, leveraging asyncio for concurrent execution.      This approach enhances performance and allows for simultaneous processing of tasks.</p> </li> <li> <p>Decision-Making: We introduced decision-making as a form of single-label      classification, enabling the system to classify inputs based on predefined      questions and labels. This ensures that the system's responses are structured      and adhere to the specified schemas.</p> </li> <li> <p>Conditional Branching: We explored the use of the Branch module to route      input data models based on decisions, allowing for conditional execution of      branches. This feature is essential for creating adaptive and context-aware      applications.</p> </li> <li> <p>Data Model Operators: We discussed various data model operators, such as      concatenation, <code>logical_and</code>, and <code>logical_or</code>. These operators enable      sophisticated data manipulation and flow control, ensuring robust program     execution even when branches output <code>None</code>.</p> </li> </ul>"},{"location":"Code%20Examples/Basics/Conversational%20Applications/","title":"Conversational Applications","text":"<p>Synalinks is designed to handle conversational applications as well as  query-based systems. In the case of a conversational applications, the input data model is a list of chat messages, and the output an individual chat message. The <code>Program</code> is in that case responsible of handling a single conversation turn.</p> <p>Now we can program our application like you would do with any <code>Program</code>. For this example, we are going to make a very simple chatbot.</p> <p>By default, if no data_model/schema is provided to the <code>Generator</code> it will output a <code>ChatMessage</code> like output. If the data model is <code>None</code>, then you can enable streaming.</p> <p>Note: Streaming is disabled during training and should only be used in the last <code>Generator</code> of your pipeline.</p> <pre><code>import synalinks\nimport asyncio\n\nfrom synalinks.backend import ChatMessage\nfrom synalinks.backend import ChatRole\nfrom synalinks.backend import ChatMessages\n\nlanguage_model = synalinks.LanguageModel(\n    model=\"ollama/mistral\",\n)\n\nasync def main():\n    inputs = synalinks.Input(data_model=ChatMessages)\n    outputs = await synalinks.Generator(\n        language_model=language_model,\n        prompt_template=synalinks.chat_prompt_template(),\n        streaming=False,  # Marimo chat don't handle streaming yet\n    )(inputs)\n\n    program = synalinks.Program(\n        inputs=inputs,\n        outputs=outputs,\n        name=\"simple_chatbot\",\n        description=\"A simple conversation application\",\n    )\n\n    # Plot this program to understand it\n    synalinks.utils.plot_program(\n        program,\n        show_module_names=True,\n        show_trainable=True,\n        show_schemas=True,\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p></p>"},{"location":"Code%20Examples/Basics/Conversational%20Applications/#conclusion","title":"Conclusion","text":"<p>In this notebook, we explored how Synalinks handle conversational applications. You have now a solid understanding to create chatbots and conversational agents.</p>"},{"location":"Code%20Examples/Basics/Conversational%20Applications/#key-takeaways","title":"Key Takeaways","text":"<ul> <li> <p>Conversational Flow Management: Synalinks effectively manages conversational      applications by handling inputs as a list of chat messages and generating     individual chat messages as outputs. This structure allows for efficient      processing of conversation turns.</p> </li> <li> <p>Streaming and Real-Time Interaction: Synalinks supports streaming for      real-time interactions, enhancing user engagement. However, streaming is      disabled during training and should be used only in the final <code>Generator</code>.</p> </li> <li> <p>Customizable Prompt Templates: The prompt templates can be tailored to fit     conversational contexts, guiding the language model to produce coherent and      relevant responses.</p> </li> </ul>"},{"location":"Code%20Examples/Basics/First%20Programs/","title":"First Programs","text":"<p>The main concept of Synalinks, is that an application (we call it a <code>Program</code>) is a computation graph (a Directed Acyclic Graph or DAG to be exact) with JSON data (<code>JsonDataModel</code>) as edges and <code>Operation</code>s as nodes.</p> <p>What set apart Synalinks from other similar frameworks like DSPy or AdalFlow is that we focus on graph-based systems but also that it allow users to declare the computation graph using a Functional API inherited from Keras.</p> <p>About modules, similar to layers in deep learning applications, modules are composable blocks that you can assemble in multiple ways. Providing a modular and composable architecture to experiment and unlock creativity.</p> <p>Note that each <code>Program</code> is also a <code>Module</code>! Allowing you to encapsulate them as you want.</p> <p>Many people think that what enabled the Deep Learning revolution was compute and data, but in reality, frameworks also played a pivotal role as they enabled researchers and engineers to create complex architectures without having to  re-implement everything from scatch.</p> <pre><code>import synalinks\nimport asyncio\n# Now we can define the data models that we are going to use in the tutorial.\n\nclass Query(synalinks.DataModel):\n    query: str = synalinks.Field(\n        description=\"The user query\",\n    )\n\nclass AnswerWithThinking(synalinks.DataModel):\n    thinking: str = synalinks.Field(\n        description=\"Your step by step thinking\",\n    )\n    answer: str = synalinks.Field(\n        description=\"The correct answer\",\n    )\n\n# And the language model to use\n\nlanguage_model = synalinks.LanguageModel(\n    model=\"ollama/mistral\",\n)\n</code></pre>"},{"location":"Code%20Examples/Basics/First%20Programs/#functional-api","title":"Functional API","text":"<p>You can program your application using 4 different ways, let's start with the Functional way.</p> <p>In this case, you start from <code>Input</code> and you chain modules calls to specify the programs's structure, and finally, you create your program from inputs and outputs:</p> <pre><code>async def main():\n\n    inputs = synalinks.Input(data_model=Query)\n    outputs = await synalinks.Generator(\n        data_model=AnswerWithThinking,\n        language_model=language_model,\n    )(x0)\n\n    program = synalinks.Program(\n        inputs=inputs,\n        outputs=outputs,\n        name=\"chain_of_thought\",\n        description=\"Useful to answer in a step by step manner.\",\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"Code%20Examples/Basics/First%20Programs/#subclassing-the-program-class","title":"Subclassing the <code>Program</code> class","text":"<p>Now let's try to program it using another method, subclassing the <code>Program</code> class. It is the more complicated one, and reserved for skilled developers or contributors.</p> <p>In that case, you define your modules in <code>__init__()</code> and you should implement the program's structure in <code>call()</code> and the serialization methods (<code>get_config</code> and <code>from_config</code>).</p> <pre><code>class ChainOfThought(synalinks.Program):\n    \"\"\"Useful to answer in a step by step manner.\n\n    The first line of the docstring is provided as description for the program\n    if not provided in the `super().__init__()`. In a similar way the name is\n    automatically infered based on the class name if not provided.\n    \"\"\"\n\n    def __init__(self, language_model=None):\n        super().__init__()\n        self.answer = synalinks.Generator(\n            data_model=AnswerWithThinking, language_model=language_model\n        )\n\n    async def call(self, inputs, training=False):\n        x = await self.answer(inputs)\n        return x\n\n    def get_config(self):\n        config = {\n            \"name\": self.name,\n            \"description\": self.description,\n            \"trainable\": self.trainable,\n        }\n        language_model_config = {\n            \"language_model\": synalinks.saving.serialize_synalinks_object(\n                self.language_model\n            )\n        }\n        return {**config, **language_model_config}\n\n    @classmethod\n    def from_config(cls, config):\n        language_model = synalinks.saving.deserialize_synalinks_object(\n            config.pop(\"language_model\")\n        )\n        return cls(language_model=language_model, **config)\n\nasync def main():\n    program = ChainOfThought(language_model=language_model)\n    # Build the program for Query inputs\n    await program.build(Query)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>Note that the program isn't actually built, this behavior is intended its  means that it can accept any king of input, making the program truly  generalizable. You can use <code>program.build()</code> to built it, otherwise it will be built automatically the first time used.</p>"},{"location":"Code%20Examples/Basics/First%20Programs/#mixing-the-subclassing-and-the-functional-api","title":"Mixing the subclassing and the <code>Functional</code> API","text":"<p>This way of programming is recommended to encapsulate your application while providing an easy to use setup. It is the recommended way for most users as it avoid making your program/agents from scratch. In that case, you should implement only the <code>__init__()</code> and <code>build()</code> methods.</p> <pre><code>class ChainOfThought(synalinks.Program):\n    \"\"\"Useful to answer in a step by step manner.\"\"\"\n\n    def __init__(\n        self,\n        language_model=None,\n        name=None,\n        description=None,\n        trainable=True,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n            trainable=trainable,\n        )\n        self.language_model = language_model\n\n    async def build(self, inputs):\n        outputs = await synalinks.Generator(\n            data_model=AnswerWithThinking,\n            language_model=self.language_model,\n        )(inputs)\n\n        # Create your program using the functional API\n        super().__init__(\n            inputs=inputs,\n            outputs=outputs,\n            name=self.name,\n            description=self.description,\n            trainable=self.trainable,\n        )\n\nasync def main():\n    program = ChainOfThought(language_model=language_model)\n    # Build the program for Query inputs\n    await program.build(Query)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>Like when using the subclassing method, the program will be built on the fly when called for the first time.</p>"},{"location":"Code%20Examples/Basics/First%20Programs/#using-the-sequential-api","title":"Using the <code>Sequential</code> API","text":"<p>In addition, <code>Sequential</code> is a special case of program where the program is purely a stack of single-input, single-output modules.</p> <pre><code>async def main():\n    program = synalinks.Sequential(\n        [\n            synalinks.Input(\n                data_model=Query,\n            ),\n            synalinks.Generator(\n                data_model=AnswerWithThinking,\n                language_model=language_model,\n            ),\n        ],\n        name=\"chain_of_thought\",\n        description=\"Useful to answer in a step by step manner.\",\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"Code%20Examples/Basics/First%20Programs/#running-your-programs","title":"Running your programs","text":"<p>In order to run your program, you just have to call it like a function with the input data model as argument.</p> <pre><code>async def main():\n    # ... program definition\n\n    result = await program(\n        Query(query=\"What are the key aspects of human cognition?\"),\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"Code%20Examples/Basics/First%20Programs/#conclusion","title":"Conclusion","text":"<p>Congratulations! You've successfully explored the fundamental concepts of programming applications using Synalinks.</p> <p>Now that we know how to program applications, you can learn how to control the data flow in the next tutorial.</p>"},{"location":"Code%20Examples/Basics/First%20Programs/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>Functional API: Allows you to chain modules to define the program's structure,      providing a clear and intuitive way to build applications.</li> <li>Subclassing: Offers flexibility and control by defining modules and implementing     the program's structure from scratch within a class.</li> <li>Mixing the subclassing and the Functional API: Allows to benefit from the     compositionality of the subclassing while having the ease of use of the functional way of programming.</li> <li>Sequential Programs: Simplifies the creation of linear workflows, making it easy     to stack single-input, single-output modules.</li> <li>Modularity and Composability: Enables the reuse of components, fostering     creativity and efficiency in application development.</li> </ul>"},{"location":"Code%20Examples/Basics/First%20Steps/","title":"First Steps","text":"<p>First, install Synalinks, the easiest way is using pip:</p> <pre><code>pip install synalinks\n</code></pre> <p>Or uv (recommended):</p> <pre><code>uv pip install synalinks\n</code></pre> <p>Note for Windows users: Use the Windows Linux Sub-System (WLS).</p> <p>If you want to install it from source (for contributors), then do:</p> <pre><code>git clone https://github.com/SynaLinks/synalinks\ncd synalinks\n./shell/uv.sh # Install uv\n./shell/install.sh # Create the virtual env and install Synalinks\n</code></pre> <p>After this, open a python file or notebook and check the install:</p> <pre><code>import synalinks\nprint(synalinks.__version__)\n</code></pre> <p>or use <code>uv run synalinks --version</code></p> <p>Now create a new project using the following command:</p> <pre><code>uv run synalinks init\n</code></pre> <p>This will setup a template project ready to work on.</p> <p>Synalinks use a global context to ensure that each variable/module have a unique name. Clear it at the beginning of your scripts to  ensure naming reproductability.</p> <pre><code># Clear the global context\nsynalinks.clear_session()\n</code></pre> <p>Addtionally, you can install Ollama here to run Language Models (LMs) locally, which is very useful to development.</p>"},{"location":"Code%20Examples/Basics/First%20Steps/#prompting","title":"Prompting","text":"<p>You will notice that there is no traditional prompting involved in  Synalinks, everything is described as data models in and out. However we use a prompt template, that will tell the system how to  construct the prompt automatically.</p> <p>The prompt template is a jinja2 template that describe how to render  the examples, instructions and how to convert them into chat messages:</p>"},{"location":"Code%20Examples/Basics/First%20Steps/#default-prompt-template","title":"Default Prompt template","text":"<p>Returns the default prompt template.</p> <p>Returns:</p> Type Description <code>str</code> <p>The default prompt template.</p> Source code in <code>synalinks/src/modules/core/generator.py</code> <pre><code>@synalinks_export(\"synalinks.default_prompt_template\")\ndef default_prompt_template():\n    \"\"\"Returns the default prompt template.\n\n    Returns:\n        (str): The default prompt template.\n    \"\"\"\n    return \"\"\"\n&lt;system&gt;\n{% if inputs_schema %}You will be given an input JSON object with the following schema. \nInput JSON Schema:\n{{ inputs_schema }}\n{% endif %}\n{% if outputs_schema %}\nYour task is to answer with a JSON object following this output JSON schema.\n\nOutput JSON Schema:\n{{ outputs_schema }}\n{% endif %}\n{% if examples %}\n### Examples\n{% for example in examples %}\nInput:\n{{ example[0] }}\nOutput:\n{{ example[1] }}\n{% endfor %}\n{% endif %}\n{% if instructions %}\n### Instructions:\n{% for instruction in instructions %}\n - {{ instruction }}\n{% endfor %}\n{% endif %}\n&lt;/system&gt;\n&lt;user&gt;\nInput:\n{{ inputs }}\nOutput:\n&lt;/user&gt;\"\"\"\n</code></pre> <p>The template use the XML tags <code>&lt;system&gt;...&lt;/system&gt;</code>, <code>&lt;user&gt;...&lt;/user&gt;</code> and <code>&lt;assistant&gt;...&lt;/assistant&gt;</code> to know how to convert the prompt template  into chat messages. You can modify at any time the default template used by using the  <code>prompt_template</code> argument in Synalinks modules. You can notice also,  that we send the inputs's and output's JSON schema to instruct the LMs how to answer, you can enable/disable that behavior by using <code>use_inputs_schema</code> and <code>use_outputs_schema</code> in Synalinks modules. Synalinks use constrained structured output ensuring that the LMs answer respect the data models specification (the JSON schema), and is ready to parse, so in theory we don't need it, except if you use it to provide additional information to the LMs. You can find more information in the  <code>Generator</code> documentation.</p>"},{"location":"Code%20Examples/Basics/First%20Steps/#data-models","title":"Data Models","text":"<p>To provide additional information to the LMs, you can use the data models <code>Field</code>. You can notice that Synalinks use Pydantic as default data backend. Allowing Synalinks to be compatible out-of-the-box with constrained structured output, FastAPI and FastMCP.</p> <pre><code>class AnswerWithThinking(synalinks.DataModel):\n    thinking: str = synalinks.Field(\n        description=\"Your step by step thinking\",\n    )\n    answer: str = synalinks.Field(\n        description=\"The correct answer\",\n    )\n</code></pre>"},{"location":"Code%20Examples/Basics/First%20Steps/#conclusion","title":"Conclusion","text":"<p>Usually that will be enough to instruct the LMs, you don't need to modify the prompt template. Just by adding additional descriptions to the data models fields you can instruct your system to behave as you want.  If the system needs general instructions about how to behave, you can  use the <code>instructions</code> argument in Synalinks modules that will be formatted as  presented in the prompt template.</p>"},{"location":"Code%20Examples/Basics/First%20Steps/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>Ease of Integration: Synalinks seamlessly integrates with existing     Python projects, making it easy to incorporate advanced language      model capabilities without extensive modifications.</li> <li>Structured Outputs: By using data models and JSON schemas combined with     constrained structed output, Synalinks ensures that the LMs responses are structured and ready for parsing, reducing the need for additional post-processing.</li> <li>Customizable Prompts: The prompt templates in Synalinks are highly     customizable, allowing you to tailor the instructions provided to     the LMs based on your specific use case. </li> <li>Compatibility: Synalinks use Pydantic as the default data backend     ensures compatibility with structured output, FastAPI and FastMCP.</li> </ul>"},{"location":"Code%20Examples/Basics/Reward%20Metrics%20And%20Optimizers/","title":"Rewards, Metrics &amp; Optimizers","text":""},{"location":"Code%20Examples/Basics/Reward%20Metrics%20And%20Optimizers/#understanding-rewards","title":"Understanding Rewards","text":"<p><code>Reward</code>s are an essential part of reinforcement learning frameworks.  They are typically float values (usually between 0.0 and 1.0, but they can be  negative also) that guide the process into making more efficient decisions or  predictions. During training, the goal is to maximize the reward function.  The reward gives the system an indication of how well it performed for that task.</p> <pre><code>graph LR\nA[Training Data] --&gt;|Provide x:DataModel| B[Program];\nB --&gt;|Generate y_pred:JsonDataModel| C[Reward];\nA --&gt;|Provide y_true:DataModel| C;\nC --&gt;|Compute reward:Float| D[Optimizer];\nD --&gt;|Update trainable_variable:Variable| B;</code></pre> <p>This reinforcement loop is what makes possible for the system to learn by repeatedly making predictions and refining its knowledge/methodology in order  to maximize the reward.</p> <p>All rewards consist of a function or program that takes two inputs:</p> <ul> <li><code>y_pred</code>: The prediction of the program.</li> <li><code>y_true</code>: The ground truth/target value provided by the training data.</li> </ul> <p>In Synalinks, we provide for several built-in rewards but it is also possible to easily create new rewards if you needs to. Overall the choice will depend on the task to perform. You can have a look at the rewards provided in the  API section.</p>"},{"location":"Code%20Examples/Basics/Reward%20Metrics%20And%20Optimizers/#understanding-metrics","title":"Understanding Metrics","text":"<p><code>Metric</code>s are scalar values that are monitored during training and evaluation. These values are used to know which program is best, in order to save it. Or to  provide additional information to compare different architectures with each others. Unlike <code>Reward</code>s, a <code>Metric</code> is not used during training, meaning the metric value  is not backpropagated. Additionaly every reward function can be used as metric.  You can have a look at the metrics provided in the  API section.</p>"},{"location":"Code%20Examples/Basics/Reward%20Metrics%20And%20Optimizers/#predictions-filtering","title":"Predictions Filtering","text":"<p>Sometimes, your program have to output a complex JSON but you want to evaluate just part of it. This could be because your training data only include a subset of the JSON, or because the additonal fields were added only to help the LMs. In that case, you have to filter out or filter in your predictions and ground truth. Meaning that you want to remove or keep respectively only specific fields of your JSON data. This can be achieved by adding a <code>out_mask</code> or <code>in_mask</code> list parameter containing the keys to remove or keep for evaluation. This parameters can be added to both reward and metrics. Like in the above example where we only keep the field <code>answer</code> to compute the rewards and metrics.</p>"},{"location":"Code%20Examples/Basics/Reward%20Metrics%20And%20Optimizers/#understanding-optimizers","title":"Understanding Optimizers","text":"<p>Optimizers are systems that handle the update of the module's state in order to make them more performant. They are in charge of backpropagating the rewards  from the training process and select or generate examples and instructions for the LMs.</p> <p>Here is an example of program compilation, which is how you configure the reward, metrics, and optimizer:</p> <pre><code>import synalinks\nimport asyncio\n\nclass Query(synalinks.DataModel):\n    query: str = synalinks.Field(\n        description=\"The user query\",\n    )\n\nclass AnswerWithThinking(synalinks.DataModel):\n    thinking: str = synalinks.Field(\n        description=\"Your step by step thinking\",\n    )\n    answer: str = synalinks.Field(\n        description=\"The correct answer\",\n    )\n\nlanguage_model = synalinks.LanguageModel(\n    model=\"ollama/mistral\",\n)\n\nasync def main():\n    inputs = synalinks.Input(data_model=Query)\n    outputs = await synalinks.Generator(\n        data_model=AnswerWithThinking,\n        language_model=language_model,\n    )(inputs)\n\n    program = synalinks.Program(\n        inputs=inputs,\n        outputs=outputs,\n        name=\"chain_of_thought\",\n        description=\"Useful to answer in a step by step manner.\",\n    )\n\n    program.compile(\n        reward=synalinks.rewards.CosineSimilarity(\n            embedding_model=embedding_model,\n            in_mask=[\"answer\"],\n        ),\n        optimizer=synalinks.optimizers.RandomFewShot(),\n        metrics=[\n            synalinks.metrics.F1Score(in_mask=[\"answer\"]),\n        ],\n    )\n</code></pre>"},{"location":"Code%20Examples/Basics/Reward%20Metrics%20And%20Optimizers/#conclusion","title":"Conclusion","text":"<p>In this tutorial, we explored the fundamental concepts of training and  optimizing Synalinks programs using rewards, metrics, and optimizers.  These components are crucial for building efficient and adaptive language  model applications.</p>"},{"location":"Code%20Examples/Basics/Reward%20Metrics%20And%20Optimizers/#key-takeaways","title":"Key Takeaways","text":"<ul> <li> <p>Rewards: <code>Reward</code>s guide the reinforcement learning process by      providing feedback on the system's performance. They are typically     float values that indicate how well the system performed a task,      with the goal of maximizing the reward function during training.      Synalinks offers built-in rewards and allows for custom reward      functions to suit specific tasks.</p> </li> <li> <p>Metrics: <code>Metric</code>s are scalar values monitored during training     and evaluation to determine the best-performing program. Unlike     rewards, metrics are not used for backpropagation. They provide      additional insights for comparing different architectures and      saving the optimal model.</p> </li> <li> <p>Optimizers: <code>Optimizer</code>s update the module's state to improve     performance. They handle the backpropagation of rewards and      select or generate examples and instructions for the language models.     Proper configuration of optimizers is essential for effective     training.</p> </li> <li> <p>Filtering Outputs: When dealing with complex JSON outputs,      filtering predictions and ground truths using <code>out_mask</code> or      <code>in_mask</code> parameters ensures that only relevant fields are      evaluated. This is particularly useful when the training data      includes a subset of the JSON or when additional fields are     used to aid the language models.</p> </li> </ul>"},{"location":"Code%20Examples/Basics/Training%20Programs/","title":"Training Programs","text":"<p>Like in machine learning, a LM application needs to be trained. In that case, we don't update the weights of the model, but optimize the prompts by automatically picking the best examples or generate instructions in order to help the program to  perform better on your dataset.</p> <p>For this lesson we are going to work on GSM8k a well known dataset of grade school math word problems. Nowedays, most (all?) public datasets have been leaked, meaning that their test set have been included in the LM trainset. This basically means that the baseline score won't give you much information about the reasoning abilities of the underlying language model (but more about its capability to remember), however it is still interesing to have it as a baseline to evaluate the progress  of the programs training and the neuro-symbolic methods used or if you use small models like here.</p> <p>First, let's have a look at the dataset.</p>"},{"location":"Code%20Examples/Basics/Training%20Programs/#input-data-model","title":"Input Data Model","text":"<p>               Bases: <code>DataModel</code></p> Source code in <code>synalinks/src/datasets/gsm8k.py</code> <pre><code>class MathQuestion(DataModel):\n    question: str = Field(\n        description=\"The math word problem\",\n    )\n</code></pre>"},{"location":"Code%20Examples/Basics/Training%20Programs/#output-data-model","title":"Output Data Model","text":"<p>               Bases: <code>DataModel</code></p> Source code in <code>synalinks/src/datasets/gsm8k.py</code> <pre><code>class NumericalAnswerWithThinking(DataModel):\n    thinking: str = Field(\n        description=\"Your step by step thinking\",\n    )\n    answer: float = Field(\n        description=\"The numerical answer\",\n    )\n</code></pre> <p>Now we can dive into the code used for this benchmark. In this example, we are going to use a small distilled model that can run locally. Training an LM application involves numerous calls to LMs, and it is better to experiment with small models. We are also proving that, despite what most people think, small models, when trained, can compete with their larger counterparts. This makes Synalinks a framework of choice if you want to reduce the costs of your LM applications.</p> <p>In production settings, this means that you can use smaller and more cost-effective models from your preferred provider while enhancing their accuracy with Synalinks. This is also a good way to fight model obsolescence, as many proprietary providers degrade the performance of their models over time to make people switch to newer/more costly models.</p>"},{"location":"Code%20Examples/Basics/Training%20Programs/#benchmark-code","title":"Benchmark Code","text":"<pre><code>import asyncio\nimport os\n\nimport synalinks\n\nNB_EPOCHS = 2\nBATCH_SIZE = 32\nNB_SAMPLES = None\nNB_RUNS = 3\n\nFOLDER = \"examples/training_programs\"\n\ncheckpoint_filepath = \"checkpoint.program.json\"\n\nasync def main():\n    language_model = synalinks.LanguageModel(\n        model=\"ollama/deepseek-r1\",\n    )\n    print(\"Loading GSM8k dataset...\")\n    (x_train, y_train), (x_test, y_test) = synalinks.datasets.gsm8k.load_data()\n\n    if NB_SAMPLES:\n        x_train = x_train[:NB_SAMPLES]\n        y_train = y_train[:NB_SAMPLES]\n        x_test = x_test[:NB_SAMPLES]\n        y_test = y_test[:NB_SAMPLES]\n\n    print(\"Done.\")\n\n    print(\"Creating program...\")\n    inputs = synalinks.Input(\n        data_model=synalinks.datasets.gsm8k.get_input_data_model(),\n    )\n    outputs = await synalinks.Generator(\n        data_model=synalinks.datasets.gsm8k.get_output_data_model(),\n        language_model=language_model,\n    )(inputs)\n    program = synalinks.Program(\n        inputs=inputs,\n        outputs=outputs,\n        name=\"gsm8k_baseline\",\n        description=\"The GSM8k baseline\",\n    )\n\n    synalinks.utils.plot_program(\n        program,\n        to_folder=FOLDER,\n        show_module_names=True,\n        show_schemas=True,\n        show_trainable=True,\n    )\n\n    print(\"Compiling...\")\n    program.compile(\n        reward=synalinks.rewards.ExactMatch(in_mask=[\"answer\"]),\n        optimizer=synalinks.optimizers.RandomFewShot(),\n    )\n    print(\"Done.\")\n\n    print(f\"Perform baseline evaluation samples with {NB_RUNS} runs...\")\n    baseline_metric_list = []\n    for i in range(NB_RUNS):\n        print(f\"Run {i + 1}/{NB_RUNS}\")\n        metrics = await program.evaluate(\n            x=x_test,\n            y=y_test,\n            batch_size=BATCH_SIZE,\n        )\n        baseline_metric_list.append(metrics)\n    print(\"Done.\")\n\n    synalinks.utils.plot_metrics_with_mean_and_std(\n        baseline_metric_list,\n        to_folder=FOLDER,\n        title=\"Evaluation without training\",\n    )\n\n    program.compile(\n        reward=synalinks.rewards.ExactMatch(in_mask=[\"answer\"]),\n        optimizer=synalinks.optimizers.RandomFewShot(),\n    )\n\n    program_checkpoint_callback = synalinks.callbacks.ProgramCheckpoint(\n        filepath=os.path.join(FOLDER, checkpoint_filepath),\n        monitor=\"val_reward\",\n        mode=\"max\",\n        save_best_only=True,\n    )\n\n    print(f\"Start training for {NB_EPOCHS} epochs...\")\n    history = await program.fit(\n        x=x_train,\n        y=y_train,\n        validation_data=(x_test, y_test),\n        epochs=NB_EPOCHS,\n        batch_size=BATCH_SIZE,\n        callbacks=[program_checkpoint_callback],\n    )\n    print(\"Done.\")\n\n    synalinks.utils.plot_history(\n        history,\n        to_folder=FOLDER,\n        to_file=\"gsm8k_baseline_training_history.png\",\n    )\n\n    print(\"Load best performing checkpoint...\")\n    program.load(os.path.join(FOLDER, checkpoint_filepath))\n    print(\"Done.\")\n\n    print(f\"Perform final evaluation...\")\n    trained_metric_list = []\n    for i in range(NB_RUNS):\n        print(f\"Run {i + 1}/{NB_RUNS}\")\n        metrics = await program.evaluate(\n            x=x_test,\n            y=y_test,\n            batch_size=BATCH_SIZE,\n        )\n        trained_metric_list.append(metrics)\n    print(\"Done.\")\n\n    metrics_comparison = {\n        \"without_training\": baseline_metric_list,\n        \"with_training\": trained_metric_list,\n    }\n\n    synalinks.utils.plot_metrics_comparison_with_mean_and_std(\n        metrics_comparison,\n        to_folder=FOLDER,\n        to_file=\"gsm8k_evaluation_comparison.png\",\n        title=\"Comparison w/o training (GSM8K with EM reward)\",\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"Code%20Examples/Basics/Training%20Programs/#the-program-architecture","title":"The Program Architecture","text":""},{"location":"Code%20Examples/Basics/Training%20Programs/#training-result","title":"Training Result","text":"<p>Here we have a 77.142% increase of performance, not bad for a small distilled model. You can push the results even higher by training for more epochs or by using multiple optimizers one after another. Another way to have better results is to modify the architecture, using agents with a calculator or a more complex workflow.</p>"},{"location":"Code%20Examples/Basics/Training%20Programs/#conclusion","title":"Conclusion","text":"<p>In this tutorial, we explored the process of training Synalinks programs to optimize their performance on specific datasets. By leveraging the GSM8k dataset of grade school math word problems, we demonstrated how to train a language model application to improve its reasoning abilities and accuracy.</p>"},{"location":"Code%20Examples/Basics/Training%20Programs/#key-takeaways","title":"Key Takeaways","text":"<ul> <li> <p>Rewards: <code>Reward</code>s guide the reinforcement learning process by      providing feedback on the system's performance. They are typically     float values that indicate how well the system performed a task,      with the goal of maximizing the reward function during training.      Synalinks offers built-in rewards and allows for custom reward      functions to suit specific tasks.</p> </li> <li> <p>Metrics: <code>Metric</code>s are scalar values monitored during training     and evaluation to determine the best-performing program. Unlike     rewards, metrics are not used for backpropagation. They provide      additional insights for comparing different architectures and      saving the optimal model.</p> </li> <li> <p>Optimizers: <code>Optimizer</code>s update the module's state to improve     performance. They handle the backpropagation of rewards and      select or generate examples and instructions for the language models.     Proper configuration of optimizers is essential for effective     training.</p> </li> <li> <p>Filtering Outputs: When dealing with complex JSON outputs,      filtering predictions and ground truths using <code>out_mask</code> or      <code>in_mask</code> parameters ensures that only relevant fields are      evaluated. This is particularly useful when the training data      includes a subset of the JSON or when additional fields are     used to aid the language models.</p> </li> </ul>"},{"location":"Deployment/Building%20a%20REST%20API/","title":"Building a REST API","text":"<p>The optimal approach to developing web-apps or micro-services using Synalinks involves building REST APIs and deploying them. You can deploy these APIs locally to test your system or on a cloud provider of your choice to scale to millions of users.</p> <p>For this purpose, you will need to use FastAPI, a Python library that makes it easy and straightforward to create REST APIs. If you use the default backend, the DataModel will be compatible with FastAPI as their both use Pydantic.</p> <p>In this tutorial we are going to make a backend that run locally to test our system.</p>"},{"location":"Deployment/Building%20a%20REST%20API/#project-structure","title":"Project structure","text":"<p>Your project structure should look like this:</p> <pre><code>demo/\n\u251c\u2500\u2500 backend/\n\u2502   \u251c\u2500\u2500 app/\n\u2502   \u2502   \u251c\u2500\u2500 checkpoint.program.json\n\u2502   \u2502   \u2514\u2500\u2500 main.py\n\u2502   \u251c\u2500\u2500 requirements.txt\n\u2502   \u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 frontend/\n\u2502   \u2514\u2500\u2500 ... (your frontend code)\n\u251c\u2500\u2500 scripts/\n\u2502   \u2514\u2500\u2500 train.py (refer to the code examples to learn how to train programs)\n\u251c\u2500\u2500 docker-compose.yml\n\u251c\u2500\u2500 .env.backend\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"Deployment/Building%20a%20REST%20API/#your-requirementstxt-file","title":"Your <code>requirements.txt</code> file","text":"<p>Import additionally any necessary dependency</p> requirements.txt<pre><code>fastapi[standard]\nuvicorn\nsynalinks\nopeninference-instrumentation-litellm\narize-otel\n</code></pre>"},{"location":"Deployment/Building%20a%20REST%20API/#creating-your-endpoint-using-fastapi-and-synalinks","title":"Creating your endpoint using FastAPI and SynaLinks","text":"<p>Now you can create you endpoint using FastAPI.</p> main.py<pre><code>import argparse\nimport logging\nimport os\nimport uvicorn\nfrom dotenv import load_dotenv\nfrom fastapi import FastAPI\n\nimport synalinks\n\n# Import open-telemetry dependencies\nfrom arize.otel import register\nfrom openinference.instrumentation.litellm import LiteLLMInstrumentor\n\n# Load the environment variables\nload_dotenv()\n\n# Setup OTel via Arize Phoenix convenience function\ntracer_provider = register(\n    space_id = os.environ[\"ARIZE_SPACE_ID\"], # in app space settings page\n    api_key = os.environ[\"ARIZE_API_KEY\"], # in app space settings page\n    project_name = os.environ[\"ARIZE_PROJECT_NAME\"], # name this to whatever you would like\n)\n\nLiteLLMInstrumentor().instrument(tracer_provider=tracer_provider)\n\n# Set up logging\nlogger = logging.getLogger(__name__)\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n)\n# Set up FastAPI\napp = FastAPI()\n\n# The dictionary mapping the name of your custom modules to their class\ncustom_modules = {}\n\n# Load your program\nprogram = synalinks.Program.load(\n    \"checkpoint.program.json\",\n    custom_modules=custom_modules,\n)\n\n@app.post(\"/v1/chat_completion\")\nasync def chat_completion(messages: synalinks.ChatMessages):\n    logger.info(messages.pretty_json())\n    try:\n        result = await program(messages)\n        if result:\n            logger.info(result.prettify_json())\n            return result.get_json()\n        else:\n            return None\n    except Exception as e:\n        logger.error(f\"Error occured: {str(e)}\")\n        return None\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--host\", type=str, default=\"127.0.0.1\")\n    parser.add_argument(\"--port\", type=int, default=8000)\n    args = parser.parse_args()\n    uvicorn.run(app, host=args.host, port=args.port)\n</code></pre>"},{"location":"Deployment/Building%20a%20REST%20API/#creating-the-dockerfile","title":"Creating the Dockerfile","text":"<p>Here is the dockerfile to use according to FastAPI documentation.</p> Dockerfile<pre><code>FROM python:3.13\n\nWORKDIR /code\n\nCOPY ./requirements.txt /code/requirements.txt\n\nRUN pip install --no-cache-dir --upgrade -r /code/requirements.txt\n\nCOPY ./app /code/app\n\nCMD [\"fastapi\", \"run\", \"app/main.py\", \"--port\", \"8000\"]\n</code></pre>"},{"location":"Deployment/Building%20a%20REST%20API/#the-docker-compose-file","title":"The docker compose file","text":"<p>And finally your docker compose file.</p> docker-compose.yml<pre><code>services:\n  arizephoenix:\n    image: arizephoenix/phoenix:latest\n    ports:\n      - \"6006:6006\"\n      - \"4317:4317\"\n  backend:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    ports:\n      - \"8000:8000\"\n    env_file:\n      - .env.backend\n    depends_on:\n      - arizephoenix\n</code></pre>"},{"location":"Deployment/Building%20a%20REST%20API/#launching-your-backend","title":"Launching your backend","text":"<p>Launch your backend using <code>docker compose</code></p> <pre><code>cd demo\ndocker compose up\n</code></pre> <p>Open you browser to <code>http://0.0.0.0:8000/docs</code> and test your API with the FastAPI UI</p>"},{"location":"Deployment/Enabling%20LM%20Tracing/","title":"Enabling LM Tracing with Arize Phoenix","text":"<p>Tracing is important for several reasons, especially in the context of machine learning and software development. It helps identify issues and bugs in your Synalinks programs by providing a detailed log of events and operations. This makes it easier to pinpoint where things went wrong and why.</p> <p>In this guide we are going to setup the tracing locally, for more information on how to setup in the cloud, refer to Arize Phoenix documentation</p> <pre><code>uv pip install openinference-instrumentation-litellm arize-otel\n</code></pre> <p>To activate the LM tracing, add the following lines to the top of your script</p> <pre><code># Import open-telemetry dependencies\nfrom arize.otel import register\nfrom openinference.instrumentation.litellm import LiteLLMInstrumentor\n\n# Setup OTel via Arize Phoenix convenience function\ntracer_provider = register(\n    space_id = \"your-space-id\", # in app space settings page\n    api_key = \"your-api-key\", # in app space settings page\n    project_name = \"your-project-name\", # name this to whatever you would like\n)\n\nLiteLLMInstrumentor().instrument(tracer_provider=tracer_provider)\n</code></pre> <p>You are done, Arize Phoenix is now configured.</p> <p>To launch Arize Phoenix server, first pull the docker image with the following command.</p> <pre><code>docker pull arizephoenix/phoenix\n</code></pre> <p>Then use the following command in a shell</p> <pre><code>docker run -p 6006:6006 -p 4317:4317 -i -t arizephoenix/phoenix:latest\n</code></pre> <p>Finally go to <code>http://0.0.0.0:6006</code> to monitor your application.</p>"},{"location":"Synalinks%20API/Config/","title":"Config","text":""},{"location":"Synalinks%20API/Config/#synalinks.src.backend.common.global_state.clear_session","title":"<code>clear_session(free_memory=True)</code>","text":"<p>Resets all state generated by synalinks.</p> <p>synalinks manages a global state, which it uses to implement the Functional model-building API and to uniquify autogenerated modules names.</p> <p>If you are creating many models in a loop, this global state will consume an increasing amount of memory over time, and you may want to clear it. Calling <code>clear_session()</code> releases the global state: this helps avoid clutter from old programs and modules, especially when memory is limited.</p> <p>Parameters:</p> Name Type Description Default <code>free_memory</code> <code>bool</code> <p>Whether to call Python garbage collection. It's usually a good practice to call it to make sure memory used by deleted objects is immediately freed. However, it may take a few seconds to execute, so when using <code>clear_session()</code> in a short loop, you may want to skip it.</p> <code>True</code> Source code in <code>synalinks/src/backend/common/global_state.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.utils.clear_session\",\n        \"synalinks.backend.clear_session\",\n        \"synalinks.clear_session\",\n    ]\n)\ndef clear_session(free_memory=True):\n    \"\"\"Resets all state generated by synalinks.\n\n    synalinks manages a global state, which it uses to implement the Functional\n    model-building API and to uniquify autogenerated modules names.\n\n    If you are creating many models in a loop, this global state will consume\n    an increasing amount of memory over time, and you may want to clear it.\n    Calling `clear_session()` releases the global state: this helps avoid\n    clutter from old programs and modules, especially when memory is limited.\n\n    Args:\n        free_memory (bool): Whether to call Python garbage collection.\n            It's usually a good practice to call it to make sure\n            memory used by deleted objects is immediately freed.\n            However, it may take a few seconds to execute, so\n            when using `clear_session()` in a short loop,\n            you may want to skip it.\n    \"\"\"\n    global GLOBAL_STATE_TRACKER\n    global GLOBAL_SETTINGS_TRACKER\n\n    GLOBAL_STATE_TRACKER = threading.local()\n    GLOBAL_SETTINGS_TRACKER = threading.local()\n\n    if free_memory:\n        # Manually trigger garbage collection.\n        gc.collect()\n</code></pre>"},{"location":"Synalinks%20API/Config/#synalinks.src.backend.config.api_key","title":"<code>api_key()</code>","text":"<p>Synalinks API key.</p> <p>Returns:</p> Type Description <code>str</code> <p>Synalinks API key.</p> <pre><code>&gt;&gt;&gt; synalinks.config.api_key()\n'my-secret-api-key'\n</code></pre> Source code in <code>synalinks/src/backend/config.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.config.api_key\",\n        \"synalinks.backend.api_key\",\n    ]\n)\ndef api_key():\n    \"\"\"Synalinks API key.\n\n    Returns:\n        (str): Synalinks API key.\n\n    ```python\n    &gt;&gt;&gt; synalinks.config.api_key()\n    'my-secret-api-key'\n    ```\n\n    \"\"\"\n    return _SYNALINKS_API_KEY\n</code></pre>"},{"location":"Synalinks%20API/Config/#synalinks.src.backend.config.backend","title":"<code>backend()</code>","text":"<p>Publicly accessible method for determining the current backend.</p> <p>Returns:</p> Type Description <code>str</code> <p>The name of the backend synalinks is currently using. like <code>\"pydantic\"</code>.</p> <p>Example:</p> <pre><code>&gt;&gt;&gt; synalinks.config.backend()\n'pydantic'\n</code></pre> Source code in <code>synalinks/src/backend/config.py</code> <pre><code>@synalinks_export([\"synalinks.config.backend\", \"synalinks.backend.backend\"])\ndef backend():\n    \"\"\"Publicly accessible method for determining the current backend.\n\n    Returns:\n        (str): The name of the backend synalinks is currently using. like\n            `\"pydantic\"`.\n\n    Example:\n\n    ```python\n    &gt;&gt;&gt; synalinks.config.backend()\n    'pydantic'\n    ```\n    \"\"\"\n    return _BACKEND\n</code></pre>"},{"location":"Synalinks%20API/Config/#synalinks.src.backend.config.disable_telemetry","title":"<code>disable_telemetry()</code>","text":"<p>Disable the telemetry</p> Source code in <code>synalinks/src/backend/config.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.config.disable_telemetry\",\n        \"synalinks.disable_telemetry\",\n    ]\n)\ndef disable_telemetry():\n    \"\"\"Disable the telemetry\"\"\"\n    global _synalinks_telemetry_enabled\n    _synalinks_telemetry_enabled = False\n</code></pre>"},{"location":"Synalinks%20API/Config/#synalinks.src.backend.config.epsilon","title":"<code>epsilon()</code>","text":"<p>Return the value of the fuzz factor used in numeric expressions.</p> <p>Returns:</p> Type Description <code>float</code> <p>The epsilon value.</p> <p>Example:</p> <pre><code>&gt;&gt;&gt; synalinks.config.epsilon()\n1e-07\n</code></pre> Source code in <code>synalinks/src/backend/config.py</code> <pre><code>@synalinks_export([\"synalinks.config.epsilon\", \"synalinks.backend.epsilon\"])\ndef epsilon():\n    \"\"\"Return the value of the fuzz factor used in numeric expressions.\n\n    Returns:\n        (float): The epsilon value.\n\n    Example:\n\n    ```python\n    &gt;&gt;&gt; synalinks.config.epsilon()\n    1e-07\n    ```\n\n    \"\"\"\n    return _EPSILON\n</code></pre>"},{"location":"Synalinks%20API/Config/#synalinks.src.backend.config.floatx","title":"<code>floatx()</code>","text":"<p>Return the default float type, as a string.</p> <p>E.g. <code>'bfloat16'</code>, <code>'float16'</code>, <code>'float32'</code>, <code>'float64'</code>.</p> <p>Returns:</p> Type Description <code>str</code> <p>The current default float type.</p> <p>Example:</p> <pre><code>&gt;&gt;&gt; synalinks.config.floatx()\n'float32'\n</code></pre> Source code in <code>synalinks/src/backend/config.py</code> <pre><code>@synalinks_export([\"synalinks.config.floatx\", \"synalinks.backend.floatx\"])\ndef floatx():\n    \"\"\"Return the default float type, as a string.\n\n    E.g. `'bfloat16'`, `'float16'`, `'float32'`, `'float64'`.\n\n    Returns:\n        (str): The current default float type.\n\n    Example:\n\n    ```python\n    &gt;&gt;&gt; synalinks.config.floatx()\n    'float32'\n    ```\n\n    \"\"\"\n    return _FLOATX\n</code></pre>"},{"location":"Synalinks%20API/Config/#synalinks.src.backend.config.is_telemetry_enabled","title":"<code>is_telemetry_enabled()</code>","text":"<p>Return wether of not the telemetry is enabled</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the telemetry is enabled False otherwise.</p> Source code in <code>synalinks/src/backend/config.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.config.is_telemetry_enabled\",\n        \"synalinks.backend.is_telemetry_enabled\",\n    ]\n)\ndef is_telemetry_enabled():\n    \"\"\"Return wether of not the telemetry is enabled\n\n    Returns:\n        (bool): True if the telemetry is enabled False otherwise.\n    \"\"\"\n    return _synalinks_telemetry_enabled\n</code></pre>"},{"location":"Synalinks%20API/Config/#synalinks.src.backend.config.set_api_key","title":"<code>set_api_key(key)</code>","text":"<p>Set Synalinks API key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The API key value.</p> required <p>The API key is retrieved from the env variables at start.</p> <pre><code>&gt;&gt;&gt; os.environ[\"SYNALINKS_API_KEY\"] = 'my-secret-api-key'\n</code></pre> <p>Or you can setup it using the config</p> <pre><code>&gt;&gt;&gt; synalinks.config.set_api_key('my-secret-api-key')\n&gt;&gt;&gt; synalinks.config.api_key()\n'my-secret-api-key'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Synalinks API key.</p> required Source code in <code>synalinks/src/backend/config.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.config.set_api_key\",\n        \"synalinks.backend.set_api_key\",\n    ]\n)\ndef set_api_key(key):\n    \"\"\"Set Synalinks API key.\n\n    Args:\n        key (str): The API key value.\n\n    The API key is retrieved from the env variables at start.\n\n    ```python\n    &gt;&gt;&gt; os.environ[\"SYNALINKS_API_KEY\"] = 'my-secret-api-key'\n    ```\n\n    Or you can setup it using the config\n\n    ```python\n    &gt;&gt;&gt; synalinks.config.set_api_key('my-secret-api-key')\n    &gt;&gt;&gt; synalinks.config.api_key()\n    'my-secret-api-key'\n    ```\n\n    Args:\n        key (str): Synalinks API key.\n    \"\"\"\n    global _SYNALINKS_API_KEY\n    _SYNALINKS_API_KEY = key\n</code></pre>"},{"location":"Synalinks%20API/Config/#synalinks.src.backend.config.set_epsilon","title":"<code>set_epsilon(value)</code>","text":"<p>Set the value of the fuzz factor used in numeric expressions.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>float</code> <p>The new value of epsilon.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; synalinks.config.epsilon()\n1e-07\n</code></pre> <pre><code>&gt;&gt;&gt; synalinks.config.set_epsilon(1e-5)\n&gt;&gt;&gt; synalinks.config.epsilon()\n1e-05\n</code></pre> <pre><code>&gt;&gt;&gt; # Set it back to the default value.\n&gt;&gt;&gt; synalinks.config.set_epsilon(1e-7)\n</code></pre> Source code in <code>synalinks/src/backend/config.py</code> <pre><code>@synalinks_export([\"synalinks.config.set_epsilon\", \"synalinks.backend.set_epsilon\"])\ndef set_epsilon(value):\n    \"\"\"Set the value of the fuzz factor used in numeric expressions.\n\n    Args:\n        value (float): The new value of epsilon.\n\n    Examples:\n\n    ```python\n    &gt;&gt;&gt; synalinks.config.epsilon()\n    1e-07\n    ```\n\n    ```python\n    &gt;&gt;&gt; synalinks.config.set_epsilon(1e-5)\n    &gt;&gt;&gt; synalinks.config.epsilon()\n    1e-05\n    ```\n\n    ```python\n    &gt;&gt;&gt; # Set it back to the default value.\n    &gt;&gt;&gt; synalinks.config.set_epsilon(1e-7)\n    ```\n\n    \"\"\"\n    global _EPSILON\n    _EPSILON = value\n</code></pre>"},{"location":"Synalinks%20API/Config/#synalinks.src.backend.config.set_floatx","title":"<code>set_floatx(value)</code>","text":"<p>Set the default float dtype.</p> <p>Note: It is not recommended to set this to <code>\"float16\"</code>, as this will likely cause numeric stability issues. Instead, use <code>float64</code> or <code>float32</code>.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>The float type between <code>'bfloat16'</code>, <code>'float16'</code>, <code>'float32'</code>, or <code>'float64'</code>.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; synalinks.config.floatx()\n'float32'\n</code></pre> <pre><code>&gt;&gt;&gt; synalinks.config.set_floatx('float64')\n&gt;&gt;&gt; synalinks.config.floatx()\n'float64'\n</code></pre> <pre><code>&gt;&gt;&gt; # Set it back to float32\n&gt;&gt;&gt; synalinks.config.set_floatx('float32')\n</code></pre> <p>Raises:</p> Type Description <code>ValueError</code> <p>In case of invalid value.</p> Source code in <code>synalinks/src/backend/config.py</code> <pre><code>@synalinks_export([\"synalinks.config.set_floatx\", \"synalinks.backend.set_floatx\"])\ndef set_floatx(value):\n    \"\"\"Set the default float dtype.\n\n    Note: It is not recommended to set this to `\"float16\"`,\n    as this will likely cause numeric stability issues.\n    Instead, use `float64` or `float32`.\n\n    Args:\n        value (str): The float type between `'bfloat16'`, `'float16'`, `'float32'`,\n            or `'float64'`.\n\n    Examples:\n\n    ```python\n    &gt;&gt;&gt; synalinks.config.floatx()\n    'float32'\n    ```\n\n    ```python\n    &gt;&gt;&gt; synalinks.config.set_floatx('float64')\n    &gt;&gt;&gt; synalinks.config.floatx()\n    'float64'\n    ```\n\n    ```python\n    &gt;&gt;&gt; # Set it back to float32\n    &gt;&gt;&gt; synalinks.config.set_floatx('float32')\n    ```\n\n    Raises:\n        ValueError: In case of invalid value.\n    \"\"\"\n    global _FLOATX\n    accepted_dtypes = {\"bfloat16\", \"float16\", \"float32\", \"float64\"}\n    if value not in accepted_dtypes:\n        raise ValueError(\n            f\"Unknown `floatx` value: {value}. Expected one of {accepted_dtypes}\"\n        )\n    _FLOATX = str(value)\n</code></pre>"},{"location":"Synalinks%20API/Embedding%20Models%20API/","title":"Embedding Models API","text":""},{"location":"Synalinks%20API/Embedding%20Models%20API/#synalinks.src.embedding_models.embedding_model.EmbeddingModel","title":"<code>EmbeddingModel</code>","text":"<p>               Bases: <code>SynalinksSaveable</code></p> <p>An embedding model API wrapper.</p> <p>Embedding models are a type of machine learning model used to convert high-dimensional data, such as text into lower-dimensional vector representations while preserving the semantic meaning and relationships within the data. These vector representations, known as embeddings, allow for more efficient and effective processing in various tasks.</p> <p>Many providers are available like OpenAI, Azure OpenAI, Vertex AI or Ollama.</p> <p>For the complete list of models, please refer to the providers documentation.</p> <p>Using OpenAI models</p> <pre><code>import synalinks\nimport os\n\nos.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n\nembedding_model = synalinks.EmbeddingModel(\n    model=\"openai/text-embedding-ada-002\",\n)\n</code></pre> <p>Using Azure OpenAI models</p> <pre><code>import synalinks\nimport os\n\nos.environ[\"AZURE_API_KEY\"] = \"your-api-key\"\nos.environ[\"AZURE_API_BASE\"] = \"your-api-base\"\nos.environ[\"AZURE_API_VERSION\"] = \"your-api-version\"\n\nembedding_model = synalinks.EmbeddingModel(\n    model=\"azure/&lt;your_deployment_name&gt;\",\n)\n</code></pre> <p>Using VertexAI models</p> <pre><code>import synalinks\nimport os\n\nembedding_model = synalinks.EmbeddingModel(\n    model=\"vertex_ai/text-embedding-004\",\n    vertex_project = \"hardy-device-38811\", # Your Project ID\n    vertex_location = \"us-central1\",  # Project location\n)\n</code></pre> <p>Using Ollama models</p> <pre><code>import synalinks\n\nembedding_model = synalinks.EmbeddingModel(\n    model=\"ollama/mxbai-embed-large\",\n)\n</code></pre> <p>Note: Obviously, use an <code>.env</code> file and <code>.gitignore</code> to avoid putting your API keys in the code or a config file that can lead to leackage when pushing it into repositories.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>The model to use.</p> <code>None</code> <code>api_base</code> <code>str</code> <p>Optional. The endpoint to use.</p> <code>None</code> <code>retry</code> <code>int</code> <p>Optional. The number of retry.</p> <code>5</code> <code>fallback</code> <code>EmbeddingModel</code> <p>Optional. The embedding model to fallback if anything is wrong.</p> <code>None</code> Source code in <code>synalinks/src/embedding_models/embedding_model.py</code> <pre><code>@synalinks_export(\n    [\"synalinks.EmbeddingModel\", \"synalinks.embedding_models.EmbeddingModel\"]\n)\nclass EmbeddingModel(SynalinksSaveable):\n    \"\"\"An embedding model API wrapper.\n\n    Embedding models are a type of machine learning model used to convert\n    high-dimensional data, such as text into lower-dimensional vector\n    representations while preserving the semantic meaning and relationships\n    within the data. These vector representations, known as embeddings,\n    allow for more efficient and effective processing in various tasks.\n\n    Many providers are available like OpenAI, Azure OpenAI, Vertex AI or Ollama.\n\n    For the complete list of models, please refer to the providers documentation.\n\n    **Using OpenAI models**\n\n    ```python\n    import synalinks\n    import os\n\n    os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n\n    embedding_model = synalinks.EmbeddingModel(\n        model=\"openai/text-embedding-ada-002\",\n    )\n    ```\n\n    **Using Azure OpenAI models**\n\n    ```python\n    import synalinks\n    import os\n\n    os.environ[\"AZURE_API_KEY\"] = \"your-api-key\"\n    os.environ[\"AZURE_API_BASE\"] = \"your-api-base\"\n    os.environ[\"AZURE_API_VERSION\"] = \"your-api-version\"\n\n    embedding_model = synalinks.EmbeddingModel(\n        model=\"azure/&lt;your_deployment_name&gt;\",\n    )\n    ```\n\n    **Using VertexAI models**\n\n    ```python\n    import synalinks\n    import os\n\n    embedding_model = synalinks.EmbeddingModel(\n        model=\"vertex_ai/text-embedding-004\",\n        vertex_project = \"hardy-device-38811\", # Your Project ID\n        vertex_location = \"us-central1\",  # Project location\n    )\n    ```\n\n    **Using Ollama models**\n\n    ```python\n    import synalinks\n\n    embedding_model = synalinks.EmbeddingModel(\n        model=\"ollama/mxbai-embed-large\",\n    )\n    ```\n\n    **Note**: Obviously, use an `.env` file and `.gitignore` to avoid\n    putting your API keys in the code or a config file that can lead to\n    leackage when pushing it into repositories.\n\n    Args:\n        model (str): The model to use.\n        api_base (str): Optional. The endpoint to use.\n        retry (int): Optional. The number of retry.\n        fallback (EmbeddingModel): Optional. The embedding model to fallback\n            if anything is wrong.\n    \"\"\"\n\n    def __init__(\n        self,\n        model=None,\n        api_base=None,\n        retry=5,\n        fallback=None,\n    ):\n        if model is None:\n            raise ValueError(\n                \"You need to set the `model` argument for any EmbeddingModel\"\n            )\n        self.model = model\n        if self.model.startswith(\"ollama\") and not api_base:\n            self.api_base = \"http://localhost:11434\"\n        else:\n            self.api_base = api_base\n        self.retry = retry\n        self.fallback = fallback\n\n    async def __call__(self, texts, **kwargs):\n        \"\"\"\n        Call method to get dense embeddings vectors\n\n        Args:\n            texts (list): A list of texts to embed.\n\n        Returns:\n            (list): The list of corresponding vectors.\n        \"\"\"\n        maybe_initialize_telemetry()\n\n        for i in range(self.retry):\n            try:\n                if self.api_base:\n                    response = litellm.embedding(\n                        model=self.model,\n                        input=texts,\n                        api_base=self.api_base,\n                        **kwargs,\n                    )\n                else:\n                    response = litellm.embedding(\n                        model=self.model,\n                        input=texts,\n                        **kwargs,\n                    )\n                vectors = []\n                for data in response[\"data\"]:\n                    vectors.append(data[\"embedding\"])\n                return {\"embeddings\": vectors}\n            except Exception as e:\n                warnings.warn(f\"Error occured while trying to call {self}: \" + str(e))\n                capture_exception(e)\n        if self.fallback:\n            return self.fallback(\n                texts,\n                **kwargs,\n            )\n        else:\n            return None\n\n    def _obj_type(self):\n        return \"EmbeddingModel\"\n\n    def get_config(self):\n        config = {\n            \"model\": self.model,\n            \"api_base\": self.api_base,\n            \"retry\": self.retry,\n        }\n        if self.fallback:\n            fallback_config = {\n                \"fallback\": serialization_lib.serialize_synalinks_object(\n                    self.fallback,\n                )\n            }\n            return {**fallback_config, **config}\n        else:\n            return config\n\n    @classmethod\n    def from_config(cls, config):\n        if \"fallback\" in config:\n            fallback = serialization_lib.deserialize_synalinks_object(\n                config.pop(\"fallback\")\n            )\n            return cls(fallback=fallback, **config)\n        else:\n            return cls(**config)\n\n    def __repr__(self):\n        api_base = f\" api_base={self.api_base}\" if self.api_base else \"\"\n        return f\"&lt;EmbeddingModel model={self.model}{api_base}&gt;\"\n</code></pre>"},{"location":"Synalinks%20API/Embedding%20Models%20API/#synalinks.src.embedding_models.embedding_model.EmbeddingModel.__call__","title":"<code>__call__(texts, **kwargs)</code>  <code>async</code>","text":"<p>Call method to get dense embeddings vectors</p> <p>Parameters:</p> Name Type Description Default <code>texts</code> <code>list</code> <p>A list of texts to embed.</p> required <p>Returns:</p> Type Description <code>list</code> <p>The list of corresponding vectors.</p> Source code in <code>synalinks/src/embedding_models/embedding_model.py</code> <pre><code>async def __call__(self, texts, **kwargs):\n    \"\"\"\n    Call method to get dense embeddings vectors\n\n    Args:\n        texts (list): A list of texts to embed.\n\n    Returns:\n        (list): The list of corresponding vectors.\n    \"\"\"\n    maybe_initialize_telemetry()\n\n    for i in range(self.retry):\n        try:\n            if self.api_base:\n                response = litellm.embedding(\n                    model=self.model,\n                    input=texts,\n                    api_base=self.api_base,\n                    **kwargs,\n                )\n            else:\n                response = litellm.embedding(\n                    model=self.model,\n                    input=texts,\n                    **kwargs,\n                )\n            vectors = []\n            for data in response[\"data\"]:\n                vectors.append(data[\"embedding\"])\n            return {\"embeddings\": vectors}\n        except Exception as e:\n            warnings.warn(f\"Error occured while trying to call {self}: \" + str(e))\n            capture_exception(e)\n    if self.fallback:\n        return self.fallback(\n            texts,\n            **kwargs,\n        )\n    else:\n        return None\n</code></pre>"},{"location":"Synalinks%20API/Knowledge%20Bases%20API/","title":"Knowledge Bases API","text":""},{"location":"Synalinks%20API/Knowledge%20Bases%20API/#synalinks.src.knowledge_bases.knowledge_base.KnowledgeBase","title":"<code>KnowledgeBase</code>","text":"<p>               Bases: <code>SynalinksSaveable</code></p> <p>A generic graph knowledge base.</p> <p>Using Neo4j graph database</p> <pre><code>import synalinks\nimport os\n\nclass Document(synalinks.Entity):\n    title: str\n    content: str\n\nclass Chunk(synalinks.Entity):\n    content: str\n\nclass IsPartOf(synalinks.Relation):\n    source: Chunk\n    target: Document\n\nembedding_model = synalinks.EmbeddingModel(\n    model=\"ollama/mxbai-embed-large\"\n)\n\nos.environ[\"NEO4J_DATABASE\"] = \"your-neo4j-db\" # (Default to \"neo4j\")\nos.environ[\"NEO4J_USERNAME\"] = \"your-neo4j-username\" # (Default to \"neo4j\")\nos.environ[\"NEO4J_PASSWORD\"] = \"your-neo4j-password\" # (Default to \"neo4j\")\n\nknowledge_base = synalinks.KnowledgeBase(\n    index_name=\"neo4j://localhost:7687\",\n    entity_models=[Document, Chunk],\n    relation_models=[IsPartOf],\n    embedding_model=embedding_model,\n    metric=\"cosine\",\n    wipe_on_start=False,\n)\n</code></pre> <p>Note: Obviously, use an <code>.env</code> file and <code>.gitignore</code> to avoid putting your username and password in the code or a config file that can lead to leackage when pushing it into repositories.</p> <p>Parameters:</p> Name Type Description Default <code>index_name</code> <code>str</code> <p>The index name/url of the database.</p> <code>None</code> <code>entity_models</code> <code>list</code> <p>The entity models being a list of <code>Entity</code>.</p> <code>None</code> <code>relation_models</code> <code>list</code> <p>The relation models being a list of <code>Relation</code>.</p> <code>None</code> <code>embedding_model</code> <code>EmbeddingModel</code> <p>The embedding model.</p> <code>None</code> <code>metric</code> <code>str</code> <p>The metric to use for the vector index (<code>cosine</code> or <code>euclidean</code>).</p> <code>'cosine'</code> <code>wipe_on_start</code> <code>bool</code> <p>Wether or not to wipe the graph database at start (Default to False).</p> <code>False</code> Source code in <code>synalinks/src/knowledge_bases/knowledge_base.py</code> <pre><code>@synalinks_export(\"synalinks.KnowledgeBase\")\nclass KnowledgeBase(SynalinksSaveable):\n    \"\"\"A generic graph knowledge base.\n\n    **Using Neo4j graph database**\n\n    ```python\n    import synalinks\n    import os\n\n    class Document(synalinks.Entity):\n        title: str\n        content: str\n\n    class Chunk(synalinks.Entity):\n        content: str\n\n    class IsPartOf(synalinks.Relation):\n        source: Chunk\n        target: Document\n\n    embedding_model = synalinks.EmbeddingModel(\n        model=\"ollama/mxbai-embed-large\"\n    )\n\n    os.environ[\"NEO4J_DATABASE\"] = \"your-neo4j-db\" # (Default to \"neo4j\")\n    os.environ[\"NEO4J_USERNAME\"] = \"your-neo4j-username\" # (Default to \"neo4j\")\n    os.environ[\"NEO4J_PASSWORD\"] = \"your-neo4j-password\" # (Default to \"neo4j\")\n\n    knowledge_base = synalinks.KnowledgeBase(\n        index_name=\"neo4j://localhost:7687\",\n        entity_models=[Document, Chunk],\n        relation_models=[IsPartOf],\n        embedding_model=embedding_model,\n        metric=\"cosine\",\n        wipe_on_start=False,\n    )\n    ```\n\n    **Note**: Obviously, use an `.env` file and `.gitignore` to avoid putting\n    your username and password in the code or a config file that can lead to\n    leackage when pushing it into repositories.\n\n    Args:\n        index_name (str): The index name/url of the database.\n        entity_models (list): The entity models being a list of `Entity`.\n        relation_models (list): The relation models being a list of `Relation`.\n        embedding_model (EmbeddingModel): The embedding model.\n        metric (str): The metric to use for the vector index (`cosine` or `euclidean`).\n        wipe_on_start (bool): Wether or not to wipe the graph database at start\n            (Default to False).\n    \"\"\"\n\n    def __init__(\n        self,\n        index_name=None,\n        entity_models=None,\n        relation_models=None,\n        embedding_model=None,\n        metric=\"cosine\",\n        wipe_on_start=False,\n    ):\n        self.adapter = database_adapters.get(index_name)(\n            index_name=index_name,\n            entity_models=entity_models,\n            relation_models=relation_models,\n            embedding_model=embedding_model,\n            metric=metric,\n            wipe_on_start=wipe_on_start,\n        )\n        self.index_name = index_name\n        self.entity_models = entity_models\n        self.relation_models = relation_models\n        self.embedding_model = embedding_model\n        self.metric = metric\n        self.wipe_on_start = wipe_on_start\n\n    async def update(\n        self,\n        data_model,\n        threshold=0.8,\n    ):\n        \"\"\"Update the knowledge base with new data.\n\n        Adds or updates entities and relationships in the knowledge graph based on\n        the provided data model. Perform alignment operations to\n        merge similar entities.\n\n        Args:\n            data_model (JsonDataModel | DataModel): The data model containing entities\n                and relations to be added or updated in the knowledge base.\n                Should conform to the entity or relation models defined during\n                initialization.\n            threshold (float): Similarity threshold for entity alignment.\n                Entities with similarity above this threshold will be merged.\n                Should be between 0.0 and 1.0 (Defaults to 0.8).\n        \"\"\"\n        maybe_initialize_telemetry()\n        return await self.adapter.update(data_model)\n\n    async def query(self, query: str, params: Dict[str, Any] = None, **kwargs):\n        \"\"\"Execute a query against the knowledge base.\n\n        Args:\n            query (str): The Cypher query to execute. The format depends on the\n                underlying database adapter (e.g., Cypher for Neo4j).\n\n        Returns:\n            (GenericResult): the query results\n        \"\"\"\n        maybe_initialize_telemetry()\n        return await self.adapter.query(query, params=params, **kwargs)\n\n    async def similarity_search(\n        self,\n        similarity_search,\n        k=10,\n        threshold=0.8,\n    ):\n        \"\"\"Perform similarity search to find entities similar to the given text.\n\n        Uses vector embeddings to find entities in the knowledge base that are\n        semantically similar to the provided text query.\n\n        Args:\n            similarity_search (JsonDataModel): The `SimilaritySearch` data model.\n            k (int): Maximum number of similar entities to return.\n                Defaults to 10.\n            threshold (float): Minimum similarity score for results.\n                Entities with similarity below this threshold are excluded.\n                Should be between 0.0 and 1.0 (Defaults to 0.8).\n        \"\"\"\n        maybe_initialize_telemetry()\n        return await self.adapter.similarity_search(\n            similarity_search,\n            k=k,\n            threshold=threshold,\n        )\n\n    async def triplet_search(\n        self,\n        triplet_search,\n        k=10,\n        threshold=0.8,\n    ):\n        \"\"\"Search for triplets in the knowledge graph.\n\n        Finds relationship triplets in the knowledge base that match or are similar\n        to the provided triplet pattern.\n\n        Args:\n            triplet_search (JsonDataModel): The `TripletSearch` data model.\n            k (int): Maximum number of matching triplets to return.\n                (Defaults to 10).\n            threshold (float, optional): Minimum similarity score for triplet matches.\n                Triplets with similarity below this threshold are excluded.\n                Should be between 0.0 and 1.0. (Defaults to 0.8).\n        \"\"\"\n        maybe_initialize_telemetry()\n        return await self.adapter.triplet_search(\n            triplet_search,\n            k=k,\n            threshold=threshold,\n        )\n\n    def get_config(self):\n        config = {\n            \"index_name\": self.index_name,\n            \"metric\": self.metric,\n            \"wipe_on_start\": self.wipe_on_start,\n        }\n        entity_models_config = {\n            \"entity_models\": [\n                serialization_lib.serialize_synalinks_object(\n                    entity_model.to_symbolic_data_model()\n                )\n                if not is_symbolic_data_model(entity_model)\n                else serialization_lib.serialize_synalinks_object(entity_model)\n                for entity_model in self.entity_models\n            ]\n        }\n        relation_models_config = {\n            \"relation_models\": [\n                serialization_lib.serialize_synalinks_object(\n                    relation_model.to_symbolic_data_model()\n                )\n                if not is_symbolic_data_model(relation_model)\n                else serialization_lib.serialize_synalinks_object(relation_model)\n                for relation_model in self.relation_models\n            ]\n        }\n        embedding_model_config = {\n            \"embedding_model\": serialization_lib.serialize_synalinks_object(\n                self.embedding_model,\n            )\n        }\n        return {\n            **entity_models_config,\n            **relation_models_config,\n            **embedding_model_config,\n            **config,\n        }\n\n    @classmethod\n    def from_config(cls, config):\n        entity_models_config = config.pop(\"entity_models\")\n        entity_models = [\n            serialization_lib.deserialize_synalinks_object(entity_model)\n            for entity_model in entity_models_config\n        ]\n        relation_models_config = config.pop(\"relation_models\")\n        relation_models = [\n            serialization_lib.deserialize_synalinks_object(relation_model)\n            for relation_model in relation_models_config\n        ]\n        embedding_model = serialization_lib.deserialize_synalinks_object(\n            config.pop(\"embedding_model\"),\n        )\n        return cls(\n            entity_models=entity_models,\n            relation_models=relation_models,\n            embedding_model=embedding_model,\n            **config,\n        )\n</code></pre>"},{"location":"Synalinks%20API/Knowledge%20Bases%20API/#synalinks.src.knowledge_bases.knowledge_base.KnowledgeBase.query","title":"<code>query(query, params=None, **kwargs)</code>  <code>async</code>","text":"<p>Execute a query against the knowledge base.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The Cypher query to execute. The format depends on the underlying database adapter (e.g., Cypher for Neo4j).</p> required <p>Returns:</p> Type Description <code>GenericResult</code> <p>the query results</p> Source code in <code>synalinks/src/knowledge_bases/knowledge_base.py</code> <pre><code>async def query(self, query: str, params: Dict[str, Any] = None, **kwargs):\n    \"\"\"Execute a query against the knowledge base.\n\n    Args:\n        query (str): The Cypher query to execute. The format depends on the\n            underlying database adapter (e.g., Cypher for Neo4j).\n\n    Returns:\n        (GenericResult): the query results\n    \"\"\"\n    maybe_initialize_telemetry()\n    return await self.adapter.query(query, params=params, **kwargs)\n</code></pre>"},{"location":"Synalinks%20API/Knowledge%20Bases%20API/#synalinks.src.knowledge_bases.knowledge_base.KnowledgeBase.similarity_search","title":"<code>similarity_search(similarity_search, k=10, threshold=0.8)</code>  <code>async</code>","text":"<p>Perform similarity search to find entities similar to the given text.</p> <p>Uses vector embeddings to find entities in the knowledge base that are semantically similar to the provided text query.</p> <p>Parameters:</p> Name Type Description Default <code>similarity_search</code> <code>JsonDataModel</code> <p>The <code>SimilaritySearch</code> data model.</p> required <code>k</code> <code>int</code> <p>Maximum number of similar entities to return. Defaults to 10.</p> <code>10</code> <code>threshold</code> <code>float</code> <p>Minimum similarity score for results. Entities with similarity below this threshold are excluded. Should be between 0.0 and 1.0 (Defaults to 0.8).</p> <code>0.8</code> Source code in <code>synalinks/src/knowledge_bases/knowledge_base.py</code> <pre><code>async def similarity_search(\n    self,\n    similarity_search,\n    k=10,\n    threshold=0.8,\n):\n    \"\"\"Perform similarity search to find entities similar to the given text.\n\n    Uses vector embeddings to find entities in the knowledge base that are\n    semantically similar to the provided text query.\n\n    Args:\n        similarity_search (JsonDataModel): The `SimilaritySearch` data model.\n        k (int): Maximum number of similar entities to return.\n            Defaults to 10.\n        threshold (float): Minimum similarity score for results.\n            Entities with similarity below this threshold are excluded.\n            Should be between 0.0 and 1.0 (Defaults to 0.8).\n    \"\"\"\n    maybe_initialize_telemetry()\n    return await self.adapter.similarity_search(\n        similarity_search,\n        k=k,\n        threshold=threshold,\n    )\n</code></pre>"},{"location":"Synalinks%20API/Knowledge%20Bases%20API/#synalinks.src.knowledge_bases.knowledge_base.KnowledgeBase.triplet_search","title":"<code>triplet_search(triplet_search, k=10, threshold=0.8)</code>  <code>async</code>","text":"<p>Search for triplets in the knowledge graph.</p> <p>Finds relationship triplets in the knowledge base that match or are similar to the provided triplet pattern.</p> <p>Parameters:</p> Name Type Description Default <code>triplet_search</code> <code>JsonDataModel</code> <p>The <code>TripletSearch</code> data model.</p> required <code>k</code> <code>int</code> <p>Maximum number of matching triplets to return. (Defaults to 10).</p> <code>10</code> <code>threshold</code> <code>float</code> <p>Minimum similarity score for triplet matches. Triplets with similarity below this threshold are excluded. Should be between 0.0 and 1.0. (Defaults to 0.8).</p> <code>0.8</code> Source code in <code>synalinks/src/knowledge_bases/knowledge_base.py</code> <pre><code>async def triplet_search(\n    self,\n    triplet_search,\n    k=10,\n    threshold=0.8,\n):\n    \"\"\"Search for triplets in the knowledge graph.\n\n    Finds relationship triplets in the knowledge base that match or are similar\n    to the provided triplet pattern.\n\n    Args:\n        triplet_search (JsonDataModel): The `TripletSearch` data model.\n        k (int): Maximum number of matching triplets to return.\n            (Defaults to 10).\n        threshold (float, optional): Minimum similarity score for triplet matches.\n            Triplets with similarity below this threshold are excluded.\n            Should be between 0.0 and 1.0. (Defaults to 0.8).\n    \"\"\"\n    maybe_initialize_telemetry()\n    return await self.adapter.triplet_search(\n        triplet_search,\n        k=k,\n        threshold=threshold,\n    )\n</code></pre>"},{"location":"Synalinks%20API/Knowledge%20Bases%20API/#synalinks.src.knowledge_bases.knowledge_base.KnowledgeBase.update","title":"<code>update(data_model, threshold=0.8)</code>  <code>async</code>","text":"<p>Update the knowledge base with new data.</p> <p>Adds or updates entities and relationships in the knowledge graph based on the provided data model. Perform alignment operations to merge similar entities.</p> <p>Parameters:</p> Name Type Description Default <code>data_model</code> <code>JsonDataModel | DataModel</code> <p>The data model containing entities and relations to be added or updated in the knowledge base. Should conform to the entity or relation models defined during initialization.</p> required <code>threshold</code> <code>float</code> <p>Similarity threshold for entity alignment. Entities with similarity above this threshold will be merged. Should be between 0.0 and 1.0 (Defaults to 0.8).</p> <code>0.8</code> Source code in <code>synalinks/src/knowledge_bases/knowledge_base.py</code> <pre><code>async def update(\n    self,\n    data_model,\n    threshold=0.8,\n):\n    \"\"\"Update the knowledge base with new data.\n\n    Adds or updates entities and relationships in the knowledge graph based on\n    the provided data model. Perform alignment operations to\n    merge similar entities.\n\n    Args:\n        data_model (JsonDataModel | DataModel): The data model containing entities\n            and relations to be added or updated in the knowledge base.\n            Should conform to the entity or relation models defined during\n            initialization.\n        threshold (float): Similarity threshold for entity alignment.\n            Entities with similarity above this threshold will be merged.\n            Should be between 0.0 and 1.0 (Defaults to 0.8).\n    \"\"\"\n    maybe_initialize_telemetry()\n    return await self.adapter.update(data_model)\n</code></pre>"},{"location":"Synalinks%20API/Language%20Models%20API/","title":"Language Models API","text":""},{"location":"Synalinks%20API/Language%20Models%20API/#synalinks.src.language_models.language_model.LanguageModel","title":"<code>LanguageModel</code>","text":"<p>               Bases: <code>SynalinksSaveable</code></p> <p>A language model API wrapper.</p> <p>A language model is a type of AI model designed to generate, and interpret human language. It is trained on large amounts of text data to learn patterns and structures in language. Language models can perform various tasks such as text generation, translation, summarization, and answering questions.</p> <p>We support providers that implement constrained structured output like OpenAI, Azure, Ollama or Mistral. In addition we support providers that otherwise allow to constrain the use of a specific tool like Groq or Anthropic.</p> <p>For the complete list of models, please refer to the providers documentation.</p> <p>Using OpenAI models</p> <pre><code>import synalinks\nimport os\n\nos.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n\nlanguage_model = synalinks.LanguageModel(\n    model=\"openai/gpt-4o-mini\",\n)\n</code></pre> <p>Using Groq models</p> <pre><code>import synalinks\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = \"your-api-key\"\n\nlanguage_model = synalinks.LanguageModel(\n    model=\"groq/llama3-8b-8192\",\n)\n</code></pre> <p>Using Anthropic models</p> <pre><code>import synalinks\nimport os\n\nos.environ[\"ANTHROPIC_API_KEY\"] = \"your-api-key\"\n\nlanguage_model = synalinks.LanguageModel(\n    model=\"anthropic/claude-3-sonnet-20240229\",\n)\n</code></pre> <p>Using Mistral models</p> <pre><code>import synalinks\nimport os\n\nos.environ[\"MISTRAL_API_KEY\"] = \"your-api-key\"\n\nlanguage_model = synalinks.LanguageModel(\n    model=\"mistral/codestral-latest\",\n)\n</code></pre> <p>Using Ollama models</p> <pre><code>import synalinks\nimport os\n\nlanguage_model = synalinks.LanguageModel(\n    model=\"ollama/mistral\",\n)\n</code></pre> <p>Using Azure OpenAI models</p> <pre><code>import synalinks\nimport os\n\nos.environ[\"AZURE_API_KEY\"] = \"your-api-key\"\nos.environ[\"AZURE_API_BASE\"] = \"your-api-key\"\nos.environ[\"AZURE_API_VERSION\"] = \"your-api-key\"\n\nlanguage_model = synalinks.LanguageModel(\n    model=\"azure/&lt;your_deployment_name&gt;\",\n)\n</code></pre> <p>To cascade models to make the pipeline robust in case there is anything wrong with the model provider (hence making your pipelines more robust). Use the <code>fallback</code> argument like in this example:</p> <pre><code>import synalinks\nimport os\n\nos.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\nos.environ[\"ANTHROPIC_API_KEY\"] = \"your-api-key\"\n\nlanguage_model = synalinks.LanguageModel(\n    model=\"anthropic/claude-3-sonnet-20240229\",\n    fallback=synalinks.LanguageModel(\n        model=\"openai/gpt-4o-mini\",\n    )\n)\n</code></pre> <p>Note: Obviously, use an <code>.env</code> file and <code>.gitignore</code> to avoid putting your API keys in the code or a config file that can lead to leackage when pushing it into repositories.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>The model to use.</p> <code>None</code> <code>api_base</code> <code>str</code> <p>Optional. The endpoint to use.</p> <code>None</code> <code>retry</code> <code>int</code> <p>Optional. The number of retry (default to 5).</p> <code>5</code> <code>fallback</code> <code>LanguageModel</code> <p>Optional. The language model to fallback if anything is wrong.</p> <code>None</code> Source code in <code>synalinks/src/language_models/language_model.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.LanguageModel\",\n        \"synalinks.language_models.LanguageModel\",\n    ]\n)\nclass LanguageModel(SynalinksSaveable):\n    \"\"\"A language model API wrapper.\n\n    A language model is a type of AI model designed to generate, and interpret human\n    language. It is trained on large amounts of text data to learn patterns and\n    structures in language. Language models can perform various tasks such as text\n    generation, translation, summarization, and answering questions.\n\n    We support providers that implement *constrained structured output*\n    like OpenAI, Azure, Ollama or Mistral. In addition we support providers that otherwise\n    allow to constrain the use of a specific tool like Groq or Anthropic.\n\n    For the complete list of models, please refer to the providers documentation.\n\n    **Using OpenAI models**\n\n    ```python\n    import synalinks\n    import os\n\n    os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n\n    language_model = synalinks.LanguageModel(\n        model=\"openai/gpt-4o-mini\",\n    )\n    ```\n\n    **Using Groq models**\n\n    ```python\n    import synalinks\n    import os\n\n    os.environ[\"GROQ_API_KEY\"] = \"your-api-key\"\n\n    language_model = synalinks.LanguageModel(\n        model=\"groq/llama3-8b-8192\",\n    )\n    ```\n\n    **Using Anthropic models**\n\n    ```python\n    import synalinks\n    import os\n\n    os.environ[\"ANTHROPIC_API_KEY\"] = \"your-api-key\"\n\n    language_model = synalinks.LanguageModel(\n        model=\"anthropic/claude-3-sonnet-20240229\",\n    )\n    ```\n\n    **Using Mistral models**\n\n    ```python\n    import synalinks\n    import os\n\n    os.environ[\"MISTRAL_API_KEY\"] = \"your-api-key\"\n\n    language_model = synalinks.LanguageModel(\n        model=\"mistral/codestral-latest\",\n    )\n    ```\n\n    **Using Ollama models**\n\n    ```python\n    import synalinks\n    import os\n\n    language_model = synalinks.LanguageModel(\n        model=\"ollama/mistral\",\n    )\n    ```\n\n    **Using Azure OpenAI models**\n\n    ```python\n    import synalinks\n    import os\n\n    os.environ[\"AZURE_API_KEY\"] = \"your-api-key\"\n    os.environ[\"AZURE_API_BASE\"] = \"your-api-key\"\n    os.environ[\"AZURE_API_VERSION\"] = \"your-api-key\"\n\n    language_model = synalinks.LanguageModel(\n        model=\"azure/&lt;your_deployment_name&gt;\",\n    )\n    ```\n\n    To cascade models to make the pipeline robust in case there is anything wrong with\n    the model provider (hence making your pipelines more robust).\n    Use the `fallback` argument like in this example:\n\n    ```python\n    import synalinks\n    import os\n\n    os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n    os.environ[\"ANTHROPIC_API_KEY\"] = \"your-api-key\"\n\n    language_model = synalinks.LanguageModel(\n        model=\"anthropic/claude-3-sonnet-20240229\",\n        fallback=synalinks.LanguageModel(\n            model=\"openai/gpt-4o-mini\",\n        )\n    )\n    ```\n\n    **Note**: Obviously, use an `.env` file and `.gitignore` to avoid\n    putting your API keys in the code or a config file that can lead to\n    leackage when pushing it into repositories.\n\n    Args:\n        model (str): The model to use.\n        api_base (str): Optional. The endpoint to use.\n        retry (int): Optional. The number of retry (default to 5).\n        fallback (LanguageModel): Optional. The language model to fallback\n            if anything is wrong.\n    \"\"\"\n\n    def __init__(\n        self,\n        model=None,\n        api_base=None,\n        retry=5,\n        fallback=None,\n    ):\n        if model is None:\n            raise ValueError(\"You need to set the `model` argument for any LanguageModel\")\n        model_provider = model.split(\"/\")[0]\n        if model_provider == \"ollama\":\n            # Switch from `ollama` to `ollama_chat`\n            # because it have better performance due to the chat prompts\n            model = model.replace(\"ollama\", \"ollama_chat\")\n        self.model = model\n        self.fallback = fallback\n        if self.model.startswith(\"ollama\") and not api_base:\n            self.api_base = \"http://localhost:11434\"\n        else:\n            self.api_base = api_base\n        self.retry = retry\n\n    async def __call__(self, messages, schema=None, streaming=False, **kwargs):\n        \"\"\"\n        Call method to generate a response using the language model.\n\n        Args:\n            messages (dict): A formatted dict of chat messages.\n            schema (dict): The target JSON schema for structed output (optional).\n                If None, output a ChatMessage-like answer.\n            streaming (bool): Enable streaming (optional). Default to False.\n                Can be enabled only if schema is None.\n            **kwargs (keyword arguments): The additional keywords arguments\n                forwarded to the LLM call.\n\n        Returns:\n            (dict): The generated structured response.\n        \"\"\"\n        maybe_initialize_telemetry()\n\n        formatted_messages = messages.get_json().get(\"messages\", [])\n        json_instance = {}\n        input_kwargs = copy.deepcopy(kwargs)\n        if schema:\n            if self.model.startswith(\"groq\"):\n                # Use a tool created on the fly for groq\n                kwargs.update(\n                    {\n                        \"tools\": [\n                            {\n                                \"function\": {\n                                    \"name\": \"structured_output\",\n                                    \"description\": \"Generate a valid JSON output\",\n                                    \"parameters\": schema.get(\"properties\"),\n                                },\n                                \"type\": \"function\",\n                            }\n                        ],\n                        \"tool_choice\": {\n                            \"type\": \"function\",\n                            \"function\": {\"name\": \"structured_output\"},\n                        },\n                    }\n                )\n            elif self.model.startswith(\"anthropic\"):\n                # Use a tool created on the fly for anthropic\n                kwargs.update(\n                    {\n                        \"tools\": [\n                            {\n                                \"name\": \"structured_output\",\n                                \"description\": \"Generate a valid JSON output\",\n                                \"input_schema\": {\n                                    \"type\": \"object\",\n                                    \"properties\": schema.get(\"properties\"),\n                                    \"required\": schema.get(\"required\"),\n                                },\n                            }\n                        ],\n                        \"tool_choice\": {\n                            \"type\": \"tool\",\n                            \"name\": \"structured_output\",\n                        },\n                    }\n                )\n            elif self.model.startswith(\"ollama\") or self.model.startswith(\"mistral\"):\n                # Use constrained structured output for ollama/mistral\n                kwargs.update(\n                    {\n                        \"response_format\": {\n                            \"type\": \"json_schema\",\n                            \"json_schema\": {\"schema\": schema},\n                            \"strict\": True,\n                        },\n                    }\n                )\n            elif self.model.startswith(\"openai\") or self.model.startswith(\"azure\"):\n                # Use constrained structured output for openai\n                # OpenAI require the field  \"additionalProperties\"\n                kwargs.update(\n                    {\n                        \"response_format\": {\n                            \"type\": \"json_schema\",\n                            \"json_schema\": {\n                                \"name\": \"structured_output\",\n                                \"strict\": True,\n                                \"schema\": schema,\n                            },\n                        }\n                    }\n                )\n            else:\n                provider = self.model.split(\"/\")[0]\n                raise ValueError(\n                    f\"LM provider '{provider}' not supported yet, please ensure that\"\n                    \" they support constrained structured output and fill an issue.\"\n                )\n\n        if self.api_base:\n            kwargs.update(\n                {\n                    \"api_base\": self.api_base,\n                }\n            )\n        if streaming and schema:\n            streaming = False\n        if streaming:\n            kwargs.update({\"stream\": True})\n        for i in range(self.retry):\n            try:\n                response_str = \"\"\n                response = litellm.completion(\n                    model=self.model,\n                    messages=formatted_messages,\n                    caching=False,\n                    **kwargs,\n                )\n                if streaming:\n                    return StreamingIterator(response)\n                if (\n                    self.model.startswith(\"groq\") or self.model.startswith(\"anthropic\")\n                ) and schema:\n                    response_str = response[\"choices\"][0][\"message\"][\"tool_calls\"][0][\n                        \"function\"\n                    ][\"arguments\"]\n                else:\n                    response_str = response[\"choices\"][0][\"message\"][\"content\"].strip()\n                if schema:\n                    json_instance = json.loads(response_str)\n                else:\n                    json_instance = {\"role\": ChatRole.ASSISTANT, \"content\": response_str}\n                return json_instance\n            except Exception as e:\n                warnings.warn(f\"Error occured while trying to call {self}: \" + str(e))\n                capture_exception(e)\n        if self.fallback:\n            return self.fallback(\n                messages,\n                schema=schema,\n                streaming=streaming,\n                **input_kwargs,\n            )\n        else:\n            return None\n\n    def _obj_type(self):\n        return \"LanguageModel\"\n\n    def get_config(self):\n        config = {\n            \"model\": self.model,\n            \"api_base\": self.api_base,\n            \"retry\": self.retry,\n        }\n        if self.fallback:\n            fallback_config = {\n                \"fallback\": serialization_lib.serialize_synalinks_object(\n                    self.fallback,\n                )\n            }\n            return {**fallback_config, **config}\n        else:\n            return config\n\n    @classmethod\n    def from_config(cls, config):\n        if \"fallback\" in config:\n            fallback = serialization_lib.deserialize_synalinks_object(\n                config.pop(\"fallback\")\n            )\n            return cls(fallback=fallback, **config)\n        else:\n            return cls(**config)\n\n    def __repr__(self):\n        api_base = f\" api_base={self.api_base}\" if self.api_base else \"\"\n        return f\"&lt;LanguageModel model={self.model}{api_base}&gt;\"\n</code></pre>"},{"location":"Synalinks%20API/Language%20Models%20API/#synalinks.src.language_models.language_model.LanguageModel.__call__","title":"<code>__call__(messages, schema=None, streaming=False, **kwargs)</code>  <code>async</code>","text":"<p>Call method to generate a response using the language model.</p> <p>Parameters:</p> Name Type Description Default <code>messages</code> <code>dict</code> <p>A formatted dict of chat messages.</p> required <code>schema</code> <code>dict</code> <p>The target JSON schema for structed output (optional). If None, output a ChatMessage-like answer.</p> <code>None</code> <code>streaming</code> <code>bool</code> <p>Enable streaming (optional). Default to False. Can be enabled only if schema is None.</p> <code>False</code> <code>**kwargs</code> <code>keyword arguments</code> <p>The additional keywords arguments forwarded to the LLM call.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>The generated structured response.</p> Source code in <code>synalinks/src/language_models/language_model.py</code> <pre><code>async def __call__(self, messages, schema=None, streaming=False, **kwargs):\n    \"\"\"\n    Call method to generate a response using the language model.\n\n    Args:\n        messages (dict): A formatted dict of chat messages.\n        schema (dict): The target JSON schema for structed output (optional).\n            If None, output a ChatMessage-like answer.\n        streaming (bool): Enable streaming (optional). Default to False.\n            Can be enabled only if schema is None.\n        **kwargs (keyword arguments): The additional keywords arguments\n            forwarded to the LLM call.\n\n    Returns:\n        (dict): The generated structured response.\n    \"\"\"\n    maybe_initialize_telemetry()\n\n    formatted_messages = messages.get_json().get(\"messages\", [])\n    json_instance = {}\n    input_kwargs = copy.deepcopy(kwargs)\n    if schema:\n        if self.model.startswith(\"groq\"):\n            # Use a tool created on the fly for groq\n            kwargs.update(\n                {\n                    \"tools\": [\n                        {\n                            \"function\": {\n                                \"name\": \"structured_output\",\n                                \"description\": \"Generate a valid JSON output\",\n                                \"parameters\": schema.get(\"properties\"),\n                            },\n                            \"type\": \"function\",\n                        }\n                    ],\n                    \"tool_choice\": {\n                        \"type\": \"function\",\n                        \"function\": {\"name\": \"structured_output\"},\n                    },\n                }\n            )\n        elif self.model.startswith(\"anthropic\"):\n            # Use a tool created on the fly for anthropic\n            kwargs.update(\n                {\n                    \"tools\": [\n                        {\n                            \"name\": \"structured_output\",\n                            \"description\": \"Generate a valid JSON output\",\n                            \"input_schema\": {\n                                \"type\": \"object\",\n                                \"properties\": schema.get(\"properties\"),\n                                \"required\": schema.get(\"required\"),\n                            },\n                        }\n                    ],\n                    \"tool_choice\": {\n                        \"type\": \"tool\",\n                        \"name\": \"structured_output\",\n                    },\n                }\n            )\n        elif self.model.startswith(\"ollama\") or self.model.startswith(\"mistral\"):\n            # Use constrained structured output for ollama/mistral\n            kwargs.update(\n                {\n                    \"response_format\": {\n                        \"type\": \"json_schema\",\n                        \"json_schema\": {\"schema\": schema},\n                        \"strict\": True,\n                    },\n                }\n            )\n        elif self.model.startswith(\"openai\") or self.model.startswith(\"azure\"):\n            # Use constrained structured output for openai\n            # OpenAI require the field  \"additionalProperties\"\n            kwargs.update(\n                {\n                    \"response_format\": {\n                        \"type\": \"json_schema\",\n                        \"json_schema\": {\n                            \"name\": \"structured_output\",\n                            \"strict\": True,\n                            \"schema\": schema,\n                        },\n                    }\n                }\n            )\n        else:\n            provider = self.model.split(\"/\")[0]\n            raise ValueError(\n                f\"LM provider '{provider}' not supported yet, please ensure that\"\n                \" they support constrained structured output and fill an issue.\"\n            )\n\n    if self.api_base:\n        kwargs.update(\n            {\n                \"api_base\": self.api_base,\n            }\n        )\n    if streaming and schema:\n        streaming = False\n    if streaming:\n        kwargs.update({\"stream\": True})\n    for i in range(self.retry):\n        try:\n            response_str = \"\"\n            response = litellm.completion(\n                model=self.model,\n                messages=formatted_messages,\n                caching=False,\n                **kwargs,\n            )\n            if streaming:\n                return StreamingIterator(response)\n            if (\n                self.model.startswith(\"groq\") or self.model.startswith(\"anthropic\")\n            ) and schema:\n                response_str = response[\"choices\"][0][\"message\"][\"tool_calls\"][0][\n                    \"function\"\n                ][\"arguments\"]\n            else:\n                response_str = response[\"choices\"][0][\"message\"][\"content\"].strip()\n            if schema:\n                json_instance = json.loads(response_str)\n            else:\n                json_instance = {\"role\": ChatRole.ASSISTANT, \"content\": response_str}\n            return json_instance\n        except Exception as e:\n            warnings.warn(f\"Error occured while trying to call {self}: \" + str(e))\n            capture_exception(e)\n    if self.fallback:\n        return self.fallback(\n            messages,\n            schema=schema,\n            streaming=streaming,\n            **input_kwargs,\n        )\n    else:\n        return None\n</code></pre>"},{"location":"Synalinks%20API/Built-in%20Datasets/","title":"Built-in Datasets","text":"<p>The <code>synalinks.datasets</code> module provide a few datasets that can be used for debugging, evaluation or to create code examples.</p> <p>These datasets are leaked in nowadays LMs training data, which is a big concern in todays ML community, so they won't give you much information about the reasoning abilities of the underlying models. But they are still useful as baseline to compare neuro-symbolic methods or when using small language models.</p> <ul> <li> <p>GSM8K dataset: A dataset of 8.5K high quality linguistically diverse grade school math word problems. Useful to evaluate reasoning capabilities.</p> </li> <li> <p>HotpotQA: A dataset of 113k wikipedia-based question/answer pairs that need multiple documents to answer. This dataset is useful to evaluate Agentic RAGs or KnowledgeGraph RAGs with multi-hop.</p> </li> <li> <p>ARC-AGI dataset: A dataset of 400 different tasks about general artificial intelligence, as a program synthesis benchmark. Useful to evaluate general reasoning abilities and program synthesis applications.</p> </li> </ul>"},{"location":"Synalinks%20API/Built-in%20Datasets/ARC-AGI/","title":"ARC AGI","text":""},{"location":"Synalinks%20API/Built-in%20Datasets/ARC-AGI/#synalinks.src.datasets.arcagi.arcagi.ARCAGIInput","title":"<code>ARCAGIInput</code>","text":"<p>               Bases: <code>DataModel</code></p> <p>Input data model</p> Source code in <code>synalinks/src/datasets/arcagi/arcagi.py</code> <pre><code>class ARCAGIInput(DataModel):\n    \"\"\"Input data model\"\"\"\n\n    examples: List[TaskExample] = []\n    grid: Grid\n</code></pre>"},{"location":"Synalinks%20API/Built-in%20Datasets/ARC-AGI/#synalinks.src.datasets.arcagi.arcagi.ARCAGIOutput","title":"<code>ARCAGIOutput</code>","text":"<p>               Bases: <code>DataModel</code></p> <p>Find the common rule that maps an input grid to an output grid.</p> Source code in <code>synalinks/src/datasets/arcagi/arcagi.py</code> <pre><code>class ARCAGIOutput(DataModel):\n    \"\"\"Find the common rule that maps an input grid to an output grid.\"\"\"\n\n    grid: Grid\n</code></pre>"},{"location":"Synalinks%20API/Built-in%20Datasets/ARC-AGI/#synalinks.src.datasets.arcagi.arcagi.TaskExample","title":"<code>TaskExample</code>","text":"<p>               Bases: <code>DataModel</code></p> <p>An example of task</p> Source code in <code>synalinks/src/datasets/arcagi/arcagi.py</code> <pre><code>class TaskExample(DataModel):\n    \"\"\"An example of task\"\"\"\n\n    inputs: Grid\n    outputs: Grid\n</code></pre>"},{"location":"Synalinks%20API/Built-in%20Datasets/ARC-AGI/#synalinks.src.datasets.arcagi.arcagi.fetch_and_format","title":"<code>fetch_and_format(task_name)</code>","text":"<p>Fetch and format one task by name</p> <p>Example:</p> <pre><code>x, y = synalinks.datasets.arcagi.fetch_and_format(\"62c24649\")\n</code></pre> Source code in <code>synalinks/src/datasets/arcagi/arcagi.py</code> <pre><code>@synalinks_export(\"synalinks.datasets.arcagi.fetch_and_format\")\ndef fetch_and_format(task_name):\n    \"\"\"\n    Fetch and format one task by name\n\n    Example:\n\n    ```python\n    x, y = synalinks.datasets.arcagi.fetch_and_format(\"62c24649\")\n    ```\n    \"\"\"\n    if task_name in TRAINING_TASK_NAMES:\n        url = f\"{BASE_URL}/training/{task_name}.json\"\n    elif task_name in EVALUATION_TASK_NAMES:\n        url = f\"{BASE_URL}/evaluation/{task_name}.json\"\n    else:\n        raise ValueError(\n            f\"Task '{task_name}' not recognized, make sure that the task name is valid.\"\n        )\n\n    x = None\n    y = None\n\n    file_path = file_utils.get_file(origin=url, progbar=False)\n    with open(file_path, \"r\") as f:\n        json_data = json.loads(f.read())\n        trainset = json_data.get(\"train\")\n        testset = json_data.get(\"test\")\n        x = ARCAGIInput(grid=testset[0].get(\"input\"))\n        x.examples.append(\n            TaskExample(\n                inputs=tuple(map(tuple, trainset[0].get(\"input\"))),\n                outputs=tuple(map(tuple, trainset[0].get(\"output\"))),\n            )\n        )\n        x.examples.append(\n            TaskExample(\n                inputs=tuple(map(tuple, trainset[1].get(\"input\"))),\n                outputs=tuple(map(tuple, trainset[1].get(\"output\"))),\n            )\n        )\n        if len(trainset) &gt; 2:\n            x.examples.append(\n                TaskExample(\n                    inputs=tuple(map(tuple, trainset[2].get(\"input\"))),\n                    outputs=tuple(map(tuple, trainset[2].get(\"output\"))),\n                )\n            )\n        y = ARCAGIOutput(grid=tuple(map(tuple, testset[0].get(\"output\"))))\n    return x, y\n</code></pre>"},{"location":"Synalinks%20API/Built-in%20Datasets/ARC-AGI/#synalinks.src.datasets.arcagi.arcagi.get_input_data_model","title":"<code>get_input_data_model()</code>","text":"<p>Returns ARC-AGI input data_model for pipeline configurations.</p> <p>Returns:</p> Type Description <code>DataModel</code> <p>The ARC-AGI input data_model</p> Source code in <code>synalinks/src/datasets/arcagi/arcagi.py</code> <pre><code>@synalinks_export(\"synalinks.datasets.arcagi.get_input_data_model\")\ndef get_input_data_model():\n    \"\"\"\n    Returns ARC-AGI input data_model for pipeline configurations.\n\n    Returns:\n        (DataModel): The ARC-AGI input data_model\n    \"\"\"\n    return ARCAGIInput\n</code></pre>"},{"location":"Synalinks%20API/Built-in%20Datasets/ARC-AGI/#synalinks.src.datasets.arcagi.arcagi.get_output_data_model","title":"<code>get_output_data_model()</code>","text":"<p>Returns ARC-AGI output data_model for pipeline configurations.</p> <p>Returns:</p> Type Description <code>DataModel</code> <p>The ARC-AGI output data_model</p> Source code in <code>synalinks/src/datasets/arcagi/arcagi.py</code> <pre><code>@synalinks_export(\"synalinks.datasets.arcagi.get_output_data_model\")\ndef get_output_data_model():\n    \"\"\"\n    Returns ARC-AGI output data_model for pipeline configurations.\n\n    Returns:\n        (DataModel): The ARC-AGI output data_model\n    \"\"\"\n    return ARCAGIOutput\n</code></pre>"},{"location":"Synalinks%20API/Built-in%20Datasets/ARC-AGI/#synalinks.src.datasets.arcagi.arcagi.load_data","title":"<code>load_data(task_names=None)</code>","text":"<p>Load and format data from github</p> <p>Example:</p> <pre><code>(x_train, y_train), (x_test, y_test) = synalinks.datasets.arcagi.load_data()\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>task_names</code> <code>list</code> <p>Optional. The list of tasks to fetch.</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple</code> <p>The train and test data ready for training</p> Source code in <code>synalinks/src/datasets/arcagi/arcagi.py</code> <pre><code>@synalinks_export(\"synalinks.datasets.arcagi.load_data\")\ndef load_data(task_names=None):\n    \"\"\"\n    Load and format data from github\n\n    Example:\n\n    ```python\n    (x_train, y_train), (x_test, y_test) = synalinks.datasets.arcagi.load_data()\n    ```\n\n    Args:\n        task_names (list): Optional. The list of tasks to fetch.\n\n    Returns:\n        (tuple): The train and test data ready for training\n    \"\"\"\n    x_train = []\n    y_train = []\n    x_test = []\n    y_test = []\n\n    if not task_names:\n        for task_name in TRAINING_TASK_NAMES:\n            (x, y) = fetch_and_format(task_name)\n            x_train.append(x)\n            y_train.append(y)\n\n        for task_name in EVALUATION_TASK_NAMES:\n            (x, y) = fetch_and_format(task_name)\n            x_test.append(x)\n            y_test.append(y)\n\n    else:\n        for task_name in task_names:\n            if task_name in TRAINING_TASK_NAMES:\n                (x, y) = fetch_and_format(task_name)\n                x_train.append(x)\n                y_train.append(y)\n\n            if task_name in EVALUATION_TASK_NAMES:\n                (x, y) = fetch_and_format(task_name)\n                x_test.append(x)\n                x_test.append(y)\n\n    x_train = np.array(x_train, dtype=\"object\")\n    y_train = np.array(y_train, dtype=\"object\")\n    x_test = np.array(x_test, dtype=\"object\")\n    y_test = np.array(y_test, dtype=\"object\")\n\n    return (x_train, y_train), (x_test, y_test)\n</code></pre>"},{"location":"Synalinks%20API/Built-in%20Datasets/ARC-AGI/#synalinks.src.datasets.arcagi.arcagi.plot_task","title":"<code>plot_task(x=None, y_true=None, y_pred=None, task_name=None, to_file=None)</code>","text":"<p>Plot a task for debugging purposes</p> <p>Code Example:</p> <pre><code>synlinks.datasets.arcagi.plot_task(task_name=\"025d127b\")\n</code></pre> <p>Example:</p> <p></p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>DataModel</code> <p>Optional. The task inputs.</p> <code>None</code> <code>y_true</code> <code>DataModel</code> <p>Optional. The task target data.</p> <code>None</code> <code>y_pred</code> <code>DataModel</code> <p>Optional. The prediction.</p> <code>None</code> <code>task_name</code> <code>str</code> <p>The task name to fetch the data if not provided.</p> <code>None</code> <code>to_file</code> <code>str</code> <p>The filepath where to save the figure.</p> <code>None</code> Source code in <code>synalinks/src/datasets/arcagi/arcagi.py</code> <pre><code>@synalinks_export(\"synalinks.datasets.arcagi.plot_task\")\ndef plot_task(\n    x=None,\n    y_true=None,\n    y_pred=None,\n    task_name=None,\n    to_file=None,\n):\n    \"\"\"\n    Plot a task for debugging purposes\n\n    Code Example:\n\n    ```python\n    synlinks.datasets.arcagi.plot_task(task_name=\"025d127b\")\n    ```\n\n    Example:\n\n    ![025d127b](../../assets/025d127b.png)\n\n    Args:\n        x (DataModel): Optional. The task inputs.\n        y_true (DataModel): Optional. The task target data.\n        y_pred (DataModel): Optional. The prediction.\n        task_name (str): The task name to fetch the data if not provided.\n        to_file (str): The filepath where to save the figure.\n    \"\"\"\n    if not x and not y_true and task_name:\n        x, y_true = fetch_and_format(task_name)\n        if not to_file:\n            to_file = f\"{task_name}.png\"\n\n    if not to_file:\n        to_file = \"arc_agi_task.png\"\n\n    cmap = colors.ListedColormap(\n        [\n            \"#000000\",\n            \"#0074D9\",\n            \"#FF4136\",\n            \"#2ECC40\",\n            \"#FFDC00\",\n            \"#AAAAAA\",\n            \"#F012BE\",\n            \"#FF851B\",\n            \"#7FDBFF\",\n            \"#870C25\",\n        ]\n    )\n    norm = colors.Normalize(vmin=0, vmax=9)\n\n    nb_examples = len(x.examples)\n    n = nb_examples + 1\n    fig, axis = plt.subplots(2, n)\n\n    for i, example in enumerate(x.examples):\n        inputs, outputs = x.examples[i].inputs, x.examples[i].outputs\n        inputs, outputs = np.array(inputs), np.array(outputs)\n\n        axis[0, i].imshow(inputs, cmap=cmap, norm=norm)\n        axis[0, i].set_title(f\"x_train {i}\")\n        axis[0, i].grid(axis=\"both\", color=\"white\", linewidth=1)\n        axis[0, i].set_yticks(np.arange(-0.5, inputs.shape[0], 1))\n        axis[0, i].set_xticks(np.arange(-0.5, inputs.shape[1], 1))\n        axis[0, i].set_yticklabels([])\n        axis[0, i].set_xticklabels([])\n\n        axis[1, i].imshow(outputs, cmap=cmap, norm=norm)\n        axis[1, i].set_title(f\"y_train {i}\")\n        axis[1, i].grid(axis=\"both\", color=\"white\", linewidth=1)\n        axis[1, i].set_yticks(np.arange(-0.5, outputs.shape[0], 1))\n        axis[1, i].set_xticks(np.arange(-0.5, outputs.shape[1], 1))\n        axis[1, i].set_yticklabels([])\n        axis[1, i].set_xticklabels([])\n\n    inputs = np.array(x.grid)\n    axis[0, nb_examples].imshow(inputs, cmap=cmap, norm=norm)\n    axis[0, nb_examples].set_title(\"x_test\")\n    axis[0, nb_examples].grid(axis=\"both\", color=\"white\", linewidth=1)\n    axis[0, nb_examples].set_yticks(np.arange(-0.5, inputs.shape[0], 1))\n    axis[0, nb_examples].set_xticks(np.arange(-0.5, inputs.shape[1], 1))\n    axis[0, nb_examples].set_yticklabels([])\n    axis[0, nb_examples].set_xticklabels([])\n\n    if y_true:\n        outputs = np.array(y_true.grid)\n        title = \"y_true\"\n    if y_pred:\n        outputs = np.array(y_pred.grid)\n        title = \"y_pred\"\n    axis[1, nb_examples].imshow(outputs, cmap=cmap, norm=norm)\n    axis[1, nb_examples].set_title(title)\n    axis[1, nb_examples].grid(axis=\"both\", color=\"white\", linewidth=1)\n    axis[1, nb_examples].set_yticks(np.arange(-0.5, outputs.shape[0], 1))\n    axis[1, nb_examples].set_xticks(np.arange(-0.5, outputs.shape[1], 1))\n    axis[1, nb_examples].set_yticklabels([])\n    axis[1, nb_examples].set_xticklabels([])\n\n    plt.tight_layout()\n    plt.savefig(to_file)\n    plt.close()\n    try:\n        from IPython import display\n\n        return display.Image(filename=to_file)\n    except ImportError:\n        pass\n</code></pre>"},{"location":"Synalinks%20API/Built-in%20Datasets/GSM8K/","title":"GSM8K","text":""},{"location":"Synalinks%20API/Built-in%20Datasets/GSM8K/#synalinks.src.datasets.gsm8k.get_input_data_model","title":"<code>get_input_data_model()</code>","text":"<p>Returns GSM8K input data_model for pipeline configurations.</p> <p>Returns:</p> Type Description <code>DataModel</code> <p>The GSM8K input data_model</p> Source code in <code>synalinks/src/datasets/gsm8k.py</code> <pre><code>@synalinks_export(\"synalinks.datasets.gsm8k.get_input_data_model\")\ndef get_input_data_model():\n    \"\"\"\n    Returns GSM8K input data_model for pipeline configurations.\n\n    Returns:\n        (DataModel): The GSM8K input data_model\n    \"\"\"\n    return MathQuestion\n</code></pre>"},{"location":"Synalinks%20API/Built-in%20Datasets/GSM8K/#synalinks.src.datasets.gsm8k.get_output_data_model","title":"<code>get_output_data_model()</code>","text":"<p>Returns GSM8K output data_model for pipeline configurations.</p> <p>Returns:</p> Type Description <code>DataModel</code> <p>The GSM8K output data_model</p> Source code in <code>synalinks/src/datasets/gsm8k.py</code> <pre><code>@synalinks_export(\"synalinks.datasets.gsm8k.get_output_data_model\")\ndef get_output_data_model():\n    \"\"\"\n    Returns GSM8K output data_model for pipeline configurations.\n\n    Returns:\n        (DataModel): The GSM8K output data_model\n    \"\"\"\n    return NumericalAnswerWithThinking\n</code></pre>"},{"location":"Synalinks%20API/Built-in%20Datasets/GSM8K/#synalinks.src.datasets.gsm8k.load_data","title":"<code>load_data()</code>","text":"<p>Load and format data from HuggingFace</p> <p>Example:</p> <pre><code>(x_train, y_train), (x_test, y_test) = synalinks.datasets.gsm8k.load_data()\n</code></pre> <p>Returns:</p> Type Description <code>tuple</code> <p>The train and test data ready for training</p> Source code in <code>synalinks/src/datasets/gsm8k.py</code> <pre><code>@synalinks_export(\"synalinks.datasets.gsm8k.load_data\")\ndef load_data():\n    \"\"\"\n    Load and format data from HuggingFace\n\n    Example:\n\n    ```python\n    (x_train, y_train), (x_test, y_test) = synalinks.datasets.gsm8k.load_data()\n    ```\n\n    Returns:\n        (tuple): The train and test data ready for training\n    \"\"\"\n    dataset = load_dataset(\"gsm8k\", \"main\")\n\n    x_train = []\n    y_train = []\n    x_test = []\n    y_test = []\n\n    for data_point in dataset[\"train\"]:\n        question = data_point[\"question\"]\n        thinking = data_point[\"answer\"].split(\"####\")[0].strip()\n        answer = data_point[\"answer\"].split(\"####\")[-1].strip()\n        x_train.append(MathQuestion(question=question))\n        y_train.append(\n            NumericalAnswerWithThinking(\n                thinking=thinking,\n                answer=float(answer.replace(\",\", \"\")),\n            )\n        )\n\n    for data_point in dataset[\"test\"]:\n        question = data_point[\"question\"]\n        thinking = data_point[\"answer\"].split(\"####\")[0].strip()\n        answer = data_point[\"answer\"].split(\"####\")[-1].strip()\n        x_test.append(MathQuestion(question=question))\n        y_test.append(\n            NumericalAnswerWithThinking(\n                thinking=thinking,\n                answer=float(answer.replace(\",\", \"\")),\n            )\n        )\n\n    x_train = np.array(x_train, dtype=\"object\")\n    y_train = np.array(y_train, dtype=\"object\")\n\n    x_test = np.array(x_test, dtype=\"object\")\n    y_test = np.array(y_test, dtype=\"object\")\n\n    return (x_train, y_train), (x_test, y_test)\n</code></pre>"},{"location":"Synalinks%20API/Built-in%20Datasets/HotpotQA/","title":"HotpotQA","text":""},{"location":"Synalinks%20API/Built-in%20Datasets/HotpotQA/#synalinks.src.datasets.hotpotqa.get_input_data_model","title":"<code>get_input_data_model()</code>","text":"<p>Returns HotpotQA input data model for pipeline configurations.</p> <p>Returns:</p> Type Description <code>DataModel</code> <p>The HotpotQA input data model</p> Source code in <code>synalinks/src/datasets/hotpotqa.py</code> <pre><code>@synalinks_export(\"synalinks.datasets.hotpotqa.get_input_data_model\")\ndef get_input_data_model():\n    \"\"\"\n    Returns HotpotQA input data model for pipeline configurations.\n\n    Returns:\n        (DataModel): The HotpotQA input data model\n    \"\"\"\n    return Question\n</code></pre>"},{"location":"Synalinks%20API/Built-in%20Datasets/HotpotQA/#synalinks.src.datasets.hotpotqa.get_knowledge_data_model","title":"<code>get_knowledge_data_model()</code>","text":"<p>Returns HotpotQA knowledge data model for pipeline configurations.</p> <p>Returns:</p> Type Description <code>DataModel</code> <p>The HotpotQA knowledge data model</p> Source code in <code>synalinks/src/datasets/hotpotqa.py</code> <pre><code>@synalinks_export(\"synalinks.datasets.hotpotqa.get_knowledge_data_model\")\ndef get_knowledge_data_model():\n    \"\"\"\n    Returns HotpotQA knowledge data model for pipeline configurations.\n\n    Returns:\n        (DataModel): The HotpotQA knowledge data model\n    \"\"\"\n    return Document\n</code></pre>"},{"location":"Synalinks%20API/Built-in%20Datasets/HotpotQA/#synalinks.src.datasets.hotpotqa.get_output_data_model","title":"<code>get_output_data_model()</code>","text":"<p>Returns HotpotQA output data model for pipeline configurations.</p> <p>Returns:</p> Type Description <code>DataModel</code> <p>The HotpotQA output data model</p> Source code in <code>synalinks/src/datasets/hotpotqa.py</code> <pre><code>@synalinks_export(\"synalinks.datasets.hotpotqa.get_output_data_model\")\ndef get_output_data_model():\n    \"\"\"\n    Returns HotpotQA output data model for pipeline configurations.\n\n    Returns:\n        (DataModel): The HotpotQA output data model\n    \"\"\"\n    return Answer\n</code></pre>"},{"location":"Synalinks%20API/Built-in%20Datasets/HotpotQA/#synalinks.src.datasets.hotpotqa.load_data","title":"<code>load_data()</code>","text":"<p>Load and format data from HuggingFace</p> <p>Example:</p> <pre><code>(x_train, y_train), (x_test, y_test) = synalinks.datasets.hotpotqa.load_data()\n</code></pre> <p>Returns:</p> Type Description <code>tuple</code> <p>The train and test data ready for training</p> Source code in <code>synalinks/src/datasets/hotpotqa.py</code> <pre><code>@synalinks_export(\"synalinks.datasets.hotpotqa.load_data\")\ndef load_data():\n    \"\"\"\n    Load and format data from HuggingFace\n\n    Example:\n\n    ```python\n    (x_train, y_train), (x_test, y_test) = synalinks.datasets.hotpotqa.load_data()\n    ```\n\n    Returns:\n        (tuple): The train and test data ready for training\n    \"\"\"\n    x_train = []\n    y_train = []\n    x_test = []\n    y_test = []\n\n    train_examples = load_dataset(\n        \"hotpot_qa\", \"fullwiki\", split=\"train\", trust_remote_code=True\n    )\n    eval_examples = load_dataset(\n        \"hotpot_qa\", \"fullwiki\", split=\"validation\", trust_remote_code=True\n    )\n\n    for raw_example in train_examples:\n        x_train.append(Question(question=raw_example[\"question\"]))\n        y_train.append(Answer(answer=raw_example[\"answer\"]))\n\n    for raw_example in eval_examples:\n        if raw_example[\"level\"] == \"hard\":\n            x_test.append(Question(question=raw_example[\"question\"]))\n            y_test.append(Answer(answer=raw_example[\"answer\"]))\n\n    x_train = np.array(x_train, dtype=\"object\")\n    y_train = np.array(y_train, dtype=\"object\")\n\n    x_test = np.array(x_test, dtype=\"object\")\n    y_test = np.array(y_test, dtype=\"object\")\n\n    return (x_train, y_train), (x_test, y_test)\n</code></pre>"},{"location":"Synalinks%20API/Built-in%20Datasets/HotpotQA/#synalinks.src.datasets.hotpotqa.load_knowledge","title":"<code>load_knowledge()</code>","text":"<p>Load and format data from HuggingFace</p> <p>Example:</p> <pre><code>knowledge = synalinks.datasets.hotpotqa.load_knowledge()\n</code></pre> <p>Returns:</p> Type Description <code>list</code> <p>The  data ready for knowledge injestion</p> Source code in <code>synalinks/src/datasets/hotpotqa.py</code> <pre><code>@synalinks_export(\"synalinks.datasets.hotpotqa.load_knowledge\")\ndef load_knowledge():\n    \"\"\"\n    Load and format data from HuggingFace\n\n    Example:\n\n    ```python\n    knowledge = synalinks.datasets.hotpotqa.load_knowledge()\n    ```\n\n    Returns:\n        (list): The  data ready for knowledge injestion\n    \"\"\"\n    documents = []\n    train_examples = load_dataset(\n        \"hotpot_qa\", \"fullwiki\", split=\"train\", trust_remote_code=True\n    )\n    for raw_example in train_examples:\n        context = raw_example.get(\"context\", None)\n        if context:\n            for i in range(len(context[\"title\"])):\n                documents.append(\n                    Document(\n                        title=context[\"title\"][i], text=\"\\n\".join(context[\"sentences\"][i])\n                    )\n                )\n    documents = np.array(documents, dtype=\"object\")\n    return documents\n</code></pre>"},{"location":"Synalinks%20API/Callbacks%20API/","title":"Callbacks API","text":"<p>A callback is an object that can perform various actions at multiple stages of the program's training. For example, at the start or end of an epoch, before or after a single batch, etc.</p>"},{"location":"Synalinks%20API/Callbacks%20API/#how-to-use-callbacks","title":"How to use Callbacks","text":"<p>You can pass a list of callbacks to the <code>.fit()</code> method of a program.</p> <pre><code>import synalinks\nimport asyncio\n\nasync def main():\n    # ... you program declaration here\n\n    callbacks = [\n        synalinks.callbacks.CSVLogger(filepath=\"training_log.csv\"),\n        synalinks.callbacks.ProgramCheckpoint(\n            filepath=\"program.{epoch:02d}-{val_loss:.2f}.json\"\n        ),\n    ]\n\n    history = await program.fit(\n        x=x_train,\n        y=y_train,\n        epochs=10,\n        callbacks=callbacks,\n    )\n\nif __main__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"Synalinks%20API/Callbacks%20API/#callbacks-overview","title":"Callbacks Overview","text":"<ul> <li>Base Callback class</li> <li>CSVLogger callback</li> <li>ProgramCheckPoint callback</li> </ul>"},{"location":"Synalinks%20API/Callbacks%20API/Base%20Callback%20class/","title":"Base Callback class","text":""},{"location":"Synalinks%20API/Callbacks%20API/Base%20Callback%20class/#synalinks.src.callbacks.callback.Callback","title":"<code>Callback</code>","text":"<p>Base class used to build new callbacks.</p> <p>Callbacks can be passed to synalinks methods such as <code>fit()</code>, <code>evaluate()</code>, and <code>predict()</code> in order to hook into the various stages of the program training, evaluation, and inference lifecycle.</p> <p>To create a custom callback, subclass <code>synalinks.callbacks.Callback</code> and override the method associated with the stage of interest.</p> <p>If you want to use <code>Callback</code> objects in a custom training loop:</p> <ol> <li>You should pack all your callbacks into a single <code>callbacks.CallbackList</code>    so they can all be called together.</li> <li>You will need to manually call all the <code>on_*</code> methods at the appropriate    locations in your loop.</li> </ol> <p>The <code>logs</code> dictionary that callback methods take as argument will contain keys for quantities relevant to the current batch or epoch (see method-specific docstrings).</p> <p>Attributes:</p> Name Type Description <code>params</code> <code>dict</code> <p>Training parameters (eg. verbosity, batch size, number of epochs...).</p> <code>program</code> <code>Program</code> <p>Instance of <code>Program</code>. Reference of the program being trained.</p> Source code in <code>synalinks/src/callbacks/callback.py</code> <pre><code>@synalinks_export(\"synalinks.callbacks.Callback\")\nclass Callback:\n    \"\"\"Base class used to build new callbacks.\n\n    Callbacks can be passed to synalinks methods such as `fit()`, `evaluate()`, and\n    `predict()` in order to hook into the various stages of the program training,\n    evaluation, and inference lifecycle.\n\n    To create a custom callback, subclass `synalinks.callbacks.Callback` and\n    override the method associated with the stage of interest.\n\n    If you want to use `Callback` objects in a custom training loop:\n\n    1. You should pack all your callbacks into a single `callbacks.CallbackList`\n       so they can all be called together.\n    2. You will need to manually call all the `on_*` methods at the appropriate\n       locations in your loop.\n\n    The `logs` dictionary that callback methods\n    take as argument will contain keys for quantities relevant to\n    the current batch or epoch (see method-specific docstrings).\n\n    Attributes:\n        params (dict): Training parameters\n            (eg. verbosity, batch size, number of epochs...).\n        program (Program): Instance of `Program`.\n            Reference of the program being trained.\n    \"\"\"\n\n    def __init__(self):\n        self.params = None\n        self._program = None\n\n    def set_params(self, params):\n        self.params = params\n\n    def set_program(self, program):\n        self._program = program\n\n    @property\n    def program(self):\n        return self._program\n\n    @utils.default\n    def on_batch_begin(self, batch, logs=None):\n        \"\"\"A backwards compatibility alias for `on_train_batch_begin`.\"\"\"\n\n    @utils.default\n    def on_batch_end(self, batch, logs=None):\n        \"\"\"A backwards compatibility alias for `on_train_batch_end`.\"\"\"\n\n    @utils.default\n    def on_epoch_begin(self, epoch, logs=None):\n        \"\"\"Called at the start of an epoch.\n\n        Subclasses should override for any actions to run. This function should\n        only be called during TRAIN mode.\n\n        Args:\n            epoch (int): Index of epoch.\n            logs (dict): Currently no data is passed to this argument for this\n                method but that may change in the future.\n        \"\"\"\n\n    @utils.default\n    def on_epoch_end(self, epoch, logs=None):\n        \"\"\"Called at the end of an epoch.\n\n        Subclasses should override for any actions to run. This function should\n        only be called during TRAIN mode.\n\n        Args:\n            epoch (int): Index of epoch.\n            logs (dict): Metric results for this training epoch, and for the\n                validation epoch if validation is performed. Validation result\n                keys are prefixed with `val_`. For training epoch, the values of\n                the `Program`'s metrics are returned. Example:\n                `{'reward': 0.2, 'accuracy': 0.7}`.\n        \"\"\"\n\n    @utils.default\n    def on_train_batch_begin(self, batch, logs=None):\n        \"\"\"Called at the beginning of a training batch in `fit` methods.\n\n        Subclasses should override for any actions to run.\n\n        Note that if the `steps_per_execution` argument to `compile` in\n        `Program` is set to `N`, this method will only be called every\n        `N` batches.\n\n        Args:\n            batch (int): Index of batch within the current epoch.\n            logs (dict): Currently no data is passed to this argument for this\n                method but that may change in the future.\n        \"\"\"\n        # For backwards compatibility.\n        self.on_batch_begin(batch, logs=logs)\n\n    @utils.default\n    def on_train_batch_end(self, batch, logs=None):\n        \"\"\"Called at the end of a training batch in `fit` methods.\n\n        Subclasses should override for any actions to run.\n\n        Note that if the `steps_per_execution` argument to `compile` in\n        `Program` is set to `N`, this method will only be called every\n        `N` batches.\n\n        Args:\n            batch (int): Index of batch within the current epoch.\n            logs (dict): Aggregated metric results up until this batch.\n        \"\"\"\n        # For backwards compatibility.\n        self.on_batch_end(batch, logs=logs)\n\n    @utils.default\n    def on_test_batch_begin(self, batch, logs=None):\n        \"\"\"Called at the beginning of a batch in `evaluate` methods.\n\n        Also called at the beginning of a validation batch in the `fit`\n        methods, if validation data is provided.\n\n        Subclasses should override for any actions to run.\n\n        Note that if the `steps_per_execution` argument to `compile` in\n        `Program` is set to `N`, this method will only be called every\n        `N` batches.\n\n        Args:\n            batch (int): Index of batch within the current epoch.\n            logs (dict): Currently no data is passed to this argument for this\n                method but that may change in the future.\n        \"\"\"\n\n    @utils.default\n    def on_test_batch_end(self, batch, logs=None):\n        \"\"\"Called at the end of a batch in `evaluate` methods.\n\n        Also called at the end of a validation batch in the `fit`\n        methods, if validation data is provided.\n\n        Subclasses should override for any actions to run.\n\n        Note that if the `steps_per_execution` argument to `compile` in\n        `Program` is set to `N`, this method will only be called every\n        `N` batches.\n\n        Args:\n            batch (int): Index of batch within the current epoch.\n            logs (dict): Aggregated metric results up until this batch.\n        \"\"\"\n\n    @utils.default\n    def on_predict_batch_begin(self, batch, logs=None):\n        \"\"\"Called at the beginning of a batch in `predict` methods.\n\n        Subclasses should override for any actions to run.\n\n        Note that if the `steps_per_execution` argument to `compile` in\n        `Program` is set to `N`, this method will only be called every\n        `N` batches.\n\n        Args:\n            batch (int): Index of batch within the current epoch.\n            logs (dict): Currently no data is passed to this argument for this\n                method but that may change in the future.\n        \"\"\"\n\n    @utils.default\n    def on_predict_batch_end(self, batch, logs=None):\n        \"\"\"Called at the end of a batch in `predict` methods.\n\n        Subclasses should override for any actions to run.\n\n        Note that if the `steps_per_execution` argument to `compile` in\n        `Program` is set to `N`, this method will only be called every\n        `N` batches.\n\n        Args:\n            batch (int): Index of batch within the current epoch.\n            logs (dict): Aggregated metric results up until this batch.\n        \"\"\"\n\n    @utils.default\n    def on_train_begin(self, logs=None):\n        \"\"\"Called at the beginning of training.\n\n        Subclasses should override for any actions to run.\n\n        Args:\n            logs (dict): Currently no data is passed to this argument for this\n                method but that may change in the future.\n        \"\"\"\n\n    @utils.default\n    def on_train_end(self, logs=None):\n        \"\"\"Called at the end of training.\n\n        Subclasses should override for any actions to run.\n\n        Args:\n            logs (dict): Currently the output of the last call to\n                `on_epoch_end()` is passed to this argument for this method but\n                that may change in the future.\n        \"\"\"\n\n    @utils.default\n    def on_test_begin(self, logs=None):\n        \"\"\"Called at the beginning of evaluation or validation.\n\n        Subclasses should override for any actions to run.\n\n        Args:\n            logs (dict): Currently no data is passed to this argument for this\n                method but that may change in the future.\n        \"\"\"\n\n    @utils.default\n    def on_test_end(self, logs=None):\n        \"\"\"Called at the end of evaluation or validation.\n\n        Subclasses should override for any actions to run.\n\n        Args:\n            logs (dict): Currently the output of the last call to\n                `on_test_batch_end()` is passed to this argument for this method\n                but that may change in the future.\n        \"\"\"\n\n    @utils.default\n    def on_predict_begin(self, logs=None):\n        \"\"\"Called at the beginning of prediction.\n\n        Subclasses should override for any actions to run.\n\n        Args:\n            logs (dict): Currently no data is passed to this argument for this\n                method but that may change in the future.\n        \"\"\"\n\n    @utils.default\n    def on_predict_end(self, logs=None):\n        \"\"\"Called at the end of prediction.\n\n        Subclasses should override for any actions to run.\n\n        Args:\n            logs (dict): Currently no data is passed to this argument for this\n                method but that may change in the future.\n        \"\"\"\n</code></pre>"},{"location":"Synalinks%20API/Callbacks%20API/Base%20Callback%20class/#synalinks.src.callbacks.callback.Callback.on_batch_begin","title":"<code>on_batch_begin(batch, logs=None)</code>","text":"<p>A backwards compatibility alias for <code>on_train_batch_begin</code>.</p> Source code in <code>synalinks/src/callbacks/callback.py</code> <pre><code>@utils.default\ndef on_batch_begin(self, batch, logs=None):\n    \"\"\"A backwards compatibility alias for `on_train_batch_begin`.\"\"\"\n</code></pre>"},{"location":"Synalinks%20API/Callbacks%20API/Base%20Callback%20class/#synalinks.src.callbacks.callback.Callback.on_batch_end","title":"<code>on_batch_end(batch, logs=None)</code>","text":"<p>A backwards compatibility alias for <code>on_train_batch_end</code>.</p> Source code in <code>synalinks/src/callbacks/callback.py</code> <pre><code>@utils.default\ndef on_batch_end(self, batch, logs=None):\n    \"\"\"A backwards compatibility alias for `on_train_batch_end`.\"\"\"\n</code></pre>"},{"location":"Synalinks%20API/Callbacks%20API/Base%20Callback%20class/#synalinks.src.callbacks.callback.Callback.on_epoch_begin","title":"<code>on_epoch_begin(epoch, logs=None)</code>","text":"<p>Called at the start of an epoch.</p> <p>Subclasses should override for any actions to run. This function should only be called during TRAIN mode.</p> <p>Parameters:</p> Name Type Description Default <code>epoch</code> <code>int</code> <p>Index of epoch.</p> required <code>logs</code> <code>dict</code> <p>Currently no data is passed to this argument for this method but that may change in the future.</p> <code>None</code> Source code in <code>synalinks/src/callbacks/callback.py</code> <pre><code>@utils.default\ndef on_epoch_begin(self, epoch, logs=None):\n    \"\"\"Called at the start of an epoch.\n\n    Subclasses should override for any actions to run. This function should\n    only be called during TRAIN mode.\n\n    Args:\n        epoch (int): Index of epoch.\n        logs (dict): Currently no data is passed to this argument for this\n            method but that may change in the future.\n    \"\"\"\n</code></pre>"},{"location":"Synalinks%20API/Callbacks%20API/Base%20Callback%20class/#synalinks.src.callbacks.callback.Callback.on_epoch_end","title":"<code>on_epoch_end(epoch, logs=None)</code>","text":"<p>Called at the end of an epoch.</p> <p>Subclasses should override for any actions to run. This function should only be called during TRAIN mode.</p> <p>Parameters:</p> Name Type Description Default <code>epoch</code> <code>int</code> <p>Index of epoch.</p> required <code>logs</code> <code>dict</code> <p>Metric results for this training epoch, and for the validation epoch if validation is performed. Validation result keys are prefixed with <code>val_</code>. For training epoch, the values of the <code>Program</code>'s metrics are returned. Example: <code>{'reward': 0.2, 'accuracy': 0.7}</code>.</p> <code>None</code> Source code in <code>synalinks/src/callbacks/callback.py</code> <pre><code>@utils.default\ndef on_epoch_end(self, epoch, logs=None):\n    \"\"\"Called at the end of an epoch.\n\n    Subclasses should override for any actions to run. This function should\n    only be called during TRAIN mode.\n\n    Args:\n        epoch (int): Index of epoch.\n        logs (dict): Metric results for this training epoch, and for the\n            validation epoch if validation is performed. Validation result\n            keys are prefixed with `val_`. For training epoch, the values of\n            the `Program`'s metrics are returned. Example:\n            `{'reward': 0.2, 'accuracy': 0.7}`.\n    \"\"\"\n</code></pre>"},{"location":"Synalinks%20API/Callbacks%20API/Base%20Callback%20class/#synalinks.src.callbacks.callback.Callback.on_predict_batch_begin","title":"<code>on_predict_batch_begin(batch, logs=None)</code>","text":"<p>Called at the beginning of a batch in <code>predict</code> methods.</p> <p>Subclasses should override for any actions to run.</p> <p>Note that if the <code>steps_per_execution</code> argument to <code>compile</code> in <code>Program</code> is set to <code>N</code>, this method will only be called every <code>N</code> batches.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>int</code> <p>Index of batch within the current epoch.</p> required <code>logs</code> <code>dict</code> <p>Currently no data is passed to this argument for this method but that may change in the future.</p> <code>None</code> Source code in <code>synalinks/src/callbacks/callback.py</code> <pre><code>@utils.default\ndef on_predict_batch_begin(self, batch, logs=None):\n    \"\"\"Called at the beginning of a batch in `predict` methods.\n\n    Subclasses should override for any actions to run.\n\n    Note that if the `steps_per_execution` argument to `compile` in\n    `Program` is set to `N`, this method will only be called every\n    `N` batches.\n\n    Args:\n        batch (int): Index of batch within the current epoch.\n        logs (dict): Currently no data is passed to this argument for this\n            method but that may change in the future.\n    \"\"\"\n</code></pre>"},{"location":"Synalinks%20API/Callbacks%20API/Base%20Callback%20class/#synalinks.src.callbacks.callback.Callback.on_predict_batch_end","title":"<code>on_predict_batch_end(batch, logs=None)</code>","text":"<p>Called at the end of a batch in <code>predict</code> methods.</p> <p>Subclasses should override for any actions to run.</p> <p>Note that if the <code>steps_per_execution</code> argument to <code>compile</code> in <code>Program</code> is set to <code>N</code>, this method will only be called every <code>N</code> batches.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>int</code> <p>Index of batch within the current epoch.</p> required <code>logs</code> <code>dict</code> <p>Aggregated metric results up until this batch.</p> <code>None</code> Source code in <code>synalinks/src/callbacks/callback.py</code> <pre><code>@utils.default\ndef on_predict_batch_end(self, batch, logs=None):\n    \"\"\"Called at the end of a batch in `predict` methods.\n\n    Subclasses should override for any actions to run.\n\n    Note that if the `steps_per_execution` argument to `compile` in\n    `Program` is set to `N`, this method will only be called every\n    `N` batches.\n\n    Args:\n        batch (int): Index of batch within the current epoch.\n        logs (dict): Aggregated metric results up until this batch.\n    \"\"\"\n</code></pre>"},{"location":"Synalinks%20API/Callbacks%20API/Base%20Callback%20class/#synalinks.src.callbacks.callback.Callback.on_predict_begin","title":"<code>on_predict_begin(logs=None)</code>","text":"<p>Called at the beginning of prediction.</p> <p>Subclasses should override for any actions to run.</p> <p>Parameters:</p> Name Type Description Default <code>logs</code> <code>dict</code> <p>Currently no data is passed to this argument for this method but that may change in the future.</p> <code>None</code> Source code in <code>synalinks/src/callbacks/callback.py</code> <pre><code>@utils.default\ndef on_predict_begin(self, logs=None):\n    \"\"\"Called at the beginning of prediction.\n\n    Subclasses should override for any actions to run.\n\n    Args:\n        logs (dict): Currently no data is passed to this argument for this\n            method but that may change in the future.\n    \"\"\"\n</code></pre>"},{"location":"Synalinks%20API/Callbacks%20API/Base%20Callback%20class/#synalinks.src.callbacks.callback.Callback.on_predict_end","title":"<code>on_predict_end(logs=None)</code>","text":"<p>Called at the end of prediction.</p> <p>Subclasses should override for any actions to run.</p> <p>Parameters:</p> Name Type Description Default <code>logs</code> <code>dict</code> <p>Currently no data is passed to this argument for this method but that may change in the future.</p> <code>None</code> Source code in <code>synalinks/src/callbacks/callback.py</code> <pre><code>@utils.default\ndef on_predict_end(self, logs=None):\n    \"\"\"Called at the end of prediction.\n\n    Subclasses should override for any actions to run.\n\n    Args:\n        logs (dict): Currently no data is passed to this argument for this\n            method but that may change in the future.\n    \"\"\"\n</code></pre>"},{"location":"Synalinks%20API/Callbacks%20API/Base%20Callback%20class/#synalinks.src.callbacks.callback.Callback.on_test_batch_begin","title":"<code>on_test_batch_begin(batch, logs=None)</code>","text":"<p>Called at the beginning of a batch in <code>evaluate</code> methods.</p> <p>Also called at the beginning of a validation batch in the <code>fit</code> methods, if validation data is provided.</p> <p>Subclasses should override for any actions to run.</p> <p>Note that if the <code>steps_per_execution</code> argument to <code>compile</code> in <code>Program</code> is set to <code>N</code>, this method will only be called every <code>N</code> batches.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>int</code> <p>Index of batch within the current epoch.</p> required <code>logs</code> <code>dict</code> <p>Currently no data is passed to this argument for this method but that may change in the future.</p> <code>None</code> Source code in <code>synalinks/src/callbacks/callback.py</code> <pre><code>@utils.default\ndef on_test_batch_begin(self, batch, logs=None):\n    \"\"\"Called at the beginning of a batch in `evaluate` methods.\n\n    Also called at the beginning of a validation batch in the `fit`\n    methods, if validation data is provided.\n\n    Subclasses should override for any actions to run.\n\n    Note that if the `steps_per_execution` argument to `compile` in\n    `Program` is set to `N`, this method will only be called every\n    `N` batches.\n\n    Args:\n        batch (int): Index of batch within the current epoch.\n        logs (dict): Currently no data is passed to this argument for this\n            method but that may change in the future.\n    \"\"\"\n</code></pre>"},{"location":"Synalinks%20API/Callbacks%20API/Base%20Callback%20class/#synalinks.src.callbacks.callback.Callback.on_test_batch_end","title":"<code>on_test_batch_end(batch, logs=None)</code>","text":"<p>Called at the end of a batch in <code>evaluate</code> methods.</p> <p>Also called at the end of a validation batch in the <code>fit</code> methods, if validation data is provided.</p> <p>Subclasses should override for any actions to run.</p> <p>Note that if the <code>steps_per_execution</code> argument to <code>compile</code> in <code>Program</code> is set to <code>N</code>, this method will only be called every <code>N</code> batches.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>int</code> <p>Index of batch within the current epoch.</p> required <code>logs</code> <code>dict</code> <p>Aggregated metric results up until this batch.</p> <code>None</code> Source code in <code>synalinks/src/callbacks/callback.py</code> <pre><code>@utils.default\ndef on_test_batch_end(self, batch, logs=None):\n    \"\"\"Called at the end of a batch in `evaluate` methods.\n\n    Also called at the end of a validation batch in the `fit`\n    methods, if validation data is provided.\n\n    Subclasses should override for any actions to run.\n\n    Note that if the `steps_per_execution` argument to `compile` in\n    `Program` is set to `N`, this method will only be called every\n    `N` batches.\n\n    Args:\n        batch (int): Index of batch within the current epoch.\n        logs (dict): Aggregated metric results up until this batch.\n    \"\"\"\n</code></pre>"},{"location":"Synalinks%20API/Callbacks%20API/Base%20Callback%20class/#synalinks.src.callbacks.callback.Callback.on_test_begin","title":"<code>on_test_begin(logs=None)</code>","text":"<p>Called at the beginning of evaluation or validation.</p> <p>Subclasses should override for any actions to run.</p> <p>Parameters:</p> Name Type Description Default <code>logs</code> <code>dict</code> <p>Currently no data is passed to this argument for this method but that may change in the future.</p> <code>None</code> Source code in <code>synalinks/src/callbacks/callback.py</code> <pre><code>@utils.default\ndef on_test_begin(self, logs=None):\n    \"\"\"Called at the beginning of evaluation or validation.\n\n    Subclasses should override for any actions to run.\n\n    Args:\n        logs (dict): Currently no data is passed to this argument for this\n            method but that may change in the future.\n    \"\"\"\n</code></pre>"},{"location":"Synalinks%20API/Callbacks%20API/Base%20Callback%20class/#synalinks.src.callbacks.callback.Callback.on_test_end","title":"<code>on_test_end(logs=None)</code>","text":"<p>Called at the end of evaluation or validation.</p> <p>Subclasses should override for any actions to run.</p> <p>Parameters:</p> Name Type Description Default <code>logs</code> <code>dict</code> <p>Currently the output of the last call to <code>on_test_batch_end()</code> is passed to this argument for this method but that may change in the future.</p> <code>None</code> Source code in <code>synalinks/src/callbacks/callback.py</code> <pre><code>@utils.default\ndef on_test_end(self, logs=None):\n    \"\"\"Called at the end of evaluation or validation.\n\n    Subclasses should override for any actions to run.\n\n    Args:\n        logs (dict): Currently the output of the last call to\n            `on_test_batch_end()` is passed to this argument for this method\n            but that may change in the future.\n    \"\"\"\n</code></pre>"},{"location":"Synalinks%20API/Callbacks%20API/Base%20Callback%20class/#synalinks.src.callbacks.callback.Callback.on_train_batch_begin","title":"<code>on_train_batch_begin(batch, logs=None)</code>","text":"<p>Called at the beginning of a training batch in <code>fit</code> methods.</p> <p>Subclasses should override for any actions to run.</p> <p>Note that if the <code>steps_per_execution</code> argument to <code>compile</code> in <code>Program</code> is set to <code>N</code>, this method will only be called every <code>N</code> batches.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>int</code> <p>Index of batch within the current epoch.</p> required <code>logs</code> <code>dict</code> <p>Currently no data is passed to this argument for this method but that may change in the future.</p> <code>None</code> Source code in <code>synalinks/src/callbacks/callback.py</code> <pre><code>@utils.default\ndef on_train_batch_begin(self, batch, logs=None):\n    \"\"\"Called at the beginning of a training batch in `fit` methods.\n\n    Subclasses should override for any actions to run.\n\n    Note that if the `steps_per_execution` argument to `compile` in\n    `Program` is set to `N`, this method will only be called every\n    `N` batches.\n\n    Args:\n        batch (int): Index of batch within the current epoch.\n        logs (dict): Currently no data is passed to this argument for this\n            method but that may change in the future.\n    \"\"\"\n    # For backwards compatibility.\n    self.on_batch_begin(batch, logs=logs)\n</code></pre>"},{"location":"Synalinks%20API/Callbacks%20API/Base%20Callback%20class/#synalinks.src.callbacks.callback.Callback.on_train_batch_end","title":"<code>on_train_batch_end(batch, logs=None)</code>","text":"<p>Called at the end of a training batch in <code>fit</code> methods.</p> <p>Subclasses should override for any actions to run.</p> <p>Note that if the <code>steps_per_execution</code> argument to <code>compile</code> in <code>Program</code> is set to <code>N</code>, this method will only be called every <code>N</code> batches.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>int</code> <p>Index of batch within the current epoch.</p> required <code>logs</code> <code>dict</code> <p>Aggregated metric results up until this batch.</p> <code>None</code> Source code in <code>synalinks/src/callbacks/callback.py</code> <pre><code>@utils.default\ndef on_train_batch_end(self, batch, logs=None):\n    \"\"\"Called at the end of a training batch in `fit` methods.\n\n    Subclasses should override for any actions to run.\n\n    Note that if the `steps_per_execution` argument to `compile` in\n    `Program` is set to `N`, this method will only be called every\n    `N` batches.\n\n    Args:\n        batch (int): Index of batch within the current epoch.\n        logs (dict): Aggregated metric results up until this batch.\n    \"\"\"\n    # For backwards compatibility.\n    self.on_batch_end(batch, logs=logs)\n</code></pre>"},{"location":"Synalinks%20API/Callbacks%20API/Base%20Callback%20class/#synalinks.src.callbacks.callback.Callback.on_train_begin","title":"<code>on_train_begin(logs=None)</code>","text":"<p>Called at the beginning of training.</p> <p>Subclasses should override for any actions to run.</p> <p>Parameters:</p> Name Type Description Default <code>logs</code> <code>dict</code> <p>Currently no data is passed to this argument for this method but that may change in the future.</p> <code>None</code> Source code in <code>synalinks/src/callbacks/callback.py</code> <pre><code>@utils.default\ndef on_train_begin(self, logs=None):\n    \"\"\"Called at the beginning of training.\n\n    Subclasses should override for any actions to run.\n\n    Args:\n        logs (dict): Currently no data is passed to this argument for this\n            method but that may change in the future.\n    \"\"\"\n</code></pre>"},{"location":"Synalinks%20API/Callbacks%20API/Base%20Callback%20class/#synalinks.src.callbacks.callback.Callback.on_train_end","title":"<code>on_train_end(logs=None)</code>","text":"<p>Called at the end of training.</p> <p>Subclasses should override for any actions to run.</p> <p>Parameters:</p> Name Type Description Default <code>logs</code> <code>dict</code> <p>Currently the output of the last call to <code>on_epoch_end()</code> is passed to this argument for this method but that may change in the future.</p> <code>None</code> Source code in <code>synalinks/src/callbacks/callback.py</code> <pre><code>@utils.default\ndef on_train_end(self, logs=None):\n    \"\"\"Called at the end of training.\n\n    Subclasses should override for any actions to run.\n\n    Args:\n        logs (dict): Currently the output of the last call to\n            `on_epoch_end()` is passed to this argument for this method but\n            that may change in the future.\n    \"\"\"\n</code></pre>"},{"location":"Synalinks%20API/Callbacks%20API/CSVLogger/","title":"CSVLogger","text":""},{"location":"Synalinks%20API/Callbacks%20API/CSVLogger/#synalinks.src.callbacks.csv_logger.CSVLogger","title":"<code>CSVLogger</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Callback that streams epoch results to a CSV file.</p> <p>Supports all values that can be represented as a string, including 1D iterables such as <code>np.ndarray</code>.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str | PathLike</code> <p>Filepath of the CSV file, e.g. <code>'run/log.csv'</code>.</p> required <code>separator</code> <code>str</code> <p>String used to separate elements in the CSV file.</p> <code>','</code> <code>append</code> <code>bool</code> <p>True: append if file exists (useful for continuing training). False: overwrite existing file.</p> <code>False</code> <p>Example:</p> <pre><code>csv_logger = CSVLogger(filepath='training.log')\nprogram.fit(x_train, y_train, callbacks=[csv_logger])\n</code></pre> Source code in <code>synalinks/src/callbacks/csv_logger.py</code> <pre><code>@synalinks_export(\"synalinks.callbacks.CSVLogger\")\nclass CSVLogger(Callback):\n    \"\"\"Callback that streams epoch results to a CSV file.\n\n    Supports all values that can be represented as a string,\n    including 1D iterables such as `np.ndarray`.\n\n    Args:\n        filepath (str | os.PathLike): Filepath of the CSV file, e.g. `'run/log.csv'`.\n        separator (str): String used to separate elements in the CSV file.\n        append (bool): True: append if file exists (useful for continuing\n            training). False: overwrite existing file.\n\n    Example:\n\n    ```python\n    csv_logger = CSVLogger(filepath='training.log')\n    program.fit(x_train, y_train, callbacks=[csv_logger])\n    ```\n    \"\"\"\n\n    def __init__(self, filepath, separator=\",\", append=False):\n        super().__init__()\n        self.sep = separator\n        self.filepath = file_utils.path_to_string(filepath)\n        self.append = append\n        self.writer = None\n        self.keys = None\n        self.append_header = True\n\n    def on_train_begin(self, logs=None):\n        if self.append:\n            if file_utils.exists(self.filepath):\n                with file_utils.File(self.filepath, \"r\") as f:\n                    self.append_header = not bool(len(f.readline()))\n            mode = \"a\"\n        else:\n            mode = \"w\"\n        self.csv_file = file_utils.File(self.filepath, mode)\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n\n        def handle_value(k):\n            is_zero_dim_ndarray = isinstance(k, np.ndarray) and k.ndim == 0\n            if isinstance(k, str):\n                return k\n            elif isinstance(k, collections.abc.Iterable) and not is_zero_dim_ndarray:\n                return f'\"[{\", \".join(map(str, k))}]\"'\n            else:\n                return k\n\n        if self.keys is None:\n            self.keys = sorted(logs.keys())\n            # When validation_freq &gt; 1, `val_` keys are not in first epoch logs\n            # Add the `val_` keys so that its part of the fieldnames of writer.\n            val_keys_found = False\n            for key in self.keys:\n                if key.startswith(\"val_\"):\n                    val_keys_found = True\n                    break\n            if not val_keys_found:\n                self.keys.extend([\"val_\" + k for k in self.keys])\n\n        if not self.writer:\n\n            class CustomDialect(csv.excel):\n                delimiter = self.sep\n\n            fieldnames = [\"epoch\"] + self.keys\n\n            self.writer = csv.DictWriter(\n                self.csv_file, fieldnames=fieldnames, dialect=CustomDialect\n            )\n            if self.append_header:\n                self.writer.writeheader()\n\n        row_dict = collections.OrderedDict({\"epoch\": epoch})\n        row_dict.update((key, handle_value(logs.get(key, \"NA\"))) for key in self.keys)\n        self.writer.writerow(row_dict)\n        self.csv_file.flush()\n\n    def on_train_end(self, logs=None):\n        self.csv_file.close()\n        self.writer = None\n</code></pre>"},{"location":"Synalinks%20API/Callbacks%20API/ProgramCheckpoint/","title":"ProgramCheckpoint","text":""},{"location":"Synalinks%20API/Callbacks%20API/ProgramCheckpoint/#synalinks.src.callbacks.program_checkpoint.ProgramCheckpoint","title":"<code>ProgramCheckpoint</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Callback to save the Synalinks program or program variables at some frequency.</p> <p><code>ProgramCheckpoint</code> callback is used in conjunction with training using <code>program.fit()</code> to save a program or variables (in a checkpoint file) at some interval, so the program or variables can be loaded later to continue the training from the state saved.</p> <p>A few options this callback provides include:</p> <ul> <li>Whether to only keep the program that has achieved the \"best performance\" so   far, or whether to save the program at the end of every epoch regardless of   performance.</li> <li>Definition of \"best\"; which quantity to monitor and whether it should be   maximized or minimized.</li> <li>The frequency it should save at. Currently, the callback supports saving   at the end of every epoch, or after a fixed number of training batches.</li> <li>Whether only variables are saved, or the whole program is saved.</li> </ul> <p>Example:</p> <pre><code>program.compile(\n    reward=...,\n    optimizer=...,\n    metrics=[\n        ...\n    ],\n)\n\nEPOCHS = 10\ncheckpoint_filepath = '/tmp/synalinks/checkpoint.program.json'\n\nprogram_checkpoint_callback = synalinks.callbacks.ProgramCheckpoint(\n    filepath=checkpoint_filepath,\n    monitor='val_reward',\n    mode='max',\n    save_best_only=True,\n)\n\n# Program is saved at the end of every epoch, if it's the best seen so far.\nprogram.fit(\n    x=x_train,\n    y=y_train,\n    validation_data=(x_test, y_test),\n    epochs=EPOCHS,\n    callbacks=[program_checkpoint_callback]\n)\n\n# The program (that are considered the best) can be loaded as -\nsynalinks.programs.load_program(checkpoint_filepath)\n\n# Alternatively, one could checkpoint just the program variables as -\ncheckpoint_filepath = '/tmp/synalinks/checkpoint.variables.json'\nprogram_checkpoint_callback = synalinks.callbacks.ProgramCheckpoint(\n    filepath=checkpoint_filepath,\n    save_variables_only=True,\n    monitor='val_accuracy',\n    mode='max',\n    save_best_only=True,\n)\n\n# Program variables are saved at the end of every epoch, if it's the best seen\n# so far.\nprogram.fit(\n    x=x_train,\n    y=y_train,\n    validation_data=(x_test, y_test),\n    epochs=EPOCHS,\n    callbacks=[program_checkpoint_callback]\n)\n\n# The program variables (that are considered the best) can be loaded as -\nprogram.load_variables(checkpoint_filepath)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str | PathLike</code> <p>string or <code>PathLike</code>, path to save the program file. <code>filepath</code> can contain named formatting options, which will be filled the value of <code>epoch</code> and keys in <code>logs</code> (passed in <code>on_epoch_end</code>). The <code>filepath</code> name needs to end with <code>\".variables.json\"</code> when <code>save_variables_only=True</code> or should end with <code>\".json\"</code> when checkpoint saving the whole program (default). For example, if <code>filepath</code> is <code>\"{epoch:02d}-{val_loss:.2f}.json\"</code> or \"{epoch:02d}-{val_loss:.2f}.variables.json\"`, then the program checkpoints will be saved with the epoch number and the validation loss in the filename. The directory of the filepath should not be reused by any other callbacks to avoid conflicts.</p> required <code>monitor</code> <code>str</code> <p>The metric name to monitor. Typically the metrics are set by the <code>Program.compile</code> method. Note: * Prefix the name with <code>\"val_\"</code> to monitor validation metrics. * Use <code>\"reward\"</code> or <code>\"val_reward\"</code> to monitor the program's total reward. * If you specify metrics as strings, like <code>\"accuracy\"</code>, pass the     same string (with or without the <code>\"val_\"</code> prefix). * If you pass <code>metrics.Metric</code> objects, <code>monitor</code> should be set to     <code>metric.name</code> * If you're not sure about the metric names you can check the     contents of the <code>history.history</code> dictionary returned by     <code>history = program.fit()</code> * Multi-output programs set additional prefixes on the metric names.</p> <code>'val_reward'</code> <code>verbose</code> <code>str | int</code> <p>Verbosity mode, 0 or 1. Mode 0 is silent, and mode 1 displays messages when the callback takes an action.</p> <code>0</code> <code>save_best_only</code> <code>bool</code> <p>if <code>save_best_only=True</code>, it only saves when the program is considered the \"best\" and the latest best program according to the quantity monitored will not be overwritten. If <code>filepath</code> doesn't contain formatting options like <code>{epoch}</code> then <code>filepath</code> will be overwritten by each new better program.</p> <code>False</code> <code>mode</code> <code>str</code> <p>one of {<code>\"auto\"</code>, <code>\"min\"</code>, <code>\"max\"</code>}. If <code>save_best_only=True</code>, the decision to overwrite the current save file is made based on either the maximization or the minimization of the monitored quantity. In <code>\"auto\"</code> mode, the mode is set to <code>\"max\"</code>.</p> <code>'auto'</code> <code>save_variables_only</code> <code>bool</code> <p>if <code>True</code>, then only the program's variables will be saved (<code>program.save_variables(filepath)</code>), else the full program is saved (<code>program.save(filepath)</code>).</p> <code>False</code> <code>save_freq</code> <code>str | int</code> <p><code>\"epoch\"</code> or integer. When using <code>\"epoch\"</code>, the callback saves the program after each epoch. When using integer, the callback saves the program at end of this many batches. If the <code>Program</code> is compiled with <code>steps_per_execution=N</code>, then the saving criteria will be checked every Nth batch. Note that if the saving isn't aligned to epochs, the monitored metric may potentially be less reliable (it could reflect as little as 1 batch, since the metrics get reset every epoch). Defaults to <code>\"epoch\"</code>.</p> <code>'epoch'</code> <code>initial_value_threshold</code> <code>float</code> <p>Floating point initial \"best\" value of the metric to be monitored. Only applies if <code>save_best_value=True</code>. Only overwrites the program variables already saved if the performance of current program is better than this value.</p> <code>None</code> Source code in <code>synalinks/src/callbacks/program_checkpoint.py</code> <pre><code>@synalinks_export(\"synalinks.callbacks.ProgramCheckpoint\")\nclass ProgramCheckpoint(Callback):\n    \"\"\"Callback to save the Synalinks program or program variables at some frequency.\n\n    `ProgramCheckpoint` callback is used in conjunction with training using\n    `program.fit()` to save a program or variables (in a checkpoint file) at some\n    interval, so the program or variables can be loaded later to continue the\n    training from the state saved.\n\n    A few options this callback provides include:\n\n    - Whether to only keep the program that has achieved the \"best performance\" so\n      far, or whether to save the program at the end of every epoch regardless of\n      performance.\n    - Definition of \"best\"; which quantity to monitor and whether it should be\n      maximized or minimized.\n    - The frequency it should save at. Currently, the callback supports saving\n      at the end of every epoch, or after a fixed number of training batches.\n    - Whether only variables are saved, or the whole program is saved.\n\n    Example:\n\n    ```python\n    program.compile(\n        reward=...,\n        optimizer=...,\n        metrics=[\n            ...\n        ],\n    )\n\n    EPOCHS = 10\n    checkpoint_filepath = '/tmp/synalinks/checkpoint.program.json'\n\n    program_checkpoint_callback = synalinks.callbacks.ProgramCheckpoint(\n        filepath=checkpoint_filepath,\n        monitor='val_reward',\n        mode='max',\n        save_best_only=True,\n    )\n\n    # Program is saved at the end of every epoch, if it's the best seen so far.\n    program.fit(\n        x=x_train,\n        y=y_train,\n        validation_data=(x_test, y_test),\n        epochs=EPOCHS,\n        callbacks=[program_checkpoint_callback]\n    )\n\n    # The program (that are considered the best) can be loaded as -\n    synalinks.programs.load_program(checkpoint_filepath)\n\n    # Alternatively, one could checkpoint just the program variables as -\n    checkpoint_filepath = '/tmp/synalinks/checkpoint.variables.json'\n    program_checkpoint_callback = synalinks.callbacks.ProgramCheckpoint(\n        filepath=checkpoint_filepath,\n        save_variables_only=True,\n        monitor='val_accuracy',\n        mode='max',\n        save_best_only=True,\n    )\n\n    # Program variables are saved at the end of every epoch, if it's the best seen\n    # so far.\n    program.fit(\n        x=x_train,\n        y=y_train,\n        validation_data=(x_test, y_test),\n        epochs=EPOCHS,\n        callbacks=[program_checkpoint_callback]\n    )\n\n    # The program variables (that are considered the best) can be loaded as -\n    program.load_variables(checkpoint_filepath)\n    ```\n\n    Args:\n        filepath (str | os.PathLike): string or `PathLike`, path to save the program file.\n            `filepath` can contain named formatting options,\n            which will be filled the value of `epoch` and keys in `logs`\n            (passed in `on_epoch_end`).\n            The `filepath` name needs to end with `\".variables.json\"` when\n            `save_variables_only=True` or should end with `\".json\"`\n            when checkpoint saving the whole program (default).\n            For example, if `filepath` is `\"{epoch:02d}-{val_loss:.2f}.json\"` or\n            \"{epoch:02d}-{val_loss:.2f}.variables.json\"`, then the program\n            checkpoints will be saved with the epoch number and the validation\n            loss in the filename. The directory of the filepath\n            should not be reused by any other callbacks to avoid conflicts.\n        monitor (str): The metric name to monitor. Typically the metrics are set by\n            the `Program.compile` method. Note:\n            * Prefix the name with `\"val_\"` to monitor validation metrics.\n            * Use `\"reward\"` or `\"val_reward\"` to monitor the program's total reward.\n            * If you specify metrics as strings, like `\"accuracy\"`, pass the\n                same string (with or without the `\"val_\"` prefix).\n            * If you pass `metrics.Metric` objects, `monitor` should be set to\n                `metric.name`\n            * If you're not sure about the metric names you can check the\n                contents of the `history.history` dictionary returned by\n                `history = program.fit()`\n            * Multi-output programs set additional prefixes on the metric names.\n        verbose (str | int): Verbosity mode, 0 or 1. Mode 0 is silent, and mode 1\n            displays messages when the callback takes an action.\n        save_best_only (bool): if `save_best_only=True`, it only saves when the program\n            is considered the \"best\" and the latest best program according to the\n            quantity monitored will not be overwritten. If `filepath` doesn't\n            contain formatting options like `{epoch}` then `filepath` will be\n            overwritten by each new better program.\n        mode (str): one of {`\"auto\"`, `\"min\"`, `\"max\"`}. If `save_best_only=True`, the\n            decision to overwrite the current save file is made based on either\n            the maximization or the minimization of the monitored quantity.\n            In `\"auto\"` mode, the mode is set to `\"max\"`.\n        save_variables_only (bool): if `True`, then only the program's variables will be\n            saved (`program.save_variables(filepath)`), else the full program is\n            saved (`program.save(filepath)`).\n        save_freq (str | int): `\"epoch\"` or integer. When using `\"epoch\"`, the callback\n            saves the program after each epoch. When using integer, the callback\n            saves the program at end of this many batches. If the `Program` is\n            compiled with `steps_per_execution=N`, then the saving criteria will\n            be checked every Nth batch. Note that if the saving isn't aligned to\n            epochs, the monitored metric may potentially be less reliable (it\n            could reflect as little as 1 batch, since the metrics get reset\n            every epoch). Defaults to `\"epoch\"`.\n        initial_value_threshold (float): Floating point initial \"best\" value of the\n            metric to be monitored. Only applies if `save_best_value=True`. Only\n            overwrites the program variables already saved if the performance of\n            current program is better than this value.\n    \"\"\"\n\n    def __init__(\n        self,\n        filepath,\n        monitor=\"val_reward\",\n        verbose=0,\n        save_best_only=False,\n        save_variables_only=False,\n        mode=\"auto\",\n        save_freq=\"epoch\",\n        initial_value_threshold=None,\n    ):\n        super().__init__()\n        self.monitor = monitor\n        self.verbose = verbose\n        self.filepath = file_utils.path_to_string(filepath)\n        self.save_best_only = save_best_only\n        self.save_variables_only = save_variables_only\n        self.save_freq = save_freq\n        self._batches_seen_since_last_saving = 0\n        self._last_batch_seen = 0\n        self.best = initial_value_threshold\n\n        if mode not in [\"auto\", \"min\", \"max\"]:\n            warnings.warn(\n                f\"ProgramCheckpoint mode '{mode}' is unknown, fallback to auto mode.\",\n                stacklevel=2,\n            )\n            mode = \"auto\"\n\n        if mode == \"min\":\n            self.monitor_op = np.less\n            if self.best is None:\n                self.best = np.inf\n        elif mode == \"max\":\n            self.monitor_op = np.greater\n            if self.best is None:\n                self.best = -np.inf\n        else:\n            self.monitor_op = np.greater\n            if self.best is None:\n                self.best = -np.inf\n\n        if self.save_freq != \"epoch\" and not isinstance(self.save_freq, int):\n            raise ValueError(\n                f\"Unrecognized save_freq: {self.save_freq}. \"\n                \"Expected save_freq are 'epoch' or integer values\"\n            )\n\n        if save_variables_only:\n            if not self.filepath.endswith(\".variables.json\"):\n                raise ValueError(\n                    \"When using `save_variables_only=True` in `ProgramCheckpoint`\"\n                    \", the filepath provided must end in `.variables.json` \"\n                    \"(Synalinks variables format). Received: \"\n                    f\"filepath={self.filepath}\"\n                )\n        else:\n            if not self.filepath.endswith(\".json\"):\n                raise ValueError(\n                    \"The filepath provided must end in `.json` \"\n                    \"(Synalinks program format). Received: \"\n                    f\"filepath={self.filepath}\"\n                )\n\n    def on_train_batch_end(self, batch, logs=None):\n        if self._should_save_on_batch(batch):\n            self._save_program(epoch=self._current_epoch, batch=batch, logs=logs)\n\n    def on_epoch_begin(self, epoch, logs=None):\n        self._current_epoch = epoch\n\n    def on_epoch_end(self, epoch, logs=None):\n        if self.save_freq == \"epoch\":\n            self._save_program(epoch=epoch, batch=None, logs=logs)\n\n    def _should_save_on_batch(self, batch):\n        \"\"\"Handles batch-level saving logic, supports steps_per_execution.\"\"\"\n        if self.save_freq == \"epoch\":\n            return False\n        if batch &lt;= self._last_batch_seen:  # New epoch.\n            add_batches = batch + 1  # batches are zero-indexed.\n        else:\n            add_batches = batch - self._last_batch_seen\n        self._batches_seen_since_last_saving += add_batches\n        self._last_batch_seen = batch\n\n        if self._batches_seen_since_last_saving &gt;= self.save_freq:\n            self._batches_seen_since_last_saving = 0\n            return True\n        return False\n\n    def _save_program(self, epoch, batch, logs):\n        \"\"\"Saves the program.\n\n        Args:\n            epoch (int): the epoch this iteration is in.\n            batch (int): the batch this iteration is in. `None` if the `save_freq`\n                is set to `\"epoch\"`.\n            logs (dict): the `logs` dict passed in to `on_batch_end` or `on_epoch_end`.\n        \"\"\"\n        logs = logs or {}\n\n        filepath = self._get_file_path(epoch, batch, logs)\n        # Create host directory if it doesn't exist.\n        dirname = os.path.dirname(filepath)\n        if dirname and not file_utils.exists(dirname):\n            file_utils.makedirs(dirname)\n\n        try:\n            if self.save_best_only:\n                current = logs.get(self.monitor)\n                if current is None:\n                    warnings.warn(\n                        f\"Can save best model only with {self.monitor} \"\n                        \"available, skipping.\",\n                        stacklevel=2,\n                    )\n                elif isinstance(current, np.ndarray) and len(current.shape) &gt; 0:\n                    warnings.warn(\n                        \"Can save best model only when `monitor` is \"\n                        f\"a scalar value. Received: {current}. \"\n                        \"Falling back to `save_best_only=False`.\"\n                    )\n                    self.program.save(filepath, overwrite=True)\n                else:\n                    if self.monitor_op(current, self.best):\n                        if self.verbose &gt; 0:\n                            io_utils.print_msg(\n                                f\"\\nEpoch {epoch + 1}: {self.monitor} \"\n                                \"improved \"\n                                f\"from {self.best:.5f} to {current:.5f}, \"\n                                f\"saving program to {filepath}\"\n                            )\n                        self.best = current\n                        if self.save_variables_only:\n                            self.program.save_variables(filepath, overwrite=True)\n                        else:\n                            self.program.save(filepath, overwrite=True)\n                    else:\n                        if self.verbose &gt; 0:\n                            io_utils.print_msg(\n                                f\"\\nEpoch {epoch + 1}: \"\n                                f\"{self.monitor} did not improve \"\n                                f\"from {self.best:.5f}\"\n                            )\n            else:\n                if self.verbose &gt; 0:\n                    io_utils.print_msg(f\"\\nEpoch {epoch + 1}: saving model to {filepath}\")\n                if self.save_variables_only:\n                    self.program.save_variables(filepath, overwrite=True)\n                else:\n                    self.program.save(filepath, overwrite=True)\n        except IsADirectoryError:  # h5py 3.x\n            raise IOError(\n                \"Please specify a non-directory filepath for \"\n                \"ProgramCheckpoint. Filepath used is an existing \"\n                f\"directory: {filepath}\"\n            )\n        except IOError as e:  # h5py 2.x\n            # `e.errno` appears to be `None` so checking the content of\n            # `e.args[0]`.\n            if \"is a directory\" in str(e.args[0]).lower():\n                raise IOError(\n                    \"Please specify a non-directory filepath for \"\n                    \"ModelCheckpoint. Filepath used is an existing \"\n                    f\"directory: {filepath}\"\n                )\n            # Re-throw the error for any other causes.\n            raise e\n\n    def _get_file_path(self, epoch, batch, logs):\n        \"\"\"Returns the file path for checkpoint.\"\"\"\n\n        try:\n            # `filepath` may contain placeholders such as\n            # `{epoch:02d}`,`{batch:02d}` and `{mape:.2f}`. A mismatch between\n            # logged metrics and the path's placeholders can cause formatting to\n            # fail.\n            if batch is None or \"batch\" in logs:\n                file_path = self.filepath.format(epoch=epoch + 1, **logs)\n            else:\n                file_path = self.filepath.format(epoch=epoch + 1, batch=batch + 1, **logs)\n        except KeyError as e:\n            raise KeyError(\n                f'Failed to format this callback filepath: \"{self.filepath}\". Reason: {e}'\n            )\n        return file_path\n\n    def _checkpoint_exists(self, filepath):\n        \"\"\"Returns whether the checkpoint `filepath` refers to exists.\"\"\"\n        return file_utils.exists(filepath)\n\n    def _get_most_recently_modified_file_matching_pattern(self, pattern):\n        \"\"\"Returns the most recently modified filepath matching pattern.\n\n        In the rare case where there are more than one pattern-matching file\n        having the same modified time that is most recent among all, return the\n        filepath that is largest (by `&gt;` operator, lexicographically using the\n        numeric equivalents). This provides a tie-breaker when multiple files\n        are most recent. Note that a larger `filepath` can sometimes indicate a\n        later time of modification (for instance, when epoch/batch is used as\n        formatting option), but not necessarily (when accuracy or loss is used).\n        The tie-breaker is put in the logic as best effort to return the most\n        recent, and to avoid nondeterministic result.\n\n        Modified time of a file is obtained with `os.path.getmtime()`.\n\n        This utility function is best demonstrated via an example:\n\n        ```python\n        file_pattern = 'batch{batch:02d}epoch{epoch:02d}.json'\n        test_dir = self.get_temp_dir()\n        path_pattern = os.path.join(test_dir, file_pattern)\n        file_paths = [\n            os.path.join(test_dir, file_name) for file_name in\n            ['batch03epoch02.json',\n             'batch02epoch02.json', 'batch01epoch01.json']\n        ]\n        for file_path in file_paths:\n            # Write something to each of the files\n            ...\n        self.assertEqual(\n            _get_most_recently_modified_file_matching_pattern(path_pattern),\n            file_paths[-1])\n        ```\n\n        Args:\n            pattern (str): The file pattern that may optionally contain python\n                placeholder such as `{epoch:02d}`.\n\n        Returns:\n            (str): The most recently modified file's full filepath matching `pattern`.\n                If `pattern` does not contain any placeholder, this returns the\n                filepath that exactly matches `pattern`. Returns `None` if no match\n                is found.\n        \"\"\"\n        dir_name = os.path.dirname(pattern)\n        base_name = os.path.basename(pattern)\n        base_name_regex = \"^\" + re.sub(r\"{.*}\", r\".*\", base_name) + \"$\"\n\n        latest_mod_time = 0\n        file_path_with_latest_mod_time = None\n        n_file_with_latest_mod_time = 0\n        file_path_with_largest_file_name = None\n\n        if file_utils.exists(dir_name):\n            for file_name in os.listdir(dir_name):\n                # Only consider if `file_name` matches the pattern.\n                if re.match(base_name_regex, file_name):\n                    file_path = os.path.join(dir_name, file_name)\n                    mod_time = os.path.getmtime(file_path)\n                    if (\n                        file_path_with_largest_file_name is None\n                        or file_path &gt; file_path_with_largest_file_name\n                    ):\n                        file_path_with_largest_file_name = file_path\n                    if mod_time &gt; latest_mod_time:\n                        latest_mod_time = mod_time\n                        file_path_with_latest_mod_time = file_path\n                        # In the case a file with later modified time is found,\n                        # reset the counter for the number of files with latest\n                        # modified time.\n                        n_file_with_latest_mod_time = 1\n                    elif mod_time == latest_mod_time:\n                        # In the case a file has modified time tied with the\n                        # most recent, increment the counter for the number of\n                        # files with latest modified time by 1.\n                        n_file_with_latest_mod_time += 1\n\n        if n_file_with_latest_mod_time == 1:\n            # Return the sole file that has most recent modified time.\n            return file_path_with_latest_mod_time\n        else:\n            # If there are more than one file having latest modified time,\n            # return the file path with the largest file name.\n            return file_path_with_largest_file_name\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/","title":"Data Models API","text":"<p>Synalinks features four distinct types of data models, each serving a unique purpose within the framework:</p> <ul> <li> <p>DataModel: This is the backend-dependent data model, built on Pydantic's <code>BaseModel</code>. It is the primary model most users will interact with. It allows for schema and variable declarations, and is used to format datasets. When entering a workflow, this data model is automatically converted into a backend-independent format.</p> </li> <li> <p>JsonDataModel: This is the backend-independent data model that flows through the pipelines. It holds both a JSON schema and a JSON value, enabling it to perform computations. Unlike the backend-dependent model, this one is dynamically created and modified.</p> </li> <li> <p>SymbolicDataModel: This is the symbolic data model used during the functional API declaration to infer the pipeline's edges and nodes. It only holds a JSON schema, allowing the system to compute the pipeline from inputs and outputs without performing actual computations.</p> </li> <li> <p>Variable: This data model holds the module's state and can be updated during training. It includes a JSON schema and JSON value, enabling computations, and also contains metadata about training. <code>Optimizer</code>s can update it during the training process.</p> </li> </ul>"},{"location":"Synalinks%20API/Data%20Models%20API/#data-models-api-overview","title":"Data Models API Overview","text":"<ul> <li>The DataModel Class: The backend-dependent data models.</li> <li>The JsonDataModel Class: The backend-independent data models.</li> <li>The SymbolicDataModel Class: The symbolic data models.</li> <li>The Variable Class: The variable data models that the optimizers can act upon.</li> <li>The Base DataModels: A collection of basic backend-dependent data models.</li> </ul>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/","title":"The Base DataModels","text":"<p>We provide different backend-dependent <code>DataModel</code>s to use.</p> <p>These data models provide I/O for chatbots, agents, rags, knowledge graphs etc.</p> <p>The user can build new data models by inheriting from these base models.</p> <p>The check functions works for every type of data models (by checking the schema) e.g. <code>SymbolicDataModel</code>, <code>JsonDataModel</code>, <code>DataModel</code> or <code>Variable</code>.</p>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/#synalinks.src.backend.pydantic.base.ChatMessage","title":"<code>ChatMessage</code>","text":"<p>               Bases: <code>DataModel</code></p> <p>A chat message</p> Source code in <code>synalinks/src/backend/pydantic/base.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.backend.ChatMessage\",\n        \"synalinks.ChatMessage\",\n    ]\n)\nclass ChatMessage(DataModel):\n    \"\"\"A chat message\"\"\"\n\n    role: ChatRole\n    content: str\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/#synalinks.src.backend.pydantic.base.ChatMessages","title":"<code>ChatMessages</code>","text":"<p>               Bases: <code>DataModel</code></p> <p>A list of chat messages</p> Source code in <code>synalinks/src/backend/pydantic/base.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.backend.ChatMessages\",\n        \"synalinks.ChatMessages\",\n    ]\n)\nclass ChatMessages(DataModel):\n    \"\"\"A list of chat messages\"\"\"\n\n    messages: List[ChatMessage] = Field(\n        description=\"The list of chat messages\",\n        default=[],\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/#synalinks.src.backend.pydantic.base.ChatRole","title":"<code>ChatRole</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>The chat message roles</p> Source code in <code>synalinks/src/backend/pydantic/base.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.backend.ChatRole\",\n        \"synalinks.ChatRole\",\n    ]\n)\nclass ChatRole(str, Enum):\n    \"\"\"The chat message roles\"\"\"\n\n    SYSTEM = \"system\"\n    USER = \"user\"\n    ASSISTANT = \"assistant\"\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/#synalinks.src.backend.pydantic.base.Embedding","title":"<code>Embedding</code>","text":"<p>               Bases: <code>DataModel</code></p> <p>An embedding vector</p> Source code in <code>synalinks/src/backend/pydantic/base.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.backend.Embedding\",\n    ]\n)\nclass Embedding(DataModel):\n    \"\"\"An embedding vector\"\"\"\n\n    embedding: List[float] = Field(\n        description=\"The embedding vector\",\n        default=[],\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/#synalinks.src.backend.pydantic.base.Embeddings","title":"<code>Embeddings</code>","text":"<p>               Bases: <code>DataModel</code></p> <p>A list of embeddings</p> Source code in <code>synalinks/src/backend/pydantic/base.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.backend.Embeddings\",\n        \"synalinks.Embeddings\",\n    ]\n)\nclass Embeddings(DataModel):\n    \"\"\"A list of embeddings\"\"\"\n\n    embeddings: List[List[float]] = Field(\n        description=\"The list of embedding vectors\",\n        default=[],\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/#synalinks.src.backend.pydantic.base.Entity","title":"<code>Entity</code>","text":"<p>               Bases: <code>DataModel</code></p> <p>An entity data model</p> Source code in <code>synalinks/src/backend/pydantic/base.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.backend.Entity\",\n        \"synalinks.Entity\",\n    ]\n)\nclass Entity(DataModel):\n    \"\"\"An entity data model\"\"\"\n\n    label: str = Field(\n        description=\"The entity label\",\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/#synalinks.src.backend.pydantic.base.GenericIO","title":"<code>GenericIO</code>","text":"<p>               Bases: <code>DataModel</code></p> <p>A pair of generic inputs/outputs</p> Source code in <code>synalinks/src/backend/pydantic/base.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.backend.GenericIO\",\n        \"synalinks.GenericIO\",\n    ]\n)\nclass GenericIO(DataModel):\n    \"\"\"A pair of generic inputs/outputs\"\"\"\n\n    inputs: Dict[str, Any] = Field(\n        description=\"The inputs\",\n    )\n    outputs: Dict[str, Any] = Field(\n        description=\"The outputs\",\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/#synalinks.src.backend.pydantic.base.GenericInputs","title":"<code>GenericInputs</code>","text":"<p>               Bases: <code>DataModel</code></p> <p>A generic inputs</p> Source code in <code>synalinks/src/backend/pydantic/base.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.backend.GenericInputs\",\n        \"synalinks.GenericInputs\",\n    ]\n)\nclass GenericInputs(DataModel):\n    \"\"\"A generic inputs\"\"\"\n\n    inputs: Dict[str, Any] = Field(\n        description=\"The inputs\",\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/#synalinks.src.backend.pydantic.base.GenericOutputs","title":"<code>GenericOutputs</code>","text":"<p>               Bases: <code>DataModel</code></p> <p>A generic outputs</p> Source code in <code>synalinks/src/backend/pydantic/base.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.backend.GenericOutputs\",\n        \"synalinks.GenericOutputs\",\n    ]\n)\nclass GenericOutputs(DataModel):\n    \"\"\"A generic outputs\"\"\"\n\n    outputs: Dict[str, Any] = Field(\n        description=\"The outputs\",\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/#synalinks.src.backend.pydantic.base.GenericResult","title":"<code>GenericResult</code>","text":"<p>               Bases: <code>DataModel</code></p> <p>A generic result</p> Source code in <code>synalinks/src/backend/pydantic/base.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.backend.GenericResult\",\n        \"synalinks.GenericResult\",\n    ]\n)\nclass GenericResult(DataModel):\n    \"\"\"A generic result\"\"\"\n\n    result: List[Any] = Field(\n        description=\"The result\",\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/#synalinks.src.backend.pydantic.base.Instructions","title":"<code>Instructions</code>","text":"<p>               Bases: <code>Entity</code></p> <p>The generator's instructions</p> Source code in <code>synalinks/src/backend/pydantic/base.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.backend.Instructions\",\n        \"synalinks.Instructions\",\n    ]\n)\nclass Instructions(Entity):\n    \"\"\"The generator's instructions\"\"\"\n\n    label: Literal[\"Instructions\"] = \"Instructions\"\n    instructions: List[str] = Field(\n        description=\"The list of instructions\",\n    )\n    reward: Optional[float] = Field(\n        description=\"The instruction's reward\",\n        default=None,\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/#synalinks.src.backend.pydantic.base.Prediction","title":"<code>Prediction</code>","text":"<p>               Bases: <code>Entity</code>, <code>GenericIO</code></p> <p>The generator's prediction</p> Source code in <code>synalinks/src/backend/pydantic/base.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.backend.Prediction\",\n        \"synalinks.Prediction\",\n    ]\n)\nclass Prediction(Entity, GenericIO):\n    \"\"\"The generator's prediction\"\"\"\n\n    label: Literal[\"Prediction\"] = \"Prediction\"\n    reward: Optional[float] = Field(\n        description=\"The prediction's reward\",\n        default=None,\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/#synalinks.src.backend.pydantic.base.Relation","title":"<code>Relation</code>","text":"<p>               Bases: <code>DataModel</code></p> <p>A relation model</p> Source code in <code>synalinks/src/backend/pydantic/base.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.backend.Relation\",\n        \"synalinks.Relation\",\n    ]\n)\nclass Relation(DataModel):\n    \"\"\"A relation model\"\"\"\n\n    obj: Entity = Field(\n        description=\"The object entity\",\n    )\n    label: str = Field(\n        description=\"The relation label\",\n    )\n    subj: Entity = Field(\n        description=\"The subject entity\",\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/#synalinks.src.backend.pydantic.base.is_chat_message","title":"<code>is_chat_message(x)</code>","text":"<p>Checks if the given data model is a chat message</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>DataModel | JsonDataModel | SymbolicDataModel | Variable</code> <p>The data model to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the condition is met</p> Source code in <code>synalinks/src/backend/pydantic/base.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.backend.is_chat_message\",\n        \"synalinks.is_chat_message\",\n    ]\n)\ndef is_chat_message(x):\n    \"\"\"Checks if the given data model is a chat message\n\n    Args:\n        x (DataModel | JsonDataModel | SymbolicDataModel | Variable):\n            The data model to check.\n\n    Returns:\n        (bool): True if the condition is met\n    \"\"\"\n    if contains_schema(x.get_schema(), ChatMessage.get_schema()):\n        return True\n    return False\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/#synalinks.src.backend.pydantic.base.is_chat_messages","title":"<code>is_chat_messages(x)</code>","text":"<p>Checks if the given data model are chat messages</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>DataModel | JsonDataModel | SymbolicDataModel | Variable</code> <p>The data model to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the condition is met</p> Source code in <code>synalinks/src/backend/pydantic/base.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.backend.is_chat_messages\",\n        \"synalinks.is_chat_messages\",\n    ]\n)\ndef is_chat_messages(x):\n    \"\"\"Checks if the given data model are chat messages\n\n    Args:\n        x (DataModel | JsonDataModel | SymbolicDataModel | Variable):\n            The data model to check.\n\n    Returns:\n        (bool): True if the condition is met\n    \"\"\"\n    if contains_schema(x.get_schema(), ChatMessages.get_schema()):\n        return True\n    return False\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/#synalinks.src.backend.pydantic.base.is_embedded_entity","title":"<code>is_embedded_entity(x)</code>","text":"<p>Checks if the given data model is an embedded entity</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>DataModel | JsonDataModel | SymbolicDataModel | Variable</code> <p>The data model to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the condition is met</p> Source code in <code>synalinks/src/backend/pydantic/base.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.backend.is_embedded_entity\",\n        \"synalinks.is_embedded_entity\",\n    ]\n)\ndef is_embedded_entity(x):\n    \"\"\"Checks if the given data model is an embedded entity\n\n    Args:\n        x (DataModel | JsonDataModel | SymbolicDataModel | Variable):\n            The data model to check.\n\n    Returns:\n        (bool): True if the condition is met\n    \"\"\"\n    schema = x.get_schema()\n    properties = schema.get(\"properties\", None)\n    if properties:\n        if properties.get(\"label\", None) and properties.get(\"embedding\", None):\n            return True\n    return False\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/#synalinks.src.backend.pydantic.base.is_embedding","title":"<code>is_embedding(x)</code>","text":"<p>Checks if the given data model is an embedding</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>DataModel | JsonDataModel | SymbolicDataModel | Variable</code> <p>The data model to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the condition is met</p> Source code in <code>synalinks/src/backend/pydantic/base.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.backend.is_embedding\",\n        \"synalinks.is_embedding\",\n    ]\n)\ndef is_embedding(x):\n    \"\"\"Checks if the given data model is an embedding\n\n    Args:\n        x (DataModel | JsonDataModel | SymbolicDataModel | Variable):\n            The data model to check.\n\n    Returns:\n        (bool): True if the condition is met\n    \"\"\"\n    if contains_schema(x.get_schema(), Embedding.get_schema()):\n        return True\n    return False\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/#synalinks.src.backend.pydantic.base.is_embeddings","title":"<code>is_embeddings(x)</code>","text":"<p>Checks if the given data model are embeddings</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>DataModel | JsonDataModel | SymbolicDataModel | Variable</code> <p>The data model to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the condition is met</p> Source code in <code>synalinks/src/backend/pydantic/base.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.backend.is_embeddings\",\n        \"synalinks.is_embeddings\",\n    ]\n)\ndef is_embeddings(x):\n    \"\"\"Checks if the given data model are embeddings\n\n    Args:\n        x (DataModel | JsonDataModel | SymbolicDataModel | Variable):\n            The data model to check.\n\n    Returns:\n        (bool): True if the condition is met\n    \"\"\"\n    if contains_schema(x.get_schema(), Embeddings.get_schema()):\n        return True\n    return False\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/#synalinks.src.backend.pydantic.base.is_entities","title":"<code>is_entities(x)</code>","text":"<p>Checks if is an entities model</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>DataModel | JsonDataModel | SymbolicDataModel | Variable</code> <p>The data model to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the condition is met</p> Source code in <code>synalinks/src/backend/pydantic/base.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.backend.is_entities\",\n        \"synalinks.is_entities\",\n    ]\n)\ndef is_entities(x):\n    \"\"\"Checks if is an entities model\n\n    Args:\n        x (DataModel | JsonDataModel | SymbolicDataModel | Variable):\n            The data model to check.\n\n    Returns:\n        (bool): True if the condition is met\n    \"\"\"\n    schema = x.get_schema()\n    properties = schema.get(\"properties\", None)\n    if properties:\n        if properties.get(\"entities\", None):\n            return True\n    return False\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/#synalinks.src.backend.pydantic.base.is_entity","title":"<code>is_entity(x)</code>","text":"<p>Checks if the given data model is an entity</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>DataModel | JsonDataModel | SymbolicDataModel | Variable</code> <p>The data model to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the condition is met</p> Source code in <code>synalinks/src/backend/pydantic/base.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.backend.is_entity\",\n        \"synalinks.is_entity\",\n    ]\n)\ndef is_entity(x):\n    \"\"\"Checks if the given data model is an entity\n\n    Args:\n        x (DataModel | JsonDataModel | SymbolicDataModel | Variable):\n            The data model to check.\n\n    Returns:\n        (bool): True if the condition is met\n    \"\"\"\n    schema = x.get_schema()\n    properties = schema.get(\"properties\", None)\n    if properties:\n        if properties.get(\"label\", None):\n            return True\n    return False\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/#synalinks.src.backend.pydantic.base.is_instructions","title":"<code>is_instructions(x)</code>","text":"<p>Checks if the given data model is an instructions data model</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>DataModel | JsonDataModel | SymbolicDataModel | Variable</code> <p>The data model to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the condition is met</p> Source code in <code>synalinks/src/backend/pydantic/base.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.backend.is_instructions\",\n        \"synalinks.is_instructions\",\n    ]\n)\ndef is_instructions(x):\n    \"\"\"Checks if the given data model is an instructions data model\n\n    Args:\n        x (DataModel | JsonDataModel | SymbolicDataModel | Variable):\n            The data model to check.\n\n    Returns:\n        (bool): True if the condition is met\n    \"\"\"\n    if contains_schema(x.get_schema(), Instructions.get_schema()):\n        return True\n    return False\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/#synalinks.src.backend.pydantic.base.is_knowledge_graph","title":"<code>is_knowledge_graph(x)</code>","text":"<p>Checks if is a knowledge graph model</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>DataModel | JsonDataModel | SymbolicDataModel | Variable</code> <p>The data model to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the condition is met</p> Source code in <code>synalinks/src/backend/pydantic/base.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.backend.is_knowledge_graph\",\n        \"synalinks.is_knowledge_graph\",\n    ]\n)\ndef is_knowledge_graph(x):\n    \"\"\"Checks if is a knowledge graph model\n\n    Args:\n        x (DataModel | JsonDataModel | SymbolicDataModel | Variable):\n            The data model to check.\n\n    Returns:\n        (bool): True if the condition is met\n    \"\"\"\n    schema = x.get_schema()\n    properties = schema.get(\"properties\", None)\n    if properties:\n        if properties.get(\"entities\", None) and properties.get(\"relations\", None):\n            return True\n    return False\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/#synalinks.src.backend.pydantic.base.is_prediction","title":"<code>is_prediction(x)</code>","text":"<p>Checks if the given data model is a prediction</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>DataModel | JsonDataModel | SymbolicDataModel | Variable</code> <p>The data model to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the condition is met</p> Source code in <code>synalinks/src/backend/pydantic/base.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.backend.is_prediction\",\n        \"synalinks.is_prediction\",\n    ]\n)\ndef is_prediction(x):\n    \"\"\"Checks if the given data model is a prediction\n\n    Args:\n        x (DataModel | JsonDataModel | SymbolicDataModel | Variable):\n            The data model to check.\n\n    Returns:\n        (bool): True if the condition is met\n    \"\"\"\n    if contains_schema(x.get_schema(), Prediction.get_schema()):\n        return True\n    return False\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/#synalinks.src.backend.pydantic.base.is_relation","title":"<code>is_relation(x)</code>","text":"<p>Checks if is a relation model</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>DataModel | JsonDataModel | SymbolicDataModel | Variable</code> <p>The data model to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the condition is met</p> Source code in <code>synalinks/src/backend/pydantic/base.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.backend.is_relation\",\n        \"synalinks.is_relation\",\n    ]\n)\ndef is_relation(x):\n    \"\"\"Checks if is a relation model\n\n    Args:\n        x (DataModel | JsonDataModel | SymbolicDataModel | Variable):\n            The data model to check.\n\n    Returns:\n        (bool): True if the condition is met\n    \"\"\"\n    schema = x.get_schema()\n    properties = schema.get(\"properties\", None)\n    if properties:\n        if (\n            properties.get(\"subj\", None)\n            and properties.get(\"label\", None)\n            and properties.get(\"obj\", None)\n        ):\n            return True\n    return False\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/#synalinks.src.backend.pydantic.base.is_relations","title":"<code>is_relations(x)</code>","text":"<p>Checks if is an relations model</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>DataModel | JsonDataModel | SymbolicDataModel | Variable</code> <p>The data model to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the condition is met</p> Source code in <code>synalinks/src/backend/pydantic/base.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.backend.is_relations\",\n        \"synalinks.is_relations\",\n    ]\n)\ndef is_relations(x):\n    \"\"\"Checks if is an relations model\n\n    Args:\n        x (DataModel | JsonDataModel | SymbolicDataModel | Variable):\n            The data model to check.\n\n    Returns:\n        (bool): True if the condition is met\n    \"\"\"\n    schema = x.get_schema()\n    properties = schema.get(\"properties\", None)\n    if properties:\n        if properties.get(\"relations\", None):\n            return True\n    return False\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/#synalinks.src.backend.pydantic.base.is_similarity_search","title":"<code>is_similarity_search(x)</code>","text":"<p>Checks if is a similarity search data model</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>DataModel | JsonDataModel | SymbolicDataModel | Variable</code> <p>The data model to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the condition is met</p> Source code in <code>synalinks/src/backend/pydantic/base.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.backend.is_similarity_search\",\n        \"synalinks.is_similarity_search\",\n    ]\n)\ndef is_similarity_search(x):\n    \"\"\"Checks if is a similarity search data model\n\n    Args:\n        x (DataModel | JsonDataModel | SymbolicDataModel | Variable):\n            The data model to check.\n\n    Returns:\n        (bool): True if the condition is met\n    \"\"\"\n    schema = x.get_schema()\n    properties = schema.get(\"properties\", None)\n    if properties:\n        if properties.get(\"entity_label\", None) and properties.get(\n            \"similarity_search\", None\n        ):\n            return True\n    return False\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Base%20DataModels/#synalinks.src.backend.pydantic.base.is_triplet_search","title":"<code>is_triplet_search(x)</code>","text":"<p>Checks if is a triplet seach data model</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>DataModel | JsonDataModel | SymbolicDataModel | Variable</code> <p>The data model to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the condition is met</p> Source code in <code>synalinks/src/backend/pydantic/base.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.backend.is_triplet_search\",\n        \"synalinks.is_triplet_search\",\n    ]\n)\ndef is_triplet_search(x):\n    \"\"\"Checks if is a triplet seach data model\n\n    Args:\n        x (DataModel | JsonDataModel | SymbolicDataModel | Variable):\n            The data model to check.\n\n    Returns:\n        (bool): True if the condition is met\n    \"\"\"\n    schema = x.get_schema()\n    properties = schema.get(\"properties\", None)\n    if properties:\n        if (\n            properties.get(\"subject_label\", None)\n            and properties.get(\"subject_similarity_search\", None)\n            and properties.get(\"where_not\", None)\n            and properties.get(\"relation_label\", None)\n            and properties.get(\"object_label\", None)\n            and properties.get(\"object_similarity_search\", None)\n            and properties.get(\"returns\", None)\n        ):\n            return True\n    return False\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/","title":"The DataModel class","text":""},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.DataModel","title":"<code>DataModel</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>SynalinksSaveable</code></p> <p>The backend-dependent data model.</p> <p>This data model uses Pydantic to provide, JSON schema inference and JSON serialization.</p> <p>Examples:</p> <p>Creating a DataModel for structured output</p> <pre><code>class AnswerWithReflection(synalinks.DataModel):\n    thinking: str = synalinks.Field(\n        description=\"Your step by step thinking\",\n    )\n    reflection: str = synalinks.Field(\n        description=\"The reflection about your thinking\",\n    )\n    answer: str = synalinks.Field(\n        description=\"The correct answer\",\n    )\n\nlanguage_model = synalinks.LanguageModel(\"ollama/mistral\")\n\ngenerator = synalinks.Generator(\n    data_model=AnswerWithReflection,\n    language_model=language_model,\n)\n</code></pre> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>class DataModel(pydantic.BaseModel, SynalinksSaveable, metaclass=MetaDataModel):\n    \"\"\"The backend-dependent data model.\n\n    This data model uses Pydantic to provide, JSON schema inference\n    and JSON serialization.\n\n    Examples:\n\n    **Creating a DataModel for structured output**\n\n    ```python\n    class AnswerWithReflection(synalinks.DataModel):\n        thinking: str = synalinks.Field(\n            description=\"Your step by step thinking\",\n        )\n        reflection: str = synalinks.Field(\n            description=\"The reflection about your thinking\",\n        )\n        answer: str = synalinks.Field(\n            description=\"The correct answer\",\n        )\n\n    language_model = synalinks.LanguageModel(\"ollama/mistral\")\n\n    generator = synalinks.Generator(\n        data_model=AnswerWithReflection,\n        language_model=language_model,\n    )\n    ```\n    \"\"\"\n\n    model_config: ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra=\"forbid\")\n\n    @classmethod\n    def get_schema(cls):\n        \"\"\"Gets the JSON schema of the data model.\n\n        Returns:\n            (dict): The JSON schema.\n        \"\"\"\n        return cls.model_json_schema()\n\n    @classmethod\n    def prettify_schema(cls):\n        \"\"\"Get a pretty version of the JSON schema for display.\n\n        Returns:\n            (str): The indented JSON schema.\n        \"\"\"\n        import json\n\n        return json.dumps(cls.get_schema(), indent=2)\n\n    @classmethod\n    def to_symbolic_data_model(cls):\n        \"\"\"Converts the data model to a symbolic data model.\n\n        Returns:\n            (SymbolicDataModel): The symbolic data model.\n        \"\"\"\n        return SymbolicDataModel(schema=cls.get_schema())\n\n    def get_json(self):\n        \"\"\"Gets the JSON value of the data model.\n\n        Returns:\n            (dict): The JSON value.\n        \"\"\"\n        return self.model_dump(mode=\"json\")\n\n    def prettify_json(self):\n        \"\"\"Get a pretty version of the JSON object for display.\n\n        Returns:\n            (str): The indented JSON object.\n        \"\"\"\n        import json\n\n        return json.dumps(self.get_json(), indent=2)\n\n    def __repr__(self):\n        return f\"&lt;DataModel json={self.get_json()}, schema={self.get_schema()}&gt;\"\n\n    def to_json_data_model(self):\n        \"\"\"Converts the data model to a backend-independent data model.\n\n        Returns:\n            (JsonDataModel): The backend-independent data model.\n        \"\"\"\n        return JsonDataModel(schema=self.get_schema(), json=self.get_json())\n\n    def __add__(self, other):\n        \"\"\"Concatenates this data model with another.\n\n        Args:\n            other (JsonDataModel | DataModel | SymbolicDataModel):\n                The other data model to concatenate with.\n\n        Returns:\n            (JsonDataModel | SymbolicDataModel): The concatenated data model.\n                If one of them is a metaclass or symbolic data model,\n                then output a `SymbolicDataModel`.\n        \"\"\"\n        from synalinks.src import ops\n\n        if any_meta_class(self, other):\n            return asyncio.get_event_loop().run_until_complete(\n                ops.Concat().symbolic_call(self, other)\n            )\n        else:\n            return asyncio.get_event_loop().run_until_complete(ops.Concat()(self, other))\n\n    def __radd__(self, other):\n        \"\"\"Concatenates another data model with this one.\n\n        Args:\n            other (JsonDataModel | DataModel | SymbolicDataModel):\n                The other data model to concatenate with.\n\n        Returns:\n            (JsonDataModel | SymbolicDataModel): The concatenated data model.\n                If one of them is a metaclass or symbolic data model,\n                then output a `SymbolicDataModel`.\n        \"\"\"\n        from synalinks.src import ops\n\n        if any_meta_class(self, other):\n            return asyncio.get_event_loop().run_until_complete(\n                ops.Concat().symbolic_call(other, self),\n            )\n        else:\n            return asyncio.get_event_loop().run_until_complete(\n                ops.Concat()(other, self),\n            )\n\n    def __and__(self, other):\n        \"\"\"Perform a `logical_and` with another data model.\n\n        If one of them is None, output None. If both are provided,\n        then concatenates the other data model with this one.\n\n        If the other is a metaclass or symbolic data model, output a symbolic data model.\n\n        Args:\n            other (JsonDataModel | SymbolicDataModel | DataModel):\n                The other data model to concatenate with.\n\n        Returns:\n            (JsonDataModel | SymbolicDataModel | None): The concatenated data model or\n                `None` based on the `logical_and` table.\n        \"\"\"\n        from synalinks.src import ops\n\n        if any_meta_class(self, other):\n            return asyncio.get_event_loop().run_until_complete(\n                ops.Add().symbolic_call(self, other),\n            )\n        else:\n            return asyncio.get_event_loop().run_until_complete(\n                ops.Add()(self, other),\n            )\n\n    def __rand__(self, other):\n        \"\"\"Perform a `logical_and` (reverse) with another data model.\n\n        If one of them is None, output None. If both are provided,\n        then concatenates the other data model with this one.\n\n        If the other is a metaclass or symbolic data model, output a symbolic data model.\n\n        Args:\n            other (JsonDataModel | SymbolicDataModel | DataModel):\n                The other data model to concatenate with.\n\n        Returns:\n            (JsonDataModel | SymbolicDataModel | None): The concatenated data model or\n                `None` based on the `logical_and` table.\n        \"\"\"\n        from synalinks.src import ops\n\n        if any_meta_class(other, self):\n            return asyncio.get_event_loop().run_until_complete(\n                ops.Add().symbolic_call(other, self),\n            )\n        else:\n            return asyncio.get_event_loop().run_until_complete(\n                ops.Add()(other, self),\n            )\n\n    def __or__(self, other):\n        \"\"\"Perform a `logical_or` with another data model\n\n        If one of them is None, output the other one. If both are provided,\n        then concatenates this data model with the other.\n\n        If the other is a metaclass or symbolic data model, output a symbolic data model.\n\n        Args:\n            other (JsonDataModel | SymbolicDataModel | DataModel):\n                The other data model to concatenate with.\n\n        Returns:\n            (JsonDataModel | SymbolicDataModel | None): The concatenation of data model\n                if both are provided, or the non-None data model or None if none are\n                provided. (See `logical_or` table).\n        \"\"\"\n        from synalinks.src import ops\n\n        if any_meta_class(self, other):\n            return asyncio.get_event_loop().run_until_complete(\n                ops.Or().symbolic_call(self, other),\n            )\n        else:\n            return asyncio.get_event_loop().run_until_complete(\n                ops.Or()(self, other),\n            )\n\n    def __ror__(self, other):\n        \"\"\"Perform a `logical_or` (reverse) with another data model\n\n        If one of them is None, output the other one. If both are provided,\n        then concatenates the other data model with this one.\n\n        If the other is a metaclass or symbolic data model, output a symbolic data model.\n\n        Args:\n            other (JsonDataModel | SymbolicDataModel | DataModel):\n                The other data model to concatenate with.\n\n        Returns:\n            (JsonDataModel | SymbolicDataModel | None): The concatenation of data model\n                if both are provided, or the non-None data model or None if none are\n                provided. (See `logical_or` table).\n        \"\"\"\n        from synalinks.src import ops\n\n        if any_meta_class(other, self):\n            return asyncio.get_event_loop().run_until_complete(\n                ops.Or().symbolic_call(other, self),\n            )\n        else:\n            return asyncio.get_event_loop().run_until_complete(\n                ops.Or()(other, self),\n            )\n\n    def __xor__(self, other):\n        \"\"\"Perform a `logical_xor` with another data model.\n\n        If one of them is `None`, output the other one. If both are provided,\n        then the output is `None`.\n\n        Args:\n            other (SymbolicDataModel): The other data model to concatenate with.\n\n        Returns:\n            (SymbolicDataModel | None): `None` if both are\n                provided, or the non-None data model if one is provided\n                or `None` if none are provided. (See `logical_xor` table).\n        \"\"\"\n        from synalinks.src import ops\n\n        if any_meta_class(self, other):\n            return asyncio.get_event_loop().run_until_complete(\n                ops.Xor().symbolic_call(self, other),\n            )\n        else:\n            return asyncio.get_event_loop().run_until_complete(\n                ops.Xor()(self, other),\n            )\n\n    def __rxor__(self, other):\n        \"\"\"Perform a `logical_xor` (reverse) with another data model.\n\n        If one of them is None, output the other one. If both are provided,\n        then concatenates the other data model with this one.\n\n        Args:\n            other (SymbolicDataModel | DataModel): The other data model to concatenate\n                with.\n\n        Returns:\n            (SymbolicDataModel | None): `None` if both are\n                provided, or the non-None data model if one is provided\n                or `None` if none are provided. (See `logical_xor` table).\n        \"\"\"\n        from synalinks.src import ops\n\n        if any_meta_class(other, self):\n            return asyncio.get_event_loop().run_until_complete(\n                ops.Xor().symbolic_call(other, self),\n            )\n        else:\n            return asyncio.get_event_loop().run_until_complete(\n                ops.Xor()(other, self),\n            )\n\n    def get_config(self):\n        return self.get_json()\n\n    @classmethod\n    def from_config(cls, config):\n        return cls(**config)\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.DataModel.__add__","title":"<code>__add__(other)</code>","text":"<p>Concatenates this data model with another.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>JsonDataModel | DataModel | SymbolicDataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>JsonDataModel | SymbolicDataModel</code> <p>The concatenated data model. If one of them is a metaclass or symbolic data model, then output a <code>SymbolicDataModel</code>.</p> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>def __add__(self, other):\n    \"\"\"Concatenates this data model with another.\n\n    Args:\n        other (JsonDataModel | DataModel | SymbolicDataModel):\n            The other data model to concatenate with.\n\n    Returns:\n        (JsonDataModel | SymbolicDataModel): The concatenated data model.\n            If one of them is a metaclass or symbolic data model,\n            then output a `SymbolicDataModel`.\n    \"\"\"\n    from synalinks.src import ops\n\n    if any_meta_class(self, other):\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Concat().symbolic_call(self, other)\n        )\n    else:\n        return asyncio.get_event_loop().run_until_complete(ops.Concat()(self, other))\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.DataModel.__and__","title":"<code>__and__(other)</code>","text":"<p>Perform a <code>logical_and</code> with another data model.</p> <p>If one of them is None, output None. If both are provided, then concatenates the other data model with this one.</p> <p>If the other is a metaclass or symbolic data model, output a symbolic data model.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>JsonDataModel | SymbolicDataModel | DataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>JsonDataModel | SymbolicDataModel | None</code> <p>The concatenated data model or <code>None</code> based on the <code>logical_and</code> table.</p> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>def __and__(self, other):\n    \"\"\"Perform a `logical_and` with another data model.\n\n    If one of them is None, output None. If both are provided,\n    then concatenates the other data model with this one.\n\n    If the other is a metaclass or symbolic data model, output a symbolic data model.\n\n    Args:\n        other (JsonDataModel | SymbolicDataModel | DataModel):\n            The other data model to concatenate with.\n\n    Returns:\n        (JsonDataModel | SymbolicDataModel | None): The concatenated data model or\n            `None` based on the `logical_and` table.\n    \"\"\"\n    from synalinks.src import ops\n\n    if any_meta_class(self, other):\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Add().symbolic_call(self, other),\n        )\n    else:\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Add()(self, other),\n        )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.DataModel.__or__","title":"<code>__or__(other)</code>","text":"<p>Perform a <code>logical_or</code> with another data model</p> <p>If one of them is None, output the other one. If both are provided, then concatenates this data model with the other.</p> <p>If the other is a metaclass or symbolic data model, output a symbolic data model.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>JsonDataModel | SymbolicDataModel | DataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>JsonDataModel | SymbolicDataModel | None</code> <p>The concatenation of data model if both are provided, or the non-None data model or None if none are provided. (See <code>logical_or</code> table).</p> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>def __or__(self, other):\n    \"\"\"Perform a `logical_or` with another data model\n\n    If one of them is None, output the other one. If both are provided,\n    then concatenates this data model with the other.\n\n    If the other is a metaclass or symbolic data model, output a symbolic data model.\n\n    Args:\n        other (JsonDataModel | SymbolicDataModel | DataModel):\n            The other data model to concatenate with.\n\n    Returns:\n        (JsonDataModel | SymbolicDataModel | None): The concatenation of data model\n            if both are provided, or the non-None data model or None if none are\n            provided. (See `logical_or` table).\n    \"\"\"\n    from synalinks.src import ops\n\n    if any_meta_class(self, other):\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Or().symbolic_call(self, other),\n        )\n    else:\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Or()(self, other),\n        )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.DataModel.__radd__","title":"<code>__radd__(other)</code>","text":"<p>Concatenates another data model with this one.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>JsonDataModel | DataModel | SymbolicDataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>JsonDataModel | SymbolicDataModel</code> <p>The concatenated data model. If one of them is a metaclass or symbolic data model, then output a <code>SymbolicDataModel</code>.</p> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>def __radd__(self, other):\n    \"\"\"Concatenates another data model with this one.\n\n    Args:\n        other (JsonDataModel | DataModel | SymbolicDataModel):\n            The other data model to concatenate with.\n\n    Returns:\n        (JsonDataModel | SymbolicDataModel): The concatenated data model.\n            If one of them is a metaclass or symbolic data model,\n            then output a `SymbolicDataModel`.\n    \"\"\"\n    from synalinks.src import ops\n\n    if any_meta_class(self, other):\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Concat().symbolic_call(other, self),\n        )\n    else:\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Concat()(other, self),\n        )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.DataModel.__rand__","title":"<code>__rand__(other)</code>","text":"<p>Perform a <code>logical_and</code> (reverse) with another data model.</p> <p>If one of them is None, output None. If both are provided, then concatenates the other data model with this one.</p> <p>If the other is a metaclass or symbolic data model, output a symbolic data model.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>JsonDataModel | SymbolicDataModel | DataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>JsonDataModel | SymbolicDataModel | None</code> <p>The concatenated data model or <code>None</code> based on the <code>logical_and</code> table.</p> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>def __rand__(self, other):\n    \"\"\"Perform a `logical_and` (reverse) with another data model.\n\n    If one of them is None, output None. If both are provided,\n    then concatenates the other data model with this one.\n\n    If the other is a metaclass or symbolic data model, output a symbolic data model.\n\n    Args:\n        other (JsonDataModel | SymbolicDataModel | DataModel):\n            The other data model to concatenate with.\n\n    Returns:\n        (JsonDataModel | SymbolicDataModel | None): The concatenated data model or\n            `None` based on the `logical_and` table.\n    \"\"\"\n    from synalinks.src import ops\n\n    if any_meta_class(other, self):\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Add().symbolic_call(other, self),\n        )\n    else:\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Add()(other, self),\n        )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.DataModel.__ror__","title":"<code>__ror__(other)</code>","text":"<p>Perform a <code>logical_or</code> (reverse) with another data model</p> <p>If one of them is None, output the other one. If both are provided, then concatenates the other data model with this one.</p> <p>If the other is a metaclass or symbolic data model, output a symbolic data model.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>JsonDataModel | SymbolicDataModel | DataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>JsonDataModel | SymbolicDataModel | None</code> <p>The concatenation of data model if both are provided, or the non-None data model or None if none are provided. (See <code>logical_or</code> table).</p> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>def __ror__(self, other):\n    \"\"\"Perform a `logical_or` (reverse) with another data model\n\n    If one of them is None, output the other one. If both are provided,\n    then concatenates the other data model with this one.\n\n    If the other is a metaclass or symbolic data model, output a symbolic data model.\n\n    Args:\n        other (JsonDataModel | SymbolicDataModel | DataModel):\n            The other data model to concatenate with.\n\n    Returns:\n        (JsonDataModel | SymbolicDataModel | None): The concatenation of data model\n            if both are provided, or the non-None data model or None if none are\n            provided. (See `logical_or` table).\n    \"\"\"\n    from synalinks.src import ops\n\n    if any_meta_class(other, self):\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Or().symbolic_call(other, self),\n        )\n    else:\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Or()(other, self),\n        )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.DataModel.__rxor__","title":"<code>__rxor__(other)</code>","text":"<p>Perform a <code>logical_xor</code> (reverse) with another data model.</p> <p>If one of them is None, output the other one. If both are provided, then concatenates the other data model with this one.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>SymbolicDataModel | DataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>SymbolicDataModel | None</code> <p><code>None</code> if both are provided, or the non-None data model if one is provided or <code>None</code> if none are provided. (See <code>logical_xor</code> table).</p> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>def __rxor__(self, other):\n    \"\"\"Perform a `logical_xor` (reverse) with another data model.\n\n    If one of them is None, output the other one. If both are provided,\n    then concatenates the other data model with this one.\n\n    Args:\n        other (SymbolicDataModel | DataModel): The other data model to concatenate\n            with.\n\n    Returns:\n        (SymbolicDataModel | None): `None` if both are\n            provided, or the non-None data model if one is provided\n            or `None` if none are provided. (See `logical_xor` table).\n    \"\"\"\n    from synalinks.src import ops\n\n    if any_meta_class(other, self):\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Xor().symbolic_call(other, self),\n        )\n    else:\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Xor()(other, self),\n        )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.DataModel.__xor__","title":"<code>__xor__(other)</code>","text":"<p>Perform a <code>logical_xor</code> with another data model.</p> <p>If one of them is <code>None</code>, output the other one. If both are provided, then the output is <code>None</code>.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>SymbolicDataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>SymbolicDataModel | None</code> <p><code>None</code> if both are provided, or the non-None data model if one is provided or <code>None</code> if none are provided. (See <code>logical_xor</code> table).</p> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>def __xor__(self, other):\n    \"\"\"Perform a `logical_xor` with another data model.\n\n    If one of them is `None`, output the other one. If both are provided,\n    then the output is `None`.\n\n    Args:\n        other (SymbolicDataModel): The other data model to concatenate with.\n\n    Returns:\n        (SymbolicDataModel | None): `None` if both are\n            provided, or the non-None data model if one is provided\n            or `None` if none are provided. (See `logical_xor` table).\n    \"\"\"\n    from synalinks.src import ops\n\n    if any_meta_class(self, other):\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Xor().symbolic_call(self, other),\n        )\n    else:\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Xor()(self, other),\n        )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.DataModel.get_json","title":"<code>get_json()</code>","text":"<p>Gets the JSON value of the data model.</p> <p>Returns:</p> Type Description <code>dict</code> <p>The JSON value.</p> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>def get_json(self):\n    \"\"\"Gets the JSON value of the data model.\n\n    Returns:\n        (dict): The JSON value.\n    \"\"\"\n    return self.model_dump(mode=\"json\")\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.DataModel.get_schema","title":"<code>get_schema()</code>  <code>classmethod</code>","text":"<p>Gets the JSON schema of the data model.</p> <p>Returns:</p> Type Description <code>dict</code> <p>The JSON schema.</p> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>@classmethod\ndef get_schema(cls):\n    \"\"\"Gets the JSON schema of the data model.\n\n    Returns:\n        (dict): The JSON schema.\n    \"\"\"\n    return cls.model_json_schema()\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.DataModel.prettify_json","title":"<code>prettify_json()</code>","text":"<p>Get a pretty version of the JSON object for display.</p> <p>Returns:</p> Type Description <code>str</code> <p>The indented JSON object.</p> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>def prettify_json(self):\n    \"\"\"Get a pretty version of the JSON object for display.\n\n    Returns:\n        (str): The indented JSON object.\n    \"\"\"\n    import json\n\n    return json.dumps(self.get_json(), indent=2)\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.DataModel.prettify_schema","title":"<code>prettify_schema()</code>  <code>classmethod</code>","text":"<p>Get a pretty version of the JSON schema for display.</p> <p>Returns:</p> Type Description <code>str</code> <p>The indented JSON schema.</p> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>@classmethod\ndef prettify_schema(cls):\n    \"\"\"Get a pretty version of the JSON schema for display.\n\n    Returns:\n        (str): The indented JSON schema.\n    \"\"\"\n    import json\n\n    return json.dumps(cls.get_schema(), indent=2)\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.DataModel.to_json_data_model","title":"<code>to_json_data_model()</code>","text":"<p>Converts the data model to a backend-independent data model.</p> <p>Returns:</p> Type Description <code>JsonDataModel</code> <p>The backend-independent data model.</p> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>def to_json_data_model(self):\n    \"\"\"Converts the data model to a backend-independent data model.\n\n    Returns:\n        (JsonDataModel): The backend-independent data model.\n    \"\"\"\n    return JsonDataModel(schema=self.get_schema(), json=self.get_json())\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.DataModel.to_symbolic_data_model","title":"<code>to_symbolic_data_model()</code>  <code>classmethod</code>","text":"<p>Converts the data model to a symbolic data model.</p> <p>Returns:</p> Type Description <code>SymbolicDataModel</code> <p>The symbolic data model.</p> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>@classmethod\ndef to_symbolic_data_model(cls):\n    \"\"\"Converts the data model to a symbolic data model.\n\n    Returns:\n        (SymbolicDataModel): The symbolic data model.\n    \"\"\"\n    return SymbolicDataModel(schema=cls.get_schema())\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.MetaDataModel","title":"<code>MetaDataModel</code>","text":"<p>               Bases: <code>type(BaseModel)</code></p> <p>The metaclass data model.</p> <p>This class defines operations at the metaclass level. Allowing to use Synalinks Python operators with <code>DataModel</code> types.</p> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>class MetaDataModel(type(pydantic.BaseModel)):\n    \"\"\"The metaclass data model.\n\n    This class defines operations at the metaclass level.\n    Allowing to use Synalinks Python operators with `DataModel` types.\n    \"\"\"\n\n    def __add__(cls, other):\n        \"\"\"Concatenates this data model with another.\n\n        Args:\n            other (SymbolicDataModel | DataModel):\n                The other data model to concatenate with.\n\n        Returns:\n            (SymbolicDataModel): The concatenated data model.\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Concat().symbolic_call(cls, other)\n        )\n\n    def __radd__(cls, other):\n        \"\"\"Concatenates (reverse) another data model with this one.\n\n        Args:\n            other (SymbolicDataModel | DataModel):\n                The other data model to concatenate with.\n\n        Returns:\n            (SymbolicDataModel): The concatenated data model.\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Concat().symbolic_call(other, cls)\n        )\n\n    def __and__(cls, other):\n        \"\"\"Perform a `logical_and` with another data model.\n\n        If one of them is `None`, output `None`. If both are provided,\n        then concatenates this data model with the other.\n\n        Args:\n            other (SymbolicDataModel | DataModel): The other data model to concatenate\n                with.\n\n        Returns:\n            (SymbolicDataModel | None): The concatenated data model or `None`\n                based on the `logical_and` table.\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.And().symbolic_call(cls, other)\n        )\n\n    def __rand__(cls, other):\n        \"\"\"Perform a `logical_and` (reverse) with another data model.\n\n        If one of them is `None`, output `None`. If both are provided,\n        then concatenates the other data model with this one.\n\n        Args:\n            other (SymbolicDataModel | DataModel): The other data model to concatenate\n                with.\n\n        Returns:\n            (SymbolicDataModel | None): The concatenated data model or `None`\n                based on the `logical_and` table.\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.And().symbolic_call(other, cls)\n        )\n\n    def __or__(cls, other):\n        \"\"\"Perform a `logical_or` with another data model.\n\n        If one of them is `None`, output the other one. If both are provided,\n        then concatenates this data model with the other.\n\n        Args:\n            other (SymbolicDataModel): The other data model to concatenate with.\n\n        Returns:\n            (SymbolicDataModel | None): The concatenation of data model if both are\n                provided, or the non-None data model or None if none are provided.\n                (See `logical_or` table).\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Or().symbolic_call(cls, other)\n        )\n\n    def __ror__(cls, other):\n        \"\"\"Perform a `logical_or` (reverse) with another data model.\n\n        If one of them is `None`, output the other one. If both are provided,\n        then concatenates the other data model with this one.\n\n        Args:\n            other (SymbolicDataModel | DataModel): The other data model to concatenate\n                with.\n\n        Returns:\n            (SymbolicDataModel | None): The concatenation of data model if both are\n                provided, or the non-None data model or None if none are provided.\n                (See `logical_or` table).\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Or().symbolic_call(other, cls)\n        )\n\n    def __xor__(cls, other):\n        \"\"\"Perform a `logical_xor` with another data model.\n\n        If one of them is `None`, output the other one. If both are provided,\n        then the output is `None`.\n\n        Args:\n            other (SymbolicDataModel): The other data model to concatenate with.\n\n        Returns:\n            (SymbolicDataModel | None): `None` if both are\n                provided, or the non-None data model if one is provided\n                or `None` if none are provided. (See `logical_xor` table).\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Xor().symbolic_call(cls, other)\n        )\n\n    def __rxor__(cls, other):\n        \"\"\"Perform a `logical_xor` (reverse) with another data model.\n\n        If one of them is None, output the other one. If both are provided,\n        then concatenates the other data model with this one.\n\n        Args:\n            other (SymbolicDataModel | DataModel): The other data model to concatenate\n                with.\n\n        Returns:\n            (SymbolicDataModel | None): `None` if both are\n                provided, or the non-None data model if one is provided\n                or `None` if none are provided. (See `logical_xor` table).\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Xor().symbolic_call(other, cls)\n        )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.MetaDataModel.__add__","title":"<code>__add__(other)</code>","text":"<p>Concatenates this data model with another.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>SymbolicDataModel | DataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>SymbolicDataModel</code> <p>The concatenated data model.</p> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>def __add__(cls, other):\n    \"\"\"Concatenates this data model with another.\n\n    Args:\n        other (SymbolicDataModel | DataModel):\n            The other data model to concatenate with.\n\n    Returns:\n        (SymbolicDataModel): The concatenated data model.\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.Concat().symbolic_call(cls, other)\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.MetaDataModel.__and__","title":"<code>__and__(other)</code>","text":"<p>Perform a <code>logical_and</code> with another data model.</p> <p>If one of them is <code>None</code>, output <code>None</code>. If both are provided, then concatenates this data model with the other.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>SymbolicDataModel | DataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>SymbolicDataModel | None</code> <p>The concatenated data model or <code>None</code> based on the <code>logical_and</code> table.</p> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>def __and__(cls, other):\n    \"\"\"Perform a `logical_and` with another data model.\n\n    If one of them is `None`, output `None`. If both are provided,\n    then concatenates this data model with the other.\n\n    Args:\n        other (SymbolicDataModel | DataModel): The other data model to concatenate\n            with.\n\n    Returns:\n        (SymbolicDataModel | None): The concatenated data model or `None`\n            based on the `logical_and` table.\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.And().symbolic_call(cls, other)\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.MetaDataModel.__or__","title":"<code>__or__(other)</code>","text":"<p>Perform a <code>logical_or</code> with another data model.</p> <p>If one of them is <code>None</code>, output the other one. If both are provided, then concatenates this data model with the other.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>SymbolicDataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>SymbolicDataModel | None</code> <p>The concatenation of data model if both are provided, or the non-None data model or None if none are provided. (See <code>logical_or</code> table).</p> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>def __or__(cls, other):\n    \"\"\"Perform a `logical_or` with another data model.\n\n    If one of them is `None`, output the other one. If both are provided,\n    then concatenates this data model with the other.\n\n    Args:\n        other (SymbolicDataModel): The other data model to concatenate with.\n\n    Returns:\n        (SymbolicDataModel | None): The concatenation of data model if both are\n            provided, or the non-None data model or None if none are provided.\n            (See `logical_or` table).\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.Or().symbolic_call(cls, other)\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.MetaDataModel.__radd__","title":"<code>__radd__(other)</code>","text":"<p>Concatenates (reverse) another data model with this one.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>SymbolicDataModel | DataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>SymbolicDataModel</code> <p>The concatenated data model.</p> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>def __radd__(cls, other):\n    \"\"\"Concatenates (reverse) another data model with this one.\n\n    Args:\n        other (SymbolicDataModel | DataModel):\n            The other data model to concatenate with.\n\n    Returns:\n        (SymbolicDataModel): The concatenated data model.\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.Concat().symbolic_call(other, cls)\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.MetaDataModel.__rand__","title":"<code>__rand__(other)</code>","text":"<p>Perform a <code>logical_and</code> (reverse) with another data model.</p> <p>If one of them is <code>None</code>, output <code>None</code>. If both are provided, then concatenates the other data model with this one.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>SymbolicDataModel | DataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>SymbolicDataModel | None</code> <p>The concatenated data model or <code>None</code> based on the <code>logical_and</code> table.</p> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>def __rand__(cls, other):\n    \"\"\"Perform a `logical_and` (reverse) with another data model.\n\n    If one of them is `None`, output `None`. If both are provided,\n    then concatenates the other data model with this one.\n\n    Args:\n        other (SymbolicDataModel | DataModel): The other data model to concatenate\n            with.\n\n    Returns:\n        (SymbolicDataModel | None): The concatenated data model or `None`\n            based on the `logical_and` table.\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.And().symbolic_call(other, cls)\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.MetaDataModel.__ror__","title":"<code>__ror__(other)</code>","text":"<p>Perform a <code>logical_or</code> (reverse) with another data model.</p> <p>If one of them is <code>None</code>, output the other one. If both are provided, then concatenates the other data model with this one.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>SymbolicDataModel | DataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>SymbolicDataModel | None</code> <p>The concatenation of data model if both are provided, or the non-None data model or None if none are provided. (See <code>logical_or</code> table).</p> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>def __ror__(cls, other):\n    \"\"\"Perform a `logical_or` (reverse) with another data model.\n\n    If one of them is `None`, output the other one. If both are provided,\n    then concatenates the other data model with this one.\n\n    Args:\n        other (SymbolicDataModel | DataModel): The other data model to concatenate\n            with.\n\n    Returns:\n        (SymbolicDataModel | None): The concatenation of data model if both are\n            provided, or the non-None data model or None if none are provided.\n            (See `logical_or` table).\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.Or().symbolic_call(other, cls)\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.MetaDataModel.__rxor__","title":"<code>__rxor__(other)</code>","text":"<p>Perform a <code>logical_xor</code> (reverse) with another data model.</p> <p>If one of them is None, output the other one. If both are provided, then concatenates the other data model with this one.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>SymbolicDataModel | DataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>SymbolicDataModel | None</code> <p><code>None</code> if both are provided, or the non-None data model if one is provided or <code>None</code> if none are provided. (See <code>logical_xor</code> table).</p> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>def __rxor__(cls, other):\n    \"\"\"Perform a `logical_xor` (reverse) with another data model.\n\n    If one of them is None, output the other one. If both are provided,\n    then concatenates the other data model with this one.\n\n    Args:\n        other (SymbolicDataModel | DataModel): The other data model to concatenate\n            with.\n\n    Returns:\n        (SymbolicDataModel | None): `None` if both are\n            provided, or the non-None data model if one is provided\n            or `None` if none are provided. (See `logical_xor` table).\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.Xor().symbolic_call(other, cls)\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.MetaDataModel.__xor__","title":"<code>__xor__(other)</code>","text":"<p>Perform a <code>logical_xor</code> with another data model.</p> <p>If one of them is <code>None</code>, output the other one. If both are provided, then the output is <code>None</code>.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>SymbolicDataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>SymbolicDataModel | None</code> <p><code>None</code> if both are provided, or the non-None data model if one is provided or <code>None</code> if none are provided. (See <code>logical_xor</code> table).</p> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>def __xor__(cls, other):\n    \"\"\"Perform a `logical_xor` with another data model.\n\n    If one of them is `None`, output the other one. If both are provided,\n    then the output is `None`.\n\n    Args:\n        other (SymbolicDataModel): The other data model to concatenate with.\n\n    Returns:\n        (SymbolicDataModel | None): `None` if both are\n            provided, or the non-None data model if one is provided\n            or `None` if none are provided. (See `logical_xor` table).\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.Xor().symbolic_call(cls, other)\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.any_data_model","title":"<code>any_data_model(args=None, kwargs=None)</code>","text":"<p>Check if any of the arguments are backend-dependent data models.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>tuple</code> <p>Optional. The positional arguments to check.</p> <code>None</code> <code>kwargs</code> <code>dict</code> <p>Optional. The keyword arguments to check.</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if any of the arguments are meta classes, False otherwise.</p> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>def any_data_model(args=None, kwargs=None):\n    \"\"\"Check if any of the arguments are backend-dependent data models.\n\n    Args:\n        args (tuple): Optional. The positional arguments to check.\n        kwargs (dict): Optional. The keyword arguments to check.\n\n    Returns:\n        (bool): True if any of the arguments are meta classes, False otherwise.\n    \"\"\"\n    args = args or ()\n    kwargs = kwargs or {}\n    for x in tree.flatten((args, kwargs)):\n        if is_meta_class(x):\n            return True\n    return False\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.any_meta_class","title":"<code>any_meta_class(args=None, kwargs=None)</code>","text":"<p>Check if any of the arguments are meta classes.</p> <p>This happen when using a <code>DataModel</code> without instanciating it. In Synalinks this is used when declaring data models for schema inference.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>tuple</code> <p>Optional. The positional arguments to check.</p> <code>None</code> <code>kwargs</code> <code>dict</code> <p>Optional. The keyword arguments to check.</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if any of the arguments are meta classes, False otherwise.</p> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>def any_meta_class(args=None, kwargs=None):\n    \"\"\"Check if any of the arguments are meta classes.\n\n    This happen when using a `DataModel` without instanciating it.\n    In Synalinks this is used when declaring data models for schema inference.\n\n    Args:\n        args (tuple): Optional. The positional arguments to check.\n        kwargs (dict): Optional. The keyword arguments to check.\n\n    Returns:\n        (bool): True if any of the arguments are meta classes, False otherwise.\n    \"\"\"\n    args = args or ()\n    kwargs = kwargs or {}\n    for x in tree.flatten((args, kwargs)):\n        if is_meta_class(x):\n            return True\n    return False\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.is_data_model","title":"<code>is_data_model(x)</code>","text":"<p>Returns whether <code>x</code> is a DataModel.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>any</code> <p>The object to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if <code>x</code> is a DataModel, False otherwise.</p> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>def is_data_model(x):\n    \"\"\"Returns whether `x` is a DataModel.\n\n    Args:\n        x (any): The object to check.\n\n    Returns:\n        (bool): True if `x` is a DataModel, False otherwise.\n    \"\"\"\n    return isinstance(x, DataModel)\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20DataModel%20class/#synalinks.src.backend.pydantic.core.is_meta_class","title":"<code>is_meta_class(x)</code>","text":"<p>Returns whether <code>x</code> is a meta class.</p> <p>A meta class is a python type. This method checks if the data model provided if a meta class, allowing to detect if the <code>DataModel</code> have been instanciated. Meta classes are using in Synalinks when declaring data models for schema inference.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>any</code> <p>The object to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if <code>x</code> is a meta class, False otherwise.</p> Source code in <code>synalinks/src/backend/pydantic/core.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.utils.is_meta_class\",\n        \"synalinks.backend.is_meta_class\",\n    ]\n)\ndef is_meta_class(x):\n    \"\"\"Returns whether `x` is a meta class.\n\n    A meta class is a python type. This method checks if the data model provided\n    if a meta class, allowing to detect if the `DataModel` have been instanciated.\n    Meta classes are using in Synalinks when declaring data models for schema inference.\n\n    Args:\n        x (any): The object to check.\n\n    Returns:\n        (bool): True if `x` is a meta class, False otherwise.\n    \"\"\"\n    return inspect.isclass(x)\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20JsonDataModel%20class/","title":"The JsonDataModel class","text":""},{"location":"Synalinks%20API/Data%20Models%20API/The%20JsonDataModel%20class/#synalinks.src.backend.common.json_data_model.JsonDataModel","title":"<code>JsonDataModel</code>","text":"<p>A backend-independent dynamic data model.</p> <p>This structure is the one flowing in the pipelines as the backend data models are only used for the variable/data model declaration.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>dict</code> <p>The JSON object's schema. If not provided, uses the data model to infer it.</p> <code>None</code> <code>json</code> <code>dict</code> <p>The JSON object's json. If not provided, uses the data model to infer it.</p> <code>None</code> <code>data_model</code> <code>DataModel | JsonDataModel</code> <p>The data model to use to infer the schema and json.</p> <code>None</code> <code>name</code> <code>str</code> <p>Optional. The name of the data model, automatically inferred if not provided.</p> <code>None</code> <p>Examples:</p> <p>Creating a <code>JsonDataModel</code> with a DataModel's schema and json:</p> <pre><code>class Query(synalinks.DataModel):\n    query: str = synalinks.Field(\n        description=\"The user query\",\n    )\n\njson = {\"query\": \"What is the capital of France?\"}\n\ndata_model = JsonDataModel(\n    schema=Query.get_schema(),\n    json=json,\n)\n</code></pre> <p>Creating a <code>JsonDataModel</code> with a data_model:</p> <pre><code>class Query(synalinks.DataModel):\n    query: str = synalinks.Field(\n        description=\"The user query\",\n    )\n\nquery_instance = Query(\n    query=\"What is the capital of France?\"\n)\ndata_model = JsonDataModel(\n    data_model=query_instance,\n)\n</code></pre> <p>Creating a <code>JsonDataModel</code> with <code>to_json_data_model()</code>:</p> <pre><code>class Query(synalinks.DataModel):\n    query: str = synalinks.Field(\n        description=\"The user query\",\n    )\n\ndata_model = Query(\n    query=\"What is the capital of France?\",\n).to_json_data_model()\n</code></pre> Source code in <code>synalinks/src/backend/common/json_data_model.py</code> <pre><code>@synalinks_export(\"synalinks.JsonDataModel\")\nclass JsonDataModel:\n    \"\"\"A backend-independent dynamic data model.\n\n    This structure is the one flowing in the pipelines as\n    the backend data models are only used for the variable/data model declaration.\n\n    Args:\n        schema (dict): The JSON object's schema. If not provided,\n            uses the data model to infer it.\n        json (dict): The JSON object's json. If not provided,\n            uses the data model to infer it.\n        data_model (DataModel | JsonDataModel): The data model to use to\n            infer the schema and json.\n        name (str): Optional. The name of the data model, automatically\n            inferred if not provided.\n\n    Examples:\n\n    **Creating a `JsonDataModel` with a DataModel's schema and json:**\n\n    ```python\n    class Query(synalinks.DataModel):\n        query: str = synalinks.Field(\n            description=\"The user query\",\n        )\n\n    json = {\"query\": \"What is the capital of France?\"}\n\n    data_model = JsonDataModel(\n        schema=Query.get_schema(),\n        json=json,\n    )\n    ```\n\n    **Creating a `JsonDataModel` with a data_model:**\n\n    ```python\n    class Query(synalinks.DataModel):\n        query: str = synalinks.Field(\n            description=\"The user query\",\n        )\n\n    query_instance = Query(\n        query=\"What is the capital of France?\"\n    )\n    data_model = JsonDataModel(\n        data_model=query_instance,\n    )\n    ```\n\n    **Creating a `JsonDataModel` with `to_json_data_model()`:**\n\n    ```python\n    class Query(synalinks.DataModel):\n        query: str = synalinks.Field(\n            description=\"The user query\",\n        )\n\n    data_model = Query(\n        query=\"What is the capital of France?\",\n    ).to_json_data_model()\n    ```\n    \"\"\"\n\n    def __init__(\n        self,\n        schema=None,\n        json=None,\n        data_model=None,\n        name=None,\n    ):\n        name = name or auto_name(self.__class__.__name__)\n        self.name = name\n        self._schema = None\n        self._json = None\n\n        if not data_model and not schema and not json:\n            raise ValueError(\"Initializing without arguments is not permited.\")\n        if not schema and not data_model:\n            raise ValueError(\n                \"You should specify at least one argument between \"\n                \"`data_model` or `schema`.\"\n            )\n        if not schema and not json and not data_model:\n            raise ValueError(\n                \"You should specify at least one argument between `data_model` or `json`.\"\n            )\n        if data_model:\n            if not schema:\n                schema = data_model.get_schema()\n            if not json:\n                if inspect.isclass(data_model):\n                    raise ValueError(\n                        \"Couldn't get the JSON data from the `data_model` argument, \"\n                        \"the `data_model` needs to be instanciated. \"\n                        f\"Received data_model={data_model}.\"\n                    )\n                json = data_model.get_json()\n\n        self._schema = standardize_schema(schema)\n        self._json = json\n\n    def to_symbolic_data_model(self):\n        \"\"\"Converts the JsonDataModel to a SymbolicDataModel.\n\n        Returns:\n            (SymbolicDataModel): The symbolic data model.\n        \"\"\"\n        return SymbolicDataModel(schema=self._schema)\n\n    def get_json(self):\n        \"\"\"Gets the current json of the JSON object.\n\n        Returns:\n            (dict): The current json of the JSON object.\n        \"\"\"\n        return self._json\n\n    def get_schema(self):\n        \"\"\"Gets the schema of the JSON object.\n\n        Returns:\n            (dict): The JSON schema.\n        \"\"\"\n        return self._schema\n\n    def prettify_schema(self):\n        \"\"\"Get a pretty version of the JSON schema for display.\n\n        Returns:\n            (dict): The indented JSON schema.\n        \"\"\"\n        import json\n\n        return json.dumps(self._schema, indent=2)\n\n    def prettify_json(self):\n        \"\"\"Get a pretty version of the JSON object for display.\n\n        Returns:\n            (str): The indented JSON object.\n        \"\"\"\n        import json\n\n        return json.dumps(self._json, indent=2)\n\n    def __add__(self, other):\n        \"\"\"Concatenates this data model with another.\n\n        Args:\n            other (JsonDataModel | DataModel):\n                The other data model to concatenate with.\n\n        Returns:\n            (JsonDataModel): The concatenated data model.\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Concat().call(self, other),\n        )\n\n    def __radd__(self, other):\n        \"\"\"Concatenates another data model with this one.\n\n        Args:\n            other (JsonDataModel | DataModel):\n                The other data model to concatenate with.\n\n        Returns:\n            (JsonDataModel): The concatenated data model.\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Concat().call(other, self),\n        )\n\n    def __and__(self, other):\n        \"\"\"Perform a `logical_and` with another data model.\n\n        If one of them is None, output None. If both are provided,\n        then concatenates this data model with the other.\n\n        Args:\n            other (JsonDataModel | DataModel): The other data model to concatenate with.\n\n        Returns:\n            (JsonDataModel | None): The concatenated data model or None\n                based on the `logical_and` table.\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.And().call(self, other),\n        )\n\n    def __rand__(self, other):\n        \"\"\"Perform a `logical_and` (reverse) with another data model.\n\n        If one of them is None, output None. If both are provided,\n        then concatenates the other data model with this one.\n\n        Args:\n            other (JsonDataModel | DataModel): The other data model to concatenate with.\n\n        Returns:\n            (JsonDataModel | None): The concatenated data model or None\n                based on the `logical_and` table.\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.And().call(other, self),\n        )\n\n    def __or__(self, other):\n        \"\"\"Perform a `logical_or` with another data model\n\n        If one of them is None, output the other one. If both are provided,\n        then concatenates this data model with the other.\n\n        Args:\n            other (JsonDataModel | DataModel): The other data model to concatenate with.\n\n        Returns:\n            (JsonDataModel | None): The concatenation of data model if both are provided,\n                or the non-None data model or None if none are provided.\n                (See `logical_or` table).\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Or().call(self, other),\n        )\n\n    def __ror__(self, other):\n        \"\"\"Perform a `logical_or` (reverse) with another data model\n\n        If one of them is None, output the other one. If both are provided,\n        then concatenates the other data model with this one.\n\n        Args:\n            other (JsonDataModel | DataModel): The other data model to concatenate with.\n\n        Returns:\n            (JsonDataModel | None): The concatenation of data model if both are provided,\n                or the non-None data model or None if none are provided.\n                (See `logical_or` table).\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Or().call(other, self),\n        )\n\n    def __xor__(self, other):\n        \"\"\"Perform a `logical_xor` with another data model.\n\n        If one of them is `None`, output the other one. If both are provided,\n        then the output is `None`.\n\n        Args:\n            other (SymbolicDataModel): The other data model to concatenate with.\n\n        Returns:\n            (SymbolicDataModel | None): `None` if both are\n                provided, or the non-None data model if one is provided\n                or `None` if none are provided. (See `logical_xor` table).\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Xor().call(self, other),\n        )\n\n    def __rxor__(self, other):\n        \"\"\"Perform a `logical_xor` (reverse) with another data model.\n\n        If one of them is None, output the other one. If both are provided,\n        then concatenates the other data model with this one.\n\n        Args:\n            other (SymbolicDataModel | DataModel): The other data model to concatenate\n                with.\n\n        Returns:\n            (SymbolicDataModel | None): `None` if both are\n                provided, or the non-None data model if one is provided\n                or `None` if none are provided. (See `logical_xor` table).\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Xor().call(other, self),\n        )\n\n    def factorize(self):\n        \"\"\"Factorizes the data model.\n\n        Returns:\n            (JsonDataModel): The factorized data model.\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Factorize().call(self),\n        )\n\n    def in_mask(self, mask=None, recursive=True):\n        \"\"\"Applies a mask to **keep only** specified keys of the data model.\n\n        Args:\n            mask (list): The mask to be applied.\n            recursive (bool): Optional. Whether to apply the mask recursively.\n                Defaults to True.\n\n        Returns:\n            (JsonDataModel): The data model with the mask applied.\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.InMask(mask=mask, recursive=recursive).call(self),\n        )\n\n    def out_mask(self, mask=None, recursive=True):\n        \"\"\"Applies a mask to **remove** specified keys of the data model.\n\n        Args:\n            mask (list): The mask to be applied.\n            recursive (bool): Optional. Whether to apply the mask recursively.\n                Defaults to True.\n\n        Returns:\n            (JsonDataModel): The data model with the mask applied.\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.OutMask(mask=mask, recursive=recursive).call(self),\n        )\n\n    def prefix(self, prefix=None):\n        \"\"\"Add a prefix to **all** the data model fields (non-recursive).\n\n        Args:\n            prefix (str): the prefix to add.\n\n        Returns:\n            (JsonDataModel): The data model with the prefix added.\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Prefix(prefix=prefix).call(self),\n        )\n\n    def suffix(self, suffix=None):\n        \"\"\"Add a suffix to **all** the data model fields (non-recursive).\n\n        Args:\n            suffix (str): the suffix to add.\n\n        Returns:\n            (JsonDataModel): The data model with the suffix added.\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Suffix(suffix=suffix).call(self),\n        )\n\n    def get(self, key, default_value=None):\n        \"\"\"Get wrapper to make it easier to access JSON fields.\n\n        Args:\n            key (str): The key to access.\n        \"\"\"\n        return copy.deepcopy(self._json.get(key, default_value))\n\n    def update(self, kv_dict):\n        \"\"\"Update wrapper to make it easier to modify JSON fields.\n\n        Args:\n            kv_dict (dict): The key/json dict to update.\n        \"\"\"\n        self._json.update(kv_dict)\n\n    def clone(self, name=None):\n        \"\"\"Clone a data model and give it a different name.\"\"\"\n\n        clone = copy.deepcopy(self)\n        if name:\n            clone.name = name\n        else:\n            clone.name = auto_name(self.name + \"_clone\")\n        return clone\n\n    def get_nested_entity(self, key):\n        \"\"\"Retrieve a nested Entity and convert it to a JsonDataModel\"\"\"\n        json = copy.deepcopy(self.get(key))\n        if \"label\" in json:\n            schema_key = json.get(\"label\")\n        else:\n            return None\n        schema = copy.deepcopy(self.get_schema().get(\"$defs\").get(schema_key))\n\n        defs = {}\n        for obj_key, obj_schema in copy.deepcopy(self.get_schema().get(\"$defs\")).items():\n            if str(schema).find(f\"#/$defs/{obj_key}\") &gt; 0:\n                defs[obj_key] = obj_schema\n\n        if defs:\n            schema.update({\"$defs\": defs})\n\n        if schema:\n            return JsonDataModel(json=json, schema=schema, name=self.name + \"_\" + key)\n        else:\n            return None\n\n    def get_nested_entity_list(self, key):\n        \"\"\"Retrieve a nested Entity list and convert it to a list of JsonDataModel\"\"\"\n        json = self.get(key)\n        outputs = []\n        for i, data_model_json in enumerate(json):\n            if \"label\" in data_model_json:\n                schema_key = data_model_json.get(\"label\")\n                schema = self.get_schema().get(\"$defs\").get(schema_key)\n                defs = {}\n                for obj_key, obj_schema in self.get_schema().get(\"$defs\").items():\n                    if str(schema).find(f\"#/$defs/{obj_key}\") &gt; 0:\n                        defs[obj_key] = obj_schema\n                if defs:\n                    schema.update({\"$defs\": defs})\n\n                outputs.append(\n                    JsonDataModel(\n                        json=data_model_json,\n                        schema=schema,\n                        name=self.name + \"_\" + key + f\"_{i}\",\n                    )\n                )\n        return outputs\n\n    def __repr__(self):\n        return f\"&lt;JsonDataModel schema={self._schema}, json={self._json}&gt;\"\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20JsonDataModel%20class/#synalinks.src.backend.common.json_data_model.JsonDataModel.__add__","title":"<code>__add__(other)</code>","text":"<p>Concatenates this data model with another.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>JsonDataModel | DataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>JsonDataModel</code> <p>The concatenated data model.</p> Source code in <code>synalinks/src/backend/common/json_data_model.py</code> <pre><code>def __add__(self, other):\n    \"\"\"Concatenates this data model with another.\n\n    Args:\n        other (JsonDataModel | DataModel):\n            The other data model to concatenate with.\n\n    Returns:\n        (JsonDataModel): The concatenated data model.\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.Concat().call(self, other),\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20JsonDataModel%20class/#synalinks.src.backend.common.json_data_model.JsonDataModel.__and__","title":"<code>__and__(other)</code>","text":"<p>Perform a <code>logical_and</code> with another data model.</p> <p>If one of them is None, output None. If both are provided, then concatenates this data model with the other.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>JsonDataModel | DataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>JsonDataModel | None</code> <p>The concatenated data model or None based on the <code>logical_and</code> table.</p> Source code in <code>synalinks/src/backend/common/json_data_model.py</code> <pre><code>def __and__(self, other):\n    \"\"\"Perform a `logical_and` with another data model.\n\n    If one of them is None, output None. If both are provided,\n    then concatenates this data model with the other.\n\n    Args:\n        other (JsonDataModel | DataModel): The other data model to concatenate with.\n\n    Returns:\n        (JsonDataModel | None): The concatenated data model or None\n            based on the `logical_and` table.\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.And().call(self, other),\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20JsonDataModel%20class/#synalinks.src.backend.common.json_data_model.JsonDataModel.__or__","title":"<code>__or__(other)</code>","text":"<p>Perform a <code>logical_or</code> with another data model</p> <p>If one of them is None, output the other one. If both are provided, then concatenates this data model with the other.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>JsonDataModel | DataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>JsonDataModel | None</code> <p>The concatenation of data model if both are provided, or the non-None data model or None if none are provided. (See <code>logical_or</code> table).</p> Source code in <code>synalinks/src/backend/common/json_data_model.py</code> <pre><code>def __or__(self, other):\n    \"\"\"Perform a `logical_or` with another data model\n\n    If one of them is None, output the other one. If both are provided,\n    then concatenates this data model with the other.\n\n    Args:\n        other (JsonDataModel | DataModel): The other data model to concatenate with.\n\n    Returns:\n        (JsonDataModel | None): The concatenation of data model if both are provided,\n            or the non-None data model or None if none are provided.\n            (See `logical_or` table).\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.Or().call(self, other),\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20JsonDataModel%20class/#synalinks.src.backend.common.json_data_model.JsonDataModel.__radd__","title":"<code>__radd__(other)</code>","text":"<p>Concatenates another data model with this one.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>JsonDataModel | DataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>JsonDataModel</code> <p>The concatenated data model.</p> Source code in <code>synalinks/src/backend/common/json_data_model.py</code> <pre><code>def __radd__(self, other):\n    \"\"\"Concatenates another data model with this one.\n\n    Args:\n        other (JsonDataModel | DataModel):\n            The other data model to concatenate with.\n\n    Returns:\n        (JsonDataModel): The concatenated data model.\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.Concat().call(other, self),\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20JsonDataModel%20class/#synalinks.src.backend.common.json_data_model.JsonDataModel.__rand__","title":"<code>__rand__(other)</code>","text":"<p>Perform a <code>logical_and</code> (reverse) with another data model.</p> <p>If one of them is None, output None. If both are provided, then concatenates the other data model with this one.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>JsonDataModel | DataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>JsonDataModel | None</code> <p>The concatenated data model or None based on the <code>logical_and</code> table.</p> Source code in <code>synalinks/src/backend/common/json_data_model.py</code> <pre><code>def __rand__(self, other):\n    \"\"\"Perform a `logical_and` (reverse) with another data model.\n\n    If one of them is None, output None. If both are provided,\n    then concatenates the other data model with this one.\n\n    Args:\n        other (JsonDataModel | DataModel): The other data model to concatenate with.\n\n    Returns:\n        (JsonDataModel | None): The concatenated data model or None\n            based on the `logical_and` table.\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.And().call(other, self),\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20JsonDataModel%20class/#synalinks.src.backend.common.json_data_model.JsonDataModel.__ror__","title":"<code>__ror__(other)</code>","text":"<p>Perform a <code>logical_or</code> (reverse) with another data model</p> <p>If one of them is None, output the other one. If both are provided, then concatenates the other data model with this one.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>JsonDataModel | DataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>JsonDataModel | None</code> <p>The concatenation of data model if both are provided, or the non-None data model or None if none are provided. (See <code>logical_or</code> table).</p> Source code in <code>synalinks/src/backend/common/json_data_model.py</code> <pre><code>def __ror__(self, other):\n    \"\"\"Perform a `logical_or` (reverse) with another data model\n\n    If one of them is None, output the other one. If both are provided,\n    then concatenates the other data model with this one.\n\n    Args:\n        other (JsonDataModel | DataModel): The other data model to concatenate with.\n\n    Returns:\n        (JsonDataModel | None): The concatenation of data model if both are provided,\n            or the non-None data model or None if none are provided.\n            (See `logical_or` table).\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.Or().call(other, self),\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20JsonDataModel%20class/#synalinks.src.backend.common.json_data_model.JsonDataModel.__rxor__","title":"<code>__rxor__(other)</code>","text":"<p>Perform a <code>logical_xor</code> (reverse) with another data model.</p> <p>If one of them is None, output the other one. If both are provided, then concatenates the other data model with this one.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>SymbolicDataModel | DataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>SymbolicDataModel | None</code> <p><code>None</code> if both are provided, or the non-None data model if one is provided or <code>None</code> if none are provided. (See <code>logical_xor</code> table).</p> Source code in <code>synalinks/src/backend/common/json_data_model.py</code> <pre><code>def __rxor__(self, other):\n    \"\"\"Perform a `logical_xor` (reverse) with another data model.\n\n    If one of them is None, output the other one. If both are provided,\n    then concatenates the other data model with this one.\n\n    Args:\n        other (SymbolicDataModel | DataModel): The other data model to concatenate\n            with.\n\n    Returns:\n        (SymbolicDataModel | None): `None` if both are\n            provided, or the non-None data model if one is provided\n            or `None` if none are provided. (See `logical_xor` table).\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.Xor().call(other, self),\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20JsonDataModel%20class/#synalinks.src.backend.common.json_data_model.JsonDataModel.__xor__","title":"<code>__xor__(other)</code>","text":"<p>Perform a <code>logical_xor</code> with another data model.</p> <p>If one of them is <code>None</code>, output the other one. If both are provided, then the output is <code>None</code>.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>SymbolicDataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>SymbolicDataModel | None</code> <p><code>None</code> if both are provided, or the non-None data model if one is provided or <code>None</code> if none are provided. (See <code>logical_xor</code> table).</p> Source code in <code>synalinks/src/backend/common/json_data_model.py</code> <pre><code>def __xor__(self, other):\n    \"\"\"Perform a `logical_xor` with another data model.\n\n    If one of them is `None`, output the other one. If both are provided,\n    then the output is `None`.\n\n    Args:\n        other (SymbolicDataModel): The other data model to concatenate with.\n\n    Returns:\n        (SymbolicDataModel | None): `None` if both are\n            provided, or the non-None data model if one is provided\n            or `None` if none are provided. (See `logical_xor` table).\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.Xor().call(self, other),\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20JsonDataModel%20class/#synalinks.src.backend.common.json_data_model.JsonDataModel.clone","title":"<code>clone(name=None)</code>","text":"<p>Clone a data model and give it a different name.</p> Source code in <code>synalinks/src/backend/common/json_data_model.py</code> <pre><code>def clone(self, name=None):\n    \"\"\"Clone a data model and give it a different name.\"\"\"\n\n    clone = copy.deepcopy(self)\n    if name:\n        clone.name = name\n    else:\n        clone.name = auto_name(self.name + \"_clone\")\n    return clone\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20JsonDataModel%20class/#synalinks.src.backend.common.json_data_model.JsonDataModel.factorize","title":"<code>factorize()</code>","text":"<p>Factorizes the data model.</p> <p>Returns:</p> Type Description <code>JsonDataModel</code> <p>The factorized data model.</p> Source code in <code>synalinks/src/backend/common/json_data_model.py</code> <pre><code>def factorize(self):\n    \"\"\"Factorizes the data model.\n\n    Returns:\n        (JsonDataModel): The factorized data model.\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.Factorize().call(self),\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20JsonDataModel%20class/#synalinks.src.backend.common.json_data_model.JsonDataModel.get","title":"<code>get(key, default_value=None)</code>","text":"<p>Get wrapper to make it easier to access JSON fields.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to access.</p> required Source code in <code>synalinks/src/backend/common/json_data_model.py</code> <pre><code>def get(self, key, default_value=None):\n    \"\"\"Get wrapper to make it easier to access JSON fields.\n\n    Args:\n        key (str): The key to access.\n    \"\"\"\n    return copy.deepcopy(self._json.get(key, default_value))\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20JsonDataModel%20class/#synalinks.src.backend.common.json_data_model.JsonDataModel.get_json","title":"<code>get_json()</code>","text":"<p>Gets the current json of the JSON object.</p> <p>Returns:</p> Type Description <code>dict</code> <p>The current json of the JSON object.</p> Source code in <code>synalinks/src/backend/common/json_data_model.py</code> <pre><code>def get_json(self):\n    \"\"\"Gets the current json of the JSON object.\n\n    Returns:\n        (dict): The current json of the JSON object.\n    \"\"\"\n    return self._json\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20JsonDataModel%20class/#synalinks.src.backend.common.json_data_model.JsonDataModel.get_nested_entity","title":"<code>get_nested_entity(key)</code>","text":"<p>Retrieve a nested Entity and convert it to a JsonDataModel</p> Source code in <code>synalinks/src/backend/common/json_data_model.py</code> <pre><code>def get_nested_entity(self, key):\n    \"\"\"Retrieve a nested Entity and convert it to a JsonDataModel\"\"\"\n    json = copy.deepcopy(self.get(key))\n    if \"label\" in json:\n        schema_key = json.get(\"label\")\n    else:\n        return None\n    schema = copy.deepcopy(self.get_schema().get(\"$defs\").get(schema_key))\n\n    defs = {}\n    for obj_key, obj_schema in copy.deepcopy(self.get_schema().get(\"$defs\")).items():\n        if str(schema).find(f\"#/$defs/{obj_key}\") &gt; 0:\n            defs[obj_key] = obj_schema\n\n    if defs:\n        schema.update({\"$defs\": defs})\n\n    if schema:\n        return JsonDataModel(json=json, schema=schema, name=self.name + \"_\" + key)\n    else:\n        return None\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20JsonDataModel%20class/#synalinks.src.backend.common.json_data_model.JsonDataModel.get_nested_entity_list","title":"<code>get_nested_entity_list(key)</code>","text":"<p>Retrieve a nested Entity list and convert it to a list of JsonDataModel</p> Source code in <code>synalinks/src/backend/common/json_data_model.py</code> <pre><code>def get_nested_entity_list(self, key):\n    \"\"\"Retrieve a nested Entity list and convert it to a list of JsonDataModel\"\"\"\n    json = self.get(key)\n    outputs = []\n    for i, data_model_json in enumerate(json):\n        if \"label\" in data_model_json:\n            schema_key = data_model_json.get(\"label\")\n            schema = self.get_schema().get(\"$defs\").get(schema_key)\n            defs = {}\n            for obj_key, obj_schema in self.get_schema().get(\"$defs\").items():\n                if str(schema).find(f\"#/$defs/{obj_key}\") &gt; 0:\n                    defs[obj_key] = obj_schema\n            if defs:\n                schema.update({\"$defs\": defs})\n\n            outputs.append(\n                JsonDataModel(\n                    json=data_model_json,\n                    schema=schema,\n                    name=self.name + \"_\" + key + f\"_{i}\",\n                )\n            )\n    return outputs\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20JsonDataModel%20class/#synalinks.src.backend.common.json_data_model.JsonDataModel.get_schema","title":"<code>get_schema()</code>","text":"<p>Gets the schema of the JSON object.</p> <p>Returns:</p> Type Description <code>dict</code> <p>The JSON schema.</p> Source code in <code>synalinks/src/backend/common/json_data_model.py</code> <pre><code>def get_schema(self):\n    \"\"\"Gets the schema of the JSON object.\n\n    Returns:\n        (dict): The JSON schema.\n    \"\"\"\n    return self._schema\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20JsonDataModel%20class/#synalinks.src.backend.common.json_data_model.JsonDataModel.in_mask","title":"<code>in_mask(mask=None, recursive=True)</code>","text":"<p>Applies a mask to keep only specified keys of the data model.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>list</code> <p>The mask to be applied.</p> <code>None</code> <code>recursive</code> <code>bool</code> <p>Optional. Whether to apply the mask recursively. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>JsonDataModel</code> <p>The data model with the mask applied.</p> Source code in <code>synalinks/src/backend/common/json_data_model.py</code> <pre><code>def in_mask(self, mask=None, recursive=True):\n    \"\"\"Applies a mask to **keep only** specified keys of the data model.\n\n    Args:\n        mask (list): The mask to be applied.\n        recursive (bool): Optional. Whether to apply the mask recursively.\n            Defaults to True.\n\n    Returns:\n        (JsonDataModel): The data model with the mask applied.\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.InMask(mask=mask, recursive=recursive).call(self),\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20JsonDataModel%20class/#synalinks.src.backend.common.json_data_model.JsonDataModel.out_mask","title":"<code>out_mask(mask=None, recursive=True)</code>","text":"<p>Applies a mask to remove specified keys of the data model.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>list</code> <p>The mask to be applied.</p> <code>None</code> <code>recursive</code> <code>bool</code> <p>Optional. Whether to apply the mask recursively. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>JsonDataModel</code> <p>The data model with the mask applied.</p> Source code in <code>synalinks/src/backend/common/json_data_model.py</code> <pre><code>def out_mask(self, mask=None, recursive=True):\n    \"\"\"Applies a mask to **remove** specified keys of the data model.\n\n    Args:\n        mask (list): The mask to be applied.\n        recursive (bool): Optional. Whether to apply the mask recursively.\n            Defaults to True.\n\n    Returns:\n        (JsonDataModel): The data model with the mask applied.\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.OutMask(mask=mask, recursive=recursive).call(self),\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20JsonDataModel%20class/#synalinks.src.backend.common.json_data_model.JsonDataModel.prefix","title":"<code>prefix(prefix=None)</code>","text":"<p>Add a prefix to all the data model fields (non-recursive).</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>the prefix to add.</p> <code>None</code> <p>Returns:</p> Type Description <code>JsonDataModel</code> <p>The data model with the prefix added.</p> Source code in <code>synalinks/src/backend/common/json_data_model.py</code> <pre><code>def prefix(self, prefix=None):\n    \"\"\"Add a prefix to **all** the data model fields (non-recursive).\n\n    Args:\n        prefix (str): the prefix to add.\n\n    Returns:\n        (JsonDataModel): The data model with the prefix added.\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.Prefix(prefix=prefix).call(self),\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20JsonDataModel%20class/#synalinks.src.backend.common.json_data_model.JsonDataModel.prettify_json","title":"<code>prettify_json()</code>","text":"<p>Get a pretty version of the JSON object for display.</p> <p>Returns:</p> Type Description <code>str</code> <p>The indented JSON object.</p> Source code in <code>synalinks/src/backend/common/json_data_model.py</code> <pre><code>def prettify_json(self):\n    \"\"\"Get a pretty version of the JSON object for display.\n\n    Returns:\n        (str): The indented JSON object.\n    \"\"\"\n    import json\n\n    return json.dumps(self._json, indent=2)\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20JsonDataModel%20class/#synalinks.src.backend.common.json_data_model.JsonDataModel.prettify_schema","title":"<code>prettify_schema()</code>","text":"<p>Get a pretty version of the JSON schema for display.</p> <p>Returns:</p> Type Description <code>dict</code> <p>The indented JSON schema.</p> Source code in <code>synalinks/src/backend/common/json_data_model.py</code> <pre><code>def prettify_schema(self):\n    \"\"\"Get a pretty version of the JSON schema for display.\n\n    Returns:\n        (dict): The indented JSON schema.\n    \"\"\"\n    import json\n\n    return json.dumps(self._schema, indent=2)\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20JsonDataModel%20class/#synalinks.src.backend.common.json_data_model.JsonDataModel.suffix","title":"<code>suffix(suffix=None)</code>","text":"<p>Add a suffix to all the data model fields (non-recursive).</p> <p>Parameters:</p> Name Type Description Default <code>suffix</code> <code>str</code> <p>the suffix to add.</p> <code>None</code> <p>Returns:</p> Type Description <code>JsonDataModel</code> <p>The data model with the suffix added.</p> Source code in <code>synalinks/src/backend/common/json_data_model.py</code> <pre><code>def suffix(self, suffix=None):\n    \"\"\"Add a suffix to **all** the data model fields (non-recursive).\n\n    Args:\n        suffix (str): the suffix to add.\n\n    Returns:\n        (JsonDataModel): The data model with the suffix added.\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.Suffix(suffix=suffix).call(self),\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20JsonDataModel%20class/#synalinks.src.backend.common.json_data_model.JsonDataModel.to_symbolic_data_model","title":"<code>to_symbolic_data_model()</code>","text":"<p>Converts the JsonDataModel to a SymbolicDataModel.</p> <p>Returns:</p> Type Description <code>SymbolicDataModel</code> <p>The symbolic data model.</p> Source code in <code>synalinks/src/backend/common/json_data_model.py</code> <pre><code>def to_symbolic_data_model(self):\n    \"\"\"Converts the JsonDataModel to a SymbolicDataModel.\n\n    Returns:\n        (SymbolicDataModel): The symbolic data model.\n    \"\"\"\n    return SymbolicDataModel(schema=self._schema)\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20JsonDataModel%20class/#synalinks.src.backend.common.json_data_model.JsonDataModel.update","title":"<code>update(kv_dict)</code>","text":"<p>Update wrapper to make it easier to modify JSON fields.</p> <p>Parameters:</p> Name Type Description Default <code>kv_dict</code> <code>dict</code> <p>The key/json dict to update.</p> required Source code in <code>synalinks/src/backend/common/json_data_model.py</code> <pre><code>def update(self, kv_dict):\n    \"\"\"Update wrapper to make it easier to modify JSON fields.\n\n    Args:\n        kv_dict (dict): The key/json dict to update.\n    \"\"\"\n    self._json.update(kv_dict)\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20JsonDataModel%20class/#synalinks.src.backend.common.json_data_model.is_json_data_model","title":"<code>is_json_data_model(x)</code>","text":"<p>Returns whether <code>x</code> is a backend-independent data model.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>any</code> <p>The object to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if <code>x</code> is a backend-independent data model, False otherwise.</p> Source code in <code>synalinks/src/backend/common/json_data_model.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.utils.is_json_data_model\",\n        \"synalinks.backend.is_json_data_model\",\n    ]\n)\ndef is_json_data_model(x):\n    \"\"\"Returns whether `x` is a backend-independent data model.\n\n    Args:\n        x (any): The object to check.\n\n    Returns:\n        (bool): True if `x` is a backend-independent data model, False otherwise.\n    \"\"\"\n    return isinstance(x, JsonDataModel)\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20SymbolicDataModel%20class/","title":"The SymbolicDataModel class","text":""},{"location":"Synalinks%20API/Data%20Models%20API/The%20SymbolicDataModel%20class/#synalinks.src.backend.common.symbolic_data_model.SymbolicDataModel","title":"<code>SymbolicDataModel</code>","text":"<p>               Bases: <code>SynalinksSaveable</code></p> <p>A symbolic backend-independent data model.</p> <p>A <code>SymbolicDataModel</code> is a container for a JSON schema and can be used to represent     data structures in a backend-agnostic way. It can record history and is used in     symbolic operations (in the Functional API and to compute output specs).</p> <p>A \"symbolic data model\" can be understood as a placeholder for data specification,     it does not contain any actual data, only a schema. It can be used for building     Functional models, but it cannot be used in actual computations.</p> <p>Parameters:</p> Name Type Description Default <code>data_model</code> <code>DataModel</code> <p>Optional. The data_model used to extract the schema.</p> <code>None</code> <code>schema</code> <code>dict</code> <p>Optional. The JSON schema to be used. If the schema is not provided, the data_model argument should be used to infer it.</p> <code>None</code> <code>record_history</code> <code>bool</code> <p>Optional. Boolean indicating if the history should be recorded. Defaults to <code>True</code>.</p> <code>True</code> <code>name</code> <code>str</code> <p>Optional. A unique name for the data model. Automatically generated if not set.</p> <code>None</code> <p>Examples:</p> <p>Creating a <code>SymbolicDataModel</code> with a backend data model metaclass:</p> <pre><code>class Query(synalinks.DataModel):\n    query: str = synalinks.Field(\n        description=\"The user query\",\n    )\n\ndata_model = SymbolicDataModel(data_model=Query)\n</code></pre> <p>Creating a <code>SymbolicDataModel</code> with a backend data model metaclass's schema:</p> <pre><code>class Query(synalinks.DataModel):\n    query: str = synalinks.Field(\n        description=\"The user query\",\n    )\n\ndata_model = SymbolicDataModel(schema=Query.get_schema())\n</code></pre> <p>Creating a <code>SymbolicDataModel</code> with <code>to_symbolic_data_model()</code>:</p> <p>using a backend data model metaclass</p> <pre><code>class Query(synalinks.DataModel):\n    query: str = synalinks.Field(\n        description=\"The user query\",\n    )\n\ndata_model = Query.to_symbolic_data_model()\n</code></pre> Source code in <code>synalinks/src/backend/common/symbolic_data_model.py</code> <pre><code>@synalinks_export(\"synalinks.SymbolicDataModel\")\nclass SymbolicDataModel(SynalinksSaveable):\n    \"\"\"A symbolic backend-independent data model.\n\n    A `SymbolicDataModel` is a container for a JSON schema and can be used to represent\n        data structures in a backend-agnostic way. It can record history and is used in\n        symbolic operations (in the Functional API and to compute output specs).\n\n    A \"symbolic data model\" can be understood as a placeholder for data specification,\n        it does not contain any actual data, only a schema. It can be used for building\n        Functional models, but it cannot be used in actual computations.\n\n    Args:\n        data_model (DataModel): Optional. The data_model used to extract the schema.\n        schema (dict): Optional. The JSON schema to be used. If the schema is not\n            provided, the data_model argument should be used to infer it.\n        record_history (bool): Optional. Boolean indicating if the history\n            should be recorded. Defaults to `True`.\n        name (str): Optional. A unique name for the data model. Automatically generated\n            if not set.\n\n    Examples:\n\n    **Creating a `SymbolicDataModel` with a backend data model metaclass:**\n\n    ```python\n    class Query(synalinks.DataModel):\n        query: str = synalinks.Field(\n            description=\"The user query\",\n        )\n\n    data_model = SymbolicDataModel(data_model=Query)\n    ```\n\n    **Creating a `SymbolicDataModel` with a backend data model metaclass's schema:**\n\n    ```python\n    class Query(synalinks.DataModel):\n        query: str = synalinks.Field(\n            description=\"The user query\",\n        )\n\n    data_model = SymbolicDataModel(schema=Query.get_schema())\n    ```\n\n    **Creating a `SymbolicDataModel` with `to_symbolic_data_model()`:**\n\n    using a backend data model metaclass\n\n    ```python\n    class Query(synalinks.DataModel):\n        query: str = synalinks.Field(\n            description=\"The user query\",\n        )\n\n    data_model = Query.to_symbolic_data_model()\n    ```\n    \"\"\"\n\n    def __init__(\n        self,\n        data_model=None,\n        schema=None,\n        record_history=True,\n        name=None,\n    ):\n        self.name = name or auto_name(self.__class__.__name__)\n        self._record_history = record_history\n        self._schema = None\n        if not schema and not data_model:\n            raise ValueError(\n                \"You should specify at least one argument between \"\n                \"`data_model` or `schema`\"\n            )\n        if schema and data_model:\n            if not is_schema_equal(schema, data_model.get_schema()):\n                raise ValueError(\n                    \"Attempting to create a SymbolicDataModel \"\n                    \"with both `schema` and `data_model` argument \"\n                    \"but their schemas are incompatible \"\n                    f\"received schema={schema} and \"\n                    f\"data_model.get_schema()={data_model.get_schema()}.\"\n                )\n            self._schema = standardize_schema(schema)\n        else:\n            if schema:\n                self._schema = standardize_schema(schema)\n            if data_model:\n                self._schema = standardize_schema(data_model.get_schema())\n\n    @property\n    def record_history(self):\n        \"\"\"Whether the history is being recorded.\"\"\"\n        return self._record_history\n\n    @record_history.setter\n    def record_history(self, value):\n        self._record_history = value\n\n    def get_schema(self):\n        \"\"\"Gets the JSON schema of the data model.\n\n        Returns:\n            (dict): The JSON schema.\n        \"\"\"\n        return self._schema\n\n    def get_json(self):\n        \"\"\"Gets the current value of the JSON object (impossible in `SymbolicDataModel`).\n\n        Implemented to help the user to identifying issues.\n\n        Raises:\n            ValueError: The help message.\n        \"\"\"\n        raise ValueError(\n            \"Attempting to retrieve the JSON value from a symbolic data model \"\n            \"this operation is not possible, make sure that your `call()` \"\n            \"is correctly implemented, if so then you likely need to implement \"\n            \" `compute_output_spec()` in your subclassed module.\"\n        )\n\n    def prettify_schema(self):\n        \"\"\"Get a pretty version of the JSON schema for display.\n\n        Returns:\n            (dict): The indented JSON schema.\n        \"\"\"\n        return json.dumps(self._schema, indent=2)\n\n    def __repr__(self):\n        return f\"&lt;SymbolicDataModel schema={self._schema}, name={self.name}&gt;\"\n\n    def __add__(self, other):\n        \"\"\"Concatenates this data model with another.\n\n        Args:\n            other (SymbolicDataModel | DataModel):\n                The other data model to concatenate with.\n\n        Returns:\n            (SymbolicDataModel): The concatenated data model.\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Concat().symbolic_call(self, other)\n        )\n\n    def __radd__(self, other):\n        \"\"\"Concatenates (reverse) another data model with this one.\n\n        Args:\n            other (SymbolicDataModel | DataModel):\n                The other data model to concatenate with.\n\n        Returns:\n            (SymbolicDataModel): The concatenated data model.\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Concat().symbolic_call(other, self)\n        )\n\n    def __and__(self, other):\n        \"\"\"Perform a `logical_and` with another data model.\n\n        If one of them is None, output None. If both are provided,\n        then concatenates this data model with the other.\n\n        Args:\n            other (SymbolicDataModel | DataModel): The other data model to concatenate\n                with.\n\n        Returns:\n            (SymbolicDataModel | None): The concatenated data model or None\n                based on the `logical_and` table.\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.And().symbolic_call(self, other)\n        )\n\n    def __rand__(self, other):\n        \"\"\"Perform a `logical_and` (reverse) with another data model.\n\n        If one of them is None, output None. If both are provided,\n        then concatenates the other data model with this one.\n\n        Args:\n            other (SymbolicDataModel | DataModel): The other data model to concatenate\n                with.\n\n        Returns:\n            (SymbolicDataModel | None): The concatenated data model or None\n                based on the `logical_and` table.\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.And().symbolic_call(other, self)\n        )\n\n    def __or__(self, other):\n        \"\"\"Perform a `logical_or` with another data model\n\n        If one of them is None, output the other one. If both are provided,\n        then concatenates this data model with the other.\n\n        Args:\n            other (SymbolicDataModel): The other data model to concatenate with.\n\n        Returns:\n            (SymbolicDataModel | None): The concatenation of data model if both are\n                provided, or the non-None data model or None if none are provided.\n                (See `logical_or` table).\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Or().symbolic_call(self, other)\n        )\n\n    def __ror__(self, other):\n        \"\"\"Perform a `logical_or` (reverse) with another data model\n\n        If one of them is None, output the other one. If both are provided,\n        then concatenates the other data model with this one.\n\n        Args:\n            other (SymbolicDataModel | DataModel): The other data model to concatenate\n                with.\n\n        Returns:\n            (SymbolicDataModel | None): The concatenation of data model if both are\n                provided, or the non-None data model or None if none are provided.\n                (See `logical_or` table).\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Or().symbolic_call(other, self)\n        )\n\n    def __xor__(self, other):\n        \"\"\"Perform a `logical_xor` with another data model.\n\n        If one of them is `None`, output the other one. If both are provided,\n        then the output is `None`.\n\n        Args:\n            other (SymbolicDataModel): The other data model to concatenate with.\n\n        Returns:\n            (SymbolicDataModel | None): `None` if both are\n                provided, or the non-None data model if one is provided\n                or `None` if none are provided. (See `logical_xor` table).\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Xor().symbolic_call(self, other)\n        )\n\n    def __rxor__(self, other):\n        \"\"\"Perform a `logical_xor` (reverse) with another data model.\n\n        If one of them is None, output the other one. If both are provided,\n        then concatenates the other data model with this one.\n\n        Args:\n            other (SymbolicDataModel | DataModel): The other data model to concatenate\n                with.\n\n        Returns:\n            (SymbolicDataModel | None): `None` if both are\n                provided, or the non-None data model if one is provided\n                or `None` if none are provided. (See `logical_xor` table).\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Xor().symbolic_call(other, self)\n        )\n\n    def factorize(self):\n        \"\"\"Factorizes the data model.\n\n        Returns:\n            (SymbolicDataModel): The factorized data model.\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Factorize().symbolic_call(self)\n        )\n\n    def in_mask(self, mask=None, recursive=True):\n        \"\"\"Applies a mask to **keep only** specified keys of the data model.\n\n        Args:\n            mask (list): The mask to be applied (list of keys).\n            recursive (bool): Optional. Whether to apply the mask recursively.\n                Defaults to `True`.\n\n        Returns:\n            (SymbolicDataModel): The data model with the mask applied.\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.InMask(mask=mask, recursive=True).symbolic_call(self)\n        )\n\n    def out_mask(self, mask=None, recursive=True):\n        \"\"\"Applies an mask to **remove** specified keys of the data model.\n\n        Args:\n            mask (list): The mask to be applied (list of keys).\n            recursive (bool): Optional. Whether to apply the mask recursively.\n                Defaults to `True`.\n\n        Returns:\n            (SymbolicDataModel): The data model with the mask applied.\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.OutMask(mask=mask, recursive=True).symbolic_call(self)\n        )\n\n    def prefix(self, prefix=None):\n        \"\"\"Add a prefix to **all** the data model fields (non-recursive).\n\n        Args:\n            prefix (str): the prefix to add\n\n        Returns:\n            (SymbolicDataModel): The data model with the prefix added.\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Prefix(prefix=prefix).symbolic_call(self)\n        )\n\n    def suffix(self, suffix=None):\n        \"\"\"Add a suffix to **all** the data model fields (non-recursive).\n\n        Args:\n            suffix (str): the suffix to add\n\n        Returns:\n            (SymbolicDataModel): The data model with the suffix added.\n        \"\"\"\n        from synalinks.src import ops\n\n        return asyncio.get_event_loop().run_until_complete(\n            ops.Suffix(suffix=suffix).symbolic_call(self)\n        )\n\n    def get(self, key, default_value=None):\n        \"\"\"Get wrapper to make easier to access fields.\n\n        Implemented to help the user to identifying issues.\n\n        Args:\n            key (str): The key to access.\n\n        Raises:\n            ValueError: The help message.\n        \"\"\"\n        raise ValueError(\n            f\"Attempting to get '{key}' from a symbolic data model \"\n            \"this operation is not possible, make sure that your `call()` \"\n            \"is correctly implemented, if so then you likely need to implement \"\n            \" `compute_output_spec()` in your subclassed module.\"\n        )\n\n    def update(self, kv_dict):\n        \"\"\"Update wrapper to make easier to modify fields.\n\n        Implemented to help the user to identifying issues.\n\n        Args:\n            kv_dict (dict): The key/value dict to update.\n\n        Raises:\n            ValueError: The help message.\n        \"\"\"\n        raise ValueError(\n            f\"Attempting to update keys {list(kv_dict.keys())} from a symbolic \"\n            \"data model this operation is not possible, make sure that your `call()` \"\n            \"is correctly implemented, if so then you likely need to implement \"\n            \" `compute_output_spec()` in your subclassed module.\"\n        )\n\n    def clone(self, name=None):\n        \"\"\"Clone a symbolic data model and give it a different name.\"\"\"\n        import copy\n\n        clone = copy.deepcopy(self)\n        if name:\n            clone.name = name\n        else:\n            clone.name = self.name + \"_clone\"\n        return clone\n\n    def get_config(self):\n        config = {\n            \"name\": self.name,\n            \"schema\": self.get_schema(),\n            \"record_history\": self.record_history,\n        }\n        return config\n\n    @classmethod\n    def from_config(cls, config):\n        return cls(**config)\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20SymbolicDataModel%20class/#synalinks.src.backend.common.symbolic_data_model.SymbolicDataModel.record_history","title":"<code>record_history</code>  <code>property</code> <code>writable</code>","text":"<p>Whether the history is being recorded.</p>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20SymbolicDataModel%20class/#synalinks.src.backend.common.symbolic_data_model.SymbolicDataModel.__add__","title":"<code>__add__(other)</code>","text":"<p>Concatenates this data model with another.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>SymbolicDataModel | DataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>SymbolicDataModel</code> <p>The concatenated data model.</p> Source code in <code>synalinks/src/backend/common/symbolic_data_model.py</code> <pre><code>def __add__(self, other):\n    \"\"\"Concatenates this data model with another.\n\n    Args:\n        other (SymbolicDataModel | DataModel):\n            The other data model to concatenate with.\n\n    Returns:\n        (SymbolicDataModel): The concatenated data model.\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.Concat().symbolic_call(self, other)\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20SymbolicDataModel%20class/#synalinks.src.backend.common.symbolic_data_model.SymbolicDataModel.__and__","title":"<code>__and__(other)</code>","text":"<p>Perform a <code>logical_and</code> with another data model.</p> <p>If one of them is None, output None. If both are provided, then concatenates this data model with the other.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>SymbolicDataModel | DataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>SymbolicDataModel | None</code> <p>The concatenated data model or None based on the <code>logical_and</code> table.</p> Source code in <code>synalinks/src/backend/common/symbolic_data_model.py</code> <pre><code>def __and__(self, other):\n    \"\"\"Perform a `logical_and` with another data model.\n\n    If one of them is None, output None. If both are provided,\n    then concatenates this data model with the other.\n\n    Args:\n        other (SymbolicDataModel | DataModel): The other data model to concatenate\n            with.\n\n    Returns:\n        (SymbolicDataModel | None): The concatenated data model or None\n            based on the `logical_and` table.\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.And().symbolic_call(self, other)\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20SymbolicDataModel%20class/#synalinks.src.backend.common.symbolic_data_model.SymbolicDataModel.__or__","title":"<code>__or__(other)</code>","text":"<p>Perform a <code>logical_or</code> with another data model</p> <p>If one of them is None, output the other one. If both are provided, then concatenates this data model with the other.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>SymbolicDataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>SymbolicDataModel | None</code> <p>The concatenation of data model if both are provided, or the non-None data model or None if none are provided. (See <code>logical_or</code> table).</p> Source code in <code>synalinks/src/backend/common/symbolic_data_model.py</code> <pre><code>def __or__(self, other):\n    \"\"\"Perform a `logical_or` with another data model\n\n    If one of them is None, output the other one. If both are provided,\n    then concatenates this data model with the other.\n\n    Args:\n        other (SymbolicDataModel): The other data model to concatenate with.\n\n    Returns:\n        (SymbolicDataModel | None): The concatenation of data model if both are\n            provided, or the non-None data model or None if none are provided.\n            (See `logical_or` table).\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.Or().symbolic_call(self, other)\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20SymbolicDataModel%20class/#synalinks.src.backend.common.symbolic_data_model.SymbolicDataModel.__radd__","title":"<code>__radd__(other)</code>","text":"<p>Concatenates (reverse) another data model with this one.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>SymbolicDataModel | DataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>SymbolicDataModel</code> <p>The concatenated data model.</p> Source code in <code>synalinks/src/backend/common/symbolic_data_model.py</code> <pre><code>def __radd__(self, other):\n    \"\"\"Concatenates (reverse) another data model with this one.\n\n    Args:\n        other (SymbolicDataModel | DataModel):\n            The other data model to concatenate with.\n\n    Returns:\n        (SymbolicDataModel): The concatenated data model.\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.Concat().symbolic_call(other, self)\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20SymbolicDataModel%20class/#synalinks.src.backend.common.symbolic_data_model.SymbolicDataModel.__rand__","title":"<code>__rand__(other)</code>","text":"<p>Perform a <code>logical_and</code> (reverse) with another data model.</p> <p>If one of them is None, output None. If both are provided, then concatenates the other data model with this one.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>SymbolicDataModel | DataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>SymbolicDataModel | None</code> <p>The concatenated data model or None based on the <code>logical_and</code> table.</p> Source code in <code>synalinks/src/backend/common/symbolic_data_model.py</code> <pre><code>def __rand__(self, other):\n    \"\"\"Perform a `logical_and` (reverse) with another data model.\n\n    If one of them is None, output None. If both are provided,\n    then concatenates the other data model with this one.\n\n    Args:\n        other (SymbolicDataModel | DataModel): The other data model to concatenate\n            with.\n\n    Returns:\n        (SymbolicDataModel | None): The concatenated data model or None\n            based on the `logical_and` table.\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.And().symbolic_call(other, self)\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20SymbolicDataModel%20class/#synalinks.src.backend.common.symbolic_data_model.SymbolicDataModel.__ror__","title":"<code>__ror__(other)</code>","text":"<p>Perform a <code>logical_or</code> (reverse) with another data model</p> <p>If one of them is None, output the other one. If both are provided, then concatenates the other data model with this one.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>SymbolicDataModel | DataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>SymbolicDataModel | None</code> <p>The concatenation of data model if both are provided, or the non-None data model or None if none are provided. (See <code>logical_or</code> table).</p> Source code in <code>synalinks/src/backend/common/symbolic_data_model.py</code> <pre><code>def __ror__(self, other):\n    \"\"\"Perform a `logical_or` (reverse) with another data model\n\n    If one of them is None, output the other one. If both are provided,\n    then concatenates the other data model with this one.\n\n    Args:\n        other (SymbolicDataModel | DataModel): The other data model to concatenate\n            with.\n\n    Returns:\n        (SymbolicDataModel | None): The concatenation of data model if both are\n            provided, or the non-None data model or None if none are provided.\n            (See `logical_or` table).\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.Or().symbolic_call(other, self)\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20SymbolicDataModel%20class/#synalinks.src.backend.common.symbolic_data_model.SymbolicDataModel.__rxor__","title":"<code>__rxor__(other)</code>","text":"<p>Perform a <code>logical_xor</code> (reverse) with another data model.</p> <p>If one of them is None, output the other one. If both are provided, then concatenates the other data model with this one.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>SymbolicDataModel | DataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>SymbolicDataModel | None</code> <p><code>None</code> if both are provided, or the non-None data model if one is provided or <code>None</code> if none are provided. (See <code>logical_xor</code> table).</p> Source code in <code>synalinks/src/backend/common/symbolic_data_model.py</code> <pre><code>def __rxor__(self, other):\n    \"\"\"Perform a `logical_xor` (reverse) with another data model.\n\n    If one of them is None, output the other one. If both are provided,\n    then concatenates the other data model with this one.\n\n    Args:\n        other (SymbolicDataModel | DataModel): The other data model to concatenate\n            with.\n\n    Returns:\n        (SymbolicDataModel | None): `None` if both are\n            provided, or the non-None data model if one is provided\n            or `None` if none are provided. (See `logical_xor` table).\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.Xor().symbolic_call(other, self)\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20SymbolicDataModel%20class/#synalinks.src.backend.common.symbolic_data_model.SymbolicDataModel.__xor__","title":"<code>__xor__(other)</code>","text":"<p>Perform a <code>logical_xor</code> with another data model.</p> <p>If one of them is <code>None</code>, output the other one. If both are provided, then the output is <code>None</code>.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>SymbolicDataModel</code> <p>The other data model to concatenate with.</p> required <p>Returns:</p> Type Description <code>SymbolicDataModel | None</code> <p><code>None</code> if both are provided, or the non-None data model if one is provided or <code>None</code> if none are provided. (See <code>logical_xor</code> table).</p> Source code in <code>synalinks/src/backend/common/symbolic_data_model.py</code> <pre><code>def __xor__(self, other):\n    \"\"\"Perform a `logical_xor` with another data model.\n\n    If one of them is `None`, output the other one. If both are provided,\n    then the output is `None`.\n\n    Args:\n        other (SymbolicDataModel): The other data model to concatenate with.\n\n    Returns:\n        (SymbolicDataModel | None): `None` if both are\n            provided, or the non-None data model if one is provided\n            or `None` if none are provided. (See `logical_xor` table).\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.Xor().symbolic_call(self, other)\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20SymbolicDataModel%20class/#synalinks.src.backend.common.symbolic_data_model.SymbolicDataModel.clone","title":"<code>clone(name=None)</code>","text":"<p>Clone a symbolic data model and give it a different name.</p> Source code in <code>synalinks/src/backend/common/symbolic_data_model.py</code> <pre><code>def clone(self, name=None):\n    \"\"\"Clone a symbolic data model and give it a different name.\"\"\"\n    import copy\n\n    clone = copy.deepcopy(self)\n    if name:\n        clone.name = name\n    else:\n        clone.name = self.name + \"_clone\"\n    return clone\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20SymbolicDataModel%20class/#synalinks.src.backend.common.symbolic_data_model.SymbolicDataModel.factorize","title":"<code>factorize()</code>","text":"<p>Factorizes the data model.</p> <p>Returns:</p> Type Description <code>SymbolicDataModel</code> <p>The factorized data model.</p> Source code in <code>synalinks/src/backend/common/symbolic_data_model.py</code> <pre><code>def factorize(self):\n    \"\"\"Factorizes the data model.\n\n    Returns:\n        (SymbolicDataModel): The factorized data model.\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.Factorize().symbolic_call(self)\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20SymbolicDataModel%20class/#synalinks.src.backend.common.symbolic_data_model.SymbolicDataModel.get","title":"<code>get(key, default_value=None)</code>","text":"<p>Get wrapper to make easier to access fields.</p> <p>Implemented to help the user to identifying issues.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to access.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>The help message.</p> Source code in <code>synalinks/src/backend/common/symbolic_data_model.py</code> <pre><code>def get(self, key, default_value=None):\n    \"\"\"Get wrapper to make easier to access fields.\n\n    Implemented to help the user to identifying issues.\n\n    Args:\n        key (str): The key to access.\n\n    Raises:\n        ValueError: The help message.\n    \"\"\"\n    raise ValueError(\n        f\"Attempting to get '{key}' from a symbolic data model \"\n        \"this operation is not possible, make sure that your `call()` \"\n        \"is correctly implemented, if so then you likely need to implement \"\n        \" `compute_output_spec()` in your subclassed module.\"\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20SymbolicDataModel%20class/#synalinks.src.backend.common.symbolic_data_model.SymbolicDataModel.get_json","title":"<code>get_json()</code>","text":"<p>Gets the current value of the JSON object (impossible in <code>SymbolicDataModel</code>).</p> <p>Implemented to help the user to identifying issues.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>The help message.</p> Source code in <code>synalinks/src/backend/common/symbolic_data_model.py</code> <pre><code>def get_json(self):\n    \"\"\"Gets the current value of the JSON object (impossible in `SymbolicDataModel`).\n\n    Implemented to help the user to identifying issues.\n\n    Raises:\n        ValueError: The help message.\n    \"\"\"\n    raise ValueError(\n        \"Attempting to retrieve the JSON value from a symbolic data model \"\n        \"this operation is not possible, make sure that your `call()` \"\n        \"is correctly implemented, if so then you likely need to implement \"\n        \" `compute_output_spec()` in your subclassed module.\"\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20SymbolicDataModel%20class/#synalinks.src.backend.common.symbolic_data_model.SymbolicDataModel.get_schema","title":"<code>get_schema()</code>","text":"<p>Gets the JSON schema of the data model.</p> <p>Returns:</p> Type Description <code>dict</code> <p>The JSON schema.</p> Source code in <code>synalinks/src/backend/common/symbolic_data_model.py</code> <pre><code>def get_schema(self):\n    \"\"\"Gets the JSON schema of the data model.\n\n    Returns:\n        (dict): The JSON schema.\n    \"\"\"\n    return self._schema\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20SymbolicDataModel%20class/#synalinks.src.backend.common.symbolic_data_model.SymbolicDataModel.in_mask","title":"<code>in_mask(mask=None, recursive=True)</code>","text":"<p>Applies a mask to keep only specified keys of the data model.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>list</code> <p>The mask to be applied (list of keys).</p> <code>None</code> <code>recursive</code> <code>bool</code> <p>Optional. Whether to apply the mask recursively. Defaults to <code>True</code>.</p> <code>True</code> <p>Returns:</p> Type Description <code>SymbolicDataModel</code> <p>The data model with the mask applied.</p> Source code in <code>synalinks/src/backend/common/symbolic_data_model.py</code> <pre><code>def in_mask(self, mask=None, recursive=True):\n    \"\"\"Applies a mask to **keep only** specified keys of the data model.\n\n    Args:\n        mask (list): The mask to be applied (list of keys).\n        recursive (bool): Optional. Whether to apply the mask recursively.\n            Defaults to `True`.\n\n    Returns:\n        (SymbolicDataModel): The data model with the mask applied.\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.InMask(mask=mask, recursive=True).symbolic_call(self)\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20SymbolicDataModel%20class/#synalinks.src.backend.common.symbolic_data_model.SymbolicDataModel.out_mask","title":"<code>out_mask(mask=None, recursive=True)</code>","text":"<p>Applies an mask to remove specified keys of the data model.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>list</code> <p>The mask to be applied (list of keys).</p> <code>None</code> <code>recursive</code> <code>bool</code> <p>Optional. Whether to apply the mask recursively. Defaults to <code>True</code>.</p> <code>True</code> <p>Returns:</p> Type Description <code>SymbolicDataModel</code> <p>The data model with the mask applied.</p> Source code in <code>synalinks/src/backend/common/symbolic_data_model.py</code> <pre><code>def out_mask(self, mask=None, recursive=True):\n    \"\"\"Applies an mask to **remove** specified keys of the data model.\n\n    Args:\n        mask (list): The mask to be applied (list of keys).\n        recursive (bool): Optional. Whether to apply the mask recursively.\n            Defaults to `True`.\n\n    Returns:\n        (SymbolicDataModel): The data model with the mask applied.\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.OutMask(mask=mask, recursive=True).symbolic_call(self)\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20SymbolicDataModel%20class/#synalinks.src.backend.common.symbolic_data_model.SymbolicDataModel.prefix","title":"<code>prefix(prefix=None)</code>","text":"<p>Add a prefix to all the data model fields (non-recursive).</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>the prefix to add</p> <code>None</code> <p>Returns:</p> Type Description <code>SymbolicDataModel</code> <p>The data model with the prefix added.</p> Source code in <code>synalinks/src/backend/common/symbolic_data_model.py</code> <pre><code>def prefix(self, prefix=None):\n    \"\"\"Add a prefix to **all** the data model fields (non-recursive).\n\n    Args:\n        prefix (str): the prefix to add\n\n    Returns:\n        (SymbolicDataModel): The data model with the prefix added.\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.Prefix(prefix=prefix).symbolic_call(self)\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20SymbolicDataModel%20class/#synalinks.src.backend.common.symbolic_data_model.SymbolicDataModel.prettify_schema","title":"<code>prettify_schema()</code>","text":"<p>Get a pretty version of the JSON schema for display.</p> <p>Returns:</p> Type Description <code>dict</code> <p>The indented JSON schema.</p> Source code in <code>synalinks/src/backend/common/symbolic_data_model.py</code> <pre><code>def prettify_schema(self):\n    \"\"\"Get a pretty version of the JSON schema for display.\n\n    Returns:\n        (dict): The indented JSON schema.\n    \"\"\"\n    return json.dumps(self._schema, indent=2)\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20SymbolicDataModel%20class/#synalinks.src.backend.common.symbolic_data_model.SymbolicDataModel.suffix","title":"<code>suffix(suffix=None)</code>","text":"<p>Add a suffix to all the data model fields (non-recursive).</p> <p>Parameters:</p> Name Type Description Default <code>suffix</code> <code>str</code> <p>the suffix to add</p> <code>None</code> <p>Returns:</p> Type Description <code>SymbolicDataModel</code> <p>The data model with the suffix added.</p> Source code in <code>synalinks/src/backend/common/symbolic_data_model.py</code> <pre><code>def suffix(self, suffix=None):\n    \"\"\"Add a suffix to **all** the data model fields (non-recursive).\n\n    Args:\n        suffix (str): the suffix to add\n\n    Returns:\n        (SymbolicDataModel): The data model with the suffix added.\n    \"\"\"\n    from synalinks.src import ops\n\n    return asyncio.get_event_loop().run_until_complete(\n        ops.Suffix(suffix=suffix).symbolic_call(self)\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20SymbolicDataModel%20class/#synalinks.src.backend.common.symbolic_data_model.SymbolicDataModel.update","title":"<code>update(kv_dict)</code>","text":"<p>Update wrapper to make easier to modify fields.</p> <p>Implemented to help the user to identifying issues.</p> <p>Parameters:</p> Name Type Description Default <code>kv_dict</code> <code>dict</code> <p>The key/value dict to update.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>The help message.</p> Source code in <code>synalinks/src/backend/common/symbolic_data_model.py</code> <pre><code>def update(self, kv_dict):\n    \"\"\"Update wrapper to make easier to modify fields.\n\n    Implemented to help the user to identifying issues.\n\n    Args:\n        kv_dict (dict): The key/value dict to update.\n\n    Raises:\n        ValueError: The help message.\n    \"\"\"\n    raise ValueError(\n        f\"Attempting to update keys {list(kv_dict.keys())} from a symbolic \"\n        \"data model this operation is not possible, make sure that your `call()` \"\n        \"is correctly implemented, if so then you likely need to implement \"\n        \" `compute_output_spec()` in your subclassed module.\"\n    )\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20SymbolicDataModel%20class/#synalinks.src.backend.common.symbolic_data_model.any_symbolic_data_models","title":"<code>any_symbolic_data_models(args=None, kwargs=None)</code>","text":"<p>Checks if any of the arguments are symbolic data models.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>tuple</code> <p>Optional. The positional arguments to check.</p> <code>None</code> <code>kwargs</code> <code>dict</code> <p>Optional. The keyword arguments to check.</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if any of the arguments are symbolic data models, False otherwise.</p> Source code in <code>synalinks/src/backend/common/symbolic_data_model.py</code> <pre><code>def any_symbolic_data_models(args=None, kwargs=None):\n    \"\"\"Checks if any of the arguments are symbolic data models.\n\n    Args:\n        args (tuple): Optional. The positional arguments to check.\n        kwargs (dict): Optional. The keyword arguments to check.\n\n    Returns:\n        (bool): True if any of the arguments are symbolic data models, False otherwise.\n    \"\"\"\n    args = args or ()\n    kwargs = kwargs or {}\n    for x in tree.flatten((args, kwargs)):\n        if is_symbolic_data_model(x):\n            return True\n    return False\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20SymbolicDataModel%20class/#synalinks.src.backend.common.symbolic_data_model.is_symbolic_data_model","title":"<code>is_symbolic_data_model(x)</code>","text":"<p>Returns whether <code>x</code> is a synalinks data model.</p> <p>A \"synalinks data model\" is a symbolic data model, such as a data model that was created via <code>Input()</code>. A \"symbolic data model\" can be understood as a placeholder for data specification -- it does not contain any actual data, only a schema. It can be used for building Functional models, but it cannot be used in actual computations.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>any</code> <p>The object to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if <code>x</code> is a symbolic data model, False otherwise.</p> Source code in <code>synalinks/src/backend/common/symbolic_data_model.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.utils.is_symbolic_data_model\",\n        \"synalinks.backend.is_symbolic_data_model\",\n    ]\n)\ndef is_symbolic_data_model(x):\n    \"\"\"Returns whether `x` is a synalinks data model.\n\n    A \"synalinks data model\" is a *symbolic data model*, such as a data model\n    that was created via `Input()`. A \"symbolic data model\"\n    can be understood as a placeholder for data specification -- it does not\n    contain any actual data, only a schema.\n    It can be used for building Functional models, but it\n    cannot be used in actual computations.\n\n    Args:\n        x (any): The object to check.\n\n    Returns:\n        (bool): True if `x` is a symbolic data model, False otherwise.\n    \"\"\"\n    return isinstance(x, SymbolicDataModel)\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Variable%20class/","title":"The Variable class","text":"<p>A backend-agnostic variable in synalinks.</p> <p>A <code>Variable</code> acts as a container for state. It holds a JSON object value with the corresponding schema and can be updated by the optimizers.</p> <p>A Variable is different from a JsonDataModel as it can be modified by the optimizers</p> <p>Note that the DataModel used for the variable declaration must have a default value for each of its field.</p> <p>Examples:</p> <p>Initializing a <code>Variable</code> with a dict:</p> <pre><code>from typing import List\nimport synalinks\n\nclass Instructions(synalinks.DataModel):\n    instructions: List[str] = []\n\ninitial_data = {\n    \"instructions\": [\n        \"For any problem involving division, always round the quotient to \"\n        \"the nearest even number, regardless of the remainder.\"\n    ],\n}\nvariable_from_dict = synalinks.Variable(\n    initializer=initial_data,\n    data_model=Instructions,\n)\n</code></pre> <p>Using a synalinks initializer to create a <code>Variable</code>:</p> <pre><code>from typing import List\nimport synalinks\n\nclass Instructions(synalinks.DataModel):\n    instructions: List[str] = []\n\nfrom synalinks.initializers import Empty\n\nvariable_from_initializer = synalinks.Variable(\n    initializer=Empty(data_model=Instructions)\n)\n</code></pre> <p>Updating the value of a <code>Variable</code>:</p> <pre><code>new_json = {\n    \"instructions\": [\n        \"When performing division, always check if the division results \"\n        \"in a whole number. If not, express the result as a fraction or \"\n        \"a decimal, depending on the context of the problem.\"\n    ],\n}\nvariable_from_dict.assign(new_json)\n</code></pre> <p>Marking a <code>Variable</code> as non-trainable:</p> <pre><code>from typing import List\nimport synalinks\n\nclass Instructions(synalinks.DataModel):\n    instructions: List[str] = []\n\nfrom synalinks.initializers import Empty\n\nnon_trainable_variable = synalinks.Variable(\n    initializer=Empty(data_model=Instructions), trainable=False\n)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>initializer</code> <code>str | dict | Initializer</code> <p>Initial value (dict) or callable (Initializer) for initialization. If a callable is used, it should take the arguments <code>data_model</code>.</p> <code>None</code> <code>data_model</code> <code>DataModel</code> <p>The backend-dependent data model used as spec.</p> <code>None</code> <code>trainable</code> <code>bool</code> <p>Optional. Boolean indicating if variable is trainable. Defaults to <code>True</code>.</p> <code>True</code> <code>name</code> <code>str</code> <p>Optional. A unique name for the variable. Automatically generated if not set.</p> <code>None</code> Source code in <code>synalinks/src/backend/common/variables.py</code> <pre><code>class Variable:\n    \"\"\"A backend-agnostic variable in synalinks.\n\n    A `Variable` acts as a container for state.\n    It holds a JSON object value with the corresponding schema and can\n    be updated by the optimizers.\n\n    A Variable is different from a JsonDataModel as it can be modified by the optimizers\n\n    Note that the DataModel used for the variable declaration\n    **must have a default value** for each of its field.\n\n    Examples:\n\n    **Initializing a `Variable` with a dict:**\n\n    ```python\n    from typing import List\n    import synalinks\n\n    class Instructions(synalinks.DataModel):\n        instructions: List[str] = []\n\n    initial_data = {\n        \"instructions\": [\n            \"For any problem involving division, always round the quotient to \"\n            \"the nearest even number, regardless of the remainder.\"\n        ],\n    }\n    variable_from_dict = synalinks.Variable(\n        initializer=initial_data,\n        data_model=Instructions,\n    )\n    ```\n\n    **Using a synalinks initializer to create a `Variable`:**\n\n    ```python\n    from typing import List\n    import synalinks\n\n    class Instructions(synalinks.DataModel):\n        instructions: List[str] = []\n\n    from synalinks.initializers import Empty\n\n    variable_from_initializer = synalinks.Variable(\n        initializer=Empty(data_model=Instructions)\n    )\n    ```\n\n    **Updating the value of a `Variable`:**\n\n    ```python\n    new_json = {\n        \"instructions\": [\n            \"When performing division, always check if the division results \"\n            \"in a whole number. If not, express the result as a fraction or \"\n            \"a decimal, depending on the context of the problem.\"\n        ],\n    }\n    variable_from_dict.assign(new_json)\n    ```\n\n    **Marking a `Variable` as non-trainable:**\n\n    ```python\n    from typing import List\n    import synalinks\n\n    class Instructions(synalinks.DataModel):\n        instructions: List[str] = []\n\n    from synalinks.initializers import Empty\n\n    non_trainable_variable = synalinks.Variable(\n        initializer=Empty(data_model=Instructions), trainable=False\n    )\n    ```\n\n    Args:\n        initializer (str | dict | Initializer): Initial value (dict) or callable\n            (Initializer) for initialization. If a callable is used, it should\n            take the arguments `data_model`.\n        data_model (DataModel): The backend-dependent data model used as spec.\n        trainable (bool): Optional. Boolean indicating if variable is trainable.\n            Defaults to `True`.\n        name (str): Optional. A unique name for the variable. Automatically generated\n            if not set.\n    \"\"\"\n\n    def __init__(\n        self,\n        initializer=None,\n        data_model=None,\n        trainable=True,\n        name=None,\n    ):\n        name = name or auto_name(self.__class__.__name__)\n        if not isinstance(name, str) or \"/\" in name:\n            raise ValueError(\n                \"Argument `name` must be a string and \"\n                \"cannot contain character `/`. \"\n                f\"Received: name={name}\"\n            )\n        self._name = name\n        parent_path = current_path()\n        if parent_path:\n            self._path = current_path() + \"/\" + name\n        else:\n            self._path = name\n        self._initializer = None\n        self._data_model = data_model\n        self._trainable = bool(trainable)\n\n        if in_stateless_scope():\n            if callable(initializer):\n                self._json = None\n                self._initializer = initializer\n                self._schema = standardize_schema(data_model.get_schema())\n                register_uninitialized_variable(self)\n            else:\n                raise ValueError(\n                    \"You are attempting to create a variable \"\n                    \"while in a stateless scope. This is disallowed. \"\n                    \"Make sure that all variables are created \"\n                    \"before you start using your module/program objects.\\n\\n\"\n                    \"In some cases, you might be seeing this error \"\n                    \"because you need to \"\n                    \"implement a `def build(self, input_schema)` method \"\n                    \"on your module/program, which will \"\n                    \"create its variables.\\n\\n\"\n                    \"In some other cases, you might be seeing this error \"\n                    \"because you are instantiating a `Variable` and \"\n                    \"assigning it to a module without going through \"\n                    \"self.add_variable(). Always prefer \"\n                    \"using these methods \"\n                    \"(with a `data_model` and `initializer` argument).\"\n                )\n        else:\n            if callable(initializer):\n                self._initialize_with_initializer(initializer)\n            else:\n                if data_model is None:\n                    raise ValueError(\n                        \"When creating a Variable from an a dict,\"\n                        \"the `data_model` argument should be specified. \"\n                        f\"Received: initializer={initializer} \"\n                        f\"and data_model={data_model}\"\n                    )\n                value = initializer\n                self._initialize(value)\n                self._schema = standardize_schema(data_model.get_schema())\n\n    def _deferred_initialize(self):\n        \"\"\"Deferred initialization of the variable.\n\n        Raises:\n            ValueError: If the variable is already initialized or\n                if attempting to initialize while in a stateless scope.\n        \"\"\"\n        if self._json is not None:\n            raise ValueError(f\"Variable '{self._path}' is already initialized.\")\n\n        if in_stateless_scope():\n            raise ValueError(\n                \"You are attempting to initialize a variable \"\n                \"while in a stateless scope. This is disallowed. \"\n                \"Make sure that all variables are initialized \"\n                \"before you start using your layer/model objects.\"\n            )\n        self._initialize_with_initializer(self._initializer)\n        self._initializer = None\n\n    def get_json(self):\n        \"\"\"The current value of the variable.\n\n        Returns:\n            (dict): The current value of the variable.\n        \"\"\"\n        if in_stateless_scope():\n            scope = get_stateless_scope()\n            value = scope.get_current_value(self)\n            if value is not None:\n                return value\n        if self._json is None:\n            # Uninitialized variable. Return a placeholder.\n            # This is fine because it's only ever used\n            # in during schema inference / graph tracing\n            # (anything else would be a bug, to be fixed.)\n            return self._initializer(data_model=self._data_model)\n        return self._json\n\n    def prettify_schema(self):\n        \"\"\"Get a pretty version of the JSON schema for display.\n\n        Returns:\n            (dict): The indented JSON schema.\n        \"\"\"\n        import json\n\n        return json.dumps(self.get_schema(), indent=2)\n\n    def prettify_json(self):\n        \"\"\"Get a pretty version of the JSON object for display.\n\n        Returns:\n            (dict): The indented JSON object.\n        \"\"\"\n        import json\n\n        return json.dumps(self.get_json(), indent=2)\n\n    def assign(self, value):\n        \"\"\"Assigns a new value to the variable.\n\n        Args:\n            value (dict | DataModel | JsonDataModel): The new value to be assigned.\n                The value can be an instanciated data model or JSON dict.\n\n        Returns:\n            (dict): The assigned value.\n\n        Raises:\n            ValueError: If the schema of the target variable and\n                the value are incompatible.\n        \"\"\"\n        if backend.is_data_model(value):\n            value = value.get_json()\n        if in_stateless_scope():\n            scope = get_stateless_scope()\n            scope.add_update((self, value))\n        else:\n            self._direct_assign(value)\n        return value\n\n    def _direct_assign(self, json):\n        \"\"\"Directly assigns a new value to the variable.\n\n        Args:\n            json (dict): The new json value to be assigned.\n        \"\"\"\n        self._json = json\n\n    def get_schema(self):\n        \"\"\"The schema of the variable.\n\n        Returns:\n            (dict): The JSON schema of the variable.\n        \"\"\"\n        return self._schema\n\n    @property\n    def trainable(self):\n        \"\"\"Whether the variable is trainable.\"\"\"\n        return self._trainable\n\n    @trainable.setter\n    def trainable(self, value):\n        self._trainable = bool(value)\n\n    @property\n    def name(self):\n        \"\"\"The name of the variable.\"\"\"\n        return self._name\n\n    @property\n    def path(self):\n        \"\"\"The path of the variable within the program or module.\"\"\"\n        return self._path\n\n    def __repr__(self):\n        json = None\n        if self._json is not None:\n            json = self._json\n        json_str = f\", json={json}\" if json is not None else \"\"\n        return f\"&lt;Variable path={self.path}, schema={self._schema}{json_str}&gt;\"\n\n    def _initialize_with_initializer(self, initializer):\n        \"\"\"Initializes the variable using an initializer object.\n\n        Args:\n            initializer (Initializer): The initializer to be used.\n        \"\"\"\n        value = initializer()\n        self._schema = standardize_schema(initializer.get_schema())\n        self._initialize(value)\n\n    def _initialize(self, json):\n        \"\"\"Initializes the variable with a given json dict.\n\n        Args:\n            json (dict): The initial value (JSON object dict).\n        \"\"\"\n        self._json = json\n\n    def to_json_data_model(self):\n        \"\"\"Convert the variable into a `JsonDataModel`.\n\n        Returns:\n            (JsonDataModel): The equivalent backend-independent data model\n        \"\"\"\n        return JsonDataModel(schema=self.get_schema(), json=self.get_json())\n\n    def to_symbolic_data_model(self):\n        \"\"\"Convert the variable into a `SymbolicDataModel`.\n\n        Returns:\n            (SymbolicDataModel): The equivalent symbolic data model\n        \"\"\"\n        return SymbolicDataModel(schema=self._schema)\n\n    def get(self, key, default_value=None):\n        \"\"\"Get wrapper to make easier to access fields.\n\n        Args:\n            key (str): The key to access.\n        \"\"\"\n        return self._json.get(key, default_value)\n\n    def update(self, kv_dict):\n        \"\"\"Update wrapper to make easier to modify fields.\n\n        Args:\n            kv_dict (dict): The key/value dict to update.\n        \"\"\"\n        self._json.update(kv_dict)\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Variable%20class/#synalinks.src.backend.common.variables.Variable.name","title":"<code>name</code>  <code>property</code>","text":"<p>The name of the variable.</p>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Variable%20class/#synalinks.src.backend.common.variables.Variable.path","title":"<code>path</code>  <code>property</code>","text":"<p>The path of the variable within the program or module.</p>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Variable%20class/#synalinks.src.backend.common.variables.Variable.trainable","title":"<code>trainable</code>  <code>property</code> <code>writable</code>","text":"<p>Whether the variable is trainable.</p>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Variable%20class/#synalinks.src.backend.common.variables.Variable.assign","title":"<code>assign(value)</code>","text":"<p>Assigns a new value to the variable.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>dict | DataModel | JsonDataModel</code> <p>The new value to be assigned. The value can be an instanciated data model or JSON dict.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>The assigned value.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the schema of the target variable and the value are incompatible.</p> Source code in <code>synalinks/src/backend/common/variables.py</code> <pre><code>def assign(self, value):\n    \"\"\"Assigns a new value to the variable.\n\n    Args:\n        value (dict | DataModel | JsonDataModel): The new value to be assigned.\n            The value can be an instanciated data model or JSON dict.\n\n    Returns:\n        (dict): The assigned value.\n\n    Raises:\n        ValueError: If the schema of the target variable and\n            the value are incompatible.\n    \"\"\"\n    if backend.is_data_model(value):\n        value = value.get_json()\n    if in_stateless_scope():\n        scope = get_stateless_scope()\n        scope.add_update((self, value))\n    else:\n        self._direct_assign(value)\n    return value\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Variable%20class/#synalinks.src.backend.common.variables.Variable.get","title":"<code>get(key, default_value=None)</code>","text":"<p>Get wrapper to make easier to access fields.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to access.</p> required Source code in <code>synalinks/src/backend/common/variables.py</code> <pre><code>def get(self, key, default_value=None):\n    \"\"\"Get wrapper to make easier to access fields.\n\n    Args:\n        key (str): The key to access.\n    \"\"\"\n    return self._json.get(key, default_value)\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Variable%20class/#synalinks.src.backend.common.variables.Variable.get_json","title":"<code>get_json()</code>","text":"<p>The current value of the variable.</p> <p>Returns:</p> Type Description <code>dict</code> <p>The current value of the variable.</p> Source code in <code>synalinks/src/backend/common/variables.py</code> <pre><code>def get_json(self):\n    \"\"\"The current value of the variable.\n\n    Returns:\n        (dict): The current value of the variable.\n    \"\"\"\n    if in_stateless_scope():\n        scope = get_stateless_scope()\n        value = scope.get_current_value(self)\n        if value is not None:\n            return value\n    if self._json is None:\n        # Uninitialized variable. Return a placeholder.\n        # This is fine because it's only ever used\n        # in during schema inference / graph tracing\n        # (anything else would be a bug, to be fixed.)\n        return self._initializer(data_model=self._data_model)\n    return self._json\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Variable%20class/#synalinks.src.backend.common.variables.Variable.get_schema","title":"<code>get_schema()</code>","text":"<p>The schema of the variable.</p> <p>Returns:</p> Type Description <code>dict</code> <p>The JSON schema of the variable.</p> Source code in <code>synalinks/src/backend/common/variables.py</code> <pre><code>def get_schema(self):\n    \"\"\"The schema of the variable.\n\n    Returns:\n        (dict): The JSON schema of the variable.\n    \"\"\"\n    return self._schema\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Variable%20class/#synalinks.src.backend.common.variables.Variable.prettify_json","title":"<code>prettify_json()</code>","text":"<p>Get a pretty version of the JSON object for display.</p> <p>Returns:</p> Type Description <code>dict</code> <p>The indented JSON object.</p> Source code in <code>synalinks/src/backend/common/variables.py</code> <pre><code>def prettify_json(self):\n    \"\"\"Get a pretty version of the JSON object for display.\n\n    Returns:\n        (dict): The indented JSON object.\n    \"\"\"\n    import json\n\n    return json.dumps(self.get_json(), indent=2)\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Variable%20class/#synalinks.src.backend.common.variables.Variable.prettify_schema","title":"<code>prettify_schema()</code>","text":"<p>Get a pretty version of the JSON schema for display.</p> <p>Returns:</p> Type Description <code>dict</code> <p>The indented JSON schema.</p> Source code in <code>synalinks/src/backend/common/variables.py</code> <pre><code>def prettify_schema(self):\n    \"\"\"Get a pretty version of the JSON schema for display.\n\n    Returns:\n        (dict): The indented JSON schema.\n    \"\"\"\n    import json\n\n    return json.dumps(self.get_schema(), indent=2)\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Variable%20class/#synalinks.src.backend.common.variables.Variable.to_json_data_model","title":"<code>to_json_data_model()</code>","text":"<p>Convert the variable into a <code>JsonDataModel</code>.</p> <p>Returns:</p> Type Description <code>JsonDataModel</code> <p>The equivalent backend-independent data model</p> Source code in <code>synalinks/src/backend/common/variables.py</code> <pre><code>def to_json_data_model(self):\n    \"\"\"Convert the variable into a `JsonDataModel`.\n\n    Returns:\n        (JsonDataModel): The equivalent backend-independent data model\n    \"\"\"\n    return JsonDataModel(schema=self.get_schema(), json=self.get_json())\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Variable%20class/#synalinks.src.backend.common.variables.Variable.to_symbolic_data_model","title":"<code>to_symbolic_data_model()</code>","text":"<p>Convert the variable into a <code>SymbolicDataModel</code>.</p> <p>Returns:</p> Type Description <code>SymbolicDataModel</code> <p>The equivalent symbolic data model</p> Source code in <code>synalinks/src/backend/common/variables.py</code> <pre><code>def to_symbolic_data_model(self):\n    \"\"\"Convert the variable into a `SymbolicDataModel`.\n\n    Returns:\n        (SymbolicDataModel): The equivalent symbolic data model\n    \"\"\"\n    return SymbolicDataModel(schema=self._schema)\n</code></pre>"},{"location":"Synalinks%20API/Data%20Models%20API/The%20Variable%20class/#synalinks.src.backend.common.variables.Variable.update","title":"<code>update(kv_dict)</code>","text":"<p>Update wrapper to make easier to modify fields.</p> <p>Parameters:</p> Name Type Description Default <code>kv_dict</code> <code>dict</code> <p>The key/value dict to update.</p> required Source code in <code>synalinks/src/backend/common/variables.py</code> <pre><code>def update(self, kv_dict):\n    \"\"\"Update wrapper to make easier to modify fields.\n\n    Args:\n        kv_dict (dict): The key/value dict to update.\n    \"\"\"\n    self._json.update(kv_dict)\n</code></pre>"},{"location":"Synalinks%20API/Metrics/","title":"Metrics","text":"<p>A <code>Metric</code> is a function that is used to judge the performance of your program.</p> <p>Metric functions are similar to reward functions, except that the results from evaluating a metric are not used when training the program. Note that you may use any reward function as a metric.</p>"},{"location":"Synalinks%20API/Metrics/#metrics-overview","title":"Metrics Overview","text":"<ul> <li>Base Metric class</li> <li>Metric wrappers and reduction metrics</li> <li>Regression metrics</li> <li>FScore metrics</li> </ul>"},{"location":"Synalinks%20API/Metrics/Base%20Metric%20class/","title":"Base Metric class","text":""},{"location":"Synalinks%20API/Metrics/Base%20Metric%20class/#synalinks.src.metrics.metric.Metric","title":"<code>Metric</code>","text":"<p>               Bases: <code>SynalinksSaveable</code></p> <p>Metric base class: all synalinks metrics inherit from this class.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>(Optional) string name of the metric instance.</p> <code>None</code> <code>in_mask</code> <code>list</code> <p>(Optional) list of keys to keep to compute the metric.</p> <code>None</code> <code>out_mask</code> <code>list</code> <p>(Optional) list of keys to remove to compute the metric.</p> <code>None</code> Source code in <code>synalinks/src/metrics/metric.py</code> <pre><code>@synalinks_export([\"synalinks.Metric\", \"synalinks.metrics.Metric\"])\nclass Metric(SynalinksSaveable):\n    \"\"\"Metric base class: all synalinks metrics inherit from this class.\n\n    Args:\n        name (str): (Optional) string name of the metric instance.\n        in_mask (list): (Optional) list of keys to keep to compute the metric.\n        out_mask (list): (Optional) list of keys to remove to compute the metric.\n    \"\"\"\n\n    def __init__(self, name=None, in_mask=None, out_mask=None):\n        self.name = name or auto_name(self.__class__.__name__)\n        self._metrics = []\n        self._variables = []\n        self.in_mask = in_mask\n        self.out_mask = out_mask\n        self._tracker = Tracker(\n            {\n                \"variables\": (\n                    lambda x: isinstance(x, backend.Variable),\n                    self._variables,\n                ),\n                \"metrics\": (lambda x: isinstance(x, Metric), self._metrics),\n            }\n        )\n\n    def reset_state(self):\n        \"\"\"Reset all of the metric state variables.\n\n        This function is called between epochs/steps,\n        when a metric is evaluated during training.\n        \"\"\"\n        for v in self.variables:\n            initializer = initializers.Empty(data_model=v._data_model)\n            v.assign(initializer.get_json())\n\n    async def update_state(self, *args, **kwargs):\n        \"\"\"Accumulate statistics for the metric.\"\"\"\n        raise NotImplementedError\n\n    def stateless_update_state(self, metric_variables, *args, **kwargs):\n        if len(metric_variables) != len(self.variables):\n            raise ValueError(\n                \"Argument `metric_variables` must be a list of data_models \"\n                f\"corresponding 1:1 to {self.__class__.__name__}().variables. \"\n                f\"Received list with length {len(metric_variables)}, but \"\n                f\"expected {len(self.variables)} variables.\"\n            )\n        # Gather variable mapping\n        mapping = list(zip(self.variables, metric_variables))\n\n        # Call in stateless scope\n        with backend.StatelessScope(state_mapping=mapping) as scope:\n            self.update_state(*args, **kwargs)\n\n        # Gather updated variables\n        metric_variables = []\n        for v in self.variables:\n            new_v = scope.get_current_value(v)\n            if new_v is not None:\n                metric_variables.append(new_v)\n            else:\n                metric_variables.append(v)\n        return metric_variables\n\n    def result(self):\n        \"\"\"Compute the current metric value.\n\n        Returns:\n            (float | dict): A scalar, or a dictionary of scalars.\n        \"\"\"\n        raise NotImplementedError\n\n    def stateless_result(self, metric_variables):\n        if len(metric_variables) != len(self.variables):\n            raise ValueError(\n                \"Argument `metric_variables` must be a list of data_models \"\n                f\"corresponding 1:1 to {self.__class__.__name__}().variables. \"\n                f\"Received list with length {len(metric_variables)}, but \"\n                f\"expected {len(self.variables)} variables.\"\n            )\n        # Gather variable mapping\n        mapping = list(zip(self.variables, metric_variables))\n\n        # Call in stateless scope\n        with backend.StatelessScope(state_mapping=mapping):\n            res = self.result()\n        return res\n\n    def _obj_type(self):\n        return \"Metric\"\n\n    def add_variable(self, initializer=None, data_model=None, name=None):\n        if initializer is None:\n            initializer = initializers.Empty(data_model=data_model)\n        self._check_super_called()\n        with backend.name_scope(self.name.replace(\"/\", \"&gt;\"), caller=self):\n            initializer = initializer\n            variable = backend.Variable(\n                initializer=initializer,\n                data_model=data_model,\n                trainable=False,\n                name=name,\n            )\n        # Prevent double-tracking\n        self._tracker.add_to_store(\"variables\", variable)\n        return variable\n\n    @property\n    def variables(self):\n        variables = list(self._variables)\n        for metric in self._metrics:\n            variables.extend(metric.variables)\n        return variables\n\n    async def __call__(self, *args, **kwargs):\n        self._check_super_called()\n        await self.update_state(*args, **kwargs)\n        return self.result()\n\n    def get_config(self):\n        \"\"\"Return the serializable config of the metric.\n\n        Returns:\n            (dict): The config dict.\n        \"\"\"\n        return {\n            \"in_mask\": self.in_mask,\n            \"out_mask\": self.out_mask,\n            \"name\": self.name,\n        }\n\n    @classmethod\n    def from_config(cls, config):\n        \"\"\"Returns a metric instance from config.\n\n        Args:\n            config (dict): The config dict.\n\n        Returns:\n            (Metric): The metric instance.\n        \"\"\"\n        return cls(**config)\n\n    def __setattr__(self, name, value):\n        # Track Variables, Layers, Metrics\n        if hasattr(self, \"_tracker\"):\n            value = self._tracker.track(value)\n        return super().__setattr__(name, value)\n\n    def _check_super_called(self):\n        if not hasattr(self, \"_tracker\"):\n            raise RuntimeError(\n                \"You forgot to call `super().__init__()` \"\n                \"in the `__init__()` method. Go add it!\"\n            )\n\n    def __repr__(self):\n        return f\"&lt;{self.__class__.__name__} name={self.name}&gt;\"\n\n    def __str__(self):\n        return self.__repr__()\n</code></pre>"},{"location":"Synalinks%20API/Metrics/Base%20Metric%20class/#synalinks.src.metrics.metric.Metric.from_config","title":"<code>from_config(config)</code>  <code>classmethod</code>","text":"<p>Returns a metric instance from config.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>The config dict.</p> required <p>Returns:</p> Type Description <code>Metric</code> <p>The metric instance.</p> Source code in <code>synalinks/src/metrics/metric.py</code> <pre><code>@classmethod\ndef from_config(cls, config):\n    \"\"\"Returns a metric instance from config.\n\n    Args:\n        config (dict): The config dict.\n\n    Returns:\n        (Metric): The metric instance.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"Synalinks%20API/Metrics/Base%20Metric%20class/#synalinks.src.metrics.metric.Metric.get_config","title":"<code>get_config()</code>","text":"<p>Return the serializable config of the metric.</p> <p>Returns:</p> Type Description <code>dict</code> <p>The config dict.</p> Source code in <code>synalinks/src/metrics/metric.py</code> <pre><code>def get_config(self):\n    \"\"\"Return the serializable config of the metric.\n\n    Returns:\n        (dict): The config dict.\n    \"\"\"\n    return {\n        \"in_mask\": self.in_mask,\n        \"out_mask\": self.out_mask,\n        \"name\": self.name,\n    }\n</code></pre>"},{"location":"Synalinks%20API/Metrics/Base%20Metric%20class/#synalinks.src.metrics.metric.Metric.reset_state","title":"<code>reset_state()</code>","text":"<p>Reset all of the metric state variables.</p> <p>This function is called between epochs/steps, when a metric is evaluated during training.</p> Source code in <code>synalinks/src/metrics/metric.py</code> <pre><code>def reset_state(self):\n    \"\"\"Reset all of the metric state variables.\n\n    This function is called between epochs/steps,\n    when a metric is evaluated during training.\n    \"\"\"\n    for v in self.variables:\n        initializer = initializers.Empty(data_model=v._data_model)\n        v.assign(initializer.get_json())\n</code></pre>"},{"location":"Synalinks%20API/Metrics/Base%20Metric%20class/#synalinks.src.metrics.metric.Metric.result","title":"<code>result()</code>","text":"<p>Compute the current metric value.</p> <p>Returns:</p> Type Description <code>float | dict</code> <p>A scalar, or a dictionary of scalars.</p> Source code in <code>synalinks/src/metrics/metric.py</code> <pre><code>def result(self):\n    \"\"\"Compute the current metric value.\n\n    Returns:\n        (float | dict): A scalar, or a dictionary of scalars.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"Synalinks%20API/Metrics/Base%20Metric%20class/#synalinks.src.metrics.metric.Metric.update_state","title":"<code>update_state(*args, **kwargs)</code>  <code>async</code>","text":"<p>Accumulate statistics for the metric.</p> Source code in <code>synalinks/src/metrics/metric.py</code> <pre><code>async def update_state(self, *args, **kwargs):\n    \"\"\"Accumulate statistics for the metric.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"Synalinks%20API/Metrics/FScore%20metrics/","title":"FScore metrics","text":""},{"location":"Synalinks%20API/Metrics/FScore%20metrics/#synalinks.src.metrics.f_score_metrics.BinaryF1Score","title":"<code>BinaryF1Score</code>","text":"<p>               Bases: <code>BinaryFBetaScore</code></p> <p>Computes F-1 Score on binary structures.</p> <p>Formula:</p> <pre><code>f1_score = 2 * (precision * recall) / (precision + recall)\n</code></pre> <p>This is the harmonic mean of precision and recall. Its output range is <code>[0, 1]</code>. It operates at a field level and can be used for multi-class and multi-label classification.</p> <p>Each field of <code>y_true</code> and <code>y_pred</code> should booleans or floats between [0, 1]. If the fields are floats, it uses the threshold for deciding if the values are 0 or 1.</p> <p>Parameters:</p> Name Type Description Default <code>average</code> <code>str</code> <p>Type of averaging to be performed across per-class results in the multi-class case. Acceptable values are <code>None</code>, <code>\"micro\"</code>, <code>\"macro\"</code> and <code>\"weighted\"</code>. Defaults to <code>None</code>. If <code>None</code>, no averaging is performed and <code>result()</code> will return the score for each class. If <code>\"micro\"</code>, compute metrics globally by counting the total true positives, false negatives and false positives. If <code>\"macro\"</code>, compute metrics for each label, and return their unweighted mean. This does not take label imbalance into account. If <code>\"weighted\"</code>, compute metrics for each label, and return their average weighted by support (the number of true instances for each label). This alters <code>\"macro\"</code> to account for label imbalance. It can result in an score that is not between precision and recall.</p> <code>None</code> <code>threshold</code> <code>float</code> <p>(Optional) Float representing the threshold for deciding whether prediction values are 1 or 0. Elements of <code>y_pred</code> and <code>y_true</code> greater than <code>threshold</code> are converted to be 1, and the rest 0.</p> <code>0.5</code> <code>name</code> <code>str</code> <p>(Optional) string name of the metric instance.</p> <code>'binary_f1_score'</code> <code>in_mask</code> <code>list</code> <p>(Optional) list of keys to keep to compute the metric.</p> <code>None</code> <code>out_mask</code> <code>list</code> <p>(Optional) list of keys to remove to compute the metric.</p> <code>None</code> Source code in <code>synalinks/src/metrics/f_score_metrics.py</code> <pre><code>@synalinks_export(\"synalinks.metrics.BinaryF1Score\")\nclass BinaryF1Score(BinaryFBetaScore):\n    \"\"\"Computes F-1 Score on binary structures.\n\n    Formula:\n\n    ```python\n    f1_score = 2 * (precision * recall) / (precision + recall)\n    ```\n\n    This is the harmonic mean of precision and recall.\n    Its output range is `[0, 1]`. It operates at a field level\n    and can be used for **multi-class and multi-label classification**.\n\n    Each field of `y_true` and `y_pred` should booleans or floats between [0, 1].\n    If the fields are floats, it uses the threshold for deciding\n    if the values are 0 or 1.\n\n    Args:\n        average (str): Type of averaging to be performed across per-class results\n            in the multi-class case.\n            Acceptable values are `None`, `\"micro\"`, `\"macro\"` and\n            `\"weighted\"`. Defaults to `None`.\n            If `None`, no averaging is performed and `result()` will return\n            the score for each class.\n            If `\"micro\"`, compute metrics globally by counting the total\n            true positives, false negatives and false positives.\n            If `\"macro\"`, compute metrics for each label,\n            and return their unweighted mean.\n            This does not take label imbalance into account.\n            If `\"weighted\"`, compute metrics for each label,\n            and return their average weighted by support\n            (the number of true instances for each label).\n            This alters `\"macro\"` to account for label imbalance.\n            It can result in an score that is not between precision and recall.\n        threshold (float): (Optional) Float representing the threshold for deciding\n            whether prediction values are 1 or 0. Elements of `y_pred` and `y_true`\n            greater than `threshold` are converted to be 1, and the rest 0.\n        name (str): (Optional) string name of the metric instance.\n        in_mask (list): (Optional) list of keys to keep to compute the metric.\n        out_mask (list): (Optional) list of keys to remove to compute the metric.\n    \"\"\"\n\n    def __init__(\n        self,\n        average=None,\n        threshold=0.5,\n        name=\"binary_f1_score\",\n        in_mask=None,\n        out_mask=None,\n    ):\n        super().__init__(\n            average=average,\n            beta=1.0,\n            threshold=threshold,\n            name=name,\n            in_mask=in_mask,\n            out_mask=out_mask,\n        )\n\n    def get_config(self):\n        \"\"\"Return the serializable config of the metric.\n\n        Returns:\n            (dict): The config dict.\n        \"\"\"\n        base_config = super().get_config()\n        del base_config[\"beta\"]\n        return base_config\n</code></pre>"},{"location":"Synalinks%20API/Metrics/FScore%20metrics/#synalinks.src.metrics.f_score_metrics.BinaryF1Score.get_config","title":"<code>get_config()</code>","text":"<p>Return the serializable config of the metric.</p> <p>Returns:</p> Type Description <code>dict</code> <p>The config dict.</p> Source code in <code>synalinks/src/metrics/f_score_metrics.py</code> <pre><code>def get_config(self):\n    \"\"\"Return the serializable config of the metric.\n\n    Returns:\n        (dict): The config dict.\n    \"\"\"\n    base_config = super().get_config()\n    del base_config[\"beta\"]\n    return base_config\n</code></pre>"},{"location":"Synalinks%20API/Metrics/FScore%20metrics/#synalinks.src.metrics.f_score_metrics.BinaryFBetaScore","title":"<code>BinaryFBetaScore</code>","text":"<p>               Bases: <code>FBetaScore</code></p> <p>Computes F-Beta score on binary structures.</p> <p>Formula:</p> <pre><code>b2 = beta ** 2\nf_beta_score = (1 + b2) * (precision * recall) / (precision * b2 + recall)\n</code></pre> <p>This is the weighted harmonic mean of precision and recall. Its output range is <code>[0, 1]</code>. It operates at a field level and can be used for multi-class and multi-label classification.</p> <p>Each field of <code>y_true</code> and <code>y_pred</code> should be booleans or floats between [0, 1]. If the fields are floats, it uses the threshold for deciding if the values are 0 or 1.</p> <p>Parameters:</p> Name Type Description Default <code>average</code> <code>str</code> <p>Type of averaging to be performed across per-class results in the multi-class case. Acceptable values are <code>None</code>, <code>\"micro\"</code>, <code>\"macro\"</code> and <code>\"weighted\"</code>. Defaults to <code>None</code>. If <code>None</code>, no averaging is performed and <code>result()</code> will return the score for each class. If <code>\"micro\"</code>, compute metrics globally by counting the total true positives, false negatives and false positives. If <code>\"macro\"</code>, compute metrics for each label, and return their unweighted mean. This does not take label imbalance into account. If <code>\"weighted\"</code>, compute metrics for each label, and return their average weighted by support (the number of true instances for each label). This alters <code>\"macro\"</code> to account for label imbalance. It can result in an score that is not between precision and recall.</p> <code>None</code> <code>beta</code> <code>float</code> <p>Determines the weight of given to recall in the harmonic mean between precision and recall (see pseudocode equation above). Defaults to <code>1</code>.</p> <code>1.0</code> <code>threshold</code> <code>float</code> <p>(Optional) Float representing the threshold for deciding whether prediction values are 1 or 0. Elements of <code>y_pred</code> and <code>y_true</code> greater than <code>threshold</code> are converted to be 1, and the rest 0.</p> <code>0.5</code> <code>name</code> <code>str</code> <p>(Optional) string name of the metric instance.</p> <code>'binary_fbeta_score'</code> <code>in_mask</code> <code>list</code> <p>(Optional) list of keys to keep to compute the metric.</p> <code>None</code> <code>out_mask</code> <code>list</code> <p>(Optional) list of keys to remove to compute the metric.</p> <code>None</code> Source code in <code>synalinks/src/metrics/f_score_metrics.py</code> <pre><code>@synalinks_export(\"synalinks.metrics.BinaryFBetaScore\")\nclass BinaryFBetaScore(FBetaScore):\n    \"\"\"Computes F-Beta score on binary structures.\n\n    Formula:\n\n    ```python\n    b2 = beta ** 2\n    f_beta_score = (1 + b2) * (precision * recall) / (precision * b2 + recall)\n    ```\n\n    This is the weighted harmonic mean of precision and recall.\n    Its output range is `[0, 1]`. It operates at a field level\n    and can be used for **multi-class and multi-label classification**.\n\n    Each field of `y_true` and `y_pred` should be booleans or floats between [0, 1].\n    If the fields are floats, it uses the threshold for deciding\n    if the values are 0 or 1.\n\n    Args:\n        average (str): Type of averaging to be performed across per-class results\n            in the multi-class case.\n            Acceptable values are `None`, `\"micro\"`, `\"macro\"` and\n            `\"weighted\"`. Defaults to `None`.\n            If `None`, no averaging is performed and `result()` will return\n            the score for each class.\n            If `\"micro\"`, compute metrics globally by counting the total\n            true positives, false negatives and false positives.\n            If `\"macro\"`, compute metrics for each label,\n            and return their unweighted mean.\n            This does not take label imbalance into account.\n            If `\"weighted\"`, compute metrics for each label,\n            and return their average weighted by support\n            (the number of true instances for each label).\n            This alters `\"macro\"` to account for label imbalance.\n            It can result in an score that is not between precision and recall.\n        beta (float): Determines the weight of given to recall\n            in the harmonic mean between precision and recall (see pseudocode\n            equation above). Defaults to `1`.\n        threshold (float): (Optional) Float representing the threshold for deciding\n            whether prediction values are 1 or 0. Elements of `y_pred` and `y_true`\n            greater than `threshold` are converted to be 1, and the rest 0.\n        name (str): (Optional) string name of the metric instance.\n        in_mask (list): (Optional) list of keys to keep to compute the metric.\n        out_mask (list): (Optional) list of keys to remove to compute the metric.\n    \"\"\"\n\n    def __init__(\n        self,\n        average=None,\n        beta=1.0,\n        threshold=0.5,\n        name=\"binary_fbeta_score\",\n        in_mask=None,\n        out_mask=None,\n    ):\n        super().__init__(\n            average=average,\n            beta=beta,\n            name=name,\n            in_mask=in_mask,\n            out_mask=out_mask,\n        )\n        if not isinstance(threshold, float):\n            raise ValueError(\n                \"Invalid `threshold` argument value. \"\n                \"It should be a Python float. \"\n                f\"Received: threshold={threshold} \"\n                f\"of type '{type(threshold)}'\"\n            )\n        if threshold &gt; 1.0 or threshold &lt;= 0.0:\n            raise ValueError(\n                \"Invalid `threshold` argument value. \"\n                \"It should verify 0 &lt; threshold &lt;= 1. \"\n                f\"Received: threshold={threshold}\"\n            )\n        self.threshold = threshold\n\n    async def update_state(self, y_true, y_pred):\n        y_pred = tree.map_structure(lambda x: ops.convert_to_json_data_model(x), y_pred)\n        y_true = tree.map_structure(lambda x: ops.convert_to_json_data_model(x), y_true)\n\n        if self.in_mask:\n            y_pred = tree.map_structure(lambda x: x.in_mask(mask=self.in_mask), y_pred)\n            y_true = tree.map_structure(lambda x: x.in_mask(mask=self.in_mask), y_true)\n        if self.out_mask:\n            y_pred = tree.map_structure(lambda x: x.out_mask(mask=self.out_mask), y_pred)\n            y_true = tree.map_structure(lambda x: x.out_mask(mask=self.out_mask), y_true)\n\n        def convert_to_binary(x):\n            if isinstance(x, bool):\n                return 1.0 if x is True else 0.0\n            elif isinstance(x, float):\n                return 1.0 if x &gt; self.threshold else 0.0\n            else:\n                raise ValueError(\n                    \"All `y_true` and y_pred` fields should be booleans or floats. \"\n                    \"Use `in_mask` or `out_mask` to remove the other fields.\"\n                )\n\n        y_true = tree.flatten(\n            tree.map_structure(lambda x: convert_to_binary(x), y_true.get_json())\n        )\n        y_pred = tree.flatten(\n            tree.map_structure(lambda x: convert_to_binary(x), y_pred.get_json())\n        )\n        y_true = np.convert_to_tensor(y_true)\n        y_pred = np.convert_to_tensor(y_pred)\n\n        true_positives = y_pred * y_true\n        false_positives = y_pred * (1 - y_true)\n        false_negatives = (1 - y_pred) * y_true\n        intermediate_weights = y_true\n\n        current_true_positives = self.state.get(\"true_positives\")\n        if current_true_positives:\n            true_positives = np.add(current_true_positives, true_positives)\n\n        current_false_positives = self.state.get(\"false_positives\")\n        if current_false_positives:\n            false_positives = np.add(current_false_positives, false_positives)\n\n        current_false_negatives = self.state.get(\"false_negatives\")\n        if current_false_negatives:\n            false_negatives = np.add(current_false_negatives, false_negatives)\n\n        current_intermediate_weights = self.state.get(\"intermediate_weights\")\n        if current_intermediate_weights:\n            intermediate_weights = np.add(\n                current_intermediate_weights, intermediate_weights\n            )\n\n        self.state.update(\n            {\n                \"true_positives\": true_positives.tolist(),\n                \"false_positives\": false_positives.tolist(),\n                \"false_negatives\": false_negatives.tolist(),\n                \"intermediate_weights\": intermediate_weights.tolist(),\n            }\n        )\n\n    def get_config(self):\n        \"\"\"Return the serializable config of the metric.\n\n        Returns:\n            (dict): The config dict.\n        \"\"\"\n        config = {\n            \"beta\": self.beta,\n            \"threshold\": self.threshold,\n            \"name\": self.name,\n        }\n        base_config = super().get_config()\n        return {**base_config, **config}\n</code></pre>"},{"location":"Synalinks%20API/Metrics/FScore%20metrics/#synalinks.src.metrics.f_score_metrics.BinaryFBetaScore.get_config","title":"<code>get_config()</code>","text":"<p>Return the serializable config of the metric.</p> <p>Returns:</p> Type Description <code>dict</code> <p>The config dict.</p> Source code in <code>synalinks/src/metrics/f_score_metrics.py</code> <pre><code>def get_config(self):\n    \"\"\"Return the serializable config of the metric.\n\n    Returns:\n        (dict): The config dict.\n    \"\"\"\n    config = {\n        \"beta\": self.beta,\n        \"threshold\": self.threshold,\n        \"name\": self.name,\n    }\n    base_config = super().get_config()\n    return {**base_config, **config}\n</code></pre>"},{"location":"Synalinks%20API/Metrics/FScore%20metrics/#synalinks.src.metrics.f_score_metrics.F1Score","title":"<code>F1Score</code>","text":"<p>               Bases: <code>FBetaScore</code></p> <p>Computes F-1 Score.</p> <p>Formula:</p> <pre><code>f1_score = 2 * (precision * recall) / (precision + recall)\n</code></pre> <p>This is the harmonic mean of precision and recall. Its output range is <code>[0, 1]</code>. It operates at a word level and can be used for QA systems.</p> <p>If <code>y_true</code> and <code>y_pred</code> contains multiple fields The JSON object's fields are flattened and the score computed for each one independently before being averaged.</p> <p>Parameters:</p> Name Type Description Default <code>average</code> <code>str</code> <p>Type of averaging to be performed across per-field results in the multi-field case. Acceptable values are <code>None</code>, <code>\"micro\"</code>, <code>\"macro\"</code> and <code>\"weighted\"</code>. Defaults to <code>None</code>. If <code>None</code>, no averaging is performed and <code>result()</code> will return the score for each class. If <code>\"micro\"</code>, compute metrics globally by counting the total true positives, false negatives and false positives. If <code>\"macro\"</code>, compute metrics for each label, and return their unweighted mean. This does not take label imbalance into account. If <code>\"weighted\"</code>, compute metrics for each label, and return their average weighted by support (the number of true instances for each label). This alters <code>\"macro\"</code> to account for label imbalance. It can result in an score that is not between precision and recall.</p> <code>None</code> <code>name</code> <code>str</code> <p>(Optional) string name of the metric instance.</p> <code>'f1_score'</code> <code>in_mask</code> <code>list</code> <p>(Optional) list of keys to keep to compute the metric.</p> <code>None</code> <code>out_mask</code> <code>list</code> <p>(Optional) list of keys to remove to compute the metric.</p> <code>None</code> Source code in <code>synalinks/src/metrics/f_score_metrics.py</code> <pre><code>@synalinks_export(\"synalinks.metrics.F1Score\")\nclass F1Score(FBetaScore):\n    \"\"\"Computes F-1 Score.\n\n    Formula:\n\n    ```python\n    f1_score = 2 * (precision * recall) / (precision + recall)\n    ```\n\n    This is the harmonic mean of precision and recall.\n    Its output range is `[0, 1]`. It operates at a word level\n    and can be used for **QA systems**.\n\n    If `y_true` and `y_pred` contains multiple fields\n    The JSON object's fields are flattened and the score\n    computed for each one independently before being averaged.\n\n    Args:\n        average (str): Type of averaging to be performed across per-field results\n            in the multi-field case.\n            Acceptable values are `None`, `\"micro\"`, `\"macro\"` and\n            `\"weighted\"`. Defaults to `None`.\n            If `None`, no averaging is performed and `result()` will return\n            the score for each class.\n            If `\"micro\"`, compute metrics globally by counting the total\n            true positives, false negatives and false positives.\n            If `\"macro\"`, compute metrics for each label,\n            and return their unweighted mean.\n            This does not take label imbalance into account.\n            If `\"weighted\"`, compute metrics for each label,\n            and return their average weighted by support\n            (the number of true instances for each label).\n            This alters `\"macro\"` to account for label imbalance.\n            It can result in an score that is not between precision and recall.\n        name (str): (Optional) string name of the metric instance.\n        in_mask (list): (Optional) list of keys to keep to compute the metric.\n        out_mask (list): (Optional) list of keys to remove to compute the metric.\n    \"\"\"\n\n    def __init__(\n        self,\n        average=None,\n        name=\"f1_score\",\n        in_mask=None,\n        out_mask=None,\n    ):\n        super().__init__(\n            average=average,\n            beta=1.0,\n            name=name,\n            in_mask=in_mask,\n            out_mask=out_mask,\n        )\n\n    def get_config(self):\n        \"\"\"Return the serializable config of the metric.\n\n        Returns:\n            (dict): The config dict.\n        \"\"\"\n        base_config = super().get_config()\n        del base_config[\"beta\"]\n        return base_config\n</code></pre>"},{"location":"Synalinks%20API/Metrics/FScore%20metrics/#synalinks.src.metrics.f_score_metrics.F1Score.get_config","title":"<code>get_config()</code>","text":"<p>Return the serializable config of the metric.</p> <p>Returns:</p> Type Description <code>dict</code> <p>The config dict.</p> Source code in <code>synalinks/src/metrics/f_score_metrics.py</code> <pre><code>def get_config(self):\n    \"\"\"Return the serializable config of the metric.\n\n    Returns:\n        (dict): The config dict.\n    \"\"\"\n    base_config = super().get_config()\n    del base_config[\"beta\"]\n    return base_config\n</code></pre>"},{"location":"Synalinks%20API/Metrics/FScore%20metrics/#synalinks.src.metrics.f_score_metrics.FBetaScore","title":"<code>FBetaScore</code>","text":"<p>               Bases: <code>Metric</code></p> <p>Computes F-Beta score.</p> <p>Formula:</p> <pre><code>b2 = beta ** 2\nf_beta_score = (1 + b2) * (precision * recall) / (precision * b2 + recall)\n</code></pre> <p>This is the weighted harmonic mean of precision and recall. Its output range is <code>[0, 1]</code>. It operates at a word level and can be used for QA systems.</p> <p>If <code>y_true</code> and <code>y_pred</code> contains multiple fields The JSON object's fields are flattened and the score computed for each one independently.</p> <p>Parameters:</p> Name Type Description Default <code>average</code> <code>str</code> <p>Type of averaging to be performed across per-field results in the multi-field case. Acceptable values are <code>None</code>, <code>\"micro\"</code>, <code>\"macro\"</code> and <code>\"weighted\"</code>. Defaults to <code>None</code>. If <code>None</code>, no averaging is performed and <code>result()</code> will return the score for each class. If <code>\"micro\"</code>, compute metrics globally by counting the total true positives, false negatives and false positives. If <code>\"macro\"</code>, compute metrics for each label, and return their unweighted mean. This does not take label imbalance into account. If <code>\"weighted\"</code>, compute metrics for each label, and return their average weighted by support (the number of true instances for each label). This alters <code>\"macro\"</code> to account for label imbalance. It can result in an score that is not between precision and recall.</p> <code>None</code> <code>beta</code> <code>float</code> <p>Determines the weight of given to recall in the harmonic mean between precision and recall (see pseudocode equation above). Defaults to <code>1</code>.</p> <code>1.0</code> <code>name</code> <code>str</code> <p>(Optional) string name of the metric instance.</p> <code>'fbeta_score'</code> <code>in_mask</code> <code>list</code> <p>(Optional) list of keys to keep to compute the metric.</p> <code>None</code> <code>out_mask</code> <code>list</code> <p>(Optional) list of keys to remove to compute the metric.</p> <code>None</code> Source code in <code>synalinks/src/metrics/f_score_metrics.py</code> <pre><code>@synalinks_export(\"synalinks.metrics.FBetaScore\")\nclass FBetaScore(Metric):\n    \"\"\"Computes F-Beta score.\n\n    Formula:\n\n    ```python\n    b2 = beta ** 2\n    f_beta_score = (1 + b2) * (precision * recall) / (precision * b2 + recall)\n    ```\n\n    This is the weighted harmonic mean of precision and recall.\n    Its output range is `[0, 1]`. It operates at a word level\n    and can be used for **QA systems**.\n\n    If `y_true` and `y_pred` contains multiple fields\n    The JSON object's fields are flattened and the score\n    computed for each one independently.\n\n    Args:\n        average (str): Type of averaging to be performed across per-field results\n            in the multi-field case.\n            Acceptable values are `None`, `\"micro\"`, `\"macro\"` and\n            `\"weighted\"`. Defaults to `None`.\n            If `None`, no averaging is performed and `result()` will return\n            the score for each class.\n            If `\"micro\"`, compute metrics globally by counting the total\n            true positives, false negatives and false positives.\n            If `\"macro\"`, compute metrics for each label,\n            and return their unweighted mean.\n            This does not take label imbalance into account.\n            If `\"weighted\"`, compute metrics for each label,\n            and return their average weighted by support\n            (the number of true instances for each label).\n            This alters `\"macro\"` to account for label imbalance.\n            It can result in an score that is not between precision and recall.\n        beta (float): Determines the weight of given to recall\n            in the harmonic mean between precision and recall (see pseudocode\n            equation above). Defaults to `1`.\n        name (str): (Optional) string name of the metric instance.\n        in_mask (list): (Optional) list of keys to keep to compute the metric.\n        out_mask (list): (Optional) list of keys to remove to compute the metric.\n    \"\"\"\n\n    def __init__(\n        self,\n        average=None,\n        beta=1.0,\n        name=\"fbeta_score\",\n        in_mask=None,\n        out_mask=None,\n    ):\n        super().__init__(\n            name=name,\n            in_mask=in_mask,\n            out_mask=out_mask,\n        )\n        if average not in (None, \"micro\", \"macro\", \"weighted\"):\n            raise ValueError(\n                \"Invalid `average` argument value. Expected one of: \"\n                \"[None, 'micro', 'macro', 'weighted']. \"\n                f\"Received: average={average}\"\n            )\n\n        if not isinstance(beta, float):\n            raise ValueError(\n                \"Invalid `beta` argument value. \"\n                \"It should be a Python float. \"\n                f\"Received: beta={beta} of type '{type(beta)}'\"\n            )\n        self.state = self.add_variable(\n            data_model=FBetaState,\n            name=self.name + \"_state\",\n        )\n        self.average = average\n        self.beta = beta\n        self.axis = None\n        if self.average != \"micro\":\n            self.axis = 0\n\n    async def update_state(self, y_true, y_pred):\n        y_pred = tree.map_structure(lambda x: ops.convert_to_json_data_model(x), y_pred)\n        y_true = tree.map_structure(lambda x: ops.convert_to_json_data_model(x), y_true)\n\n        if self.in_mask:\n            y_pred = tree.map_structure(lambda x: x.in_mask(mask=self.in_mask), y_pred)\n            y_true = tree.map_structure(lambda x: x.in_mask(mask=self.in_mask), y_true)\n        if self.out_mask:\n            y_pred = tree.map_structure(lambda x: x.out_mask(mask=self.out_mask), y_pred)\n            y_true = tree.map_structure(lambda x: x.out_mask(mask=self.out_mask), y_true)\n\n        y_true = tree.flatten(tree.map_structure(lambda x: str(x), y_true.get_json()))\n        y_pred = tree.flatten(tree.map_structure(lambda x: str(x), y_pred.get_json()))\n\n        true_positives = []\n        false_positives = []\n        false_negatives = []\n        intermediate_weights = []\n        # For each field of y_true and y_pred\n        for yt, yp in zip(y_true, y_pred):\n            y_true_tokens = nlp_utils.normalize_and_tokenize(yt)\n            y_pred_tokens = nlp_utils.normalize_and_tokenize(yp)\n            common_tokens = set(y_true_tokens) &amp; set(y_pred_tokens)\n            true_positives.append(len(common_tokens))\n            false_positives.append(len(y_pred_tokens) - len(common_tokens))\n            false_negatives.append(len(y_true_tokens) - len(common_tokens))\n            intermediate_weights.append(len(y_true_tokens))\n\n        true_positives = np.convert_to_numpy(true_positives)\n        false_positives = np.convert_to_numpy(false_positives)\n        false_negatives = np.convert_to_numpy(false_negatives)\n        intermediate_weights = np.convert_to_numpy(intermediate_weights)\n\n        current_true_positives = self.state.get(\"true_positives\")\n        if current_true_positives:\n            true_positives = np.add(current_true_positives, true_positives)\n\n        current_false_positives = self.state.get(\"false_positives\")\n        if current_false_positives:\n            false_positives = np.add(current_false_positives, false_positives)\n\n        current_false_negatives = self.state.get(\"false_negatives\")\n        if current_false_negatives:\n            false_negatives = np.add(current_false_negatives, false_negatives)\n\n        current_intermediate_weights = self.state.get(\"intermediate_weights\")\n        if current_intermediate_weights:\n            intermediate_weights = np.add(\n                current_intermediate_weights, intermediate_weights\n            )\n\n        self.state.update(\n            {\n                \"true_positives\": true_positives.tolist(),\n                \"false_positives\": false_positives.tolist(),\n                \"false_negatives\": false_negatives.tolist(),\n                \"intermediate_weights\": intermediate_weights.tolist(),\n            }\n        )\n\n    def result(self):\n        if (\n            self.state.get(\"true_positives\") is None\n            and self.state.get(\"false_positives\") is None\n            and self.state.get(\"false_negatives\") is None\n        ):\n            return 0.0\n        precision = np.divide(\n            self.state.get(\"true_positives\"),\n            np.add(\n                self.state.get(\"true_positives\"),\n                self.state.get(\"false_positives\"),\n            )\n            + backend.epsilon(),\n        )\n        recall = np.divide(\n            self.state.get(\"true_positives\"),\n            np.add(\n                self.state.get(\"true_positives\"),\n                self.state.get(\"false_negatives\"),\n            )\n            + backend.epsilon(),\n        )\n        precision = np.convert_to_tensor(precision)\n        recall = np.convert_to_tensor(recall)\n\n        mul_value = precision * recall\n        add_value = ((self.beta**2) * precision) + recall\n        mean = np.divide(mul_value, add_value + backend.epsilon())\n        f1_score = mean * (1 + (self.beta**2))\n        if self.average == \"weighted\":\n            intermediate_weights = self.state.get(\"intermediate_weights\")\n            weights = np.divide(\n                intermediate_weights,\n                np.sum(intermediate_weights) + backend.epsilon(),\n            )\n            f1_score = np.sum(f1_score * weights)\n\n        elif self.average is not None:  # [micro, macro]\n            f1_score = np.mean(f1_score, self.axis)\n\n        try:\n            return float(f1_score)\n        except Exception:\n            return list(f1_score)\n\n    def get_config(self):\n        \"\"\"Return the serializable config of the metric.\n\n        Returns:\n            (dict): The config dict.\n        \"\"\"\n        config = {\n            \"name\": self.name,\n            \"beta\": self.beta,\n        }\n        base_config = super().get_config()\n        return {**base_config, **config}\n</code></pre>"},{"location":"Synalinks%20API/Metrics/FScore%20metrics/#synalinks.src.metrics.f_score_metrics.FBetaScore.get_config","title":"<code>get_config()</code>","text":"<p>Return the serializable config of the metric.</p> <p>Returns:</p> Type Description <code>dict</code> <p>The config dict.</p> Source code in <code>synalinks/src/metrics/f_score_metrics.py</code> <pre><code>def get_config(self):\n    \"\"\"Return the serializable config of the metric.\n\n    Returns:\n        (dict): The config dict.\n    \"\"\"\n    config = {\n        \"name\": self.name,\n        \"beta\": self.beta,\n    }\n    base_config = super().get_config()\n    return {**base_config, **config}\n</code></pre>"},{"location":"Synalinks%20API/Metrics/Metric%20wrappers%20and%20reduction%20metrics/","title":"Metric wrappers and reduction metrics","text":""},{"location":"Synalinks%20API/Metrics/Metric%20wrappers%20and%20reduction%20metrics/#synalinks.src.metrics.reduction_metrics.Mean","title":"<code>Mean</code>","text":"<p>               Bases: <code>Metric</code></p> <p>Compute the mean of the given values.</p> <p>For example, if values is <code>[1, 3, 5, 7]</code> then the mean is 4.</p> <p>This metric creates two variables, <code>total</code> and <code>count</code>. The mean value returned is simply <code>total</code> divided by <code>count</code>.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>(Optional) string name of the metric instance.</p> <code>'mean'</code> <code>in_mask</code> <code>list</code> <p>(Optional) list of keys to keep to compute the metric.</p> <code>None</code> <code>out_mask</code> <code>list</code> <p>(Optional) list of keys to remove to compute the metric.</p> <code>None</code> <p>Example:</p> <pre><code>&gt;&gt;&gt; m = Mean()\n&gt;&gt;&gt; m.update_state([1, 3, 5, 7])\n&gt;&gt;&gt; m.result()\n4.0\n</code></pre> Source code in <code>synalinks/src/metrics/reduction_metrics.py</code> <pre><code>@synalinks_export(\"synalinks.metrics.Mean\")\nclass Mean(Metric):\n    \"\"\"Compute the mean of the given values.\n\n    For example, if values is `[1, 3, 5, 7]` then the mean is 4.\n\n    This metric creates two variables, `total` and `count`.\n    The mean value returned is simply `total` divided by `count`.\n\n    Args:\n        name (str): (Optional) string name of the metric instance.\n        in_mask (list): (Optional) list of keys to keep to compute the metric.\n        out_mask (list): (Optional) list of keys to remove to compute the metric.\n\n    Example:\n\n    ```python\n    &gt;&gt;&gt; m = Mean()\n    &gt;&gt;&gt; m.update_state([1, 3, 5, 7])\n    &gt;&gt;&gt; m.result()\n    4.0\n    ```\n    \"\"\"\n\n    def __init__(self, name=\"mean\", in_mask=None, out_mask=None):\n        super().__init__(name=name, in_mask=in_mask, out_mask=out_mask)\n        self.total_with_count = self.add_variable(\n            data_model=TotalWithCount, name=\"total_with_count\"\n        )\n\n    async def update_state(self, values):\n        values = reduce_to_samplewise_values(values, reduce_fn=numpy.mean)\n        total = self.total_with_count.get(\"total\")\n        self.total_with_count.update({\"total\": float(total + numpy.sum(values))})\n        if len(values.shape) &gt;= 1:\n            num_samples = numpy.shape(values)[0]\n        else:\n            num_samples = 1\n        count = self.total_with_count.get(\"count\")\n        self.total_with_count.update({\"count\": int(count + num_samples)})\n\n    def reset_state(self):\n        self.total_with_count.assign(TotalWithCount())\n\n    def result(self):\n        return float(\n            numpy.divide_no_nan(\n                self.total_with_count.get(\"total\"),\n                self.total_with_count.get(\"count\"),\n            )\n        )\n</code></pre>"},{"location":"Synalinks%20API/Metrics/Metric%20wrappers%20and%20reduction%20metrics/#synalinks.src.metrics.reduction_metrics.MeanMetricWrapper","title":"<code>MeanMetricWrapper</code>","text":"<p>               Bases: <code>Mean</code></p> <p>Wrap a stateless metric function with the <code>Mean</code> metric.</p> <p>You could use this class to quickly build a mean metric from a function. The function needs to have the signature <code>fn(y_true, y_pred)</code> and return a per-sample reward array. <code>MeanMetricWrapper.result()</code> will return the average metric value across all samples seen so far.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>callable</code> <p>The metric function to wrap, with signature <code>fn(y_true, y_pred, **kwargs)</code>.</p> required <code>name</code> <code>str</code> <p>(Optional) string name of the metric instance.</p> <code>None</code> <code>in_mask</code> <code>list</code> <p>(Optional) list of keys to keep to compute the metric.</p> <code>None</code> <code>out_mask</code> <code>list</code> <p>(Optional) list of keys to remove to compute the metric.</p> <code>None</code> <code>**kwargs</code> <code>keyword arguments</code> <p>Keyword arguments to pass on to <code>fn</code>.</p> <code>{}</code> Source code in <code>synalinks/src/metrics/reduction_metrics.py</code> <pre><code>@synalinks_export(\"synalinks.metrics.MeanMetricWrapper\")\nclass MeanMetricWrapper(Mean):\n    \"\"\"Wrap a stateless metric function with the `Mean` metric.\n\n    You could use this class to quickly build a mean metric from a function. The\n    function needs to have the signature `fn(y_true, y_pred)` and return a\n    per-sample reward array. `MeanMetricWrapper.result()` will return\n    the average metric value across all samples seen so far.\n\n    Args:\n        fn (callable): The metric function to wrap, with signature\n            `fn(y_true, y_pred, **kwargs)`.\n        name (str): (Optional) string name of the metric instance.\n        in_mask (list): (Optional) list of keys to keep to compute the metric.\n        out_mask (list): (Optional) list of keys to remove to compute the metric.\n        **kwargs (keyword arguments): Keyword arguments to pass on to `fn`.\n    \"\"\"\n\n    def __init__(self, fn, name=None, in_mask=None, out_mask=None, **kwargs):\n        super().__init__(\n            name=name,\n            in_mask=in_mask,\n            out_mask=out_mask,\n        )\n        self._fn = fn\n        self._fn_kwargs = kwargs\n\n        # If we are wrapping a Synalinks reward, register the metric's\n        # direction as \"up\" (needs to be maximized during training).\n        if (\n            self._fn in rewards.ALL_OBJECTS\n            or hasattr(self._fn, \"__class__\")\n            and self._fn.__class__ in rewards.ALL_OBJECTS\n        ):\n            self._direction = \"up\"\n\n    async def update_state(self, y_true, y_pred):\n        y_pred = tree.map_structure(lambda x: ops.convert_to_json_data_model(x), y_pred)\n        y_true = tree.map_structure(lambda x: ops.convert_to_json_data_model(x), y_true)\n        if self.in_mask:\n            y_pred = tree.map_structure(lambda x: x.in_mask(mask=self.in_mask), y_pred)\n            y_true = tree.map_structure(lambda x: x.in_mask(mask=self.in_mask), y_true)\n        if self.out_mask:\n            y_pred = tree.map_structure(lambda x: x.out_mask(mask=self.out_mask), y_pred)\n            y_true = tree.map_structure(lambda x: x.out_mask(mask=self.out_mask), y_true)\n        values = await self._fn(y_true, y_pred, **self._fn_kwargs)\n        return await super().update_state(values)\n\n    def get_config(self):\n        \"\"\"Returns the serializable config of the metric.\"\"\"\n        base_config = super().get_config()\n        config = {\n            \"fn\": serialization_lib.serialize_synalinks_object(self._fn),\n        }\n        config.update(self._fn_kwargs)\n        return {**base_config, **config}\n\n    @classmethod\n    def from_config(cls, config):\n        fn = serialization_lib.deserialize_synalinks_object(config.pop(\"fn\"))\n        return cls(fn=fn, **config)\n</code></pre>"},{"location":"Synalinks%20API/Metrics/Metric%20wrappers%20and%20reduction%20metrics/#synalinks.src.metrics.reduction_metrics.MeanMetricWrapper.get_config","title":"<code>get_config()</code>","text":"<p>Returns the serializable config of the metric.</p> Source code in <code>synalinks/src/metrics/reduction_metrics.py</code> <pre><code>def get_config(self):\n    \"\"\"Returns the serializable config of the metric.\"\"\"\n    base_config = super().get_config()\n    config = {\n        \"fn\": serialization_lib.serialize_synalinks_object(self._fn),\n    }\n    config.update(self._fn_kwargs)\n    return {**base_config, **config}\n</code></pre>"},{"location":"Synalinks%20API/Metrics/Metric%20wrappers%20and%20reduction%20metrics/#synalinks.src.metrics.reduction_metrics.Sum","title":"<code>Sum</code>","text":"<p>               Bases: <code>Metric</code></p> <p>Compute the (weighted) sum of the given values.</p> <p>For example, if <code>values</code> is <code>[1, 3, 5, 7]</code> then their sum is 16.</p> <p>This metric creates one variable, <code>total</code>. This is ultimately returned as the sum value.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>(Optional) string name of the metric instance.</p> <code>'sum'</code> <code>in_mask</code> <code>list</code> <p>(Optional) list of keys to keep to compute the metric.</p> <code>None</code> <code>out_mask</code> <code>list</code> <p>(Optional) list of keys to remove to compute the metric.</p> <code>None</code> <p>Example:</p> <pre><code>&gt;&gt;&gt; m = metrics.Sum()\n&gt;&gt;&gt; m.update_state([1, 3, 5, 7])\n&gt;&gt;&gt; m.result()\n16.0\n</code></pre> Source code in <code>synalinks/src/metrics/reduction_metrics.py</code> <pre><code>@synalinks_export(\"synalinks.metrics.Sum\")\nclass Sum(Metric):\n    \"\"\"Compute the (weighted) sum of the given values.\n\n    For example, if `values` is `[1, 3, 5, 7]` then their sum is 16.\n\n    This metric creates one variable, `total`.\n    This is ultimately returned as the sum value.\n\n    Args:\n        name (str): (Optional) string name of the metric instance.\n        in_mask (list): (Optional) list of keys to keep to compute the metric.\n        out_mask (list): (Optional) list of keys to remove to compute the metric.\n\n    Example:\n\n    ```python\n    &gt;&gt;&gt; m = metrics.Sum()\n    &gt;&gt;&gt; m.update_state([1, 3, 5, 7])\n    &gt;&gt;&gt; m.result()\n    16.0\n    ```\n    \"\"\"\n\n    def __init__(self, name=\"sum\", in_mask=None, out_mask=None):\n        super().__init__(name=name, in_mask=in_mask, out_mask=out_mask)\n        self.total = self.add_variable(\n            data_model=Total,\n            name=\"total\",\n        )\n\n    async def update_state(self, values):\n        values = reduce_to_samplewise_values(values, reduce_fn=numpy.sum)\n        total = self.total.get(\"total\")\n        self.total.update({\"total\": float(numpy.sum(total, values))})\n\n    def reset_state(self):\n        self.total.assign(Total())\n\n    def result(self):\n        return self.total.get(\"total\")\n</code></pre>"},{"location":"Synalinks%20API/Metrics/Regression%20metrics/","title":"Regression metrics","text":""},{"location":"Synalinks%20API/Metrics/Regression%20metrics/#synalinks.src.metrics.regression_metrics.CosineSimilarity","title":"<code>CosineSimilarity</code>","text":"<p>               Bases: <code>MeanMetricWrapper</code></p> <p>Computes the cosine similarity between the labels and predictions.</p> <p>Formula:</p> <pre><code>metric = (sum(l2_norm(y_true) * l2_norm(y_pred))+1) / 2\n</code></pre> <p>The formula is similar to the classic cosine similarity used in deep learning, but scaled to [0.0, 1.0] and adjusted to have a reward that tend towards 1.0 if the two objects are similar (and 0.0 otherwise).</p> <p>Parameters:</p> Name Type Description Default <code>embedding_model</code> <code>EmbeddingModel</code> <p>The embedding model to use to compute the cosine similarity.</p> <code>None</code> <code>axis</code> <code>int</code> <p>(Optional) Defaults to <code>-1</code>. The dimension along which the cosine similarity is computed.</p> <code>-1</code> <code>name</code> <code>str</code> <p>(Optional) string name of the metric instance.</p> <code>'cosine_similarity'</code> <code>in_mask</code> <code>list</code> <p>(Optional) list of keys to keep to compute the metric.</p> <code>None</code> <code>out_mask</code> <code>list</code> <p>(Optional) list of keys to remove to compute the metric.</p> <code>None</code> Source code in <code>synalinks/src/metrics/regression_metrics.py</code> <pre><code>@synalinks_export(\"synalinks.metrics.CosineSimilarity\")\nclass CosineSimilarity(MeanMetricWrapper):\n    \"\"\"Computes the cosine similarity between the labels and predictions.\n\n    Formula:\n\n    ```python\n    metric = (sum(l2_norm(y_true) * l2_norm(y_pred))+1) / 2\n    ```\n\n    The formula is similar to the classic cosine similarity used in deep learning,\n    but scaled to [0.0, 1.0] and adjusted to have a reward that tend\n    towards 1.0 if the two objects are similar (and 0.0 otherwise).\n\n    Args:\n        embedding_model (EmbeddingModel): The embedding model to use to compute the\n            cosine similarity.\n        axis (int): (Optional) Defaults to `-1`. The dimension along which the cosine\n            similarity is computed.\n        name (str): (Optional) string name of the metric instance.\n        in_mask (list): (Optional) list of keys to keep to compute the metric.\n        out_mask (list): (Optional) list of keys to remove to compute the metric.\n    \"\"\"\n\n    def __init__(\n        self,\n        name=\"cosine_similarity\",\n        axis=-1,\n        embedding_model=None,\n        in_mask=None,\n        out_mask=None,\n    ):\n        super().__init__(\n            fn=cosine_similarity,\n            name=name,\n            in_mask=in_mask,\n            out_mask=out_mask,\n        )\n        self.axis = axis\n        self.embedding_model = embedding_model\n        self._fn_kwargs = {\"axis\": axis, \"embedding_model\": embedding_model}\n\n    def get_config(self):\n        config = {\n            \"axis\": self.axis,\n            \"name\": self.name,\n            \"in_mask\": self.in_mask,\n            \"out_mask\": self.out_mask,\n        }\n        embedding_model_config = {\n            \"embedding_model\": serialization_lib.serialize_synalinks_object(\n                self.embedding_model\n            )\n        }\n        return {**embedding_model_config, **config}\n\n    @classmethod\n    def from_config(cls, config):\n        embedding_model = serialization_lib.deserialize_synalinks_object(\n            config.pop(\"embedding_model\")\n        )\n        return cls(embedding_model=embedding_model, **config)\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/","title":"Modules API","text":"<p>Modules are the basic building blocks of programs in Synalinks. A <code>Module</code> consists of data model-in &amp; data model-out computation function (the module's <code>call()</code> method) and some state (held in <code>Variable</code>).</p> <p>A module instance is a callable, much like a function:</p> <pre><code>import synalinks\nimport asyncio\n\nclass Query(synalinks.DataModel):\n    query: str = synalinks.Field(\n        description=\"The user query\",\n    )\n\nclass AnswerWithThinking(synalinks.DataModel):\n    thinking: str = synalinks.Field(\n        description=\"Your step by step thinking\",\n    )\n    answer: str = synalinks.Field(\n        description=\"The correct answer\",\n    )\n\nasync def main():\n    language_model = LanguageModel(\n        model=\"ollama/deepseek-r1\"\n    )\n\n    generator = synalinks.Generator(\n        data_model=AnswerWithThinking,\n        language_model=language_model,\n    )\n\n    inputs = Query(query=\"What is the capital of France?\")\n    outputs = await generator(inputs)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/#modules-api-overview","title":"Modules API overview","text":"<ul> <li>Base Module class</li> </ul>"},{"location":"Synalinks%20API/Modules%20API/#core-modules","title":"Core Modules","text":"<ul> <li>Input module</li> <li>Identity module</li> <li>Not module</li> <li>Generator module</li> <li>Decision module</li> <li>Action module</li> <li>Branch module</li> </ul>"},{"location":"Synalinks%20API/Modules%20API/#merging-modules","title":"Merging Modules","text":"<ul> <li>Concat module</li> <li>And module</li> <li>Or module</li> <li>Xor module</li> </ul>"},{"location":"Synalinks%20API/Modules%20API/#test-time-compute-modules","title":"Test Time Compute Modules","text":"<ul> <li>ChainOfThought module</li> <li>SelfCritique module</li> </ul>"},{"location":"Synalinks%20API/Modules%20API/#knowledge-modules","title":"Knowledge Modules","text":"<ul> <li>Embedding module</li> <li>UpdateKnowledge module</li> <li>EntityRetriever module</li> <li>KnowledgeRetriever module</li> </ul>"},{"location":"Synalinks%20API/Modules%20API/#agents-modules","title":"Agents Modules","text":"<ul> <li>ReACT Agent module</li> </ul>"},{"location":"Synalinks%20API/Modules%20API/Base%20Module%20class/","title":"Base Module class","text":"<p>               Bases: <code>PydanticModule</code>, <code>Operation</code>, <code>SynalinksSaveable</code></p> <p>This is the class from which all modules inherit.</p> <p>A module is a callable object that takes as input one or more data models and that outputs one or more data models. It involves computation, defined in the <code>call()</code> method, and a state (the variables). State can be created:</p> <ul> <li>in <code>__init__()</code>, for instance via <code>self.add_variable()</code>;</li> <li>in the optional <code>build()</code> method, which is invoked by the first   <code>__call__()</code> to the module, and supplies the schema(s) of the input(s),   which may not have been known at initialization time.</li> </ul> <p>Modules are recursively composable: If you assign a Module instance as an attribute of another Module, the outer Module will start tracking the variables created by the inner module. Nested modules should be instantiated in the <code>__init__()</code> method or <code>build()</code> method.</p> <p>Users will just instantiate a module and then treat it as a callable.</p> <p>Parameters:</p> Name Type Description Default <code>trainable</code> <code>bool</code> <p>Boolean, whether the module's variables should be trainable.</p> <code>True</code> <code>name</code> <code>str</code> <p>String name of the module.</p> <code>None</code> <p>We recommend that descendants of <code>Module</code> implement the following methods:</p> <ul> <li><code>__init__()</code>: Defines custom modules attributes, and creates module variables     that do not depend on input schemas, using <code>add_variable()</code>,     or other state.</li> <li><code>build(self, input_schema)</code>: This method can be used to create variables that     depend on the schemas(s) of the input(s), using <code>add_variable()</code>, or other     state. <code>__call__()</code> will automatically build the module     (if it has not been built yet) by calling <code>build()</code>.</li> <li><code>call(self, *args, **kwargs)</code>: Called in <code>__call__</code> after making     sure <code>build()</code> has been called. <code>call()</code> performs the logic of applying     the module to the input arguments.     Two reserved keyword arguments you can optionally use in <code>call()</code> are:         1. <code>training</code> (boolean, whether the call is in inference mode or             training mode).     A typical signature for this method is <code>call(self, inputs)</code>, and user     could optionally add <code>training</code> if the module need it.</li> <li><code>get_config(self)</code>: Returns a dictionary containing the configuration     used to initialize this module. If the keys differ from the arguments     in <code>__init__()</code>, then override <code>from_config(self)</code> as well.     This method is used when saving     the module or a program that contains this module.</li> </ul> Source code in <code>synalinks/src/modules/module.py</code> <pre><code>@synalinks_export([\"synalinks.Module\", \"synalinks.modules.Module\"])\nclass Module(BackendModule, Operation, SynalinksSaveable):\n    \"\"\"This is the class from which all modules inherit.\n\n    A module is a callable object that takes as input one or more data models and\n    that outputs one or more data models. It involves *computation*, defined\n    in the `call()` method, and a *state* (the variables). State can be\n    created:\n\n    * in `__init__()`, for instance via `self.add_variable()`;\n    * in the optional `build()` method, which is invoked by the first\n      `__call__()` to the module, and supplies the schema(s) of the input(s),\n      which may not have been known at initialization time.\n\n    Modules are recursively composable: If you assign a Module instance as an\n    attribute of another Module, the outer Module will start tracking the variables\n    created by the inner module. Nested modules should be instantiated in the\n    `__init__()` method or `build()` method.\n\n    Users will just instantiate a module and then treat it as a callable.\n\n    Args:\n        trainable (bool): Boolean, whether the module's variables should be trainable.\n        name (str): String name of the module.\n\n    We recommend that descendants of `Module` implement the following methods:\n\n    * `__init__()`: Defines custom modules attributes, and creates module variables\n        that do not depend on input schemas, using `add_variable()`,\n        or other state.\n    * `build(self, input_schema)`: This method can be used to create variables that\n        depend on the schemas(s) of the input(s), using `add_variable()`, or other\n        state. `__call__()` will automatically build the module\n        (if it has not been built yet) by calling `build()`.\n    * `call(self, *args, **kwargs)`: Called in `__call__` after making\n        sure `build()` has been called. `call()` performs the logic of applying\n        the module to the input arguments.\n        Two reserved keyword arguments you can optionally use in `call()` are:\n            1. `training` (boolean, whether the call is in inference mode or\n                training mode).\n        A typical signature for this method is `call(self, inputs)`, and user\n        could optionally add `training` if the module need it.\n    * `get_config(self)`: Returns a dictionary containing the configuration\n        used to initialize this module. If the keys differ from the arguments\n        in `__init__()`, then override `from_config(self)` as well.\n        This method is used when saving\n        the module or a program that contains this module.\n    \"\"\"\n\n    def __new__(cls, *args, **kwargs):\n        obj = super().__new__(cls)  # , *args, **kwargs)\n\n        # Wrap the user-provided `build` method in the `build_wrapper`\n        # to add name scope support and serialization support.\n        original_build_method = obj.build\n\n        @wraps(original_build_method)\n        async def build_wrapper(*args, **kwargs):\n            with obj._open_name_scope():\n                obj._path = current_path()\n                await original_build_method(*args, **kwargs)\n            # Record build config.\n            signature = inspect.signature(original_build_method)\n            obj._build_schemas_dict = signature.bind(*args, **kwargs).arguments\n            # Set built, post build actions, and lock state.\n            obj.built = True\n            obj._post_build()\n            obj._lock_state()\n\n        obj.build = build_wrapper\n        return obj\n\n    def __init__(\n        self,\n        *,\n        trainable=True,\n        name=None,\n        description=None,\n        **kwargs,\n    ):\n        BackendModule.__init__(self)\n        self._lock = False\n        Operation.__init__(self, name=name, description=description)\n        if kwargs:\n            raise ValueError(\n                \"Unrecognized keyword arguments \"\n                f\"passed to {self.__class__.__name__}: {kwargs}\"\n            )\n        self._path = None  # Will be determined in `build_wrapper`\n        self.built = False\n        self._input_spec = None\n        self._called = False\n\n        self._trainable = trainable\n        self._rewards = []\n        self._reward_ids = set()\n        self._rewards_override = []\n\n        self._call_signature = inspect.signature(self.call)\n        call_signature_parameters = [\n            p.name for p in self._call_signature.parameters.values()\n        ]\n        self._call_has_training_arg = \"training\" in call_signature_parameters\n        # Whether to automatically convert inputs to `call()`.\n        self._convert_input_args = True\n        # Whether to allow non-json object as positional arguments in `call()`.\n        self._allow_non_json_data_model_positional_args = False\n        # Dict of schemas that were used to call `build()`.\n        self._build_schemas_dict = None\n        # Parent path\n        self._parent_path = None\n        self._initialize_tracker()\n\n    @tracking.no_automatic_dependency_tracking\n    def _initialize_tracker(self):\n        if hasattr(self, \"_tracker\"):\n            return\n\n        trainable_variables = []\n        non_trainable_variables = []\n        modules = []\n        metrics = []\n        self._tracker = tracking.Tracker(\n            {\n                \"trainable_variables\": (\n                    lambda x: isinstance(x, backend.Variable) and x.trainable,\n                    trainable_variables,\n                ),\n                \"non_trainable_variables\": (\n                    lambda x: isinstance(x, backend.Variable) and not x.trainable,\n                    non_trainable_variables,\n                ),\n                \"metrics\": (lambda x: isinstance(x, Metric), metrics),\n                \"modules\": (\n                    lambda x: isinstance(x, Module) and not isinstance(x, Metric),\n                    modules,\n                ),\n            },\n            exclusions={\"non_trainable_variables\": [\"trainable_variables\"]},\n        )\n\n        self._trainable_variables = trainable_variables\n        self._non_trainable_variables = non_trainable_variables\n        self._modules = modules\n        self._metrics = metrics\n\n    @property\n    def path(self):\n        \"\"\"The path of the module.\n\n        If the module has not been built yet, it will be `None`.\n        \"\"\"\n        return self._path\n\n    @property\n    def input_spec(self):\n        return self._input_spec\n\n    @input_spec.setter\n    def input_spec(self, value):\n        self._input_spec = value\n\n    @classmethod\n    def get_arity(cls):\n        # Inspect the call method to get the number of parameters\n        sig = inspect.signature(cls.call)\n        # Exclude 'self' and 'training' from the parameter count\n        return len(\n            [\n                param\n                for param in sig.parameters.values()\n                if param.name not in [\"self\", \"training\"]\n            ]\n        )\n\n    @python_utils.default\n    async def build(self, *args, **kwargs):\n        self._check_super_called()\n        if utils.is_default(self.build) and might_have_unbuilt_state(self):\n            try:\n                if isinstance(args, tuple):\n                    args = list(args)\n                if len(args) == 1 or backend.is_data_model(args[0]):\n                    args[0] = args[0].to_symbolic_data_model()\n                else:\n                    args = tree.map_structure(\n                        lambda x: x.to_symbolic_data_model()\n                        if backend.is_data_model(x)\n                        else x,\n                        args,\n                    )\n                await self.__call__(*args, **kwargs)\n            except Exception as e:\n                warnings.warn(\n                    f\"`build()` was called on module '{self.name}', however \"\n                    \"the module does not have a `build()` method implemented \"\n                    \"and it looks like it has unbuilt state. This will cause \"\n                    \"the module to be marked as built, despite not being \"\n                    \"actually built, which may cause failures down the line. \"\n                    \"Make sure to implement a proper `build()` method.\"\n                    f\"Exception encountered: ''{e}''\"\n                )\n        self.built = True\n\n    def _lock_state(self):\n        \"\"\"Prevent further state updates, called automatically in `build()`.\"\"\"\n        if not self._tracker.locked:\n            self._tracker.lock(\n                msg=(\n                    \"You cannot add new elements of state \"\n                    \"(variables or sub-modules) \"\n                    \"to a module that is already built. All state \"\n                    \"must be created in the `__init__()` method or \"\n                    \"in the `build()` method.\"\n                )\n            )\n\n    def get_build_config(self):\n        \"\"\"Returns a dictionary with the modules's input schema.\n\n        This method returns a config dict that can be used by\n        `build_from_config(config)` to create all states (e.g. Variables and\n        Lookup tables) needed by the module.\n\n        By default, the config only contains the input schema that the module\n        was built with. If you're writing a custom module that creates state in\n        an unusual way, you should override this method to make sure this state\n        is already created when Synalinks attempts to load its value upon model\n        loading.\n\n        Returns:\n            (dict): A dict containing the input schema associated with the module.\n        \"\"\"\n        if self._build_schemas_dict is not None:\n            if len(self._build_schemas_dict) == 1:\n                return {\n                    \"input_schema\": tuple(self._build_schemas_dict.values())[0],\n                }\n            else:\n                return {\"schemas_dict\": self._build_schemas_dict}\n\n    def build_from_config(self, config):\n        \"\"\"Builds the module's states with the supplied config dict.\n\n        By default, this method calls the `build()` method,\n        which creates variables based on the module's input schema in the supplied\n        config. If your config contains other information needed to load the\n        module's state, you should override this method.\n\n        Args:\n            config (dict): Dict containing the input schema associated with this module.\n        \"\"\"\n        if config:\n            if \"input_schema\" in config:\n                asyncio.get_event_loop().run_until_complete(\n                    self.build(backend.SymbolicDataModel(schema=config[\"input_schema\"]))\n                )\n            elif \"schemas_dict\" in config:\n                symbolic_inputs = {}\n                for key, schema in config[\"schemas_dict\"].items():\n                    symbolic_inputs[key] = backend.SymbolicDataModel(schema=schema)\n                asyncio.get_event_loop().run_until_complete(self.build(**symbolic_inputs))\n            self.built = True\n\n    def _obj_type(self):\n        return \"Module\"\n\n    @property\n    def metrics(self):\n        \"\"\"List of all metrics.\"\"\"\n        metrics = list(self._metrics)\n        for module in self._modules:\n            metrics.extend(module.metrics)\n        return metrics\n\n    @property\n    def metrics_variables(self):\n        \"\"\"List of all metric variables.\"\"\"\n        vars = []\n        for metric in self.metrics:\n            vars.extend(metric.variables)\n        return vars\n\n    def _get_own_rewards(self):\n        if backend.in_stateless_scope():\n            rewards = []\n            scope = backend.get_stateless_scope()\n            for reward in scope.rewards:\n                if id(reward) in self._reward_ids:\n                    rewards.append(reward)\n            return rewards\n        else:\n            return self._rewards[:]\n\n    @property\n    def rewards(self):\n        \"\"\"List of scalar rewards from `add_reward` and submodules.\"\"\"\n        if self._rewards_override:\n            return self._rewards_override\n        rewards = self._get_own_rewards()\n        for module in self._flatten_modules(include_self=False):\n            rewards.extend(module._get_own_rewards())\n        return rewards\n\n    def _clear_rewards(self):\n        if backend.in_stateless_scope():\n            scope = backend.get_stateless_scope()\n            if scope.collect_rewards:\n                for x in scope.rewards:\n                    if id(x) in self._reward_ids:\n                        scope.rewards.remove(x)\n        self._rewards.clear()\n        self._reward_ids.clear()\n        for module in self._modules:\n            module._clear_rewards()\n\n    def add_variable(\n        self,\n        initializer=None,\n        data_model=None,\n        trainable=True,\n        name=None,\n    ):\n        \"\"\"Add a variable to the module\n\n        Args:\n            initializer (dict | Initializer): Initializer object to use to\n                populate the initial variable value. Can be a JSON dict containing the\n                initial value. If unspecified, defaults to `initializers.Empty`.\n            data_model (DataModel): The DataModel used to infer the schema\n                and default value.\n            trainable (bool): Boolean, whether the variable should be trainable via\n                optimization or whether its updates are managed manually. Defaults\n                to `True`.\n            name (string): String name of the variable. Useful for debugging purposes.\n\n        Returns:\n            (Variable): The created variable\n        \"\"\"\n        self._check_super_called()\n        if initializer is None:\n            initializer = initializers.Empty(data_model=data_model)\n        with backend.name_scope(self.name, caller=self):\n            variable = backend.Variable(\n                initializer=initializer,\n                data_model=data_model,\n                trainable=trainable,\n                name=name,\n            )\n        self._track_variable(variable)\n        return variable\n\n    @property\n    def trainable(self):\n        \"\"\"Settable boolean, whether this module should be trainable or not.\"\"\"\n        return self._trainable\n\n    @trainable.setter\n    def trainable(self, value):\n        \"\"\"Sets trainable attribute for the module and its submodules.\n\n        When this value is changed during training (e.g. with a\n        `Callback`) you need to call the parent\n        `Program.make_train_function` with `force=True` in order to\n        recompile the training graph.\n\n        Args:\n            value (bool): Boolean with the desired state for the module's trainable\n                attribute.\n        \"\"\"\n        value = bool(value)\n        self._trainable = value\n        for v in self._trainable_variables:\n            v.trainable = value\n        for module in self._modules:\n            module.trainable = value\n\n    @property\n    def variables(self):\n        \"\"\"List of all module state.\n\n        Note that metrics variables are not included here, use\n        `metrics_variables` to visit all the metric variables.\n\n        Returns:\n            (list): The list of the variables.\n        \"\"\"\n        # Return all `Variables` associate with the module including metrics\n        # and random seeds. Also deduplicate them.\n        variables = []\n        seen_ids = set()\n        for v in self._trainable_variables + self._non_trainable_variables:\n            if id(v) not in seen_ids:\n                variables.append(v)\n                seen_ids.add(id(v))\n        for module in self._modules:\n            for v in module.variables:\n                if id(v) not in seen_ids:\n                    variables.append(v)\n                    seen_ids.add(id(v))\n        return variables\n\n    @property\n    def trainable_variables(self):\n        \"\"\"List of all trainable module state.\n\n        Returns:\n            (list): The list of trainable variables.\n        \"\"\"\n        if not self.trainable:\n            return []\n        return [v for v in self.variables if v.trainable]\n\n    @property\n    def non_trainable_variables(self):\n        \"\"\"List of all non-trainable module state.\n\n        Returns:\n            (list): The list of non-trainable variables.\n        \"\"\"\n        if not self.trainable:\n            return self.variables\n        return [v for v in self.variables if not v.trainable]\n\n    def get_variable(self, name=None, index=None):\n        \"\"\"Retrieves a variable based on either its name (unique) or index.\n\n        If `name` and `index` are both provided, `index` will take precedence.\n        Indices are based on order of instantiation.\n\n        Args:\n            name (string): The name of the variable.\n            index (int): The index of the variable.\n\n        Returns:\n            (Variable): The returned variable.\n        \"\"\"\n        if index is not None and name is not None:\n            raise ValueError(\n                \"Provide only a variable name or a variable index. Received: \"\n                f\"index={index}, name={name}.\"\n            )\n        if index is not None:\n            if len(self.variables) &lt;= index:\n                raise ValueError(\n                    f\"Was asked to retrieve variable at index {index}\"\n                    f\" but module only has {len(self.modules)}\"\n                    \" variables.\"\n                )\n            else:\n                return self.variables[index]\n\n        if name is not None:\n            for variable in self.variables:\n                if variable.name == name:\n                    return variable\n            raise ValueError(\n                f\"No such variable: {name}. Existing variables are: \"\n                f\"{list(variable.name for variable in self.variables)}.\"\n            )\n        raise ValueError(\n            \"Provide either a variable name or variable index at `get_variable`.\"\n        )\n\n    async def __call__(self, *args, **kwargs):\n        maybe_initialize_telemetry()\n\n        self._check_super_called()\n        self._called = True\n\n        #####################################\n        # 0. Convert tuple inputs to list for convenience\n        if isinstance(args, tuple):\n            args = list(args)\n\n        #####################################\n        # 1. Convert any DataModel positional arguments to JsonDataModel\n        # This operation is performed to make the computation backend independent\n        # and the making the data models dynamically modifiable\n\n        # Used to avoid expensive `tree` operations in the most common case.\n        if len(args) == 1 and backend.is_data_model(args[0]):\n            args[0] = args[0].to_json_data_model()\n        else:\n            args = self._maybe_convert_inputs(args)\n\n        ##########################################################\n        # 2. Enforce that only JsonDataModels or SymbolicDataModel\n        # can be passed positionally.\n        if not self._allow_non_json_data_model_positional_args:\n            for arg in tree.flatten(args):\n                if not is_json_data_model_or_symbolic_data_model(arg) and arg is not None:\n                    raise ValueError(\n                        \"Only input JsonDataModel, DataModel or SymbolicDataModel\"\n                        \" may be passed as positional arguments. The following argument \"\n                        f\"value should be passed as a keyword argument: {arg} \"\n                        f\"(of type {type(arg)})\"\n                    )\n\n        # Caches info about `call()` signature, args, kwargs.\n        call_spec = CallSpec(self._call_signature, args, kwargs)\n\n        ############################################\n        # 3. Check input spec for 1st positional arg.\n        # TODO: consider extending this to all args and kwargs.\n        self._assert_input_compatibility(call_spec.first_arg)\n\n        ################\n        # 4. Call build\n        with self._open_name_scope():\n            await self._maybe_build(call_spec)\n\n        ##########################\n        # 5. Infer training value\n        # Training phase for `Module.call` is set via (in order of priority):\n        # (1) The `training` argument passed to this `Module.call`, if not None\n        # (2) The training argument of an outer `Module.call`.\n        # (4) Any non-None default value for `training` in the call signature\n        # (5) False (treating the module as if it's in inference)\n\n        # Maintains info about the `Module.call` stack\n        # across nested calls.\n        call_context = self._get_call_context()\n\n        # This is the value explicitly passed by the user\n        training = call_spec.user_arguments_dict.get(\"training\", None)\n        if training is None:\n            # Wasn't passed explicitly: use context value\n            training = call_context.training\n            if training is None:\n                # Get signature default value\n                training = call_spec.arguments_dict.get(\"training\", None)\n        call_context.training = training\n        if self._call_has_training_arg and training is not None:\n            # Only populate arg if it has a concrete value\n            kwargs[\"training\"] = training\n\n        ####################\n        # 6. Call the module.\n        try:\n            with self._open_name_scope():\n                outputs = await super().__call__(*args, **kwargs)\n\n            if not self.built:\n                self.built = True\n        except Exception as e:\n            capture_exception(e)\n            raise e\n        finally:\n            # Destroy call context if we created it\n            self._maybe_reset_call_context()\n        return outputs\n\n    async def call(self, *args, **kwargs):\n        raise self._not_implemented_error(self.call)\n\n    def __repr__(self):\n        return (\n            f\"&lt;{self.__class__.__name__} \"\n            f\"name={self.name}, description='{self.description}', built={self.built}&gt;\"\n        )\n\n    def __str__(self):\n        return self.__repr__()\n\n    def __setattr__(self, name, value):\n        # Track Variables, Modules, Metrics.\n        name, value = self._setattr_hook(name, value)\n        if name != \"_tracker\":\n            if not hasattr(self, \"_tracker\"):\n                self._initialize_tracker()\n            value = self._tracker.track(value)\n        return super().__setattr__(name, value)\n\n    def __delattr__(self, name):\n        obj = getattr(self, name)\n        if isinstance(obj, backend.Variable):\n            import gc\n\n            # It will take a short amount of time for the corresponding buffer\n            # to be actually removed from the device.\n            # https://stackoverflow.com/a/74631949\n            self._untrack_variable(obj)\n            super().__delattr__(name)\n            gc.collect()\n        else:\n            super().__delattr__(name)\n\n    def _check_super_called(self):\n        if getattr(self, \"_lock\", True):\n            raise RuntimeError(\n                f\"In module '{self.__class__.__name__}', you forgot to call \"\n                \"`super().__init__()` as the first statement \"\n                \"in the `__init__()` method. Go add it!\"\n            )\n\n    def _assert_input_compatibility(self, first_arg):\n        # TODO perform check using schemas\n        pass\n\n    def _maybe_convert_inputs(self, inputs):\n        return tree.map_structure(\n            lambda x: x.to_json_data_model() if backend.is_data_model(x) else x,\n            inputs,\n        )\n        return inputs\n\n    def _get_call_context(self):\n        \"\"\"Returns currently active `CallContext`.\"\"\"\n        module_call_ctx = global_state.get_global_attribute(\"current_call_ctx\")\n        if module_call_ctx is None:\n            # Enter new call context.\n            module_call_ctx = CallContext(entry_module=self)\n            global_state.set_global_attribute(\"current_call_ctx\", module_call_ctx)\n            self._clear_rewards()\n        return module_call_ctx\n\n    def _maybe_reset_call_context(self):\n        module_call_ctx = global_state.get_global_attribute(\"current_call_ctx\")\n        if module_call_ctx is None or module_call_ctx.entry_module == self:\n            global_state.set_global_attribute(\"current_call_ctx\", None)\n\n    def _flatten_modules(self, include_self=True, recursive=True):\n        modules = []\n        if include_self:\n            modules.append(self)\n        seen_object_ids = set()\n        deque = collections.deque(self._modules)\n        while deque:\n            module = deque.popleft()\n            if id(module) in seen_object_ids:\n                continue\n            seen_object_ids.add(id(module))\n            modules.append(module)\n            # Introspect recursively through submodules.\n            if recursive:\n                deque.extendleft(module._modules)\n        return modules\n\n    def _not_implemented_error(self, attr, msg=None):\n        if callable(attr):\n            attr_name = attr.__name__\n            attr_type = \"method\"\n        else:\n            attr_name = str(attr)\n            attr_type = \"attribute\"\n        msg = \" \" + msg if msg is not None else \"\"\n        return NotImplementedError(\n            f\"Module {self.__class__.__name__} does not have a `{attr_name}` \"\n            f\"{attr_type} implemented.{msg}\"\n        )\n\n    def _track_variable(self, variable):\n        if variable.trainable:\n            self._tracker.add_to_store(\"trainable_variables\", variable)\n        else:\n            self._tracker.add_to_store(\"non_trainable_variables\", variable)\n        if not self.trainable:\n            variable.trainable = False\n        self._post_track_variable(variable)\n\n    def _untrack_variable(self, variable):\n        previous_lock_state = self._tracker.locked\n        self._tracker.unlock()\n        self._tracker.untrack(variable)\n        if previous_lock_state is True:\n            self._tracker.lock()\n        self._post_untrack_variable(variable)\n\n    @python_utils.default\n    def get_config(self):\n        self._check_super_called()\n        base_config = super().get_config()\n        config = {\n            \"trainable\": self.trainable,\n        }\n        return {**base_config, **config}\n\n    def _open_name_scope(self):\n        if self._parent_path is None:\n            self._parent_path = current_path()\n        return backend.name_scope(self.name, caller=self)\n\n    async def _maybe_build(self, call_spec):\n        if self.built:\n            return\n\n        # If the module has a build method, call it with our input schemas.\n        if not utils.is_default(self.build):\n            if len(call_spec.first_arg) == 1:\n                await self.build(call_spec.first_arg[0])\n            else:\n                await self.build(call_spec.first_arg)\n            # Check input spec again (after build, since self.input_spec\n            # may have been updated\n            self._assert_input_compatibility(call_spec.first_arg)\n            return\n\n        # Otherwise, attempt to build the module by calling it on symbolic input.\n        if might_have_unbuilt_state(self):\n            try:\n                if not utils.is_default(self.compute_output_spec):\n                    await self.compute_output_spec(**call_spec.arguments_dict)\n                else:\n                    await backend.compute_output_spec(\n                        self.call, **call_spec.arguments_dict\n                    )\n            except Exception as e:\n                if call_spec.eager:\n                    # Will let the actual eager call do state-building\n                    return\n                warnings.warn(\n                    f\"Module '{self.name}' looks like it has unbuilt state, but \"\n                    \"Synalinks is not able to trace the module `call()` in order to \"\n                    \"build it automatically. Possible causes:\\n\"\n                    \"1. The `call()` method of your module may be crashing. Try \"\n                    \"to `__call__()` the module eagerly on some test input \"\n                    \"first to see if it works. \"\n                    \"2. If the `call()` method is correct, then you may need \"\n                    \"to implement the `def build(self, inputs)` or \"\n                    \"`def compute_output_spec(inputs, training=False)` method on \"\n                    \"your module.\"\n                    f\"Exception encountered: ''{e}''\"\n                )\n        self.built = True\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Base%20Module%20class/#synalinks.src.modules.module.Module.metrics","title":"<code>metrics</code>  <code>property</code>","text":"<p>List of all metrics.</p>"},{"location":"Synalinks%20API/Modules%20API/Base%20Module%20class/#synalinks.src.modules.module.Module.metrics_variables","title":"<code>metrics_variables</code>  <code>property</code>","text":"<p>List of all metric variables.</p>"},{"location":"Synalinks%20API/Modules%20API/Base%20Module%20class/#synalinks.src.modules.module.Module.non_trainable_variables","title":"<code>non_trainable_variables</code>  <code>property</code>","text":"<p>List of all non-trainable module state.</p> <p>Returns:</p> Type Description <code>list</code> <p>The list of non-trainable variables.</p>"},{"location":"Synalinks%20API/Modules%20API/Base%20Module%20class/#synalinks.src.modules.module.Module.path","title":"<code>path</code>  <code>property</code>","text":"<p>The path of the module.</p> <p>If the module has not been built yet, it will be <code>None</code>.</p>"},{"location":"Synalinks%20API/Modules%20API/Base%20Module%20class/#synalinks.src.modules.module.Module.rewards","title":"<code>rewards</code>  <code>property</code>","text":"<p>List of scalar rewards from <code>add_reward</code> and submodules.</p>"},{"location":"Synalinks%20API/Modules%20API/Base%20Module%20class/#synalinks.src.modules.module.Module.trainable","title":"<code>trainable</code>  <code>property</code> <code>writable</code>","text":"<p>Settable boolean, whether this module should be trainable or not.</p>"},{"location":"Synalinks%20API/Modules%20API/Base%20Module%20class/#synalinks.src.modules.module.Module.trainable_variables","title":"<code>trainable_variables</code>  <code>property</code>","text":"<p>List of all trainable module state.</p> <p>Returns:</p> Type Description <code>list</code> <p>The list of trainable variables.</p>"},{"location":"Synalinks%20API/Modules%20API/Base%20Module%20class/#synalinks.src.modules.module.Module.variables","title":"<code>variables</code>  <code>property</code>","text":"<p>List of all module state.</p> <p>Note that metrics variables are not included here, use <code>metrics_variables</code> to visit all the metric variables.</p> <p>Returns:</p> Type Description <code>list</code> <p>The list of the variables.</p>"},{"location":"Synalinks%20API/Modules%20API/Base%20Module%20class/#synalinks.src.modules.module.Module.add_variable","title":"<code>add_variable(initializer=None, data_model=None, trainable=True, name=None)</code>","text":"<p>Add a variable to the module</p> <p>Parameters:</p> Name Type Description Default <code>initializer</code> <code>dict | Initializer</code> <p>Initializer object to use to populate the initial variable value. Can be a JSON dict containing the initial value. If unspecified, defaults to <code>initializers.Empty</code>.</p> <code>None</code> <code>data_model</code> <code>DataModel</code> <p>The DataModel used to infer the schema and default value.</p> <code>None</code> <code>trainable</code> <code>bool</code> <p>Boolean, whether the variable should be trainable via optimization or whether its updates are managed manually. Defaults to <code>True</code>.</p> <code>True</code> <code>name</code> <code>string</code> <p>String name of the variable. Useful for debugging purposes.</p> <code>None</code> <p>Returns:</p> Type Description <code>Variable</code> <p>The created variable</p> Source code in <code>synalinks/src/modules/module.py</code> <pre><code>def add_variable(\n    self,\n    initializer=None,\n    data_model=None,\n    trainable=True,\n    name=None,\n):\n    \"\"\"Add a variable to the module\n\n    Args:\n        initializer (dict | Initializer): Initializer object to use to\n            populate the initial variable value. Can be a JSON dict containing the\n            initial value. If unspecified, defaults to `initializers.Empty`.\n        data_model (DataModel): The DataModel used to infer the schema\n            and default value.\n        trainable (bool): Boolean, whether the variable should be trainable via\n            optimization or whether its updates are managed manually. Defaults\n            to `True`.\n        name (string): String name of the variable. Useful for debugging purposes.\n\n    Returns:\n        (Variable): The created variable\n    \"\"\"\n    self._check_super_called()\n    if initializer is None:\n        initializer = initializers.Empty(data_model=data_model)\n    with backend.name_scope(self.name, caller=self):\n        variable = backend.Variable(\n            initializer=initializer,\n            data_model=data_model,\n            trainable=trainable,\n            name=name,\n        )\n    self._track_variable(variable)\n    return variable\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Base%20Module%20class/#synalinks.src.modules.module.Module.build_from_config","title":"<code>build_from_config(config)</code>","text":"<p>Builds the module's states with the supplied config dict.</p> <p>By default, this method calls the <code>build()</code> method, which creates variables based on the module's input schema in the supplied config. If your config contains other information needed to load the module's state, you should override this method.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>Dict containing the input schema associated with this module.</p> required Source code in <code>synalinks/src/modules/module.py</code> <pre><code>def build_from_config(self, config):\n    \"\"\"Builds the module's states with the supplied config dict.\n\n    By default, this method calls the `build()` method,\n    which creates variables based on the module's input schema in the supplied\n    config. If your config contains other information needed to load the\n    module's state, you should override this method.\n\n    Args:\n        config (dict): Dict containing the input schema associated with this module.\n    \"\"\"\n    if config:\n        if \"input_schema\" in config:\n            asyncio.get_event_loop().run_until_complete(\n                self.build(backend.SymbolicDataModel(schema=config[\"input_schema\"]))\n            )\n        elif \"schemas_dict\" in config:\n            symbolic_inputs = {}\n            for key, schema in config[\"schemas_dict\"].items():\n                symbolic_inputs[key] = backend.SymbolicDataModel(schema=schema)\n            asyncio.get_event_loop().run_until_complete(self.build(**symbolic_inputs))\n        self.built = True\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Base%20Module%20class/#synalinks.src.modules.module.Module.get_build_config","title":"<code>get_build_config()</code>","text":"<p>Returns a dictionary with the modules's input schema.</p> <p>This method returns a config dict that can be used by <code>build_from_config(config)</code> to create all states (e.g. Variables and Lookup tables) needed by the module.</p> <p>By default, the config only contains the input schema that the module was built with. If you're writing a custom module that creates state in an unusual way, you should override this method to make sure this state is already created when Synalinks attempts to load its value upon model loading.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A dict containing the input schema associated with the module.</p> Source code in <code>synalinks/src/modules/module.py</code> <pre><code>def get_build_config(self):\n    \"\"\"Returns a dictionary with the modules's input schema.\n\n    This method returns a config dict that can be used by\n    `build_from_config(config)` to create all states (e.g. Variables and\n    Lookup tables) needed by the module.\n\n    By default, the config only contains the input schema that the module\n    was built with. If you're writing a custom module that creates state in\n    an unusual way, you should override this method to make sure this state\n    is already created when Synalinks attempts to load its value upon model\n    loading.\n\n    Returns:\n        (dict): A dict containing the input schema associated with the module.\n    \"\"\"\n    if self._build_schemas_dict is not None:\n        if len(self._build_schemas_dict) == 1:\n            return {\n                \"input_schema\": tuple(self._build_schemas_dict.values())[0],\n            }\n        else:\n            return {\"schemas_dict\": self._build_schemas_dict}\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Base%20Module%20class/#synalinks.src.modules.module.Module.get_variable","title":"<code>get_variable(name=None, index=None)</code>","text":"<p>Retrieves a variable based on either its name (unique) or index.</p> <p>If <code>name</code> and <code>index</code> are both provided, <code>index</code> will take precedence. Indices are based on order of instantiation.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>string</code> <p>The name of the variable.</p> <code>None</code> <code>index</code> <code>int</code> <p>The index of the variable.</p> <code>None</code> <p>Returns:</p> Type Description <code>Variable</code> <p>The returned variable.</p> Source code in <code>synalinks/src/modules/module.py</code> <pre><code>def get_variable(self, name=None, index=None):\n    \"\"\"Retrieves a variable based on either its name (unique) or index.\n\n    If `name` and `index` are both provided, `index` will take precedence.\n    Indices are based on order of instantiation.\n\n    Args:\n        name (string): The name of the variable.\n        index (int): The index of the variable.\n\n    Returns:\n        (Variable): The returned variable.\n    \"\"\"\n    if index is not None and name is not None:\n        raise ValueError(\n            \"Provide only a variable name or a variable index. Received: \"\n            f\"index={index}, name={name}.\"\n        )\n    if index is not None:\n        if len(self.variables) &lt;= index:\n            raise ValueError(\n                f\"Was asked to retrieve variable at index {index}\"\n                f\" but module only has {len(self.modules)}\"\n                \" variables.\"\n            )\n        else:\n            return self.variables[index]\n\n    if name is not None:\n        for variable in self.variables:\n            if variable.name == name:\n                return variable\n        raise ValueError(\n            f\"No such variable: {name}. Existing variables are: \"\n            f\"{list(variable.name for variable in self.variables)}.\"\n        )\n    raise ValueError(\n        \"Provide either a variable name or variable index at `get_variable`.\"\n    )\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Agents%20Modules/","title":"Agent Modules","text":"<ul> <li>ReACT module</li> </ul>"},{"location":"Synalinks%20API/Modules%20API/Agents%20Modules/ReACT%20Agent%20module/","title":"ReACT Agent module","text":""},{"location":"Synalinks%20API/Modules%20API/Agents%20Modules/ReACT%20Agent%20module/#synalinks.src.modules.agents.react_agent.ReACTAgent","title":"<code>ReACTAgent</code>","text":"<p>               Bases: <code>Program</code></p> <p>ReACT agent as a directed acyclic graph that choose at each step the tool to use.</p> <p>The difference with DSPy or AdalFlow implementation is that each node in the DAG is a separate module with its own trainable variables, yielding better optimization (specific for each step/tool). Which makes it more memory intensive, but since ReACT are anyway limited to a small set of tools/functions, its ok.</p> <p>Note: Each function MUST return a JSON object dict and be asynchrounous</p> <p>Example:</p> <pre><code>import synalinks\nimport asyncio\n\nclass Query(synalinks.DataModel):\n    query: str = synalinks.Field(\n        description=\"The user query\",\n    )\n\nclass FinalAnswer(synalinks.DataModel):\n    answer: float = synalinks.Field(\n        description=\"The correct final answer\",\n    )\n\nasync def main():\n\n    async def calculate(expression: str):\n        \"\"\"Calculate the result of a mathematical expression.\n\n        Args:\n            expression (str): The mathematical expression to calculate, such as\n                '2 + 2'. The expression can contain numbers, operators (+, -, *, /),\n                parentheses, and spaces.\n        \"\"\"\n        if not all(char in \"0123456789+-*/(). \" for char in expression):\n            return {\n                \"result\": None,\n                \"log\": \"Error: invalid characters in expression\",\n            }\n        try:\n            # Evaluate the mathematical expression safely\n            result = round(float(eval(expression, {\"__builtins__\": None}, {})), 2)\n            return {\n                \"result\": result,\n                \"log\": \"Successfully executed\",\n            }\n        except Exception as e:\n            return {\n                \"result\": None,\n                \"log\": f\"Error: {e}\",\n            }\n\n    language_model = LanguageModel(model=\"ollama/mistral\")\n\n    x0 = Input(data_model=Query)\n    x1 = await ReACTAgent(\n        data_model=FinalAnswer,\n        language_model=language_model,\n        functions=[calculate],\n        max_iterations=3,\n    )(x0)\n\n    program = Program(\n        inputs=x0,\n        outputs=x1,\n        name=\"math_agent\",\n        description=\"A math agent that can use a calculator\",\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> References <ul> <li>ReAct: Synergizing Reasoning and Acting in Language Models</li> </ul> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>dict</code> <p>The JSON schema to use for the final answer. If not provided, it will use the <code>output_data_model</code> argument.</p> <code>None</code> <code>data_model</code> <code>DataModel | JsonDataModel | SymbolicDataModel</code> <p>Optional. The data model to use for the final answer. If None provided, the Agent will return a ChatMessage-like data model.</p> <code>None</code> <code>functions</code> <code>list</code> <p>A list of Python functions for the agent to choose from.</p> <code>None</code> <code>question</code> <code>str</code> <p>Optional. The question to branch at each step.</p> <code>None</code> <code>language_model</code> <code>LanguageModel</code> <p>The language model to use, if provided it will ignore <code>decision_language_model</code> and <code>action_language_model</code> argument.</p> <code>None</code> <code>decision_language_model</code> <code>LanguageModel</code> <p>The language model used for decision-making.</p> <code>None</code> <code>action_language_model</code> <code>LanguageModel</code> <p>The language model used for actions.</p> <code>None</code> <code>prompt_template</code> <code>str</code> <p>Optional. The jinja2 prompt template to use (See <code>Generator</code>).</p> <code>None</code> <code>examples</code> <code>list</code> <p>A default list of examples for decision-making (See <code>Decision</code>).</p> <code>None</code> <code>instructions</code> <code>list</code> <p>A default list of instructions for decision-making (See <code>Decision</code>).</p> <code>None</code> <code>use_inputs_schema</code> <code>bool</code> <p>Optional. Whether or not use the inputs schema in the decision prompt (Default to False) (see <code>Decision</code>).</p> <code>False</code> <code>use_outputs_schema</code> <code>bool</code> <p>Optional. Whether or not use the outputs schema in the decision prompt (Default to False) (see <code>Decision</code>).</p> <code>False</code> <code>return_inputs_with_trajectory</code> <code>bool</code> <p>Optional. Whether or not to concatenate the inputs along with the agent trajectory to the outputs (Default to False).</p> <code>False</code> <code>return_inputs_only</code> <code>bool</code> <p>Optional. Whether or not to concatenate the inputs to the outputs (Default to False).</p> <code>False</code> <code>max_iterations</code> <code>int</code> <p>The maximum number of steps to perform.</p> <code>5</code> <code>name</code> <code>str</code> <p>Optional. The name of the module.</p> <code>None</code> <code>description</code> <code>str</code> <p>Optional. The description of the module.</p> <code>None</code> <code>trainable</code> <code>bool</code> <p>Whether the module's variables should be trainable.</p> <code>True</code> Source code in <code>synalinks/src/modules/agents/react_agent.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.modules.ReACTAgent\",\n        \"synalinks.ReACTAgent\",\n    ]\n)\nclass ReACTAgent(Program):\n    \"\"\"ReACT agent as a directed acyclic graph that choose at each step the tool to use.\n\n    The difference with DSPy or AdalFlow implementation is that each node in the DAG\n    is a separate module with its own trainable variables, yielding better optimization\n    (specific for each step/tool). Which makes it more memory intensive, but since ReACT\n    are anyway limited to a small set of tools/functions, its ok.\n\n    **Note:** Each function **MUST** return a JSON object dict and be asynchrounous\n\n    Example:\n\n    ```python\n    import synalinks\n    import asyncio\n\n    class Query(synalinks.DataModel):\n        query: str = synalinks.Field(\n            description=\"The user query\",\n        )\n\n    class FinalAnswer(synalinks.DataModel):\n        answer: float = synalinks.Field(\n            description=\"The correct final answer\",\n        )\n\n    async def main():\n\n        async def calculate(expression: str):\n            \\\"\"\"Calculate the result of a mathematical expression.\n\n            Args:\n                expression (str): The mathematical expression to calculate, such as\n                    '2 + 2'. The expression can contain numbers, operators (+, -, *, /),\n                    parentheses, and spaces.\n            \\\"\"\"\n            if not all(char in \"0123456789+-*/(). \" for char in expression):\n                return {\n                    \"result\": None,\n                    \"log\": \"Error: invalid characters in expression\",\n                }\n            try:\n                # Evaluate the mathematical expression safely\n                result = round(float(eval(expression, {\"__builtins__\": None}, {})), 2)\n                return {\n                    \"result\": result,\n                    \"log\": \"Successfully executed\",\n                }\n            except Exception as e:\n                return {\n                    \"result\": None,\n                    \"log\": f\"Error: {e}\",\n                }\n\n        language_model = LanguageModel(model=\"ollama/mistral\")\n\n        x0 = Input(data_model=Query)\n        x1 = await ReACTAgent(\n            data_model=FinalAnswer,\n            language_model=language_model,\n            functions=[calculate],\n            max_iterations=3,\n        )(x0)\n\n        program = Program(\n            inputs=x0,\n            outputs=x1,\n            name=\"math_agent\",\n            description=\"A math agent that can use a calculator\",\n        )\n\n    if __name__ == \"__main__\":\n        asyncio.run(main())\n    ```\n\n    References:\n        - [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629)\n\n    Args:\n        schema (dict): The JSON schema to use for the final answer.\n            If not provided, it will use the `output_data_model` argument.\n        data_model (DataModel | JsonDataModel | SymbolicDataModel): Optional.\n            The data model to use for the final answer.\n            If None provided, the Agent will return a ChatMessage-like data model.\n        functions (list): A list of Python functions for the agent to choose from.\n        question (str): Optional. The question to branch at each step.\n        language_model (LanguageModel): The language model to use, if provided\n            it will ignore `decision_language_model` and `action_language_model` argument.\n        decision_language_model (LanguageModel): The language model used for\n            decision-making.\n        action_language_model (LanguageModel): The language model used for actions.\n        prompt_template (str): Optional. The jinja2 prompt template to use\n            (See `Generator`).\n        examples (list): A default list of examples for decision-making (See `Decision`).\n        instructions (list): A default list of instructions for decision-making\n            (See `Decision`).\n        use_inputs_schema (bool): Optional. Whether or not use the inputs schema in\n            the decision prompt (Default to False) (see `Decision`).\n        use_outputs_schema (bool): Optional. Whether or not use the outputs schema in\n            the decision prompt (Default to False) (see `Decision`).\n        return_inputs_with_trajectory (bool): Optional. Whether or not to concatenate the\n            inputs along with the agent trajectory to the outputs (Default to False).\n        return_inputs_only (bool): Optional. Whether or not to concatenate the inputs\n            to the outputs (Default to False).\n        max_iterations (int): The maximum number of steps to perform.\n        name (str): Optional. The name of the module.\n        description (str): Optional. The description of the module.\n        trainable (bool): Whether the module's variables should be trainable.\n    \"\"\"\n\n    def __init__(\n        self,\n        schema=None,\n        data_model=None,\n        functions=None,\n        question=None,\n        language_model=None,\n        decision_language_model=None,\n        action_language_model=None,\n        prompt_template=None,\n        examples=None,\n        instructions=None,\n        use_inputs_schema=False,\n        use_outputs_schema=False,\n        return_inputs_with_trajectory=False,\n        return_inputs_only=False,\n        max_iterations=5,\n        name=None,\n        description=None,\n        trainable=True,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n            trainable=trainable,\n        )\n\n        if not schema and data_model:\n            schema = data_model.get_schema()\n        self.schema = schema\n\n        if language_model:\n            self.decision_language_model = language_model\n            self.action_language_model = language_model\n        elif action_language_model and decision_language_model:\n            self.decision_language_model = decision_language_model\n            self.action_language_model = action_language_model\n        else:\n            raise ValueError(\n                \"You must set either `language_model` \"\n                \" or both `action_language_model` and `decision_language_model`.\"\n            )\n\n        self.prompt_template = prompt_template\n\n        if not examples:\n            examples = []\n        self.examples = examples\n\n        if not instructions:\n            instructions = get_instructions()\n        self.instructions = instructions\n\n        self.use_inputs_schema = use_inputs_schema\n        self.use_outputs_schema = use_outputs_schema\n        if return_inputs_only and return_inputs_with_trajectory:\n            raise ValueError(\n                \"You cannot set both \"\n                \"`return_inputs_only` and `return_inputs_with_trajectory` \"\n                \"arguments to True. Choose only one.\"\n            )\n        self.return_inputs_with_trajectory = return_inputs_with_trajectory\n        self.return_inputs_only = return_inputs_only\n\n        assert max_iterations &gt; 1\n        self.max_iterations = max_iterations\n\n        if not question:\n            question = get_decision_question()\n        self.question = question\n\n        self.labels = []\n        self.functions = functions\n        for fn in self.functions:\n            self.labels.append(Tool(fn).name())\n\n        assert _fn_END not in self.labels, (\n            f\"'{_fn_END}' is a reserved keyword and cannot be used as function name\"\n        )\n\n        self.labels.append(_fn_END)\n\n    async def build(self, inputs):\n        current_steps = [inputs]\n        next_steps = []\n        finish_branches = []\n        for i in range(self.max_iterations):\n            if i &lt; self.max_iterations - 1:\n                for step in current_steps:\n                    actions = [\n                        Action(\n                            fn=fn,\n                            language_model=self.action_language_model,\n                            prompt_template=self.prompt_template,\n                            use_inputs_schema=self.use_inputs_schema,\n                            use_outputs_schema=self.use_outputs_schema,\n                        )\n                        for fn in self.functions\n                    ]\n                    actions.append(\n                        Generator(\n                            schema=self.schema,\n                            language_model=self.action_language_model,\n                            prompt_template=self.prompt_template,\n                            use_inputs_schema=self.use_inputs_schema,\n                            use_outputs_schema=self.use_outputs_schema,\n                            return_inputs=self.return_inputs_with_trajectory,\n                        )\n                    )\n                    branches = await Branch(\n                        question=self.question,\n                        labels=self.labels,\n                        branches=actions,\n                        language_model=self.decision_language_model,\n                        prompt_template=self.prompt_template,\n                        examples=self.examples,\n                        instructions=self.instructions,\n                        use_inputs_schema=self.use_inputs_schema,\n                        use_outputs_schema=self.use_outputs_schema,\n                        return_decision=False,\n                    )(step)\n                    next_steps.extend([step &amp; branch for branch in branches[:-1]])\n                    finish_branches.append(branches[-1])\n                current_steps = next_steps\n                next_steps = []\n            else:\n                for step in current_steps:\n                    last_step = await Generator(\n                        schema=self.schema,\n                        language_model=self.action_language_model,\n                        prompt_template=self.prompt_template,\n                        use_inputs_schema=self.use_inputs_schema,\n                        use_outputs_schema=self.use_outputs_schema,\n                        return_inputs=self.return_inputs_with_trajectory,\n                    )(step)\n                    finish_branches.append(last_step)\n\n        final = await Or()(finish_branches)\n\n        if self.return_inputs_with_trajectory:\n            final.factorize()\n\n        if self.return_inputs_only:\n            final = inputs + final\n\n        super().__init__(\n            inputs=inputs,\n            outputs=final,\n            name=self.name,\n            description=self.description,\n            trainable=self.trainable,\n        )\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Agents%20Modules/ReACT%20Agent%20module/#synalinks.src.modules.agents.react_agent.get_decision_question","title":"<code>get_decision_question()</code>","text":"<p>The default question used for decision-making</p> Source code in <code>synalinks/src/modules/agents/react_agent.py</code> <pre><code>def get_decision_question():\n    \"\"\"The default question used for decision-making\"\"\"\n    return \"Choose the next function to use based on its name.\"\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Agents%20Modules/ReACT%20Agent%20module/#synalinks.src.modules.agents.react_agent.get_instructions","title":"<code>get_instructions()</code>","text":"<p>The default instructions for decision-making</p> Source code in <code>synalinks/src/modules/agents/react_agent.py</code> <pre><code>def get_instructions():\n    \"\"\"The default instructions for decision-making\"\"\"\n    return [\n        \"Always reflect on your previous actions to know what to do.\",\n        \"As soon as you know the answer, or the task is finished, choose `finish`.\",\n    ]\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Core%20Modules/","title":"Core Modules","text":"<ul> <li>Input module</li> <li>Identity module</li> <li>Not module</li> <li>Generator module</li> <li>Decision module</li> <li>Action module</li> <li>Branch module</li> </ul>"},{"location":"Synalinks%20API/Modules%20API/Core%20Modules/Action%20module/","title":"Action module","text":""},{"location":"Synalinks%20API/Modules%20API/Core%20Modules/Action%20module/#synalinks.src.modules.core.action.Action","title":"<code>Action</code>","text":"<p>               Bases: <code>Module</code></p> <p>Use a <code>LanguageModel</code> to perform a function call given the input datamodel.</p> <p>This module use structured output to call a given Python function. This module can be used in agents or traditional workflows seamlessly, it use the input data model to infer the function parameters.</p> <p>The output of this module contains the inputs infered by the language model as well as the outputs of the function call.</p> <p>Note: The function MUST return a JSON object dict and be asynchronous.</p> <p>Example:</p> <pre><code>import synalinks\nimport asyncio\n\nasync def main():\n\n    class Query(synalinks.DataModel):\n        query: str\n\n    async def calculate(expression: str):\n        \"\"\"Calculate the result of a mathematical expression.\n\n        Args:\n            expression (str): The mathematical expression to calculate, such as\n                '2 + 2'. The expression can contain numbers, operators (+, -, *, /),\n                parentheses, and spaces.\n        \"\"\"\n        if not all(char in \"0123456789+-*/(). \" for char in expression):\n            return {\n                \"result\": None,\n                \"log\": \"Error: invalid characters in expression\",\n            }\n        try:\n            # Evaluate the mathematical expression safely\n            result = round(float(eval(expression, {\"__builtins__\": None}, {})), 2)\n            return {\n                \"result\": result,\n                \"log\": \"Successfully executed\",\n            }\n        except Exception as e:\n            return {\n                \"result\": None,\n                \"log\": f\"Error: {e}\",\n            }\n\n    language_model = synalinks.LanguageModel(\n        model=\"ollama/mistral\",\n    )\n\n    x0 = synalinks.Input(data_model=Query)\n    x1 = await synalinks.Action(\n        fn=calculate,\n        language_model=language_model,\n    )(x0)\n\n    program = synalinks.Program(\n        inputs=x0,\n        outputs=x1,\n        name=\"calculator\",\n        description=\"This program perform the calculation of an expression\",\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable</code> <p>The function to call.</p> required <code>language_model</code> <code>LanguageModel</code> <p>The language model to use.</p> <code>None</code> <code>prompt_template</code> <code>str</code> <p>The default jinja2 prompt template to use (see <code>Generator</code>).</p> <code>None</code> <code>examples</code> <code>list</code> <p>The default examples to use in the prompt (see <code>Generator</code>).</p> <code>None</code> <code>instructions</code> <code>list</code> <p>The default instructions to use (see <code>Generator</code>).</p> <code>None</code> <code>use_inputs_schema</code> <code>bool</code> <p>Optional. Whether or not use the inputs schema in the prompt (Default to False) (see <code>Generator</code>).</p> <code>False</code> <code>use_outputs_schema</code> <code>bool</code> <p>Optional. Whether or not use the outputs schema in the prompt (Default to False) (see <code>Generator</code>).</p> <code>False</code> <code>name</code> <code>str</code> <p>Optional. The name of the module.</p> <code>None</code> <code>description</code> <code>str</code> <p>Optional. The description of the module.</p> <code>None</code> <code>trainable</code> <code>bool</code> <p>Whether the module's variables should be trainable.</p> <code>True</code> Source code in <code>synalinks/src/modules/core/action.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.modules.Action\",\n        \"synalinks.Action\",\n    ]\n)\nclass Action(Module):\n    \"\"\"Use a `LanguageModel` to perform a function call given the input datamodel.\n\n    This module use structured output to call a given Python function.\n    This module can be used in agents or traditional workflows seamlessly,\n    it use the input data model to infer the function parameters.\n\n    The output of this module contains the inputs infered by the language model\n    as well as the outputs of the function call.\n\n    Note: The function **MUST** return a JSON object dict and be asynchronous.\n\n    Example:\n\n    ```python\n    import synalinks\n    import asyncio\n\n    async def main():\n\n        class Query(synalinks.DataModel):\n            query: str\n\n        async def calculate(expression: str):\n            \\\"\"\"Calculate the result of a mathematical expression.\n\n            Args:\n                expression (str): The mathematical expression to calculate, such as\n                    '2 + 2'. The expression can contain numbers, operators (+, -, *, /),\n                    parentheses, and spaces.\n            \\\"\"\"\n            if not all(char in \"0123456789+-*/(). \" for char in expression):\n                return {\n                    \"result\": None,\n                    \"log\": \"Error: invalid characters in expression\",\n                }\n            try:\n                # Evaluate the mathematical expression safely\n                result = round(float(eval(expression, {\"__builtins__\": None}, {})), 2)\n                return {\n                    \"result\": result,\n                    \"log\": \"Successfully executed\",\n                }\n            except Exception as e:\n                return {\n                    \"result\": None,\n                    \"log\": f\"Error: {e}\",\n                }\n\n        language_model = synalinks.LanguageModel(\n            model=\"ollama/mistral\",\n        )\n\n        x0 = synalinks.Input(data_model=Query)\n        x1 = await synalinks.Action(\n            fn=calculate,\n            language_model=language_model,\n        )(x0)\n\n        program = synalinks.Program(\n            inputs=x0,\n            outputs=x1,\n            name=\"calculator\",\n            description=\"This program perform the calculation of an expression\",\n        )\n\n    if __name__ == \"__main__\":\n        asyncio.run(main())\n    ```\n\n    Args:\n        fn (Callable): The function to call.\n        language_model (LanguageModel): The language model to use.\n        prompt_template (str): The default jinja2 prompt template\n            to use (see `Generator`).\n        examples (list): The default examples to use in the prompt\n            (see `Generator`).\n        instructions (list): The default instructions to use (see `Generator`).\n        use_inputs_schema (bool): Optional. Whether or not use the inputs schema in\n            the prompt (Default to False) (see `Generator`).\n        use_outputs_schema (bool): Optional. Whether or not use the outputs schema in\n            the prompt (Default to False) (see `Generator`).\n        name (str): Optional. The name of the module.\n        description (str): Optional. The description of the module.\n        trainable (bool): Whether the module's variables should be trainable.\n    \"\"\"\n\n    def __init__(\n        self,\n        fn,\n        language_model=None,\n        prompt_template=None,\n        examples=None,\n        instructions=None,\n        use_inputs_schema=False,\n        use_outputs_schema=False,\n        name=None,\n        description=None,\n        trainable=True,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n            trainable=trainable,\n        )\n        self.fn = fn\n        schema = tool_utils.Tool(fn).obj_schema()\n        self.language_model = language_model\n        self.prompt_template = prompt_template\n        self.examples = examples\n        self.instructions = instructions\n        self.use_inputs_schema = use_inputs_schema\n        self.use_outputs_schema = use_outputs_schema\n        self.action = Generator(\n            schema=schema,\n            language_model=language_model,\n            prompt_template=prompt_template,\n            examples=examples,\n            instructions=instructions,\n            use_inputs_schema=use_inputs_schema,\n            use_outputs_schema=use_outputs_schema,\n            name=self.name + \"_generator\",\n        )\n\n    async def call(self, inputs, training=False):\n        if not inputs:\n            return None\n        fn_inputs = await self.action(inputs, training=training)\n        fn_outputs = await self.fn(**fn_inputs.get_json())\n        generic_io = GenericIO(inputs=fn_inputs.get_json(), outputs=fn_outputs)\n        return JsonDataModel(\n            json=GenericAction(action=generic_io.get_json()).get_json(),\n            schema=GenericAction.get_schema(),\n            name=self.name,\n        )\n\n    async def compute_output_spec(self, inputs, training=False):\n        self.action(inputs)\n        return SymbolicDataModel(schema=GenericAction.get_schema(), name=self.name)\n\n    def get_config(self):\n        config = {\n            \"fn\": self.fn,\n            \"prompt_template\": self.prompt_template,\n            \"examples\": self.examples,\n            \"instructions\": self.instructions,\n            \"name\": self.name,\n            \"description\": self.description,\n            \"trainable\": self.trainable,\n        }\n        language_model_config = {\n            \"language_model\": serialization_lib.serialize_synalinks_object(\n                self.language_model\n            )\n        }\n        return {**config, **language_model_config}\n\n    @classmethod\n    def from_config(cls, config):\n        language_model = serialization_lib.deserialize_synalinks_object(\n            config.pop(\"language_model\")\n        )\n        return cls(language_model=language_model, **config)\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Core%20Modules/Action%20module/#synalinks.src.modules.core.action.GenericAction","title":"<code>GenericAction</code>","text":"<p>               Bases: <code>DataModel</code></p> <p>A generic action with inputs/outputs</p> Source code in <code>synalinks/src/modules/core/action.py</code> <pre><code>class GenericAction(DataModel):\n    \"\"\"A generic action with inputs/outputs\"\"\"\n\n    action: GenericIO = Field(description=\"An action already performed\")\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Core%20Modules/Branch%20module/","title":"Branch module","text":""},{"location":"Synalinks%20API/Modules%20API/Core%20Modules/Branch%20module/#synalinks.src.modules.core.branch.Branch","title":"<code>Branch</code>","text":"<p>               Bases: <code>Module</code></p> <p>Use a <code>LanguageModel</code> to select which module to call based on an arbitrary     input, a question and a list of labels.</p> <p>The selected branch output the data model computed using the inputs and module's branch, while the others output <code>None</code>.</p> <p>Example:</p> <pre><code>import synalinks\nimport asyncio\n\nasync def main():\n    class Query(synalinks.DataModel):\n        query: str\n\n    class Answer(synalinks.DataModel):\n        answer: str\n\n    class AnswerWithCritique(synalinks.DataModel):\n        thinking: str\n        critique: str\n        answer: str\n\n    language_model = synalinks.LanguageModel(\n        model=\"ollama/mistral\",\n    )\n\n    x0 = synalinks.Input(data_model=Query)\n    (x1, x2) = await synalinks.Branch(\n        question=\"What is the difficulty level of the above query?\",\n        labels=[\"easy\", \"difficult\"],\n        branches=[\n            synalinks.Generator(\n                data_model=Answer,\n                language_model=language_model,\n            ),\n            synalinks.Generator(\n                data_model=AnswerWithCritique,\n                language_model=language_model,\n            ),\n        ],\n        language_model=language_model,\n    )(x0)\n    x3 = x1 | x2\n\n    program = synalinks.Program(\n        inputs=x0,\n        outputs=x3,\n        name=\"adaptative_chain_of_thought\",\n        description=\"Useful to answer step by step only when needed\",\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>question</code> <code>str</code> <p>The question to ask.</p> <code>None</code> <code>labels</code> <code>list</code> <p>The list of labels to choose from (strings).</p> <code>None</code> <code>branches</code> <code>list</code> <p>The list of modules or programs to select from.</p> <code>None</code> <code>inject_decision</code> <code>bool</code> <p>If True, inject the decision to the branch inputs. (default to True).</p> <code>True</code> <code>return_decision</code> <code>bool</code> <p>If True, return the decision with the branch outputs. (default to True).</p> <code>True</code> <code>language_model</code> <code>LanguageModel</code> <p>The language model to use.</p> <code>None</code> <code>prompt_template</code> <code>str</code> <p>The default jinja2 prompt template to use (see <code>Generator</code>).</p> <code>None</code> <code>examples</code> <code>list</code> <p>The default examples to use in the prompt (see <code>Decision</code>).</p> <code>None</code> <code>instructions</code> <code>list</code> <p>The default instructions to use (see <code>Decision</code>).</p> <code>None</code> <code>use_inputs_schema</code> <code>bool</code> <p>Optional. Whether or not use the inputs schema in the decision prompt (Default to False) (see <code>Decision</code>).</p> <code>False</code> <code>use_outputs_schema</code> <code>bool</code> <p>Optional. Whether or not use the outputs schema in the decision prompt (Default to False) (see <code>Decision</code>).</p> <code>False</code> <code>name</code> <code>str</code> <p>Optional. The name of the module.</p> <code>None</code> <code>description</code> <code>str</code> <p>Optional. The description of the module.</p> <code>None</code> <code>trainable</code> <code>bool</code> <p>Whether the module's variables should be trainable.</p> <code>True</code> Source code in <code>synalinks/src/modules/core/branch.py</code> <pre><code>@synalinks_export([\"synalinks.modules.Branch\", \"synalinks.Branch\"])\nclass Branch(Module):\n    \"\"\"Use a `LanguageModel` to select which module to call based on an arbitrary\n        input, a question and a list of labels.\n\n    The selected branch output the data model computed using\n    the inputs and module's branch, while the others output `None`.\n\n    Example:\n\n    ```python\n    import synalinks\n    import asyncio\n\n    async def main():\n        class Query(synalinks.DataModel):\n            query: str\n\n        class Answer(synalinks.DataModel):\n            answer: str\n\n        class AnswerWithCritique(synalinks.DataModel):\n            thinking: str\n            critique: str\n            answer: str\n\n        language_model = synalinks.LanguageModel(\n            model=\"ollama/mistral\",\n        )\n\n        x0 = synalinks.Input(data_model=Query)\n        (x1, x2) = await synalinks.Branch(\n            question=\"What is the difficulty level of the above query?\",\n            labels=[\"easy\", \"difficult\"],\n            branches=[\n                synalinks.Generator(\n                    data_model=Answer,\n                    language_model=language_model,\n                ),\n                synalinks.Generator(\n                    data_model=AnswerWithCritique,\n                    language_model=language_model,\n                ),\n            ],\n            language_model=language_model,\n        )(x0)\n        x3 = x1 | x2\n\n        program = synalinks.Program(\n            inputs=x0,\n            outputs=x3,\n            name=\"adaptative_chain_of_thought\",\n            description=\"Useful to answer step by step only when needed\",\n        )\n\n    if __name__ == \"__main__\":\n        asyncio.run(main())\n    ```\n\n    Args:\n        question (str): The question to ask.\n        labels (list): The list of labels to choose from (strings).\n        branches (list): The list of modules or programs to select from.\n        inject_decision (bool): If True, inject the decision to the branch inputs.\n            (default to True).\n        return_decision (bool): If True, return the decision with the branch outputs.\n            (default to True).\n        language_model (LanguageModel): The language model to use.\n        prompt_template (str): The default jinja2 prompt template\n            to use (see `Generator`).\n        examples (list): The default examples to use in the prompt\n            (see `Decision`).\n        instructions (list): The default instructions to use (see `Decision`).\n        use_inputs_schema (bool): Optional. Whether or not use the inputs\n            schema in the decision prompt (Default to False) (see `Decision`).\n        use_outputs_schema (bool): Optional. Whether or not use the outputs\n            schema in the decision prompt (Default to False) (see `Decision`).\n        name (str): Optional. The name of the module.\n        description (str): Optional. The description of the module.\n        trainable (bool): Whether the module's variables should be trainable.\n    \"\"\"\n\n    def __init__(\n        self,\n        question=None,\n        labels=None,\n        branches=None,\n        inject_decision=True,\n        return_decision=True,\n        language_model=None,\n        prompt_template=None,\n        examples=None,\n        instructions=None,\n        use_inputs_schema=False,\n        use_outputs_schema=False,\n        decision_type=Decision,\n        name=None,\n        description=None,\n        trainable=True,\n        **kwargs,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n            trainable=trainable,\n        )\n        if not branches:\n            raise ValueError(\"The `branches` argument must be provided.\")\n        if not isinstance(branches, list):\n            raise ValueError(\"The `branches` must be a list of `Module` or `Program`.\")\n        if len(labels) != len(branches):\n            raise ValueError(\"The `labels` and `branches` must have the same length.\")\n        self.question = question\n        self.labels = labels\n        self.branches = {labels[i]: m for i, m in enumerate(branches)}\n        self.inject_decision = inject_decision\n        self.return_decision = return_decision\n        self.prompt_template = prompt_template\n        self.examples = examples\n        self.instructions = instructions\n        self.use_inputs_schema = use_inputs_schema\n        self.use_outputs_schema = use_outputs_schema\n        self.decision = decision_type(\n            question=question,\n            labels=labels,\n            language_model=language_model,\n            prompt_template=prompt_template,\n            examples=examples,\n            instructions=instructions,\n            use_inputs_schema=use_inputs_schema,\n            use_outputs_schema=use_outputs_schema,\n            name=self.name + \"_decision\",\n        )\n\n    async def call(self, inputs, training=False):\n        if not inputs:\n            return tuple([None] * len(self.branches))\n        decision = await self.decision(\n            inputs,\n            training=training,\n        )\n        choice = decision.get(\"choice\")\n        if not choice:\n            choice = decision.get(\"choices\")\n        outputs = []\n        if self.inject_decision:\n            inputs = await ops.concat(\n                inputs,\n                decision,\n                name=self.name + \"_inputs_with_decision\",\n            )\n        for label, module in self.branches.items():\n            selected = False\n            if isinstance(choice, str):\n                if label == choice:\n                    selected = True\n            elif isinstance(choice, (list, set)):\n                if label in choice:\n                    selected = True\n            if selected:\n                if module:\n                    if self.return_decision:\n                        outputs.append(\n                            await ops.logical_and(\n                                decision,\n                                await module(\n                                    inputs,\n                                    training=training,\n                                ),\n                                name=self.name + \"_with_decision\",\n                            )\n                        )\n                    else:\n                        outputs.append(\n                            await module(\n                                inputs,\n                                training=training,\n                            )\n                        )\n                else:\n                    outputs.append(None)\n            else:\n                outputs.append(None)\n        return tuple(outputs)\n\n    async def compute_output_spec(self, inputs, training=False):\n        outputs = []\n        decision = await self.decision(\n            inputs,\n            training=training,\n        )\n        if self.inject_decision:\n            inputs = await ops.concat(\n                inputs,\n                decision,\n                name=self.name + \"_inputs_with_decision\",\n            )\n        for module in self.branches.values():\n            if self.return_decision:\n                outputs.append(\n                    await ops.logical_and(\n                        decision,\n                        await module(\n                            inputs,\n                            training=training,\n                        ),\n                        name=self.name + \"_with_decision\",\n                    )\n                )\n            else:\n                outputs.append(\n                    await module(\n                        inputs,\n                        training=training,\n                    )\n                )\n        return tuple(outputs)\n\n    def get_config(self):\n        config = {\n            \"question\": self.question,\n            \"labels\": self.labels,\n            \"inject_decision\": self.inject_decision,\n            \"return_decision\": self.return_decision,\n            \"prompt_template\": self.prompt_template,\n            \"examples\": self.examples,\n            \"instructions\": self.instructions,\n            \"use_inputs_schema\": self.use_inputs_schema,\n            \"use_outputs_schema\": self.use_outputs_schema,\n            \"name\": self.name,\n            \"description\": self.description,\n            \"trainable\": self.trainable,\n        }\n        language_model_config = {\n            \"language_model\": serialization_lib.serialize_synalinks_object(\n                self.language_model\n            )\n        }\n        branches_config = {\n            \"branches\": [\n                serialization_lib.serialize_synalinks_object(branch)\n                for branch in self.branches.values()\n            ]\n        }\n        return {**config, **language_model_config, **branches_config}\n\n    @classmethod\n    def from_config(cls, config, custom_objects=None):\n        language_model = serialization_lib.deserialize_synalinks_object(\n            config.pop(\"language_model\")\n        )\n        branches = [\n            serialization_lib.deserialize_synalinks_object(\n                branch_config, custom_objects=custom_objects\n            )\n            for branch_config in config.pop(\"branches\")\n        ]\n        return cls(language_model=language_model, branches=branches, **config)\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Core%20Modules/Decision%20module/","title":"Decision module","text":""},{"location":"Synalinks%20API/Modules%20API/Core%20Modules/Decision%20module/#synalinks.src.modules.core.decision.Decision","title":"<code>Decision</code>","text":"<p>               Bases: <code>Module</code></p> <p>Perform a decision on the given input based on a question and a list of labels.</p> <p>This module dynamically create an <code>Enum</code> schema based on the given labels and use it to generate a possible answer using structured output.</p> <p>This ensure that the LM answer is always one of the provided labels.</p> <p>Example:</p> <pre><code>import synalinks\nimport asyncio\n\nasync def main():\n\n    language_model = synalinks.LanguageModel(\n        model=\"ollama/mistral\",\n    )\n\n    x0 = synalinks.Input(data_model=synalinks.ChatMessages)\n    x1 = await synalinks.Decision(\n        question=\"What is the danger level of the discussion?\",\n        labels=[\"low\", \"medium\", \"high\"],\n        language_model=language_model,\n    )(x0)\n\n    program = synalinks.Program(\n        inputs=x0,\n        outputs=x1,\n        name=\"discussion_danger_assessment\",\n        description=\"This program assesses the level of danger in a discussion.\",\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>You can view this module, as performing a single label classification on the input.</p> <p>Parameters:</p> Name Type Description Default <code>question</code> <code>str</code> <p>The question to ask.</p> <code>None</code> <code>labels</code> <code>list</code> <p>The list of labels to choose from (strings).</p> <code>None</code> <code>language_model</code> <code>LanguageModel</code> <p>The language model to use.</p> <code>None</code> <code>prompt_template</code> <code>str</code> <p>The default jinja2 prompt template to use (see <code>Generator</code>).</p> <code>None</code> <code>examples</code> <code>list</code> <p>The default examples to use in the prompt (see <code>Generator</code>).</p> <code>None</code> <code>instructions</code> <code>list</code> <p>The default instructions to use (see <code>Generator</code>).</p> <code>None</code> <code>use_inputs_schema</code> <code>bool</code> <p>Optional. Whether or not use the inputs schema in the prompt (Default to False) (see <code>Generator</code>).</p> <code>False</code> <code>use_outputs_schema</code> <code>bool</code> <p>Optional. Whether or not use the outputs schema in the prompt (Default to False) (see <code>Generator</code>).</p> <code>False</code> <code>name</code> <code>str</code> <p>Optional. The name of the module.</p> <code>None</code> <code>description</code> <code>str</code> <p>Optional. The description of the module.</p> <code>None</code> <code>trainable</code> <code>bool</code> <p>Whether the module's variables should be trainable.</p> <code>True</code> Source code in <code>synalinks/src/modules/core/decision.py</code> <pre><code>@synalinks_export([\"synalinks.modules.Decision\", \"synalinks.Decision\"])\nclass Decision(Module):\n    \"\"\"Perform a decision on the given input based on a question and a list of labels.\n\n    This module dynamically create an `Enum` schema based on the given labels and\n    use it to generate a possible answer using structured output.\n\n    This ensure that the LM answer is **always** one of the provided labels.\n\n    Example:\n\n    ```python\n    import synalinks\n    import asyncio\n\n    async def main():\n\n        language_model = synalinks.LanguageModel(\n            model=\"ollama/mistral\",\n        )\n\n        x0 = synalinks.Input(data_model=synalinks.ChatMessages)\n        x1 = await synalinks.Decision(\n            question=\"What is the danger level of the discussion?\",\n            labels=[\"low\", \"medium\", \"high\"],\n            language_model=language_model,\n        )(x0)\n\n        program = synalinks.Program(\n            inputs=x0,\n            outputs=x1,\n            name=\"discussion_danger_assessment\",\n            description=\"This program assesses the level of danger in a discussion.\",\n        )\n\n    if __name__ == \"__main__\":\n        asyncio.run(main())\n    ```\n\n    You can view this module, as performing a single label classification on the input.\n\n    Args:\n        question (str): The question to ask.\n        labels (list): The list of labels to choose from (strings).\n        language_model (LanguageModel): The language model to use.\n        prompt_template (str): The default jinja2 prompt template\n            to use (see `Generator`).\n        examples (list): The default examples to use in the prompt\n            (see `Generator`).\n        instructions (list): The default instructions to use (see `Generator`).\n        use_inputs_schema (bool): Optional. Whether or not use the inputs schema in\n            the prompt (Default to False) (see `Generator`).\n        use_outputs_schema (bool): Optional. Whether or not use the outputs schema in\n            the prompt (Default to False) (see `Generator`).\n        name (str): Optional. The name of the module.\n        description (str): Optional. The description of the module.\n        trainable (bool): Whether the module's variables should be trainable.\n    \"\"\"\n\n    def __init__(\n        self,\n        question=None,\n        labels=None,\n        language_model=None,\n        prompt_template=None,\n        examples=None,\n        instructions=None,\n        use_inputs_schema=False,\n        use_outputs_schema=False,\n        name=None,\n        description=None,\n        trainable=True,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n            trainable=trainable,\n        )\n        if not question:\n            raise ValueError(\"The `question` argument must be provided.\")\n        if not labels:\n            raise ValueError(\"The `labels` argument must be provided.\")\n        if not isinstance(labels, list):\n            raise ValueError(\"The `labels` parameter must be a list of string.\")\n        schema = dynamic_enum(DecisionAnswer.get_schema(), \"choice\", labels)\n        self.schema = schema\n        self.question = question\n        self.labels = labels\n        self.language_model = language_model\n        self.prompt_template = prompt_template\n        self.examples = examples\n        self.instructions = instructions\n        self.use_inputs_schema = use_inputs_schema\n        self.use_outputs_schema = use_outputs_schema\n        self.decision = Generator(\n            schema=schema,\n            language_model=language_model,\n            prompt_template=prompt_template,\n            examples=examples,\n            instructions=instructions,\n            use_inputs_schema=use_inputs_schema,\n            use_outputs_schema=use_outputs_schema,\n            name=self.name + \"_generator\",\n        )\n\n    async def call(self, inputs, training=False):\n        if not inputs:\n            return None\n        inputs = await ops.concat(\n            inputs,\n            Question(question=self.question),\n            name=self.name + \"_inputs_with_question\",\n        )\n        result = await self.decision(inputs, training=training)\n        return result\n\n    def get_config(self):\n        config = {\n            \"question\": self.question,\n            \"labels\": self.labels,\n            \"prompt_template\": self.prompt_template,\n            \"examples\": self.examples,\n            \"instructions\": self.instructions,\n            \"use_inputs_schema\": self.use_inputs_schema,\n            \"use_outputs_schema\": self.use_outputs_schema,\n            \"name\": self.name,\n            \"description\": self.description,\n            \"trainable\": self.trainable,\n        }\n        language_model_config = {\n            \"language_model\": serialization_lib.serialize_synalinks_object(\n                self.language_model\n            )\n        }\n        return {**config, **language_model_config}\n\n    @classmethod\n    def from_config(cls, config):\n        language_model = serialization_lib.deserialize_synalinks_object(\n            config.pop(\"language_model\")\n        )\n        return cls(language_model=language_model, **config)\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Core%20Modules/Generator%20module/","title":"Generator module","text":""},{"location":"Synalinks%20API/Modules%20API/Core%20Modules/Generator%20module/#synalinks.src.modules.core.generator.Generator","title":"<code>Generator</code>","text":"<p>               Bases: <code>Module</code></p> <p>Use a <code>LanguageModel</code> to generate a data model from an arbitrary input data model.</p> <p>Example:</p> <pre><code>import synalinks\nimport asyncio\n\nasync def main():\n\n    class Query(DataModel):\n        query: str = synalinks.Field(\n            description=\"The user query\",\n        )\n\n    class AnswerWithCritique(synalinks.DataModel):\n        thinking: str = synalinks.Field(\n            description=\"Your step by step thinking\",\n        )\n        critique: str = synalinks.Field(\n            description=\"The critique of the above thinking\",\n        )\n        answer: str = synalinks.Field(\n            description=\"The correct answer\",\n        )\n\n    language_model = synalinks.LanguageModel(\n        model=\"ollama/mistral\",\n    )\n\n    x0 = synalinks.Input(data_model=Query)\n    x1 = await synalinks.Generator(\n        data_model=AnswerWithCritique,\n        language_model=language_model,\n    )(x0)\n\n    program = synalinks.Program(\n        inputs=x0,\n        outputs=x1,\n        name=\"chain_of_thought_with_critique\",\n        description=\"Useful to answer step by step and evaluate your answer\",\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>dict</code> <p>The target JSON schema. If not provided use the <code>data_model</code> to infer it.</p> <code>None</code> <code>data_model</code> <code>DataModel | SymbolicDataModel | JsonDataModel</code> <p>The target data model for structured output.</p> <code>None</code> <code>language_model</code> <code>LanguageModel</code> <p>The language model to use.</p> <code>None</code> <code>prompt_template</code> <code>str</code> <p>The jinja2 prompt template.</p> <code>None</code> <code>examples</code> <code>list</code> <p>The default list of examples, the examples are a list of tuples containing input/output JSON pairs.</p> <code>None</code> <code>instructions</code> <code>list</code> <p>The default instructions being a list of string containing addtional instructions for the language model.</p> <code>None</code> <code>use_inputs_schema</code> <code>bool</code> <p>Optional. Whether or not use the inputs schema in the prompt (Default to False).</p> <code>False</code> <code>use_outputs_schema</code> <code>bool</code> <p>Optional. Whether or not use the outputs schema in the prompt (Default to False).</p> <code>False</code> <code>return_inputs</code> <code>bool</code> <p>Optional. Whether or not to concatenate the inputs to the outputs (Default to False).</p> <code>False</code> <code>streaming</code> <code>str</code> <p>Optional. If true stream the LM response, enabled only if <code>schema</code> is <code>None</code> and only during inference (not during training).</p> <code>False</code> <code>name</code> <code>str</code> <p>Optional. The name of the module.</p> <code>None</code> <code>description</code> <code>str</code> <p>Optional. The description of the module.</p> <code>None</code> <code>trainable</code> <code>bool</code> <p>Whether the module's variables should be trainable.</p> <code>True</code> Source code in <code>synalinks/src/modules/core/generator.py</code> <pre><code>@synalinks_export([\"synalinks.modules.Generator\", \"synalinks.Generator\"])\nclass Generator(Module):\n    \"\"\"\n    Use a `LanguageModel` to generate a data model from an arbitrary input data model.\n\n    Example:\n\n    ```python\n    import synalinks\n    import asyncio\n\n    async def main():\n\n        class Query(DataModel):\n            query: str = synalinks.Field(\n                description=\"The user query\",\n            )\n\n        class AnswerWithCritique(synalinks.DataModel):\n            thinking: str = synalinks.Field(\n                description=\"Your step by step thinking\",\n            )\n            critique: str = synalinks.Field(\n                description=\"The critique of the above thinking\",\n            )\n            answer: str = synalinks.Field(\n                description=\"The correct answer\",\n            )\n\n        language_model = synalinks.LanguageModel(\n            model=\"ollama/mistral\",\n        )\n\n        x0 = synalinks.Input(data_model=Query)\n        x1 = await synalinks.Generator(\n            data_model=AnswerWithCritique,\n            language_model=language_model,\n        )(x0)\n\n        program = synalinks.Program(\n            inputs=x0,\n            outputs=x1,\n            name=\"chain_of_thought_with_critique\",\n            description=\"Useful to answer step by step and evaluate your answer\",\n        )\n\n    if __name__ == \"__main__\":\n        asyncio.run(main())\n    ```\n\n    Args:\n        schema (dict): The target JSON schema.\n            If not provided use the `data_model` to infer it.\n        data_model (DataModel | SymbolicDataModel | JsonDataModel): The target data\n            model for structured output.\n        language_model (LanguageModel): The language model to use.\n        prompt_template (str): The jinja2 prompt template.\n        examples (list): The default list of examples, the examples\n            are a list of tuples containing input/output JSON pairs.\n        instructions (list): The default instructions being a list of string containing\n            addtional instructions for the language model.\n        use_inputs_schema (bool): Optional. Whether or not use the inputs schema in\n            the prompt (Default to False).\n        use_outputs_schema (bool): Optional. Whether or not use the outputs schema in\n            the prompt (Default to False).\n        return_inputs (bool): Optional. Whether or not to concatenate the inputs to\n            the outputs (Default to False).\n        streaming (str): Optional. If true stream the LM response, enabled only if\n            `schema` is `None` and only during inference (not during training).\n        name (str): Optional. The name of the module.\n        description (str): Optional. The description of the module.\n        trainable (bool): Whether the module's variables should be trainable.\n    \"\"\"\n\n    def __init__(\n        self,\n        schema=None,\n        data_model=None,\n        language_model=None,\n        prompt_template=None,\n        examples=None,\n        instructions=None,\n        use_inputs_schema=False,\n        use_outputs_schema=False,\n        return_inputs=False,\n        streaming=False,\n        name=None,\n        description=None,\n        trainable=True,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n            trainable=trainable,\n        )\n        if not schema and data_model:\n            schema = data_model.get_schema()\n        self.schema = schema\n        self.language_model = language_model\n        if not prompt_template:\n            prompt_template = default_prompt_template()\n        self.prompt_template = prompt_template\n        if not examples:\n            examples = []\n        self.examples = examples\n        if not instructions:\n            instructions = []\n        self.instructions = instructions\n\n        self.return_inputs = return_inputs\n        self.use_inputs_schema = use_inputs_schema\n        self.use_outputs_schema = use_outputs_schema\n        if schema and streaming:\n            streaming = False\n        self.streaming = streaming\n\n        predictions = [\n            Prediction(\n                inputs=example[0],\n                outputs=example[1],\n            )\n            for example in examples\n        ]\n\n        self.state = self.add_variable(\n            initializer=GeneratorState(\n                prompt_template=prompt_template,\n                examples=predictions,\n                predictions=predictions,\n                instructions=Instructions(instructions=instructions),\n            ).get_json(),\n            data_model=GeneratorState,\n            name=self.name + \"_state\",\n        )\n\n    async def call(self, inputs, training=False):\n        if not inputs:\n            return None\n        msgs = ChatMessages()\n        msgs.messages = self.format_messages(inputs)\n        if self.streaming and not training:\n            streaming = True\n        else:\n            streaming = False\n        result = await ops.predict(\n            msgs,\n            schema=self.schema,\n            language_model=self.language_model,\n            streaming=streaming,\n            name=self.name + \"_prediction\",\n        )\n        if streaming:\n            return result\n        if result:\n            if training:\n                self.state.get(\"predictions\").append(\n                    Prediction(\n                        inputs=inputs.get_json(),\n                        outputs=result.get_json(),\n                    ).get_json()\n                )\n            if self.return_inputs:\n                return await ops.concat(\n                    inputs,\n                    result,\n                    name=self.name + \"_with_inputs\",\n                )\n            else:\n                return result\n        return None\n\n    async def compute_output_spec(self, inputs, training=False):\n        if self.schema:\n            if self.return_inputs:\n                return await ops.concat(\n                    inputs,\n                    SymbolicDataModel(\n                        schema=self.schema,\n                        name=self.name,\n                    ),\n                    name=self.name + \"_with_inputs\",\n                )\n            else:\n                return SymbolicDataModel(\n                    schema=self.schema,\n                    name=self.name,\n                )\n        else:\n            if self.return_inputs:\n                return await ops.concat(\n                    inputs,\n                    SymbolicDataModel(\n                        schema=ChatMessage.get_schema(),\n                        name=self.name,\n                    ),\n                    name=self.name + \"_with_inputs\",\n                )\n            else:\n                return SymbolicDataModel(\n                    schema=ChatMessage.get_schema(),\n                    name=self.name,\n                )\n\n    def format_messages(self, inputs=None):\n        template = jinja2.Template(self.state.get(\"prompt_template\"))\n        rendered_prompt = template.render(\n            inputs_schema=inputs.get_schema() if self.use_inputs_schema else None,\n            outputs_schema=self.schema if self.use_outputs_schema else None,\n            examples=[\n                (pred.get(\"inputs\"), pred.get(\"outputs\"))\n                for pred in self.state.get(\"examples\")\n            ],\n            instructions=self.state.get(\"instructions\").get(\"instructions\"),\n            inputs=inputs.get_json(),\n        )\n        matches = XML_TAGS_REGEX.findall(rendered_prompt)\n        extracted_tags = [(match[0], match[1].strip()) for match in matches]\n        messages = []\n        for message in extracted_tags:\n            role, content = message\n            if content:\n                messages.append(ChatMessage(role=role, content=content))\n        return messages\n\n    def get_config(self):\n        config = {\n            \"schema\": self.schema,\n            \"prompt_template\": self.prompt_template,\n            \"examples\": self.examples,\n            \"instructions\": self.instructions,\n            \"use_inputs_schema\": self.use_inputs_schema,\n            \"use_outputs_schema\": self.use_outputs_schema,\n            \"return_inputs\": self.return_inputs,\n            \"name\": self.name,\n            \"description\": self.description,\n            \"trainable\": self.trainable,\n        }\n        language_model_config = {\n            \"language_model\": serialization_lib.serialize_synalinks_object(\n                self.language_model,\n            )\n        }\n        return {**config, **language_model_config}\n\n    @classmethod\n    def from_config(cls, config):\n        language_model = serialization_lib.deserialize_synalinks_object(\n            config.pop(\"language_model\"),\n        )\n        return cls(language_model=language_model, **config)\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Core%20Modules/Generator%20module/#synalinks.src.modules.core.generator.GeneratorState","title":"<code>GeneratorState</code>","text":"<p>               Bases: <code>DataModel</code></p> <p>The generator variables.</p> Source code in <code>synalinks/src/modules/core/generator.py</code> <pre><code>class GeneratorState(DataModel):\n    \"\"\"The generator variables.\"\"\"\n\n    prompt_template: str = None\n    examples: List[Prediction] = []\n    predictions: List[Prediction] = []\n    instructions: Instructions\n    instructions_candidates: List[Instructions] = []\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Core%20Modules/Generator%20module/#synalinks.src.modules.core.generator.chat_prompt_template","title":"<code>chat_prompt_template()</code>","text":"<p>Returns the default chat prompt template.</p> <p>Returns:</p> Type Description <code>str</code> <p>The default chat prompt template.</p> Source code in <code>synalinks/src/modules/core/generator.py</code> <pre><code>@synalinks_export(\"synalinks.chat_prompt_template\")\ndef chat_prompt_template():\n    \"\"\"Returns the default chat prompt template.\n\n    Returns:\n        (str): The default chat prompt template.\n    \"\"\"\n    return \"\"\"\n&lt;system&gt;\n{% if instructions %}\n### Instructions:\n{% for instruction in instructions %}\n - {{ instruction }}\n{% endfor %}{% endif %}\n&lt;/system&gt;\n{% for message in inputs.messages %}\n{% if message.role == \"assistant\" %}\n&lt;assistant&gt;\n{{ message.content }}\n&lt;/assistant&gt;\n{% elif message.role == \"user\" %}\n&lt;user&gt;\n{{ message.content }}\n&lt;/user&gt;\n{% else %}{% endif %}\n{% endfor %}\n\"\"\"\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Core%20Modules/Generator%20module/#synalinks.src.modules.core.generator.default_prompt_template","title":"<code>default_prompt_template()</code>","text":"<p>Returns the default prompt template.</p> <p>Returns:</p> Type Description <code>str</code> <p>The default prompt template.</p> Source code in <code>synalinks/src/modules/core/generator.py</code> <pre><code>@synalinks_export(\"synalinks.default_prompt_template\")\ndef default_prompt_template():\n    \"\"\"Returns the default prompt template.\n\n    Returns:\n        (str): The default prompt template.\n    \"\"\"\n    return \"\"\"\n&lt;system&gt;\n{% if inputs_schema %}You will be given an input JSON object with the following schema. \nInput JSON Schema:\n{{ inputs_schema }}\n{% endif %}\n{% if outputs_schema %}\nYour task is to answer with a JSON object following this output JSON schema.\n\nOutput JSON Schema:\n{{ outputs_schema }}\n{% endif %}\n{% if examples %}\n### Examples\n{% for example in examples %}\nInput:\n{{ example[0] }}\nOutput:\n{{ example[1] }}\n{% endfor %}\n{% endif %}\n{% if instructions %}\n### Instructions:\n{% for instruction in instructions %}\n - {{ instruction }}\n{% endfor %}\n{% endif %}\n&lt;/system&gt;\n&lt;user&gt;\nInput:\n{{ inputs }}\nOutput:\n&lt;/user&gt;\"\"\"\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Core%20Modules/Identity%20module/","title":"Identity module","text":""},{"location":"Synalinks%20API/Modules%20API/Core%20Modules/Identity%20module/#synalinks.src.modules.core.identity.Identity","title":"<code>Identity</code>","text":"<p>               Bases: <code>Module</code></p> <p>Identity module.</p> <p>This module should be used as a placeholder when no operation is to be performed. The module just returns its <code>inputs</code> argument as output.</p> <p>This module can be really useful during development process in order to implement the whole program architecture before the individual modules.</p> <p>It avoid any data models naming issue that you could have by just forwarding the inputs, that way you can implement the general program architecture, validate it and implement the individual modules later.</p> <p>Example:</p> <pre><code>import synalinks\n\nclass MyAwesomeModule(synalinks.Program):\n\n    def __init__(\n        name=None,\n        description=None,\n        trainable=True,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n            trainable=trainable,\n        )\n\n    async def build(self, inputs):\n        outputs = await synalinks.Identity()(inputs)\n\n        super().__init__(\n            inputs=inputs,\n            outputs=outputs,\n            name=self.name,\n            description=self.description,\n            trainable=self.trainable,\n        )\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>keyword arguments</code> <p>The default module's arguments</p> <code>{}</code> Source code in <code>synalinks/src/modules/core/identity.py</code> <pre><code>@synalinks_export([\"synalinks.modules.Identity\", \"synalinks.Identity\"])\nclass Identity(Module):\n    \"\"\"Identity module.\n\n    This module should be used as a placeholder when no operation is to be\n    performed. The module just returns its `inputs` argument as output.\n\n    This module can be really useful during development process in order to\n    implement the whole program architecture before the individual modules.\n\n    It avoid any data models naming issue that you could have by just\n    forwarding the inputs, that way you can implement the general\n    program architecture, validate it and implement the individual\n    modules later.\n\n    Example:\n\n    ```python\n    import synalinks\n\n    class MyAwesomeModule(synalinks.Program):\n\n        def __init__(\n            name=None,\n            description=None,\n            trainable=True,\n        ):\n            super().__init__(\n                name=name,\n                description=description,\n                trainable=trainable,\n            )\n\n        async def build(self, inputs):\n            outputs = await synalinks.Identity()(inputs)\n\n            super().__init__(\n                inputs=inputs,\n                outputs=outputs,\n                name=self.name,\n                description=self.description,\n                trainable=self.trainable,\n            )\n    ```\n\n    Args:\n        **kwargs (keyword arguments): The default module's arguments\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.built = True\n\n    async def call(self, inputs):\n        if isinstance(inputs, (JsonDataModel, SymbolicDataModel)):\n            return inputs.clone()\n        return tree.map_structure(\n            lambda x: x.clone(),\n            inputs,\n        )\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Core%20Modules/Input%20module/","title":"Input module","text":""},{"location":"Synalinks%20API/Modules%20API/Core%20Modules/Input%20module/#synalinks.src.modules.core.input_module.Input","title":"<code>Input(schema=None, data_model=None, optional=False, name=None)</code>","text":"<p>Used to instantiate a <code>SymbolicDataModel</code>.</p> <p>A <code>SymbolicDataModel</code> is a symbolic data model-like object, which we augment with certain attributes that allow us to build a Synalinks <code>Program</code> just by knowing the inputs and outputs of the program (similar to Keras symbolic tensor).</p> <p>Example:</p> <pre><code>import synalinks\n\nclass Query(synalinks.DataModel):\n    query: str\n\ninputs = synalinks.Input(data_model=Query)\n\n# You can also create it using a JSON schema like this:\n\ninputs = synalinks.Input(schema=Query.get_schema())\n\n# Or using a symbolic datamodel:\n\ninputs = synalinks.Input(data_model=Query.to_symbolic_data_model())\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>dict</code> <p>A Json schema of the data_model. If not provided uses the <code>data_model</code> argument.</p> <code>None</code> <code>data_model</code> <code>DataModel</code> <p>Optional existing data model to wrap into the <code>Input</code> layer. If set, the module will use this data_model rather than creating a new placeholder data model.</p> <code>None</code> <code>optional</code> <code>bool</code> <p>Whether the input is optional or not. An optional input can accept <code>None</code> values.</p> <code>False</code> <code>name</code> <code>string</code> <p>Optional name string for the module. Should be unique in a program (do not reuse the same name twice). It will be autogenerated if it isn't provided.</p> <code>None</code> <p>Returns:</p> Type Description <code>SymbolicDataModel</code> <p>The symbolic data model corresponding to the given data model/schema.</p> Source code in <code>synalinks/src/modules/core/input_module.py</code> <pre><code>@synalinks_export([\"synalinks.modules.Input\", \"synalinks.Input\"])\ndef Input(\n    schema=None,\n    data_model=None,\n    optional=False,\n    name=None,\n):\n    \"\"\"Used to instantiate a `SymbolicDataModel`.\n\n    A `SymbolicDataModel` is a symbolic data model-like object, which we augment with\n    certain attributes that allow us to build a Synalinks `Program` just by knowing the\n    inputs and outputs of the program (similar to Keras symbolic tensor).\n\n    Example:\n\n    ```python\n    import synalinks\n\n    class Query(synalinks.DataModel):\n        query: str\n\n    inputs = synalinks.Input(data_model=Query)\n\n    # You can also create it using a JSON schema like this:\n\n    inputs = synalinks.Input(schema=Query.get_schema())\n\n    # Or using a symbolic datamodel:\n\n    inputs = synalinks.Input(data_model=Query.to_symbolic_data_model())\n    ```\n\n    Args:\n        schema (dict): A Json schema of the data_model.\n            If not provided uses the `data_model` argument.\n        data_model (DataModel): Optional existing data model to wrap into\n            the `Input` layer. If set, the module will use this data_model rather\n            than creating a new placeholder data model.\n        optional (bool): Whether the input is optional or not.\n            An optional input can accept `None` values.\n        name (string): Optional name string for the module.\n            Should be unique in a program (do not reuse the same name twice).\n            It will be autogenerated if it isn't provided.\n\n    Returns:\n        (SymbolicDataModel): The symbolic data model corresponding to\n            the given data model/schema.\n    \"\"\"\n    module = InputModule(\n        schema=schema,\n        input_data_model=data_model.to_symbolic_data_model() if data_model else None,\n        optional=optional,\n        name=name,\n    )\n    return module.output\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Core%20Modules/Not%20module/","title":"Not module","text":""},{"location":"Synalinks%20API/Modules%20API/Core%20Modules/Not%20module/#synalinks.src.modules.core.not_module.Not","title":"<code>Not</code>","text":"<p>               Bases: <code>Module</code></p> <p>Not module.</p> <p>This module should be used as a placeholder when no operation is to be performed and the output should be None.</p> <p>This module is useful to implement stop conditions when combined with a conditional branch or as placeholder (like the Identity) before implementing guards that leverage the xor operation.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>keyword arguments</code> <p>The default module's arguments</p> <code>{}</code> Source code in <code>synalinks/src/modules/core/not_module.py</code> <pre><code>@synalinks_export([\"synalinks.modules.Not\", \"synalinks.Not\"])\nclass Not(Module):\n    \"\"\"Not module.\n\n    This module should be used as a placeholder when no operation is to be\n    performed and the output should be None.\n\n    This module is useful to implement stop conditions when combined with a conditional\n    branch or as placeholder (like the Identity) before implementing guards that leverage\n    the xor operation.\n\n    Args:\n        **kwargs (keyword arguments): The default module's arguments\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.built = True\n\n    async def call(self, inputs):\n        if isinstance(inputs, (JsonDataModel, SymbolicDataModel)):\n            return None\n        return tree.map_structure(\n            lambda x: None,\n            inputs,\n        )\n\n    async def compute_output_spec(self, inputs):\n        if isinstance(inputs, (JsonDataModel, SymbolicDataModel)):\n            return inputs.clone()\n        return tree.map_structure(\n            lambda x: x.clone(),\n            inputs,\n        )\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Knowledge%20Modules/","title":"Knowledge Modules","text":"<ul> <li>Embedding module</li> <li>UpdateKnowledge module</li> <li>EntityRetriever module</li> <li>KnowledgeRetriever module</li> </ul>"},{"location":"Synalinks%20API/Modules%20API/Knowledge%20Modules/Embedding%20module/","title":"Embedding module","text":""},{"location":"Synalinks%20API/Modules%20API/Knowledge%20Modules/Embedding%20module/#synalinks.src.modules.knowledge.embedding.Embedding","title":"<code>Embedding</code>","text":"<p>               Bases: <code>Module</code></p> <p>Extracts and updates the embedding vector of entities.</p> <p>This module is designed to work with <code>Entity</code>, <code>Relation</code>, <code>Entities</code>, <code>Relations</code> or <code>KnowledgeGraph</code> data models. It supports to mask the entity fields in order to keep only one field to embed per entity.</p> <p>Note: Each entity should have the same field to compute the embedding     from like a <code>name</code> or <code>description</code> field using <code>in_mask</code>.     Or every entity should have only one field left after masking using     <code>out_mask</code> argument.</p> <pre><code>import synalinks\nimport asyncio\nfrom typing import Literal\n\nclass Document(synalinks.Entity):\n    label: Literal[\"Document\"]\n    text: str = synalinks.Field(\n        description=\"The document content\",\n    )\n\nasync def main():\n    inputs = synalinks.Input(data_model=Document)\n    outputs = await synalinks.Embedding(\n        embedding_model=embedding_model,\n        in_mask=[\"text\"],\n    )(inputs)\n\n    program = synalinks.Program(\n        inputs=inputs,\n        outputs=outputs,\n        name=\"embbed_document\",\n        description=\"Embbed the given documents\"\n    )\n\n    doc = Document(\n        label=\"Document\",\n        text=\"my document\",\n    )\n\n    result = await program(doc)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>If you want to process batch asynchronously use <code>program.predict()</code> instead, see the FAQ to understand the difference between <code>program()</code> and <code>program.predict()</code></p> <p>Here is an example:</p> <pre><code>import synalinks\nimport asyncio\nimport numpy as np\nfrom typing import Literal\n\nclass Document(synalinks.Entity):\n    label: Literal[\"Document\"]\n    text: str = synalinks.Field(\n        description=\"The document content\",\n    )\n\nasync def main():\n    inputs = synalinks.Input(data_model=Document)\n    outputs = await synalinks.Embedding(\n        embedding_model=embedding_model,\n        in_mask=[\"text\"],\n    )(inputs)\n\n    program = synalinks.Program(\n        inputs=inputs,\n        outputs=outputs,\n        name=\"embbed_document\",\n        description=\"Embbed the given documents\"\n    )\n\n    doc1 = Document(label=\"Document\", text=\"my document 1\")\n    doc2 = Document(label=\"Document\", text=\"my document 2\")\n    doc3 = Document(label=\"Document\", text=\"my document 3\")\n\n    docs = np.array([doc1, doc2, doc3], dtype=\"object\")\n\n    embedded_docs = await program.predict(docs)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>embedding_model</code> <code>EmbeddingModel</code> <p>The embedding model to use.</p> <code>None</code> <code>in_mask</code> <code>list</code> <p>A mask applied to keep specific entity fields.</p> <code>None</code> <code>out_mask</code> <code>list</code> <p>A mask applied to remove specific entity fields.</p> <code>None</code> <code>name</code> <code>str</code> <p>Optional. The name of the module.</p> <code>None</code> <code>description</code> <code>str</code> <p>Optional. The description of the module.</p> <code>None</code> <code>trainable</code> <code>bool</code> <p>Whether the module's variables should be trainable.</p> <code>False</code> Source code in <code>synalinks/src/modules/knowledge/embedding.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.modules.Embedding\",\n        \"synalinks.Embedding\",\n    ]\n)\nclass Embedding(Module):\n    \"\"\"Extracts and updates the embedding vector of entities.\n\n    This module is designed to work with `Entity`, `Relation`, `Entities`,\n    `Relations` or `KnowledgeGraph` data models. It supports to mask the\n    entity fields in order to keep **only one** field to embed per entity.\n\n    **Note**: Each entity should have the *same field* to compute the embedding\n        from like a `name` or `description` field using `in_mask`.\n        **Or** every entity should have *only one field left* after masking using\n        `out_mask` argument.\n\n    ```python\n    import synalinks\n    import asyncio\n    from typing import Literal\n\n    class Document(synalinks.Entity):\n        label: Literal[\"Document\"]\n        text: str = synalinks.Field(\n            description=\"The document content\",\n        )\n\n    async def main():\n        inputs = synalinks.Input(data_model=Document)\n        outputs = await synalinks.Embedding(\n            embedding_model=embedding_model,\n            in_mask=[\"text\"],\n        )(inputs)\n\n        program = synalinks.Program(\n            inputs=inputs,\n            outputs=outputs,\n            name=\"embbed_document\",\n            description=\"Embbed the given documents\"\n        )\n\n        doc = Document(\n            label=\"Document\",\n            text=\"my document\",\n        )\n\n        result = await program(doc)\n\n    if __name__ == \"__main__\":\n        asyncio.run(main())\n    ```\n\n    If you want to process batch asynchronously\n    use `program.predict()` instead, see the [FAQ](https://synalinks.github.io/synalinks/FAQ/#whats-the-difference-between-program-methods-predict-and-__call__)\n    to understand the difference between `program()` and `program.predict()`\n\n    Here is an example:\n\n    ```python\n    import synalinks\n    import asyncio\n    import numpy as np\n    from typing import Literal\n\n    class Document(synalinks.Entity):\n        label: Literal[\"Document\"]\n        text: str = synalinks.Field(\n            description=\"The document content\",\n        )\n\n    async def main():\n        inputs = synalinks.Input(data_model=Document)\n        outputs = await synalinks.Embedding(\n            embedding_model=embedding_model,\n            in_mask=[\"text\"],\n        )(inputs)\n\n        program = synalinks.Program(\n            inputs=inputs,\n            outputs=outputs,\n            name=\"embbed_document\",\n            description=\"Embbed the given documents\"\n        )\n\n        doc1 = Document(label=\"Document\", text=\"my document 1\")\n        doc2 = Document(label=\"Document\", text=\"my document 2\")\n        doc3 = Document(label=\"Document\", text=\"my document 3\")\n\n        docs = np.array([doc1, doc2, doc3], dtype=\"object\")\n\n        embedded_docs = await program.predict(docs)\n\n    if __name__ == \"__main__\":\n        asyncio.run(main())\n    ```\n\n    Args:\n        embedding_model (EmbeddingModel): The embedding model to use.\n        in_mask (list): A mask applied to keep specific entity fields.\n        out_mask (list): A mask applied to remove specific entity fields.\n        name (str): Optional. The name of the module.\n        description (str): Optional. The description of the module.\n        trainable (bool): Whether the module's variables should be trainable.\n    \"\"\"\n\n    def __init__(\n        self,\n        embedding_model=None,\n        in_mask=None,\n        out_mask=None,\n        name=None,\n        description=None,\n        trainable=False,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n            trainable=trainable,\n        )\n        self.embedding_model = embedding_model\n        self.in_mask = in_mask\n        self.out_mask = out_mask\n\n    async def _embed_entity(self, entity):\n        # # Check if entity is already embedded and has valid embeddings\n        embeddings = entity.get(\"embeddings\")\n        if embeddings:\n            warnings.warn(\n                \"Embeddings already generated for entity.Returning original entity.\"\n            )\n            return JsonDataModel(\n                json=entity.get_json(),\n                schema=entity.get_schema(),\n                name=entity.name + \"_embedded\",\n            )\n        # Apply masking to the entity\n        filtered_entity = entity  # Default to original entity\n\n        if self.out_mask:\n            filtered_entity = await ops.out_mask(\n                entity,\n                mask=self.out_mask,\n                recursive=False,\n                name=entity.name + \"_out_mask\",\n            )\n        elif self.in_mask:\n            filtered_entity = await ops.in_mask(\n                entity,\n                mask=self.in_mask,\n                recursive=False,\n                name=entity.name + \"_in_mask\",\n            )\n\n        # Generate embeddings\n        embeddings = await ops.embedding(\n            filtered_entity,\n            embedding_model=self.embedding_model,\n            name=entity.name + \"_embedding\",\n        )\n\n        # Validate embeddings\n        if not embeddings or not embeddings.get(\"embeddings\"):\n            warnings.warn(\n                f\"No embeddings generated for entity {entity.name}. \"\n                \"Please check that your schema is correct.\"\n            )\n            return None\n\n        embedding_list = embeddings.get(\"embeddings\")\n        if len(embedding_list) != 1:\n            warnings.warn(\n                \"Entities can only have one embedding vector per entity, \"\n                \"adjust `Embedding` module's `in_mask` or `out_mask` \"\n                \"to keep only one field. Skipping embedding.\"\n            )\n            return None\n\n        # Add embedding to entity\n        vector = embedding_list[0]\n        return await ops.concat(\n            entity,\n            EmbeddingVector(embedding=vector),\n            name=entity.name + \"_embedded\",\n        )\n\n    async def _embed_relation(self, relation):\n        subj = relation.get_nested_entity(\"subj\")\n        obj = relation.get_nested_entity(\"obj\")\n        if not subj or not obj:\n            return None\n        embedded_subj = await self._embed_entity(subj)\n        embedded_obj = await self._embed_entity(obj)\n\n        relation_json = copy.deepcopy(relation.get_json())\n        relation_json.update(\n            {\n                \"subj\": embedded_subj.get_json(),\n                \"obj\": embedded_obj.get_json(),\n            }\n        )\n        outputs_schema = copy.deepcopy(relation.get_schema())\n\n        # Update schema definitions for embedded entities\n        if outputs_schema.get(\"$defs\"):\n            subj_label = subj.get(\"label\")\n            obj_label = obj.get(\"label\")\n\n            if subj_label and subj_label in outputs_schema[\"$defs\"]:\n                embedded_subj_schema = embedded_subj.get_schema()\n                if embedded_subj_schema.get(\"properties\"):\n                    outputs_schema[\"$defs\"][subj_label][\"properties\"].update(\n                        embedded_subj_schema[\"properties\"]\n                    )\n\n            if obj_label and obj_label in outputs_schema[\"$defs\"]:\n                embedded_obj_schema = embedded_obj.get_schema()\n                if embedded_obj_schema.get(\"properties\"):\n                    outputs_schema[\"$defs\"][obj_label][\"properties\"].update(\n                        embedded_obj_schema[\"properties\"]\n                    )\n\n        return JsonDataModel(\n            json=relation_json,\n            schema=outputs_schema,\n            name=relation.name + \"_embedded\",\n        )\n\n    async def call(self, inputs):\n        if not inputs:\n            return None\n        if is_knowledge_graph(inputs):\n            entities_json = []\n            relations_json = []\n            outputs_schema = copy.deepcopy(inputs.get_schema())\n\n            # Process entities\n            for entity in inputs.get_nested_entity_list(\"entities\"):\n                embedded_entity = await self._embed_entity(entity)\n                if embedded_entity:\n                    entities_json.append(embedded_entity.get_json())\n\n                    # Update schema definitions\n                    if outputs_schema.get(\"$defs\"):\n                        entity_label = entity.get(\"label\")\n                        if entity_label and entity_label in outputs_schema[\"$defs\"]:\n                            embedded_schema = embedded_entity.get_schema()\n                            if embedded_schema.get(\"properties\"):\n                                outputs_schema[\"$defs\"][entity_label][\n                                    \"properties\"\n                                ].update(embedded_schema[\"properties\"])\n            # Process relations\n            for relation in inputs.get_nested_entity_list(\"relations\"):\n                embedded_relation = await self._embed_relation(relation)\n                if embedded_relation:\n                    relations_json.append(embedded_relation.get_json())\n\n                    embedded_schema = embedded_relation.get_schema()\n                    if embedded_schema.get(\"$defs\") and outputs_schema.get(\"$defs\"):\n                        for def_key, def_value in embedded_schema[\"$defs\"].items():\n                            if def_key in outputs_schema[\"$defs\"]:\n                                # Merge properties if they exist\n                                if def_value.get(\"properties\") and outputs_schema[\n                                    \"$defs\"\n                                ][def_key].get(\"properties\"):\n                                    outputs_schema[\"$defs\"][def_key][\"properties\"].update(\n                                        def_value[\"properties\"]\n                                    )\n                                else:\n                                    outputs_schema[\"$defs\"][def_key] = def_value\n\n            # Update output JSON\n            outputs_json = inputs.get_json()\n            outputs_json.update({\"entities\": entities_json, \"relations\": relations_json})\n            return JsonDataModel(\n                json=outputs_json,\n                schema=outputs_schema,\n                name=inputs.name + \"_embedded\",\n            )\n\n        elif is_entities(inputs):\n            entities_json = []\n            outputs_schema = copy.deepcopy(inputs.get_schema())\n\n            # Process all entities and collect schema updates\n            for entity in inputs.get_nested_entity_list(\"entities\"):\n                embedded_entity = await self._embed_entity(entity)\n                if embedded_entity:\n                    entities_json.append(embedded_entity.get_json())\n\n                    # Update schema definitions\n                    if outputs_schema.get(\"$defs\"):\n                        entity_label = entity.get(\"label\")\n                        if entity_label and entity_label in outputs_schema[\"$defs\"]:\n                            embedded_schema = embedded_entity.get_schema()\n                            if embedded_schema.get(\"properties\"):\n                                outputs_schema[\"$defs\"][entity_label][\n                                    \"properties\"\n                                ].update(embedded_schema[\"properties\"])\n\n            # Update output JSON with embedded entities\n            outputs_json = inputs.get_json()\n            outputs_json.update({\"entities\": entities_json})\n\n            return JsonDataModel(\n                json=outputs_json,\n                schema=outputs_schema,\n                name=inputs.name + \"_embedded\",\n            )\n\n        elif is_relations(inputs):\n            relations_json = []\n            outputs_schema = copy.deepcopy(inputs.get_schema())\n\n            # Process all relations\n            for relation in inputs.get_nested_entity_list(\"relations\"):\n                embedded_relation = await self._embed_relation(relation)\n                if embedded_relation:\n                    relations_json.append(embedded_relation.get_json())\n\n                    # Merge schema definitions from embedded relation\n                    embedded_schema = embedded_relation.get_schema()\n                    if embedded_schema.get(\"$defs\") and outputs_schema.get(\"$defs\"):\n                        for def_key, def_value in embedded_schema[\"$defs\"].items():\n                            if def_key in outputs_schema[\"$defs\"]:\n                                # Merge properties if they exist\n                                if def_value.get(\"properties\") and outputs_schema[\n                                    \"$defs\"\n                                ][def_key].get(\"properties\"):\n                                    outputs_schema[\"$defs\"][def_key][\"properties\"].update(\n                                        def_value[\"properties\"]\n                                    )\n                                else:\n                                    outputs_schema[\"$defs\"][def_key] = def_value\n\n            # Update output JSON\n            outputs_json = inputs.get_json()\n            outputs_json.update({\"relations\": relations_json})\n\n            return JsonDataModel(\n                json=outputs_json,\n                schema=outputs_schema,\n                name=inputs.name + \"_embedded\",\n            )\n        elif is_relation(inputs):\n            return await self._embed_relation(inputs)\n        elif is_entity(inputs):\n            return await self._embed_entity(inputs)\n        else:\n            return None\n\n    async def compute_output_spec(self, inputs):\n        return inputs.clone(name=inputs.name + \"_embedded\")\n\n    def get_config(self):\n        config = {\n            \"in_mask\": self.in_mask,\n            \"out_mask\": self.out_mask,\n            \"name\": self.name,\n            \"description\": self.description,\n            \"trainable\": self.trainable,\n        }\n        embedding_model_config = {\n            \"embedding_model\": serialization_lib.serialize_synalinks_object(\n                self.embedding_model\n            )\n        }\n        return {**embedding_model_config, **config}\n\n    @classmethod\n    def from_config(cls, config):\n        embedding_model = serialization_lib.deserialize_synalinks_object(\n            config.pop(\"embedding_model\")\n        )\n        return cls(embedding_model=embedding_model, **config)\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Knowledge%20Modules/EntityRetriever%20module/","title":"EntityRetriever module","text":""},{"location":"Synalinks%20API/Modules%20API/Knowledge%20Modules/EntityRetriever%20module/#synalinks.src.modules.knowledge.entity_retriever.EntityRetriever","title":"<code>EntityRetriever</code>","text":"<p>               Bases: <code>Module</code></p> <p>Retrieve entities from a knowledge base, based on the embedding vector.</p> <p>This module is useful to implement vector-only (retrieval augmented generation) RAG systems, for KAG (knowledge augmented generation) systems see the <code>KnowledgeRetriever</code> module.</p> <p>If you give multiple entity models to this module, the LM will select the most suitable one to perform the search. Having multiple entity models to search for is an easy way to enhance the performance of you RAG system by having multiple indexes (one per entity model).</p> <pre><code>import synalinks\nimport asyncio\nfrom typing import Literal\n\nclass Query(synalinks.DataModel):\n    query: str = synalinks.Field(\n        description=\"The user query\",\n    )\n\nclass Answer(synalinks.DataModel):\n    query: str = synalinks.Field(\n        description=\"The answer to the user query\",\n    )\n\nclass Document(synalinks.Entity):\n    label: Literal[\"Document\"]\n    content: str = synalinks.Field(\n        description=\"The document's content\",\n    )\n\nclass Chunk(synalinks.Entity):\n    label: Literal[\"Chunk\"]\n    content: str = synalinks.Field(\n        description=\"The chunk's content\",\n    )\n\nclass IsPartOf(synalinks.Relation):\n    subj: Chunk\n    label: Literal[\"IsPartOf\"]\n    obj: Document\n\nknowledge_base = synalinks.KnowledgeBase(\n    index_name=\"neo4j://localhost:7687\",\n    entity_models=[Document, Chunk],\n    relation_models=[IsPartOf],\n    embedding_model=embedding_model,\n    metric=\"cosine\",\n    wipe_on_start=False,\n)\n\nlanguage_model = synalinks.LanguageModel(\n    model=\"ollama/mistral\",\n)\n\nasync def main():\n    inputs = synalinks.Input(data_model=Query)\n    x = await synalinks.EntityRetriever(\n        entity_models=[Chunk],\n        language_model=language_model,\n        knowledge_base=knowledge_base,\n    )(inputs)\n    outputs = await synalinks.Generator(\n        data_model=Answer,\n        language_model=language_model,\n    )(x)\n\n    program = synalinks.Program(\n        inputs=inputs,\n        outputs=outputs,\n        name=\"rag_program\",\n        description=\"A naive RAG program\",\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>knowledge_base</code> <code>KnowledgeBase</code> <p>The knowledge base to use.</p> <code>None</code> <code>language_model</code> <code>LanguageModel</code> <p>The language model to use.</p> <code>None</code> <code>entity_models</code> <code>list</code> <p>The list of entities models to search for being a list of <code>Entity</code> data models.</p> <code>None</code> <code>k</code> <code>int</code> <p>Maximum number of similar entities to return (Defaults to 10).</p> <code>10</code> <code>threshold</code> <code>float</code> <p>Minimum similarity score for results. Entities with similarity below this threshold are excluded. Should be between 0.0 and 1.0 (Defaults to 0.7).</p> <code>0.7</code> <code>prompt_template</code> <code>str</code> <p>The default jinja2 prompt template to use (see <code>Generator</code>).</p> <code>None</code> <code>examples</code> <code>list</code> <p>The default examples to use in the prompt (see <code>Generator</code>).</p> <code>None</code> <code>instructions</code> <code>list</code> <p>The default instructions to use (see <code>Generator</code>).</p> <code>None</code> <code>use_inputs_schema</code> <code>bool</code> <p>Optional. Whether or not use the inputs schema in the prompt (Default to False) (see <code>Generator</code>).</p> <code>False</code> <code>use_outputs_schema</code> <code>bool</code> <p>Optional. Whether or not use the outputs schema in the prompt (Default to False) (see <code>Generator</code>).</p> <code>False</code> <code>return_inputs</code> <code>bool</code> <p>Optional. Whether or not to concatenate the inputs to the outputs (Default to True).</p> <code>True</code> <code>return_query</code> <code>bool</code> <p>Optional. Whether or not to concatenate the search query to the outputs (Default to True).</p> <code>True</code> <code>name</code> <code>str</code> <p>Optional. The name of the module.</p> <code>None</code> <code>description</code> <code>str</code> <p>Optional. The description of the module.</p> <code>None</code> <code>trainable</code> <code>bool</code> <p>Whether the module's variables should be trainable.</p> <code>True</code> Source code in <code>synalinks/src/modules/knowledge/entity_retriever.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.modules.EntityRetriever\",\n        \"synalinks.EntityRetriever\",\n    ]\n)\nclass EntityRetriever(Module):\n    \"\"\"Retrieve entities from a knowledge base, based on the embedding vector.\n\n    This module is useful to implement vector-only (retrieval augmented generation) RAG\n    systems, for KAG (knowledge augmented generation) systems see the\n    `KnowledgeRetriever` module.\n\n    If you give multiple entity models to this module, the LM will select the most\n    suitable one to perform the search. Having multiple entity models to search\n    for is an easy way to enhance the performance of you RAG system by having\n    multiple indexes (one per entity model).\n\n    ```python\n    import synalinks\n    import asyncio\n    from typing import Literal\n\n    class Query(synalinks.DataModel):\n        query: str = synalinks.Field(\n            description=\"The user query\",\n        )\n\n    class Answer(synalinks.DataModel):\n        query: str = synalinks.Field(\n            description=\"The answer to the user query\",\n        )\n\n    class Document(synalinks.Entity):\n        label: Literal[\"Document\"]\n        content: str = synalinks.Field(\n            description=\"The document's content\",\n        )\n\n    class Chunk(synalinks.Entity):\n        label: Literal[\"Chunk\"]\n        content: str = synalinks.Field(\n            description=\"The chunk's content\",\n        )\n\n    class IsPartOf(synalinks.Relation):\n        subj: Chunk\n        label: Literal[\"IsPartOf\"]\n        obj: Document\n\n    knowledge_base = synalinks.KnowledgeBase(\n        index_name=\"neo4j://localhost:7687\",\n        entity_models=[Document, Chunk],\n        relation_models=[IsPartOf],\n        embedding_model=embedding_model,\n        metric=\"cosine\",\n        wipe_on_start=False,\n    )\n\n    language_model = synalinks.LanguageModel(\n        model=\"ollama/mistral\",\n    )\n\n    async def main():\n        inputs = synalinks.Input(data_model=Query)\n        x = await synalinks.EntityRetriever(\n            entity_models=[Chunk],\n            language_model=language_model,\n            knowledge_base=knowledge_base,\n        )(inputs)\n        outputs = await synalinks.Generator(\n            data_model=Answer,\n            language_model=language_model,\n        )(x)\n\n        program = synalinks.Program(\n            inputs=inputs,\n            outputs=outputs,\n            name=\"rag_program\",\n            description=\"A naive RAG program\",\n        )\n\n    if __name__ == \"__main__\":\n        asyncio.run(main())\n    ```\n\n    Args:\n        knowledge_base (KnowledgeBase): The knowledge base to use.\n        language_model (LanguageModel): The language model to use.\n        entity_models (list): The list of entities models to search for\n            being a list of `Entity` data models.\n        k (int): Maximum number of similar entities to return\n            (Defaults to 10).\n        threshold (float): Minimum similarity score for results.\n            Entities with similarity below this threshold are excluded.\n            Should be between 0.0 and 1.0 (Defaults to 0.7).\n        prompt_template (str): The default jinja2 prompt template\n            to use (see `Generator`).\n        examples (list): The default examples to use in the prompt\n            (see `Generator`).\n        instructions (list): The default instructions to use (see `Generator`).\n        use_inputs_schema (bool): Optional. Whether or not use the inputs schema in\n            the prompt (Default to False) (see `Generator`).\n        use_outputs_schema (bool): Optional. Whether or not use the outputs schema in\n            the prompt (Default to False) (see `Generator`).\n        return_inputs (bool): Optional. Whether or not to concatenate the inputs to\n            the outputs (Default to True).\n        return_query (bool): Optional. Whether or not to concatenate the search query to\n            the outputs (Default to True).\n        name (str): Optional. The name of the module.\n        description (str): Optional. The description of the module.\n        trainable (bool): Whether the module's variables should be trainable.\n    \"\"\"\n\n    def __init__(\n        self,\n        knowledge_base=None,\n        language_model=None,\n        entity_models=None,\n        k=10,\n        threshold=0.7,\n        prompt_template=None,\n        examples=None,\n        instructions=None,\n        use_inputs_schema=False,\n        use_outputs_schema=False,\n        return_inputs=True,\n        return_query=True,\n        name=None,\n        description=None,\n        trainable=True,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n            trainable=trainable,\n        )\n        self.knowledge_base = knowledge_base\n        self.language_model = language_model\n        self.k = k\n        self.threshold = threshold\n        self.prompt_template = prompt_template\n        self.examples = examples\n        self.instructions = instructions\n        self.use_inputs_schema = use_inputs_schema\n        self.use_outputs_schema = use_outputs_schema\n        self.return_inputs = return_inputs\n        self.return_query = return_query\n\n        self.schema = SimilaritySearch.get_schema()\n\n        if entity_models:\n            node_labels = [\n                entity_model.get_schema().get(\"title\") for entity_model in entity_models\n            ]\n        else:\n            node_labels = []\n        node_labels.append(\"*\")\n\n        self.schema = dynamic_enum(\n            schema=self.schema,\n            prop_to_update=\"entity_label\",\n            labels=node_labels,\n            description=(\"The entity label to search for (use `*` to match them all)\"),\n        )\n\n        self.query_generator = Generator(\n            schema=self.schema,\n            language_model=self.language_model,\n            prompt_template=self.prompt_template,\n            examples=self.examples,\n            instructions=self.instructions,\n            use_inputs_schema=self.use_inputs_schema,\n            use_outputs_schema=self.use_outputs_schema,\n            return_inputs=False,\n            name=self.name + \"_query_generator\",\n        )\n\n    async def call(self, inputs, training=False):\n        if not inputs:\n            return None\n        similarity_search_query = await self.query_generator(\n            inputs,\n            training=training,\n        )\n        if self.return_inputs:\n            if self.return_query:\n                return await ops.concat(\n                    inputs,\n                    await ops.concat(\n                        similarity_search_query,\n                        await ops.similarity_search(\n                            similarity_search_query,\n                            knowledge_base=self.knowledge_base,\n                            k=self.k,\n                            threshold=self.threshold,\n                            name=self.name + \"_similarity_search\",\n                        ),\n                        name=self.name + \"_similarity_search_with_query_and_inputs\",\n                    ),\n                )\n            else:\n                return await ops.concat(\n                    inputs,\n                    await ops.similarity_search(\n                        similarity_search_query,\n                        knowledge_base=self.knowledge_base,\n                        k=self.k,\n                        threshold=self.threshold,\n                        name=self.name + \"_similarity_search\",\n                    ),\n                    name=self.name + \"_similarity_search_with_inputs\",\n                )\n        else:\n            if self.return_query:\n                return await ops.concat(\n                    similarity_search_query,\n                    await ops.similarity_search(\n                        similarity_search_query,\n                        knowledge_base=self.knowledge_base,\n                        k=self.k,\n                        threshold=self.threshold,\n                        name=self.name + \"_similarity_search\",\n                    ),\n                    name=self.name + \"_similarity_search_with_query\",\n                )\n            else:\n                return await ops.similarity_search(\n                    similarity_search_query,\n                    knowledge_base=self.knowledge_base,\n                    k=self.k,\n                    threshold=self.threshold,\n                    name=self.name + \"_similarity_search\",\n                )\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Knowledge%20Modules/KnowledgeRetriever%20module/","title":"KnowledgeRetriever module","text":""},{"location":"Synalinks%20API/Modules%20API/Knowledge%20Modules/KnowledgeRetriever%20module/#synalinks.src.modules.knowledge.knowledge_retriever.KnowledgeRetriever","title":"<code>KnowledgeRetriever</code>","text":"<p>               Bases: <code>Module</code></p> <p>Retrieve knowledge using a hybrid neuro-symbolic approach.</p> <p>Unlike the Text2Cypher approach, this retriever is 100% guaranteed to generate a valid Cypher query every time.</p> <p>It doesn't need to have the graph schema in the prompt, thus helping the language models by avoiding prompt confusion, because the nodes and relation labels are enforced dynamically using constrained structured output (similar to the <code>Decision</code> module).</p> <p>It works by using the language model to infer the subject, object and relation labels to search for, along with a similarity search field for the object and subject triplets. Additionally, some boolean fields are added to integrate logic-enhanced searches.</p> <p>These parameters are then used to programmatically create a valid Cypher query.</p> <p>This approach not only ensures the syntactical correctness of the Cypher query but also protects the graph database from Cypher injections that could arise from an adversarial prompt injection.</p> <pre><code>import synalinks\nimport asyncio\nfrom typing import Literal\n\nclass Query(synalinks.DataModel):\n    query: str = synalinks.Field(\n        description=\"The user query\",\n    )\n\nclass Answer(synalinks.DataModel):\n    query: str = synalinks.Field(\n        description=\"The answer to the user query\",\n    )\n\nclass Country(synalinks.Entity):\n    label: Literal[\"Country\"]\n    name: str = synalinks.Field(\n        description=\"The country's name\",\n    )\n\nclass City(synalinks.Entity):\n    label: Literal[\"City\"]\n    name: str = synalinks.Field(\n        description=\"The city's name\",\n    )\n\nclass IsCapitalOf(synalinks.Relation):\n    subj: City\n    label: Literal[\"IsCapitalOf\"]\n    obj: Country\n\nclass IsCityOf(synalinks.Relation):\n    subj: City\n    label: Literal[\"IsCityOf\"]\n    obj: Country\n\nasync def main():\n    inputs = synalinks.Input(data_model=Query)\n    x = await synalinks.KnowledgeRetriever(\n        entity_models=[Country, City],\n        relation_models=[IsCityOf, IsCapitalOf]\n        language_model=language_model,\n        knowledge_base=knowledge_base,\n    )(inputs)\n    outputs = await synalinks.Generator(\n        data_model=Answer,\n        language_model=language_model,\n    )(x)\n\n    program = synalinks.Program(\n        inputs=inputs,\n        outputs=outputs,\n        name=\"kag_program\",\n        description=\"A simple KAG program\",\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>knowledge_base</code> <code>KnowledgeBase</code> <p>The knowledge base to use.</p> <code>None</code> <code>language_model</code> <code>LanguageModel</code> <p>The language model to use.</p> <code>None</code> <code>entity_models</code> <code>list</code> <p>The list of entities models to search for being a list of <code>Entity</code> data models.</p> <code>None</code> <code>relation_models</code> <code>list</code> <p>The list of relations models to seach for. being a list of <code>Relation</code> data models.</p> <code>None</code> <code>k</code> <code>int</code> <p>Maximum number of similar entities to return (Defaults to 10).</p> <code>10</code> <code>threshold</code> <code>float</code> <p>Minimum similarity score for results. Entities with similarity below this threshold are excluded. Should be between 0.0 and 1.0 (Defaults to 0.7).</p> <code>0.8</code> <code>prompt_template</code> <code>str</code> <p>The default jinja2 prompt template to use (see <code>Generator</code>).</p> <code>None</code> <code>examples</code> <code>list</code> <p>The default examples to use in the prompt (see <code>Generator</code>).</p> <code>None</code> <code>instructions</code> <code>list</code> <p>The default instructions to use (see <code>Generator</code>).</p> <code>None</code> <code>use_inputs_schema</code> <code>bool</code> <p>Optional. Whether or not use the inputs schema in the prompt (Default to False) (see <code>Generator</code>).</p> <code>False</code> <code>use_outputs_schema</code> <code>bool</code> <p>Optional. Whether or not use the outputs schema in the prompt (Default to False) (see <code>Generator</code>).</p> <code>False</code> <code>return_inputs</code> <code>bool</code> <p>Optional. Whether or not to concatenate the inputs to the outputs (Default to True).</p> <code>True</code> <code>return_query</code> <code>bool</code> <p>Optional. Whether or not to concatenate the search query to the outputs (Default to True).</p> <code>True</code> <code>name</code> <code>str</code> <p>Optional. The name of the module.</p> <code>None</code> <code>description</code> <code>str</code> <p>Optional. The description of the module.</p> <code>None</code> <code>trainable</code> <code>bool</code> <p>Whether the module's variables should be trainable.</p> <code>True</code> Source code in <code>synalinks/src/modules/knowledge/knowledge_retriever.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.modules.KnowledgeRetriever\",\n        \"synalinks.KnowledgeRetriever\",\n    ]\n)\nclass KnowledgeRetriever(Module):\n    \"\"\"Retrieve knowledge using a hybrid neuro-symbolic approach.\n\n    Unlike the Text2Cypher approach, this retriever is 100%\n    guaranteed to generate a valid Cypher query **every time**.\n\n    It doesn't need to have the graph schema in the prompt, thus\n    helping the language models by avoiding prompt confusion, because\n    the nodes and relation labels are enforced dynamically\n    using **constrained structured output** (similar to the `Decision` module).\n\n    It works by using the language model to infer the subject, object and\n    relation labels to search for, along with a similarity search\n    field for the object and subject triplets. Additionally, some\n    boolean fields are added to integrate logic-enhanced searches.\n\n    These parameters are then used to *programmatically create a valid Cypher query*.\n\n    This approach not only ensures the syntactical correctness of the\n    Cypher query but also protects the graph database from Cypher\n    injections that could arise from an adversarial prompt injection.\n\n    ```python\n    import synalinks\n    import asyncio\n    from typing import Literal\n\n    class Query(synalinks.DataModel):\n        query: str = synalinks.Field(\n            description=\"The user query\",\n        )\n\n    class Answer(synalinks.DataModel):\n        query: str = synalinks.Field(\n            description=\"The answer to the user query\",\n        )\n\n    class Country(synalinks.Entity):\n        label: Literal[\"Country\"]\n        name: str = synalinks.Field(\n            description=\"The country's name\",\n        )\n\n    class City(synalinks.Entity):\n        label: Literal[\"City\"]\n        name: str = synalinks.Field(\n            description=\"The city's name\",\n        )\n\n    class IsCapitalOf(synalinks.Relation):\n        subj: City\n        label: Literal[\"IsCapitalOf\"]\n        obj: Country\n\n    class IsCityOf(synalinks.Relation):\n        subj: City\n        label: Literal[\"IsCityOf\"]\n        obj: Country\n\n    async def main():\n        inputs = synalinks.Input(data_model=Query)\n        x = await synalinks.KnowledgeRetriever(\n            entity_models=[Country, City],\n            relation_models=[IsCityOf, IsCapitalOf]\n            language_model=language_model,\n            knowledge_base=knowledge_base,\n        )(inputs)\n        outputs = await synalinks.Generator(\n            data_model=Answer,\n            language_model=language_model,\n        )(x)\n\n        program = synalinks.Program(\n            inputs=inputs,\n            outputs=outputs,\n            name=\"kag_program\",\n            description=\"A simple KAG program\",\n        )\n\n    if __name__ == \"__main__\":\n        asyncio.run(main())\n    ```\n\n    Args:\n        knowledge_base (KnowledgeBase): The knowledge base to use.\n        language_model (LanguageModel): The language model to use.\n        entity_models (list): The list of entities models to search for\n            being a list of `Entity` data models.\n        relation_models (list): The list of relations models to seach for.\n            being a list of `Relation` data models.\n        k (int): Maximum number of similar entities to return\n            (Defaults to 10).\n        threshold (float): Minimum similarity score for results.\n            Entities with similarity below this threshold are excluded.\n            Should be between 0.0 and 1.0 (Defaults to 0.7).\n        prompt_template (str): The default jinja2 prompt template\n            to use (see `Generator`).\n        examples (list): The default examples to use in the prompt\n            (see `Generator`).\n        instructions (list): The default instructions to use (see `Generator`).\n        use_inputs_schema (bool): Optional. Whether or not use the inputs schema in\n            the prompt (Default to False) (see `Generator`).\n        use_outputs_schema (bool): Optional. Whether or not use the outputs schema in\n            the prompt (Default to False) (see `Generator`).\n        return_inputs (bool): Optional. Whether or not to concatenate the inputs to\n            the outputs (Default to True).\n        return_query (bool): Optional. Whether or not to concatenate the search query to\n            the outputs (Default to True).\n        name (str): Optional. The name of the module.\n        description (str): Optional. The description of the module.\n        trainable (bool): Whether the module's variables should be trainable.\n    \"\"\"\n\n    def __init__(\n        self,\n        knowledge_base=None,\n        language_model=None,\n        entity_models=None,\n        relation_models=None,\n        k=10,\n        threshold=0.8,\n        prompt_template=None,\n        examples=None,\n        instructions=None,\n        use_inputs_schema=False,\n        use_outputs_schema=False,\n        return_inputs=True,\n        return_query=True,\n        name=None,\n        description=None,\n        trainable=True,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n            trainable=trainable,\n        )\n        self.knowledge_base = knowledge_base\n        self.language_model = language_model\n        self.k = k\n        self.threshold = threshold\n        self.prompt_template = prompt_template\n        self.examples = examples\n        self.instructions = instructions\n        self.use_inputs_schema = use_inputs_schema\n        self.use_outputs_schema = use_outputs_schema\n        self.return_inputs = return_inputs\n        self.return_query = return_query\n\n        self.schema = TripletSearch.get_schema()\n\n        if entity_models:\n            node_labels = [\n                entity_model.get_schema().get(\"title\") for entity_model in entity_models\n            ]\n        else:\n            node_labels = []\n        node_labels.append(\"*\")\n\n        if relation_models:\n            relation_labels = [\n                relation_model.get_schema().get(\"title\")\n                for relation_model in relation_models\n            ]\n        else:\n            relation_labels = []\n        relation_labels.append(\"*\")\n\n        self.schema = dynamic_enum(\n            schema=self.schema,\n            prop_to_update=\"subject_label\",\n            labels=node_labels,\n            description=\"The subject label (use `*` to match them all)\",\n        )\n\n        self.schema = dynamic_enum(\n            schema=self.schema,\n            prop_to_update=\"relation_label\",\n            labels=relation_labels,\n            description=\"The relation label (use `*` to match them all)\",\n        )\n\n        self.schema = dynamic_enum(\n            schema=self.schema,\n            prop_to_update=\"object_label\",\n            labels=node_labels,\n            description=\"The object label (use `*` to match them all)\",\n        )\n\n        self.query_generator = Generator(\n            schema=self.schema,\n            language_model=self.language_model,\n            prompt_template=self.prompt_template,\n            examples=self.examples,\n            instructions=self.instructions,\n            use_inputs_schema=self.use_inputs_schema,\n            use_outputs_schema=self.use_outputs_schema,\n            return_inputs=False,\n            name=self.name + \"_query_generator\",\n        )\n\n    async def call(self, inputs, training=False):\n        if not inputs:\n            return None\n        triplet_search_query = await self.query_generator(\n            inputs,\n            training=training,\n        )\n        if self.return_inputs:\n            if self.return_query:\n                return await ops.concat(\n                    inputs,\n                    await ops.concat(\n                        triplet_search_query,\n                        await ops.triplet_search(\n                            triplet_search_query,\n                            knowledge_base=self.knowledge_base,\n                            k=self.k,\n                            threshold=self.threshold,\n                            name=self.name + \"_similarity_search\",\n                        ),\n                        name=self.name + \"_similarity_search_with_query_and_inputs\",\n                    ),\n                )\n            else:\n                return await ops.concat(\n                    inputs,\n                    await ops.triplet_search(\n                        triplet_search_query,\n                        knowledge_base=self.knowledge_base,\n                        k=self.k,\n                        threshold=self.threshold,\n                        name=self.name + \"_similarity_search\",\n                    ),\n                    name=self.name + \"_similarity_search_with_inputs\",\n                )\n        else:\n            if self.return_query:\n                return await ops.concat(\n                    triplet_search_query,\n                    await ops.triplet_search(\n                        triplet_search_query,\n                        knowledge_base=self.knowledge_base,\n                        k=self.k,\n                        threshold=self.threshold,\n                        name=self.name + \"_similarity_search\",\n                    ),\n                    name=self.name + \"_similarity_search_with_query\",\n                )\n            else:\n                return await ops.triplet_search(\n                    triplet_search_query,\n                    knowledge_base=self.knowledge_base,\n                    k=self.k,\n                    threshold=self.threshold,\n                    name=self.name + \"_similarity_search\",\n                )\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Knowledge%20Modules/UpdateKnowledge%20module/","title":"UpdateKnowledge module","text":""},{"location":"Synalinks%20API/Modules%20API/Knowledge%20Modules/UpdateKnowledge%20module/#synalinks.src.modules.knowledge.update_knowledge.UpdateKnowledge","title":"<code>UpdateKnowledge</code>","text":"<p>               Bases: <code>Module</code></p> <p>Update the given knowledge base.</p> <p>This module requires an <code>Entity</code>, <code>Relation</code>, <code>Entities</code>, <code>Relations</code> or <code>KnowledgeGraph</code> data model as input.</p> <p>This module perform alignment automatically, also called deduplication, by using the similarity search of the knowledge base. This way of performing alignment is more performant than using a linear alignement algorithm as it use the hierarchical small world neighbors (HSWN) algorithm of the knowledge base.</p> <p>It however needs to have the entities embeded using the <code>Embedding</code> module before updating the knwoledge base.</p> <p>Parameters:</p> Name Type Description Default <code>knowledge_base</code> <code>KnowledgeBase</code> <p>The knowledge base to update.</p> <code>None</code> <code>threshold</code> <code>float</code> <p>Similarity threshold for entity alignment. Entities with similarity above this threshold may be merged. Should be between 0.0 and 1.0 (Defaults to 0.8).</p> <code>0.8</code> <code>name</code> <code>str</code> <p>Optional. The name of the module.</p> <code>None</code> <code>description</code> <code>str</code> <p>Optional. The description of the module.</p> <code>None</code> <code>trainable</code> <code>bool</code> <p>Whether the module's variables should be trainable.</p> <code>False</code> Source code in <code>synalinks/src/modules/knowledge/update_knowledge.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.modules.UpdateKnowledge\",\n        \"synalinks.UpdateKnowledge\",\n    ]\n)\nclass UpdateKnowledge(Module):\n    \"\"\"Update the given knowledge base.\n\n    This module requires an `Entity`, `Relation`, `Entities`,\n    `Relations` or `KnowledgeGraph` data model as input.\n\n    This module perform alignment automatically, also called deduplication,\n    by using the similarity search of the knowledge base. This way of performing\n    alignment is more performant than using a linear alignement algorithm as it use\n    the hierarchical small world neighbors (HSWN) algorithm of the knowledge base.\n\n    It however needs to have the entities embeded using the `Embedding` module before\n    updating the knwoledge base.\n\n    Args:\n        knowledge_base (KnowledgeBase): The knowledge base to update.\n        threshold (float): Similarity threshold for entity alignment.\n            Entities with similarity above this threshold may be merged.\n            Should be between 0.0 and 1.0 (Defaults to 0.8).\n        name (str): Optional. The name of the module.\n        description (str): Optional. The description of the module.\n        trainable (bool): Whether the module's variables should be trainable.\n    \"\"\"\n\n    def __init__(\n        self,\n        knowledge_base=None,\n        threshold=0.8,\n        name=None,\n        description=None,\n        trainable=False,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n            trainable=trainable,\n        )\n        self.knowledge_base = knowledge_base\n        self.threshold = threshold\n\n    async def call(self, inputs):\n        if not inputs:\n            return None\n        if is_knowledge_graph(inputs):\n            for entity in inputs.get_nested_entity_list(\"entities\"):\n                _ = await ops.update_knowledge(\n                    entity,\n                    knowledge_base=self.knowledge_base,\n                    threshold=self.threshold,\n                    name=entity.name + \"_updated\",\n                )\n            for relation in inputs.get_nested_entity_list(\"relations\"):\n                subj = relation.get_nested_entity(\"subj\")\n                if not subj:\n                    continue\n                _ = await ops.update_knowledge(\n                    subj,\n                    knowledge_base=self.knowledge_base,\n                    threshold=self.threshold,\n                    name=subj.name + \"_updated\",\n                )\n                obj = relation.get_nested_entity(\"obj\")\n                if not obj:\n                    continue\n                _ = await ops.update_knowledge(\n                    obj,\n                    knowledge_base=self.knowledge_base,\n                    threshold=self.threshold,\n                    name=obj.name + \"_updated\",\n                )\n                _ = await ops.update_knowledge(\n                    relation,\n                    knowledge_base=self.knowledge_base,\n                    threshold=self.threshold,\n                    name=relation.name + \"_updated\",\n                )\n            return inputs.clone(name=inputs.name + \"_updated\")\n        elif is_entities(inputs):\n            for entity in inputs.get_nested_entity_list(\"entities\"):\n                _ = await ops.update_knowledge(\n                    entity,\n                    knowledge_base=self.knowledge_base,\n                    threshold=self.threshold,\n                    name=entity.name + \"_updated\",\n                )\n            return inputs.clone(name=inputs.name + \"_updated\")\n        elif is_relations(inputs):\n            for relation in inputs.get_nested_entity_list(\"relations\"):\n                subj = relation.get_nested_entity(\"subj\")\n                if not subj:\n                    continue\n                _ = await ops.update_knowledge(\n                    subj,\n                    knowledge_base=self.knowledge_base,\n                    threshold=self.threshold,\n                    name=subj.name + \"_updated\",\n                )\n                obj = relation.get_nested_entity(\"obj\")\n                if not obj:\n                    continue\n                _ = await ops.update_knowledge(\n                    obj,\n                    knowledge_base=self.knowledge_base,\n                    threshold=self.threshold,\n                    name=obj.name + \"_updated\",\n                )\n                _ = await ops.update_knowledge(\n                    relation,\n                    knowledge_base=self.knowledge_base,\n                    threshold=self.threshold,\n                    name=relation.name + \"_updated\",\n                )\n            return inputs.clone(name=inputs.name + \"_updated\")\n        elif is_relation(inputs):\n            subj = inputs.get_nested_entity(\"subj\")\n            _ = await ops.update_knowledge(\n                subj,\n                knowledge_base=self.knowledge_base,\n                threshold=self.threshold,\n                name=subj.name + \"_updated\",\n            )\n            obj = inputs.get_nested_entity(\"obj\")\n            _ = await ops.update_knowledge(\n                obj,\n                knowledge_base=self.knowledge_base,\n                threshold=self.threshold,\n                name=obj.name + \"_updated\",\n            )\n            return inputs.clone(name=inputs.name + \"_updated\")\n        elif is_entity(inputs):\n            _ = await ops.update_knowledge(\n                inputs,\n                knowledge_base=self.knowledge_base,\n                threshold=self.threshold,\n                name=inputs.name + \"_updated\",\n            )\n            return inputs.clone(name=inputs.name + \"_updated\")\n        else:\n            return None\n\n    async def compute_output_spec(self, inputs):\n        return inputs.clone()\n\n    def get_config(self):\n        config = {\n            \"threshold\": self.threshold,\n            \"name\": self.name,\n            \"description\": self.description,\n            \"trainable\": self.trainable,\n        }\n        knowledge_base_config = {\n            \"knowledge_base\": serialization_lib.serialize_synalinks_object(\n                self.knowledge_base\n            )\n        }\n        return {**knowledge_base_config, **config}\n\n    @classmethod\n    def from_config(cls, config):\n        knowledge_base = serialization_lib.deserialize_synalinks_object(\n            config.pop(\"knowledge_base\")\n        )\n        return cls(knowledge_base=knowledge_base, **config)\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Merging%20Modules/","title":"Merging Modules","text":"<ul> <li>Concat module</li> <li>And module</li> <li>Or module</li> <li>Xor module</li> </ul>"},{"location":"Synalinks%20API/Modules%20API/Merging%20Modules/And%20module/","title":"And module","text":""},{"location":"Synalinks%20API/Modules%20API/Merging%20Modules/And%20module/#synalinks.src.modules.merging.logical_and.And","title":"<code>And</code>","text":"<p>               Bases: <code>Module</code></p> <p>Perform a logical And operation.</p> <p>It takes as input a list of data models, and returns a concatenation of them.</p> <p>If any input is None, then it output None.</p> <p>Table:</p> <code>x1</code> <code>x2</code> Logical And (<code>&amp;</code>) <code>x1</code> <code>x2</code> <code>x1 + x2</code> <code>x1</code> <code>None</code> <code>None</code> <code>None</code> <code>x2</code> <code>None</code> <code>None</code> <code>None</code> <code>None</code> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>keyword arguments</code> <p>Standard keyword arguments for the module.</p> <code>{}</code> Source code in <code>synalinks/src/modules/merging/logical_and.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.And\",\n        \"synalinks.modules.And\",\n    ]\n)\nclass And(Module):\n    \"\"\"Perform a logical And operation.\n\n    It takes as input a list of data models,\n    and returns a concatenation of them.\n\n    If any input is None, then it output None.\n\n    Table:\n\n    | `x1`   | `x2`   | Logical And (`&amp;`) |\n    | ------ | ------ | ----------------- |\n    | `x1`   | `x2`   | `x1 + x2`         |\n    | `x1`   | `None` | `None`            |\n    | `None` | `x2`   | `None`            |\n    | `None` | `None` | `None`            |\n\n    Args:\n        **kwargs (keyword arguments): Standard keyword arguments for the module.\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n    async def call(self, inputs, training=False):\n        output = inputs[0]\n        for i in range(1, len(inputs)):\n            output = await ops.logical_and(\n                output,\n                inputs[i],\n                name=self.name + f\"_module_and_{i}\",\n            )\n        return output\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Merging%20Modules/Concat%20module/","title":"Concat module","text":""},{"location":"Synalinks%20API/Modules%20API/Merging%20Modules/Concat%20module/#synalinks.src.modules.merging.concat.Concat","title":"<code>Concat</code>","text":"<p>               Bases: <code>Module</code></p> <p>Perform a concatenation operation.</p> <p>It takes as input a list of data models, and returns a concatenation of them.</p> <p>If any input is None, an exception is raised.</p> <p>Table:</p> <code>x1</code> <code>x2</code> Concat (<code>+</code>) <code>x1</code> <code>x2</code> <code>x1 + x2</code> <code>x1</code> <code>None</code> <code>Exception</code> <code>None</code> <code>x2</code> <code>Exception</code> <code>None</code> <code>None</code> <code>Exception</code> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>keyword arguments</code> <p>Standard keyword arguments for the module.</p> <code>{}</code> Source code in <code>synalinks/src/modules/merging/concat.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.Concat\",\n        \"synalinks.modules.Concat\",\n    ]\n)\nclass Concat(Module):\n    \"\"\"Perform a concatenation operation.\n\n    It takes as input a list of data models,\n    and returns a concatenation of them.\n\n    If any input is None, an exception is raised.\n\n    Table:\n\n    | `x1`   | `x2`   | Concat (`+`)      |\n    | ------ | ------ | ----------------- |\n    | `x1`   | `x2`   | `x1 + x2`         |\n    | `x1`   | `None` | `Exception`       |\n    | `None` | `x2`   | `Exception`       |\n    | `None` | `None` | `Exception`       |\n\n    Args:\n        **kwargs (keyword arguments): Standard keyword arguments for the module.\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n    async def call(self, inputs, training=False):\n        output = inputs[0]\n        for i in range(1, len(inputs)):\n            output = await ops.concat(\n                output,\n                inputs[i],\n                name=self.name + f\"_module_concat_{i}\",\n            )\n        return output\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Merging%20Modules/Or%20module/","title":"Or module","text":""},{"location":"Synalinks%20API/Modules%20API/Merging%20Modules/Or%20module/#synalinks.src.modules.merging.logical_or.Or","title":"<code>Or</code>","text":"<p>               Bases: <code>Module</code></p> <p>Perform a logical Or operation.</p> <p>It takes as input a list of data models, and returns a concatenation of them (if all are provided) otherwise it output the one that is not None.</p> <p>If any input is None, it is ignored.</p> <p>Table:</p> <code>x1</code> <code>x2</code> Logical Or (<code>|</code>) <code>x1</code> <code>x2</code> <code>x1 + x2</code> <code>x1</code> <code>None</code> <code>x1</code> <code>None</code> <code>x2</code> <code>x2</code> <code>None</code> <code>None</code> <code>None</code> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>keyword arguments</code> <p>Standard keyword arguments for the module.</p> <code>{}</code> Source code in <code>synalinks/src/modules/merging/logical_or.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.Or\",\n        \"synalinks.modules.Or\",\n    ]\n)\nclass Or(Module):\n    \"\"\"Perform a logical Or operation.\n\n    It takes as input a list of data models,\n    and returns a concatenation of them (if all are provided)\n    otherwise it output the one that is not None.\n\n    If any input is None, it is ignored.\n\n    Table:\n\n    | `x1`   | `x2`   | Logical Or (`|`) |\n    | ------ | ------ | ---------------- |\n    | `x1`   | `x2`   | `x1 + x2`        |\n    | `x1`   | `None` | `x1`             |\n    | `None` | `x2`   | `x2`             |\n    | `None` | `None` | `None`           |\n\n    Args:\n        **kwargs (keyword arguments): Standard keyword arguments for the module.\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n    async def call(self, inputs, training=False):\n        output = inputs[0]\n        for i in range(1, len(inputs)):\n            output = await ops.logical_or(\n                output,\n                inputs[i],\n                name=self.name + f\"_module_or_{i}\",\n            )\n        return output\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Merging%20Modules/Xor%20module/","title":"Xor module","text":""},{"location":"Synalinks%20API/Modules%20API/Merging%20Modules/Xor%20module/#synalinks.src.modules.merging.logical_xor.Xor","title":"<code>Xor</code>","text":"<p>               Bases: <code>Module</code></p> <p>Perform a logical Xor operation.</p> <p>It takes as input a list of data models, If more than two data models are not None, then it output None. otherwise it output the one that is not None.</p> <p>Table:</p> <code>x1</code> <code>x2</code> Logical Xor (<code>^</code>) <code>x1</code> <code>x2</code> <code>None</code> <code>x1</code> <code>None</code> <code>x1</code> <code>None</code> <code>x2</code> <code>x2</code> <code>None</code> <code>None</code> <code>None</code> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>keyword arguments</code> <p>Standard keyword arguments for the module.</p> <code>{}</code> Source code in <code>synalinks/src/modules/merging/logical_xor.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.Xor\",\n        \"synalinks.modules.Xor\",\n    ]\n)\nclass Xor(Module):\n    \"\"\"Perform a logical Xor operation.\n\n    It takes as input a list of data models,\n    If more than two data models are not None, then it output None.\n    otherwise it output the one that is not None.\n\n    Table:\n\n    | `x1`   | `x2`   | Logical Xor (`^`)|\n    | ------ | ------ | ---------------- |\n    | `x1`   | `x2`   | `None`           |\n    | `x1`   | `None` | `x1`             |\n    | `None` | `x2`   | `x2`             |\n    | `None` | `None` | `None`           |\n\n    Args:\n        **kwargs (keyword arguments): Standard keyword arguments for the module.\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n    async def compute_output_spec(self, inputs, training=False):\n        return inputs[0].clone()\n\n    async def call(self, inputs, training=False):\n        output = inputs[0]\n        for i in range(1, len(inputs)):\n            if inputs[i]:\n                if not output:\n                    output = inputs[i]\n                else:\n                    return None\n        return output.clone(name=self.name)\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Test%20Time%20Compute%20Modules/","title":"Test Time Compute Modules","text":"<ul> <li>ChainOfThought module</li> <li>SelfCritique module</li> </ul>"},{"location":"Synalinks%20API/Modules%20API/Test%20Time%20Compute%20Modules/ChainOfThought%20module/","title":"ChainOfThought module","text":""},{"location":"Synalinks%20API/Modules%20API/Test%20Time%20Compute%20Modules/ChainOfThought%20module/#synalinks.src.modules.ttc.chain_of_thought.ChainOfThought","title":"<code>ChainOfThought</code>","text":"<p>               Bases: <code>Module</code></p> <p>Useful to answer in a step by step manner.</p> <p>This component concatenate thinking fields to your data model/schema and generate a prediction allowing the LM to think step by step before answering.</p> <p>The parameter K specify the number of thinking fields to add (Default to 1).</p> <p>Example:</p> <pre><code>import synalink\nimport asyncio\n\nclass Query(synalinks.DataModel):\n    query: str = synalinks.Field(\n        description=\"The user query\",\n    )\n\nclass Answer(synalinks.DataModel):\n    answer: str = synalinks.Field(\n        description=\"The correct answer\",\n    )\n\nasync def main():\n\n    language_model = synalinks.LanguageModel(\n        model=\"ollama/mistral\",\n    )\n\n    x0 = synalinks.Input(data_model=Query)\n    x1 = await synalinks.ChainOfThought(\n        data_model=Answer,\n        language_model=language_model,\n        k=3,\n    )(x0)\n\n    program = synalinks.Program(\n        inputs=x0,\n        outputs=x1,\n        name=\"answer_with_chain_of_thought\",\n        description=\"Useful to answer step by step\",\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> References <ul> <li>Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</li> </ul> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>dict</code> <p>The target JSON schema. If not provided use the <code>data_model</code> to infer it.</p> <code>None</code> <code>data_model</code> <code>DataModel | SymbolicDataModel | JsonDataModel</code> <p>The target data model.</p> <code>None</code> <code>language_model</code> <code>LanguageModel</code> <p>The language model to use.</p> <code>None</code> <code>prompt_template</code> <code>str</code> <p>The jinja2 prompt template (see <code>Generator</code>).</p> <code>None</code> <code>examples</code> <code>list</code> <p>The default list of examples (see <code>Generator</code>).</p> <code>None</code> <code>instructions</code> <code>list</code> <p>The default instructions being a list of string containing additional instructions for the language model (see <code>Generator</code>).</p> <code>None</code> <code>use_inputs_schema</code> <code>bool</code> <p>Optional. Whether or not use the inputs schema in the prompt (Default to False) (see <code>Generator</code>).</p> <code>False</code> <code>use_outputs_schema</code> <code>bool</code> <p>Optional. Whether or not use the outputs schema in the prompt (Default to False) (see <code>Generator</code>).</p> <code>False</code> <code>k</code> <code>int</code> <p>The number of thinking fields to add.</p> <code>1</code> <code>return_inputs</code> <code>bool</code> <p>Optional. Whether or not to concatenate the inputs to the outputs (Default to False) (see <code>Generator</code>).</p> <code>False</code> <code>name</code> <code>str</code> <p>Optional. The name of the module.</p> <code>None</code> <code>description</code> <code>str</code> <p>Optional. The description of the module.</p> <code>None</code> <code>trainable</code> <code>bool</code> <p>Whether the module's variables should be trainable.</p> <code>None</code> Source code in <code>synalinks/src/modules/ttc/chain_of_thought.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.modules.ChainOfThought\",\n        \"synalinks.ChainOfThought\",\n    ]\n)\nclass ChainOfThought(Module):\n    \"\"\"Useful to answer in a step by step manner.\n\n    This component concatenate thinking fields to your data model/schema and generate\n    a prediction allowing the LM to think step by step before answering.\n\n    The parameter K specify the number of thinking fields to add (Default to 1).\n\n    Example:\n\n    ```python\n    import synalink\n    import asyncio\n\n    class Query(synalinks.DataModel):\n        query: str = synalinks.Field(\n            description=\"The user query\",\n        )\n\n    class Answer(synalinks.DataModel):\n        answer: str = synalinks.Field(\n            description=\"The correct answer\",\n        )\n\n    async def main():\n\n        language_model = synalinks.LanguageModel(\n            model=\"ollama/mistral\",\n        )\n\n        x0 = synalinks.Input(data_model=Query)\n        x1 = await synalinks.ChainOfThought(\n            data_model=Answer,\n            language_model=language_model,\n            k=3,\n        )(x0)\n\n        program = synalinks.Program(\n            inputs=x0,\n            outputs=x1,\n            name=\"answer_with_chain_of_thought\",\n            description=\"Useful to answer step by step\",\n        )\n\n    if __name__ == \"__main__\":\n        asyncio.run(main())\n    ```\n\n    References:\n        - [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903)\n\n    Args:\n        schema (dict): The target JSON schema.\n            If not provided use the `data_model` to infer it.\n        data_model (DataModel | SymbolicDataModel | JsonDataModel): The target data model.\n        language_model (LanguageModel): The language model to use.\n        prompt_template (str): The jinja2 prompt template (see `Generator`).\n        examples (list): The default list of examples (see `Generator`).\n        instructions (list): The default instructions being a list of string containing\n            additional instructions for the language model (see `Generator`).\n        use_inputs_schema (bool): Optional. Whether or not use the inputs schema in\n            the prompt (Default to False) (see `Generator`).\n        use_outputs_schema (bool): Optional. Whether or not use the outputs schema in\n            the prompt (Default to False) (see `Generator`).\n        k (int): The number of thinking fields to add.\n        return_inputs (bool): Optional. Whether or not to concatenate the inputs to\n            the outputs (Default to False) (see `Generator`).\n        name (str): Optional. The name of the module.\n        description (str): Optional. The description of the module.\n        trainable (bool): Whether the module's variables should be trainable.\n    \"\"\"\n\n    def __init__(\n        self,\n        schema=None,\n        data_model=None,\n        language_model=None,\n        prompt_template=None,\n        examples=None,\n        instructions=None,\n        use_inputs_schema=False,\n        use_outputs_schema=False,\n        k=1,\n        return_inputs=False,\n        name=None,\n        description=None,\n        trainable=None,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n            trainable=trainable,\n        )\n\n        if not schema and data_model:\n            schema = data_model.get_schema()\n        self.schema = schema\n        self.language_model = language_model\n        self.prompt_template = prompt_template\n        self.examples = examples\n        self.instructions = instructions\n        self.use_inputs_schema = use_inputs_schema\n        self.use_outputs_schema = use_outputs_schema\n        self.return_inputs = return_inputs\n        self.k = k\n\n        thinking_data_model = Thinking\n        if k &gt; 1:\n            for _ in range(k - 1):\n                thinking_data_model += Thinking\n\n        final_data_model = thinking_data_model + SymbolicDataModel(schema=self.schema)\n\n        self.generator = Generator(\n            data_model=final_data_model,\n            language_model=self.language_model,\n            prompt_template=self.prompt_template,\n            examples=self.examples,\n            instructions=self.instructions,\n            use_inputs_schema=self.use_inputs_schema,\n            use_outputs_schema=self.use_outputs_schema,\n            return_inputs=self.return_inputs,\n            name=self.name + \"_generator\",\n        )\n\n    async def call(self, inputs, training=False):\n        return await self.generator(inputs, training=training)\n\n    def get_config(self):\n        config = {\n            \"schema\": self.schema,\n            \"prompt_template\": self.prompt_template,\n            \"examples\": self.examples,\n            \"instructions\": self.instructions,\n            \"use_inputs_schema\": self.use_inputs_schema,\n            \"use_outputs_schema\": self.use_outputs_schema,\n            \"return_inputs\": self.return_inputs,\n            \"k\": self.k,\n            \"name\": self.name,\n            \"description\": self.description,\n            \"trainable\": self.trainable,\n        }\n        language_model_config = {\n            \"language_model\": serialization_lib.serialize_synalinks_object(\n                self.language_model\n            )\n        }\n        return {**config, **language_model_config}\n\n    @classmethod\n    def from_config(cls, config):\n        language_model = serialization_lib.deserialize_synalinks_object(\n            config.pop(\"language_model\"),\n        )\n        return cls(language_model=language_model, **config)\n</code></pre>"},{"location":"Synalinks%20API/Modules%20API/Test%20Time%20Compute%20Modules/SelfCritique%20module/","title":"SelfCritique module","text":""},{"location":"Synalinks%20API/Modules%20API/Test%20Time%20Compute%20Modules/SelfCritique%20module/#synalinks.src.modules.ttc.self_critique.SelfCritique","title":"<code>SelfCritique</code>","text":"<p>               Bases: <code>Module</code></p> <p>Useful to critique the given inputs.</p> <p>This component critique the inputs given and eventually generate an intermediate reward between 0.0 and 1.0.</p> <p>You can enable or disable the intermediate reward computation by using the <code>return_reward</code> flag (default to True).</p> <p>To have more accurate results, ensure that the inputs are provided along with the output to evaluate using <code>return_inputs</code> in your modules.</p> <p>Example:</p> <pre><code>import synalink\nimport asyncio\n\nclass Query(synalinks.DataModel):\n    query: str = synalinks.Field(\n        description=\"The user query\",\n    )\n\nclass Answer(synalinks.DataModel):\n    answer: str = synalinks.Field(\n        description=\"The correct answer\",\n    )\n\nasync def main():\n\n    language_model = synalinks.LanguageModel(\n        model=\"ollama/mistral\",\n    )\n\n    x0 = synalinks.Input(data_model=Query)\n    x1 = await synalinks.ChainOfThought(\n        data_model=Answer,\n        language_model=language_model,\n        return_inputs=True,\n    )(x0)\n    x2 = await synalinks.SelfCritique(\n        language_model=language_model,\n    )(x1)\n\n    program = synalinks.Program(\n        inputs=x0,\n        outputs=x2,\n        name=\"answer_with_cot_and_self_critique\",\n        description=\"Useful to answer accurately\",\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>language_model</code> <code>LanguageModel</code> <p>The language model to use.</p> <code>None</code> <code>prompt_template</code> <code>str</code> <p>The jinja2 prompt template (see <code>Generator</code>).</p> <code>None</code> <code>examples</code> <code>list</code> <p>The default list of examples (see <code>Generator</code>).</p> <code>None</code> <code>instructions</code> <code>list</code> <p>The default instructions being a list of string containing additional instructions for the language model (see <code>Generator</code>).</p> <code>None</code> <code>use_inputs_schema</code> <code>bool</code> <p>Optional. Whether or not use the inputs schema in the prompt (Default to False) (see <code>Generator</code>).</p> <code>False</code> <code>use_outputs_schema</code> <code>bool</code> <p>Optional. Whether or not use the outputs schema in the prompt (Default to False) (see <code>Generator</code>).</p> <code>False</code> <code>return_reward</code> <code>bool</code> <p>Optional. Whether or not to compute an intermediate reward.</p> <code>True</code> <code>return_inputs</code> <code>bool</code> <p>Optional. Whether or not to concatenate the inputs to the outputs (Default to True) (see <code>Generator</code>).</p> <code>True</code> <code>name</code> <code>str</code> <p>Optional. The name of the module.</p> <code>None</code> <code>description</code> <code>str</code> <p>Optional. The description of the module.</p> <code>None</code> <code>trainable</code> <code>bool</code> <p>Whether the module's variables should be trainable.</p> <code>None</code> Source code in <code>synalinks/src/modules/ttc/self_critique.py</code> <pre><code>@synalinks_export(\n    [\n        \"synalinks.modules.SelfCritique\",\n        \"synalinks.SelfCritique\",\n    ]\n)\nclass SelfCritique(Module):\n    \"\"\"Useful to critique the given inputs.\n\n    This component critique the inputs given and eventually generate\n    an intermediate reward between 0.0 and 1.0.\n\n    You can enable or disable the intermediate reward computation by\n    using the `return_reward` flag (default to True).\n\n    To have more accurate results, ensure that the inputs are provided along\n    with the output to evaluate using `return_inputs` in your modules.\n\n    Example:\n\n    ```python\n    import synalink\n    import asyncio\n\n    class Query(synalinks.DataModel):\n        query: str = synalinks.Field(\n            description=\"The user query\",\n        )\n\n    class Answer(synalinks.DataModel):\n        answer: str = synalinks.Field(\n            description=\"The correct answer\",\n        )\n\n    async def main():\n\n        language_model = synalinks.LanguageModel(\n            model=\"ollama/mistral\",\n        )\n\n        x0 = synalinks.Input(data_model=Query)\n        x1 = await synalinks.ChainOfThought(\n            data_model=Answer,\n            language_model=language_model,\n            return_inputs=True,\n        )(x0)\n        x2 = await synalinks.SelfCritique(\n            language_model=language_model,\n        )(x1)\n\n        program = synalinks.Program(\n            inputs=x0,\n            outputs=x2,\n            name=\"answer_with_cot_and_self_critique\",\n            description=\"Useful to answer accurately\",\n        )\n\n    if __name__ == \"__main__\":\n        asyncio.run(main())\n    ```\n\n    Args:\n        language_model (LanguageModel): The language model to use.\n        prompt_template (str): The jinja2 prompt template (see `Generator`).\n        examples (list): The default list of examples (see `Generator`).\n        instructions (list): The default instructions being a list of string containing\n            additional instructions for the language model (see `Generator`).\n        use_inputs_schema (bool): Optional. Whether or not use the inputs schema in\n            the prompt (Default to False) (see `Generator`).\n        use_outputs_schema (bool): Optional. Whether or not use the outputs schema in\n            the prompt (Default to False) (see `Generator`).\n        return_reward (bool): Optional. Whether or not to compute an intermediate reward.\n        return_inputs (bool): Optional. Whether or not to concatenate the inputs to\n            the outputs (Default to True) (see `Generator`).\n        name (str): Optional. The name of the module.\n        description (str): Optional. The description of the module.\n        trainable (bool): Whether the module's variables should be trainable.\n    \"\"\"\n\n    def __init__(\n        self,\n        language_model=None,\n        prompt_template=None,\n        examples=None,\n        instructions=None,\n        use_inputs_schema=False,\n        use_outputs_schema=False,\n        return_reward=True,\n        return_inputs=True,\n        name=None,\n        description=None,\n        trainable=None,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n            trainable=trainable,\n        )\n\n        self.language_model = language_model\n        self.prompt_template = prompt_template\n        self.examples = examples\n        self.instructions = instructions\n        self.use_inputs_schema = use_inputs_schema\n        self.use_outputs_schema = use_outputs_schema\n        self.return_reward = return_reward\n        self.return_inputs = return_inputs\n\n        if self.return_reward:\n            schema = CritiqueWithReward.get_schema()\n        else:\n            schema = Critique.get_schema()\n\n        self.generator = Generator(\n            schema=schema,\n            language_model=self.language_model,\n            prompt_template=self.prompt_template,\n            examples=self.examples,\n            instructions=self.instructions,\n            use_inputs_schema=self.use_inputs_schema,\n            use_outputs_schema=self.use_outputs_schema,\n            return_inputs=self.return_inputs,\n            name=self.name + \"_generator\",\n        )\n\n    async def call(self, inputs, training=False):\n        return await self.generator(inputs, training=training)\n\n    def get_config(self):\n        config = {\n            \"examples\": self.examples,\n            \"instructions\": self.instructions,\n            \"use_inputs_schema\": self.use_inputs_schema,\n            \"use_outputs_schema\": self.use_outputs_schema,\n            \"return_reward\": self.return_reward,\n            \"return_inputs\": self.return_inputs,\n            \"name\": self.name,\n            \"description\": self.description,\n            \"trainable\": self.trainable,\n        }\n        language_model_config = {\n            \"language_model\": serialization_lib.serialize_synalinks_object(\n                self.language_model\n            )\n        }\n        return {**config, **language_model_config}\n\n    @classmethod\n    def from_config(cls, config):\n        language_model = serialization_lib.deserialize_synalinks_object(\n            config.pop(\"language_model\"),\n        )\n        return cls(language_model=language_model, **config)\n</code></pre>"},{"location":"Synalinks%20API/Ops%20API/","title":"Ops API","text":""},{"location":"Synalinks%20API/Ops%20API/#json-ops","title":"JSON Ops","text":"<ul> <li>concat function</li> <li>factorize function</li> <li>in_mask function</li> <li>out_mask function</li> <li>logical_and function</li> <li>logical_or function</li> <li>logical_xor function</li> <li>suffix function</li> <li>prefix function</li> </ul>"},{"location":"Synalinks%20API/Ops%20API/#language-models-ops","title":"Language Models Ops","text":"<ul> <li>predict function</li> </ul>"},{"location":"Synalinks%20API/Ops%20API/#embedding-models-ops","title":"Embedding Models Ops","text":"<ul> <li>embedding function</li> </ul>"},{"location":"Synalinks%20API/Ops%20API/Embedding%20Models%20Ops/","title":"Embedding Models Ops","text":""},{"location":"Synalinks%20API/Ops%20API/Embedding%20Models%20Ops/#synalinks.src.ops.embedding_models.Embedding","title":"<code>Embedding</code>","text":"<p>               Bases: <code>Operation</code></p> <p>Extract the embedding vectors from a data model using an <code>EmbeddingModel</code>.</p> <p>Parameters:</p> Name Type Description Default <code>embedding_model</code> <code>EmbeddingModel</code> <p>The embedding model to use.</p> <code>None</code> <code>name</code> <code>str</code> <p>Optional. The name of the operation.</p> <code>None</code> <code>description</code> <code>str</code> <p>Optional. Description of the operation.</p> <code>None</code> <code>**kwargs</code> <code>keyword warguments</code> <p>Additional keyword arguments send to the embedding model.</p> <code>{}</code> Source code in <code>synalinks/src/ops/embedding_models.py</code> <pre><code>class Embedding(Operation):\n    \"\"\"Extract the embedding vectors from a data model using an `EmbeddingModel`.\n\n    Args:\n        embedding_model (EmbeddingModel): The embedding model to use.\n        name (str): Optional. The name of the operation.\n        description (str): Optional. Description of the operation.\n        **kwargs (keyword warguments): Additional keyword arguments send to the\n            embedding model.\n    \"\"\"\n\n    def __init__(\n        self,\n        embedding_model=None,\n        name=None,\n        description=None,\n        **kwargs,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n        )\n        self.embedding_model = embedding_model\n        self.em_kwargs = kwargs\n\n    async def call(self, x):\n        texts = tree.flatten(tree.map_structure(lambda field: str(field), x.get_json()))\n        embeddings = await self.embedding_model(texts)\n        return JsonDataModel(data_model=Embeddings(**embeddings), name=self.name)\n\n    async def compute_output_spec(self, x):\n        return SymbolicDataModel(schema=Embeddings.get_schema(), name=self.name)\n\n    def get_config(self):\n        config = {\n            \"name\": self.name,\n            \"description\": self.description,\n        }\n        embedding_model_config = serialization_lib.serialize_synalinks_object(\n            self.embedding_model\n        )\n        config.update({\"em_kwargs\": self.em_kwargs})\n        return {\"embedding_model\": embedding_model_config, **config}\n\n    @classmethod\n    def from_config(cls, config):\n        embedding_model = serialization_lib.deserialize_synalinks_object(\n            config.pop(\"embedding_model\")\n        )\n        em_kwargs = config.pop(\"em_kwargs\")\n        return cls(embedding_model=embedding_model, **config, **em_kwargs)\n</code></pre>"},{"location":"Synalinks%20API/Ops%20API/Embedding%20Models%20Ops/#synalinks.src.ops.embedding_models.embedding","title":"<code>embedding(x, embedding_model=None, name=None, description=None, **kwargs)</code>  <code>async</code>","text":"<p>Extract the embedding vectors from a data model using an <code>EmbeddingModel</code>.</p> <p>Embedding consist in converting the given data_model into a vector representation. This function always output a data model that uses <code>Embeddings</code> schema.</p> <p>If the input data model have multiple fields, each one is embedded.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>JsonDataModel | SymbolicDataModel</code> <p>the input data_model</p> required <code>embedding_model</code> <code>EmbeddingModel</code> <p>The embedding model to use</p> <code>None</code> <code>name</code> <code>str</code> <p>Optional. The name of the operation.</p> <code>None</code> <code>description</code> <code>str</code> <p>Optional. The description of the operation.</p> <code>None</code> <code>**kwargs</code> <code>keyword arguments</code> <p>Additional keywords forwarded to the EmbeddingModel call.</p> <code>{}</code> <p>Returns:</p> Type Description <code>JsonDataModel | SymbolicDataModel</code> <p>The resulting data_model</p> Source code in <code>synalinks/src/ops/embedding_models.py</code> <pre><code>@synalinks_export([\"synalinks.ops.embedding\", \"synalinks.ops.embedding_models.embedding\"])\nasync def embedding(x, embedding_model=None, name=None, description=None, **kwargs):\n    \"\"\"Extract the embedding vectors from a data model using an `EmbeddingModel`.\n\n    Embedding consist in converting the given data_model into a vector representation.\n    This function always output a data model that uses `Embeddings` schema.\n\n    If the input data model have multiple fields, each one is embedded.\n\n    Args:\n        x (JsonDataModel | SymbolicDataModel): the input data_model\n        embedding_model (EmbeddingModel): The embedding model to use\n        name (str): Optional. The name of the operation.\n        description (str): Optional. The description of the operation.\n        **kwargs (keyword arguments): Additional keywords forwarded to the\n            EmbeddingModel call.\n\n    Returns:\n        (JsonDataModel | SymbolicDataModel): The resulting data_model\n    \"\"\"\n    if embedding_model is None:\n        raise ValueError(\"You should provide the `embedding_model` argument\")\n    if any_symbolic_data_models(x):\n        return await Embedding(\n            embedding_model=embedding_model,\n            name=name,\n            description=description,\n        ).symbolic_call(x)\n    return await Embedding(\n        embedding_model=embedding_model,\n        name=name,\n        description=description,\n        **kwargs,\n    )(x)\n</code></pre>"},{"location":"Synalinks%20API/Ops%20API/JSON%20Ops/","title":"JSON Ops","text":""},{"location":"Synalinks%20API/Ops%20API/JSON%20Ops/#synalinks.src.ops.json.And","title":"<code>And</code>","text":"<p>               Bases: <code>Operation</code></p> <p>Perform a logical <code>And</code> operation between data models.</p> Source code in <code>synalinks/src/ops/json.py</code> <pre><code>class And(Operation):\n    \"\"\"Perform a logical `And` operation between data models.\"\"\"\n\n    def __init__(\n        self,\n        name=None,\n        description=None,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n        )\n\n    async def call(self, x1, x2):\n        if x1 and x2:\n            json = concatenate_json(x1.get_json(), x2.get_json())\n            schema = concatenate_schema(x1.get_schema(), x2.get_schema())\n            return JsonDataModel(json=json, schema=schema, name=self.name)\n        elif x1 and not x2:\n            return None\n        elif not x1 and x2:\n            return None\n        else:\n            return None\n\n    async def compute_output_spec(self, x1, x2):\n        schema = concatenate_schema(x1.get_schema(), x2.get_schema())\n        return SymbolicDataModel(schema=schema, name=self.name)\n</code></pre>"},{"location":"Synalinks%20API/Ops%20API/JSON%20Ops/#synalinks.src.ops.json.Concat","title":"<code>Concat</code>","text":"<p>               Bases: <code>Operation</code></p> <p>Concatenate two data models together.</p> Source code in <code>synalinks/src/ops/json.py</code> <pre><code>class Concat(Operation):\n    \"\"\"Concatenate two data models together.\"\"\"\n\n    def __init__(\n        self,\n        name=None,\n        description=None,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n        )\n\n    async def call(self, x1, x2):\n        if not x1:\n            raise ValueError(f\"Received x1={x1} and x2={x2}\")\n        if not x2:\n            raise ValueError(f\"Received x1={x1} and x2={x2}\")\n        json = concatenate_json(x1.get_json(), x2.get_json())\n        schema = concatenate_schema(x1.get_schema(), x2.get_schema())\n        return JsonDataModel(json=json, schema=schema, name=self.name)\n\n    async def compute_output_spec(self, x1, x2):\n        schema = concatenate_schema(x1.get_schema(), x2.get_schema())\n        return SymbolicDataModel(schema=schema, name=self.name)\n</code></pre>"},{"location":"Synalinks%20API/Ops%20API/JSON%20Ops/#synalinks.src.ops.json.Factorize","title":"<code>Factorize</code>","text":"<p>               Bases: <code>Operation</code></p> <p>Factorize a data model by grouping similar properties together.</p> Source code in <code>synalinks/src/ops/json.py</code> <pre><code>class Factorize(Operation):\n    \"\"\"Factorize a data model by grouping similar properties together.\"\"\"\n\n    def __init__(\n        self,\n        name=None,\n        description=None,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n        )\n\n    async def call(self, x):\n        json = factorize_json(x.get_json())\n        schema = factorize_schema(x.get_schema())\n        return JsonDataModel(json=json, schema=schema, name=self.name)\n\n    async def compute_output_spec(self, x):\n        schema = factorize_schema(x.get_schema())\n        return SymbolicDataModel(schema=schema, name=self.name)\n</code></pre>"},{"location":"Synalinks%20API/Ops%20API/JSON%20Ops/#synalinks.src.ops.json.InMask","title":"<code>InMask</code>","text":"<p>               Bases: <code>Operation</code></p> <p>Keep specific fields of a data model.</p> Source code in <code>synalinks/src/ops/json.py</code> <pre><code>class InMask(Operation):\n    \"\"\"Keep specific fields of a data model.\"\"\"\n\n    def __init__(\n        self,\n        mask=None,\n        recursive=True,\n        name=None,\n        description=None,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n        )\n        self.mask = mask\n        self.recursive = recursive\n\n    async def call(self, x):\n        json = in_mask_json(x.get_json(), mask=self.mask, recursive=self.recursive)\n        schema = in_mask_schema(x.get_schema(), mask=self.mask, recursive=self.recursive)\n        return JsonDataModel(json=json, schema=schema, name=self.name)\n\n    async def compute_output_spec(self, x):\n        schema = in_mask_schema(x.get_schema(), mask=self.mask, recursive=self.recursive)\n        return SymbolicDataModel(schema=schema, name=self.name)\n</code></pre>"},{"location":"Synalinks%20API/Ops%20API/JSON%20Ops/#synalinks.src.ops.json.Or","title":"<code>Or</code>","text":"<p>               Bases: <code>Operation</code></p> <p>Perform a logical <code>Or</code> operation between data models.</p> Source code in <code>synalinks/src/ops/json.py</code> <pre><code>class Or(Operation):\n    \"\"\"Perform a logical `Or` operation between data models.\"\"\"\n\n    def __init__(\n        self,\n        name=None,\n        description=None,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n        )\n\n    async def call(self, x1, x2):\n        if x1 and x2:\n            json = concatenate_json(x1.get_json(), x2.get_json())\n            schema = concatenate_schema(x1.get_schema(), x2.get_schema())\n            return JsonDataModel(json=json, schema=schema, name=self.name)\n        elif x1 and not x2:\n            return JsonDataModel(\n                json=x1.get_json(), schema=x1.get_schema(), name=self.name\n            )\n        elif not x1 and x2:\n            return JsonDataModel(\n                json=x2.get_json(), schema=x2.get_schema(), name=self.name\n            )\n        else:\n            return None\n\n    async def compute_output_spec(self, x1, x2):\n        return SymbolicDataModel(schema=x1.get_schema(), name=self.name)\n</code></pre>"},{"location":"Synalinks%20API/Ops%20API/JSON%20Ops/#synalinks.src.ops.json.OutMask","title":"<code>OutMask</code>","text":"<p>               Bases: <code>Operation</code></p> <p>Mask specific fields of a data model.</p> Source code in <code>synalinks/src/ops/json.py</code> <pre><code>class OutMask(Operation):\n    \"\"\"Mask specific fields of a data model.\"\"\"\n\n    def __init__(\n        self,\n        mask=None,\n        recursive=True,\n        name=None,\n        description=None,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n        )\n        self.mask = mask\n        self.recursive = recursive\n\n    async def call(self, x):\n        json = out_mask_json(x.get_json(), mask=self.mask, recursive=self.recursive)\n        schema = out_mask_schema(x.get_schema(), mask=self.mask, recursive=self.recursive)\n        return JsonDataModel(json=json, schema=schema, name=self.name)\n\n    async def compute_output_spec(self, x):\n        schema = out_mask_schema(x.get_schema(), mask=self.mask, recursive=self.recursive)\n        return SymbolicDataModel(schema=schema, name=self.name)\n</code></pre>"},{"location":"Synalinks%20API/Ops%20API/JSON%20Ops/#synalinks.src.ops.json.Prefix","title":"<code>Prefix</code>","text":"<p>               Bases: <code>Operation</code></p> <p>Add a prefix to all the data model fields (non-recursive).</p> Source code in <code>synalinks/src/ops/json.py</code> <pre><code>class Prefix(Operation):\n    \"\"\"Add a prefix to **all** the data model fields (non-recursive).\"\"\"\n\n    def __init__(\n        self,\n        prefix=None,\n        name=None,\n        description=None,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n        )\n        self.prefix = prefix\n\n    async def call(self, x):\n        json = prefix_json(x.get_json(), self.prefix)\n        schema = prefix_schema(x.get_schema(), self.prefix)\n        return JsonDataModel(json=json, schema=schema, name=self.name)\n\n    async def compute_output_spec(self, x):\n        schema = prefix_schema(x.get_schema(), self.prefix)\n        return SymbolicDataModel(schema=schema, name=self.name)\n</code></pre>"},{"location":"Synalinks%20API/Ops%20API/JSON%20Ops/#synalinks.src.ops.json.Suffix","title":"<code>Suffix</code>","text":"<p>               Bases: <code>Operation</code></p> <p>Add a suffix to all the data model fields (non-recursive).</p> Source code in <code>synalinks/src/ops/json.py</code> <pre><code>class Suffix(Operation):\n    \"\"\"Add a suffix to **all** the data model fields (non-recursive).\"\"\"\n\n    def __init__(\n        self,\n        suffix=None,\n        name=None,\n        description=None,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n        )\n        self.suffix = suffix\n\n    async def call(self, x):\n        json = suffix_json(x.get_json(), self.suffix)\n        schema = suffix_schema(x.get_schema(), self.suffix)\n        return JsonDataModel(json=json, schema=schema, name=self.name)\n\n    async def compute_output_spec(self, x):\n        schema = suffix_schema(x.get_schema(), self.suffix)\n        return SymbolicDataModel(schema=schema, name=self.name)\n</code></pre>"},{"location":"Synalinks%20API/Ops%20API/JSON%20Ops/#synalinks.src.ops.json.Xor","title":"<code>Xor</code>","text":"<p>               Bases: <code>Operation</code></p> <p>Perform a logical <code>Xor</code> operation between data models.</p> Source code in <code>synalinks/src/ops/json.py</code> <pre><code>class Xor(Operation):\n    \"\"\"Perform a logical `Xor` operation between data models.\"\"\"\n\n    def __init__(\n        self,\n        name=None,\n        description=None,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n        )\n\n    async def call(self, x1, x2):\n        if x1 and x2:\n            return None\n        elif x1 and not x2:\n            return JsonDataModel(\n                json=x1.get_json(), schema=x1.get_schema(), name=self.name\n            )\n        elif not x1 and x2:\n            return JsonDataModel(\n                json=x2.get_json(), schema=x2.get_schema(), name=self.name\n            )\n        else:\n            return None\n\n    async def compute_output_spec(self, x1, x2):\n        return SymbolicDataModel(schema=x1.get_schema(), name=self.name)\n</code></pre>"},{"location":"Synalinks%20API/Ops%20API/JSON%20Ops/#synalinks.src.ops.json.concat","title":"<code>concat(x1, x2, name=None, description=None)</code>  <code>async</code>","text":"<p>Concatenate two data models together.</p> <p>Concatenation consist in creating a new data model containing all the elements of the two inputs into a new one. Each field name is made unique if needed by adding a numerical suffix <code>_n</code>, with <code>n</code> being an incremental integer.</p> <p>This operation is implemented in the <code>+</code> Python operator.</p> <p>If any of the data models used is a metaclass or symbolic data model the output is a symbolic data model.</p> <p>If any of the inputs is None, then an exception is raised.</p> <p>If the keys are used more than once, a numerical suffix is added.</p> <p>Table:</p> <code>x1</code> <code>x2</code> Concat (<code>+</code>) <code>x1</code> <code>x2</code> <code>x1 + x2</code> <code>x1</code> <code>None</code> <code>Exception</code> <code>None</code> <code>x2</code> <code>Exception</code> <code>None</code> <code>None</code> <code>Exception</code> <p>Parameters:</p> Name Type Description Default <code>x1</code> <code>JsonDataModel | SymbolicDataModel</code> <p>the first input data model.</p> required <code>x2</code> <code>JsonDataModel | SymbolicDataModel</code> <p>the second input data model.</p> required <code>name</code> <code>str</code> <p>Optional. The name of the operation.</p> <code>None</code> <code>description</code> <code>str</code> <p>Optional. The description of the operation.</p> <code>None</code> <p>Returns:</p> Type Description <code>JsonDataModel | SymbolicDataModel</code> <p>The resulting data model</p> Source code in <code>synalinks/src/ops/json.py</code> <pre><code>@synalinks_export([\"synalinks.ops.concat\", \"synalinks.ops.json.concat\"])\nasync def concat(x1, x2, name=None, description=None):\n    \"\"\"Concatenate two data models together.\n\n    Concatenation consist in creating a new data model containing\n    all the elements of the two inputs into a new one.\n    Each field name is made unique if needed by adding a numerical suffix `_n`,\n    with `n` being an incremental integer.\n\n    This operation is implemented in the `+` Python operator.\n\n    If any of the data models used is a metaclass or symbolic data model\n    the output is a symbolic data model.\n\n    If any of the inputs is None, then an exception is raised.\n\n    If the keys are used more than once, a numerical suffix is added.\n\n    Table:\n\n    | `x1`   | `x2`   | Concat (`+`)      |\n    | ------ | ------ | ----------------- |\n    | `x1`   | `x2`   | `x1 + x2`         |\n    | `x1`   | `None` | `Exception`       |\n    | `None` | `x2`   | `Exception`       |\n    | `None` | `None` | `Exception`       |\n\n    Args:\n        x1 (JsonDataModel | SymbolicDataModel): the first input data model.\n        x2 (JsonDataModel | SymbolicDataModel): the second input data model.\n        name (str): Optional. The name of the operation.\n        description (str): Optional. The description of the operation.\n\n    Returns:\n        (JsonDataModel | SymbolicDataModel): The resulting data model\n    \"\"\"\n    if any_symbolic_data_models(x1, x2):\n        return await Concat(\n            name=name,\n            description=description,\n        ).symbolic_call(x1, x2)\n    return await Concat(\n        name=name,\n        description=description,\n    )(x1, x2)\n</code></pre>"},{"location":"Synalinks%20API/Ops%20API/JSON%20Ops/#synalinks.src.ops.json.factorize","title":"<code>factorize(x, name=None, description=None)</code>  <code>async</code>","text":"<p>Factorize a data model by grouping similar properties together.</p> <p>Factorization consist in grouping the same properties into lists. The property key of the resulting grouped property is changed to its plural form. For example <code>action</code> become <code>actions</code>, or <code>query</code> become <code>queries</code>.</p> <p>If the data models used is a metaclass or symbolic data model the output is a symbolic data model.</p> <p>This operation is implemented in <code>.factorize()</code></p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>JsonDataModel | SymbolicDataModel</code> <p>the input data model.</p> required <code>name</code> <code>str</code> <p>Optional. The name of the operation.</p> <code>None</code> <code>description</code> <code>str</code> <p>Optional. The description of the operation.</p> <code>None</code> <p>Returns:</p> Type Description <code>JsonDataModel | SymbolicDataModel</code> <p>The resulting data model.</p> Source code in <code>synalinks/src/ops/json.py</code> <pre><code>@synalinks_export([\"synalinks.ops.factorize\", \"synalinks.ops.json.factorize\"])\nasync def factorize(x, name=None, description=None):\n    \"\"\"Factorize a data model by grouping similar properties together.\n\n    Factorization consist in grouping the same properties into lists.\n    The property key of the resulting grouped property is changed to its plural form.\n    For example `action` become `actions`, or `query` become `queries`.\n\n    If the data models used is a metaclass or symbolic data model\n    the output is a symbolic data model.\n\n    This operation is implemented in `.factorize()`\n\n    Args:\n        x (JsonDataModel | SymbolicDataModel): the input data model.\n        name (str): Optional. The name of the operation.\n        description (str): Optional. The description of the operation.\n\n    Returns:\n        (JsonDataModel | SymbolicDataModel): The resulting data model.\n    \"\"\"\n    if any_symbolic_data_models(x):\n        return await Factorize(\n            name=name,\n            description=description,\n        ).symbolic_call(x)\n    return await Factorize(\n        name=name,\n        description=description,\n    )(x)\n</code></pre>"},{"location":"Synalinks%20API/Ops%20API/JSON%20Ops/#synalinks.src.ops.json.in_mask","title":"<code>in_mask(x, mask=None, recursive=True, name=None, description=None)</code>  <code>async</code>","text":"<p>Keep specific fields of a data model.</p> <p>In masking consists in keeping the properties that match with the keys given in the mask. The masking process ignores the numerical suffixes that could be added by other operations.</p> <p>If the data models used is a metaclass or symbolic data model the output is a symbolic data model.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>JsonDataModel | SymbolicDataModel</code> <p>the input data model</p> required <code>mask</code> <code>list</code> <p>the input mask (list of keys)</p> <code>None</code> <code>recursive</code> <code>bool</code> <p>Whether or not to keep recursively for nested objects (default True).</p> <code>True</code> <code>name</code> <code>str</code> <p>Optional. The name of the operation.</p> <code>None</code> <code>description</code> <code>str</code> <p>Optional. The description of the operation.</p> <code>None</code> <p>Returns:</p> Type Description <code>JsonDataModel | SymbolicDataModel</code> <p>The resulting data model.</p> Source code in <code>synalinks/src/ops/json.py</code> <pre><code>@synalinks_export([\"synalinks.ops.in_mask\", \"synalinks.ops.json.in_mask\"])\nasync def in_mask(x, mask=None, recursive=True, name=None, description=None):\n    \"\"\"Keep specific fields of a data model.\n\n    In masking consists in keeping the properties that match with the keys given\n    in the mask. The masking process ignores the numerical suffixes that could be added\n    by other operations.\n\n    If the data models used is a metaclass or symbolic data model\n    the output is a symbolic data model.\n\n    Args:\n        x (JsonDataModel | SymbolicDataModel): the input data model\n        mask (list): the input mask (list of keys)\n        recursive (bool): Whether or not to keep\n            recursively for nested objects (default True).\n        name (str): Optional. The name of the operation.\n        description (str): Optional. The description of the operation.\n\n    Returns:\n        (JsonDataModel | SymbolicDataModel): The resulting data model.\n    \"\"\"\n    if x is None:\n        return x\n    if mask is None:\n        raise ValueError(\"You should specify the `mask` argument\")\n    if any_symbolic_data_models(x):\n        return await InMask(\n            mask=mask,\n            recursive=recursive,\n            name=name,\n            description=description,\n        ).symbolic_call(x)\n    return await InMask(\n        mask=mask,\n        recursive=recursive,\n        name=name,\n        description=description,\n    )(x)\n</code></pre>"},{"location":"Synalinks%20API/Ops%20API/JSON%20Ops/#synalinks.src.ops.json.logical_and","title":"<code>logical_and(x1, x2, name=None, description=None)</code>  <code>async</code>","text":"<p>Perform a logical <code>And</code> operation between two data models.</p> <p>If one of the inputs is <code>None</code>, then this operation output <code>None</code>. If both inputs are provided, the output is a concatenation of the two given data models.</p> <p>This operation is implemented in the Python <code>&amp;</code> operator.</p> <p>If any of the data models used is a metaclass or symbolic data model the output is a symbolic data model.</p> <p>Table:</p> <code>x1</code> <code>x2</code> Logical And (<code>&amp;</code>) <code>x1</code> <code>x2</code> <code>x1 + x2</code> <code>x1</code> <code>None</code> <code>None</code> <code>None</code> <code>x2</code> <code>None</code> <code>None</code> <code>None</code> <code>None</code> <p>Parameters:</p> Name Type Description Default <code>x1</code> <code>JsonDataModel | SymbolicDataModel</code> <p>The first input data model.</p> required <code>x2</code> <code>JsonDataModel | SymbolicDataModel</code> <p>The second input data model.</p> required <code>name</code> <code>str</code> <p>Optional. The name of the operation.</p> <code>None</code> <code>description</code> <code>str</code> <p>Optional. The description of the operation.</p> <code>None</code> <p>Returns:</p> Type Description <code>JsonDataModel | SymbolicDataModel | None</code> <p>The resulting data model or None if the condition is not met.</p> Source code in <code>synalinks/src/ops/json.py</code> <pre><code>@synalinks_export([\"synalinks.ops.logical_and\", \"synalinks.ops.json.logical_and\"])\nasync def logical_and(x1, x2, name=None, description=None):\n    \"\"\"Perform a logical `And` operation between two data models.\n\n    If one of the inputs is `None`, then this operation output `None`.\n    If both inputs are provided, the output is a concatenation\n    of the two given data models.\n\n    This operation is implemented in the Python `&amp;` operator.\n\n    If any of the data models used is a metaclass or symbolic data model\n    the output is a symbolic data model.\n\n    Table:\n\n    | `x1`   | `x2`   | Logical And (`&amp;`) |\n    | ------ | ------ | ----------------- |\n    | `x1`   | `x2`   | `x1 + x2`         |\n    | `x1`   | `None` | `None`            |\n    | `None` | `x2`   | `None`            |\n    | `None` | `None` | `None`            |\n\n    Args:\n        x1 (JsonDataModel | SymbolicDataModel): The first input data model.\n        x2 (JsonDataModel | SymbolicDataModel): The second input data model.\n        name (str): Optional. The name of the operation.\n        description (str): Optional. The description of the operation.\n\n    Returns:\n        (JsonDataModel | SymbolicDataModel | None): The resulting data model or\n            None if the condition is not met.\n    \"\"\"\n    if any_symbolic_data_models(x1, x2):\n        return await And(\n            name=name,\n            description=description,\n        ).symbolic_call(x1, x2)\n    return await And(\n        name=name,\n        description=description,\n    )(x1, x2)\n</code></pre>"},{"location":"Synalinks%20API/Ops%20API/JSON%20Ops/#synalinks.src.ops.json.logical_or","title":"<code>logical_or(x1, x2, name=None, description=None)</code>  <code>async</code>","text":"<p>Perform a logical <code>Or</code> between two data models.</p> <p>If one of the input is <code>None</code>, then output the other one. If both inputs are provided, the output is a concatenation of the two given data models.</p> <p>If any of the data models used is a metaclass or symbolic data model the output is a symbolic data model.</p> <p>This operation is implemented in the Python <code>|</code> operator.</p> <p>Table:</p> <code>x1</code> <code>x2</code> Logical Or (<code>|</code>) <code>x1</code> <code>x2</code> <code>x1 + x2</code> <code>x1</code> <code>None</code> <code>x1</code> <code>None</code> <code>x2</code> <code>x2</code> <code>None</code> <code>None</code> <code>None</code> <p>Parameters:</p> Name Type Description Default <code>x1</code> <code>JsonDataModel | SymbolicDataModel</code> <p>The first input data model.</p> required <code>x2</code> <code>JsonDataModel | SymbolicDataModel</code> <p>The second input data model.</p> required <code>name</code> <code>str</code> <p>Optional. The name of the operation.</p> <code>None</code> <code>description</code> <code>str</code> <p>Optional. The description of the operation.</p> <code>None</code> <p>Returns:</p> Type Description <code>JsonDataModel | SymbolicDataModel | None</code> <p>The resulting data model or None if the condition is not met.</p> Source code in <code>synalinks/src/ops/json.py</code> <pre><code>@synalinks_export([\"synalinks.ops.logical_or\", \"synalinks.ops.json.logical_or\"])\nasync def logical_or(x1, x2, name=None, description=None):\n    \"\"\"Perform a logical `Or` between two data models.\n\n    If one of the input is `None`, then output the other one.\n    If both inputs are provided, the output is a concatenation\n    of the two given data models.\n\n    If any of the data models used is a metaclass or symbolic data model\n    the output is a symbolic data model.\n\n    This operation is implemented in the Python `|` operator.\n\n    Table:\n\n    | `x1`   | `x2`   | Logical Or (`|`) |\n    | ------ | ------ | ---------------- |\n    | `x1`   | `x2`   | `x1 + x2`        |\n    | `x1`   | `None` | `x1`             |\n    | `None` | `x2`   | `x2`             |\n    | `None` | `None` | `None`           |\n\n    Args:\n        x1 (JsonDataModel | SymbolicDataModel): The first input data model.\n        x2 (JsonDataModel | SymbolicDataModel): The second input data model.\n        name (str): Optional. The name of the operation.\n        description (str): Optional. The description of the operation.\n\n    Returns:\n        (JsonDataModel | SymbolicDataModel | None): The resulting data model or\n            None if the condition is not met.\n    \"\"\"\n    if any_symbolic_data_models(x1, x2):\n        return await Or(\n            name=name,\n            description=description,\n        ).symbolic_call(x1, x2)\n    return await Or(\n        name=name,\n        description=description,\n    )(x1, x2)\n</code></pre>"},{"location":"Synalinks%20API/Ops%20API/JSON%20Ops/#synalinks.src.ops.json.logical_xor","title":"<code>logical_xor(x1, x2, name=None, description=None)</code>  <code>async</code>","text":"<p>Perform a logical <code>Xor</code> between two data models.</p> <p>If one of the input is <code>None</code>, then output the other one. If both inputs are provided, the output is <code>None</code>.</p> <p>If any of the data models used is a metaclass or symbolic data model the output is a symbolic data model.</p> <p>This operation is implemented in the Python <code>^</code> operator.</p> <p>Table:</p> <code>x1</code> <code>x2</code> Logical Xor (<code>^</code>) <code>x1</code> <code>x2</code> <code>None</code> <code>x1</code> <code>None</code> <code>x1</code> <code>None</code> <code>x2</code> <code>x2</code> <code>None</code> <code>None</code> <code>None</code> <p>Parameters:</p> Name Type Description Default <code>x1</code> <code>JsonDataModel | SymbolicDataModel</code> <p>The first input data model.</p> required <code>x2</code> <code>JsonDataModel | SymbolicDataModel</code> <p>The second input data model.</p> required <code>name</code> <code>str</code> <p>Optional. The name of the operation.</p> <code>None</code> <code>description</code> <code>str</code> <p>Optional. The description of the operation.</p> <code>None</code> <p>Returns:</p> Type Description <code>JsonDataModel | SymbolicDataModel | None</code> <p>The resulting data model or None if the condition is not met.</p> Source code in <code>synalinks/src/ops/json.py</code> <pre><code>@synalinks_export([\"synalinks.ops.logical_xor\", \"synalinks.ops.json.logical_xor\"])\nasync def logical_xor(x1, x2, name=None, description=None):\n    \"\"\"Perform a logical `Xor` between two data models.\n\n    If one of the input is `None`, then output the other one.\n    If both inputs are provided, the output is `None`.\n\n    If any of the data models used is a metaclass or symbolic data model\n    the output is a symbolic data model.\n\n    This operation is implemented in the Python `^` operator.\n\n    Table:\n\n    | `x1`   | `x2`   | Logical Xor (`^`)|\n    | ------ | ------ | ---------------- |\n    | `x1`   | `x2`   | `None`           |\n    | `x1`   | `None` | `x1`             |\n    | `None` | `x2`   | `x2`             |\n    | `None` | `None` | `None`           |\n\n    Args:\n        x1 (JsonDataModel | SymbolicDataModel): The first input data model.\n        x2 (JsonDataModel | SymbolicDataModel): The second input data model.\n        name (str): Optional. The name of the operation.\n        description (str): Optional. The description of the operation.\n\n    Returns:\n        (JsonDataModel | SymbolicDataModel | None): The resulting data model or\n            None if the condition is not met.\n    \"\"\"\n    if any_symbolic_data_models(x1, x2):\n        return await Xor(\n            name=name,\n            description=description,\n        ).symbolic_call(x1, x2)\n    return await Xor(\n        name=name,\n        description=description,\n    )(x1, x2)\n</code></pre>"},{"location":"Synalinks%20API/Ops%20API/JSON%20Ops/#synalinks.src.ops.json.out_mask","title":"<code>out_mask(x, mask=None, recursive=True, name=None, description=None)</code>  <code>async</code>","text":"<p>Mask specific fields of a data model.</p> <p>Out masking consist in removing the properties that match with the keys given in the mask. The masking process ignore the numerical suffixes that could be added by other operations.</p> <p>If the data models used is a metaclass or symbolic data model the output is a symbolic data model.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>JsonDataModel | SymbolicDataModel</code> <p>the input data model.</p> required <code>mask</code> <code>list</code> <p>the input mask (list of keys).</p> <code>None</code> <code>recursive</code> <code>bool</code> <p>Whether or not to remove recursively for nested objects (default True).</p> <code>True</code> <code>name</code> <code>str</code> <p>Optional. The name of the operation.</p> <code>None</code> <code>description</code> <code>str</code> <p>Optional. The description of the operation.</p> <code>None</code> <p>Returns:</p> Type Description <code>JsonDataModel | SymbolicDataModel</code> <p>The resulting data model.</p> Source code in <code>synalinks/src/ops/json.py</code> <pre><code>@synalinks_export([\"synalinks.ops.out_mask\", \"synalinks.ops.json.out_mask\"])\nasync def out_mask(x, mask=None, recursive=True, name=None, description=None):\n    \"\"\"Mask specific fields of a data model.\n\n    Out masking consist in removing the properties that match with the keys given\n    in the mask. The masking process ignore the numerical suffixes that could be added\n    by other operations.\n\n    If the data models used is a metaclass or symbolic data model\n    the output is a symbolic data model.\n\n    Args:\n        x (JsonDataModel | SymbolicDataModel): the input data model.\n        mask (list): the input mask (list of keys).\n        recursive (bool): Whether or not to remove\n            recursively for nested objects (default True).\n        name (str): Optional. The name of the operation.\n        description (str): Optional. The description of the operation.\n\n    Returns:\n        (JsonDataModel | SymbolicDataModel): The resulting data model.\n    \"\"\"\n    if x is None:\n        return x\n    if mask is None:\n        raise ValueError(\"You should specify the `mask` argument\")\n    if any_symbolic_data_models(x):\n        return await OutMask(\n            mask=mask,\n            recursive=recursive,\n            name=name,\n            description=description,\n        ).symbolic_call(x)\n    return await OutMask(\n        mask=mask,\n        recursive=recursive,\n        name=name,\n        description=description,\n    )(x)\n</code></pre>"},{"location":"Synalinks%20API/Ops%20API/JSON%20Ops/#synalinks.src.ops.json.prefix","title":"<code>prefix(x, prefix=None, name=None, description=None)</code>  <code>async</code>","text":"<p>Add a prefix to all the data model fields (non-recursive).</p> <p>If the data models used is a metaclass or symbolic data model the output is a symbolic data model.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>JsonDataModel | SymbolicDataModel</code> <p>the input data model</p> required <code>prefix</code> <code>str</code> <p>the prefix to add.</p> <code>None</code> <code>name</code> <code>str</code> <p>Optional. The name of the operation.</p> <code>None</code> <code>description</code> <code>str</code> <p>Optional. The description of the operation.</p> <code>None</code> <p>Returns:</p> Type Description <code>JsonDataModel | SymbolicDataModel</code> <p>The resulting data model.</p> Source code in <code>synalinks/src/ops/json.py</code> <pre><code>@synalinks_export([\"synalinks.ops.prefix\", \"synalinks.ops.json.prefix\"])\nasync def prefix(x, prefix=None, name=None, description=None):\n    \"\"\"Add a prefix to **all** the data model fields (non-recursive).\n\n    If the data models used is a metaclass or symbolic data model\n    the output is a symbolic data model.\n\n    Args:\n        x (JsonDataModel | SymbolicDataModel): the input data model\n        prefix (str): the prefix to add.\n        name (str): Optional. The name of the operation.\n        description (str): Optional. The description of the operation.\n\n    Returns:\n        (JsonDataModel | SymbolicDataModel): The resulting data model.\n    \"\"\"\n    if x is None:\n        return x\n    if prefix is None:\n        raise ValueError(\"You should specify the `prefix` argument\")\n    if any_symbolic_data_models(x):\n        return await Prefix(\n            prefix=prefix,\n            name=name,\n            description=description,\n        ).symbolic_call(x)\n    return await Prefix(\n        prefix=prefix,\n        name=name,\n        description=description,\n    )(x)\n</code></pre>"},{"location":"Synalinks%20API/Ops%20API/JSON%20Ops/#synalinks.src.ops.json.suffix","title":"<code>suffix(x, suffix=None, name=None, description=None)</code>  <code>async</code>","text":"<p>Add a suffix to all the data model fields (non-recursive).</p> <p>If the data models used is a metaclass or symbolic data model the output is a symbolic data model.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>JsonDataModel | SymbolicDataModel</code> <p>the input data model</p> required <code>suffix</code> <code>str</code> <p>the suffix to add.</p> <code>None</code> <code>name</code> <code>str</code> <p>Optional. The name of the operation.</p> <code>None</code> <code>description</code> <code>str</code> <p>Optional. The description of the operation.</p> <code>None</code> <p>Returns:</p> Type Description <code>JsonDataModel | SymbolicDataModel</code> <p>The resulting data model</p> Source code in <code>synalinks/src/ops/json.py</code> <pre><code>@synalinks_export([\"synalinks.ops.suffix\", \"synalinks.ops.json.suffix\"])\nasync def suffix(x, suffix=None, name=None, description=None):\n    \"\"\"Add a suffix to **all** the data model fields (non-recursive).\n\n    If the data models used is a metaclass or symbolic data model\n    the output is a symbolic data model.\n\n    Args:\n        x (JsonDataModel | SymbolicDataModel): the input data model\n        suffix (str): the suffix to add.\n        name (str): Optional. The name of the operation.\n        description (str): Optional. The description of the operation.\n\n    Returns:\n        (JsonDataModel | SymbolicDataModel): The resulting data model\n    \"\"\"\n    if x is None:\n        return x\n    if suffix is None:\n        raise ValueError(\"You should specify the `suffix` argument\")\n    if any_symbolic_data_models(x):\n        return await Suffix(\n            suffix=suffix,\n            name=name,\n            description=description,\n        ).symbolic_call(x)\n    return await Suffix(\n        suffix=suffix,\n        name=name,\n        description=description,\n    )(x)\n</code></pre>"},{"location":"Synalinks%20API/Ops%20API/Language%20Models%20Ops/","title":"Language Models Ops","text":""},{"location":"Synalinks%20API/Ops%20API/Language%20Models%20Ops/#synalinks.src.ops.language_models.Predict","title":"<code>Predict</code>","text":"<p>               Bases: <code>Operation</code></p> <p>Perform a prediction using a <code>LanguageModel</code>.</p> Source code in <code>synalinks/src/ops/language_models.py</code> <pre><code>class Predict(Operation):\n    \"\"\"Perform a prediction using a `LanguageModel`.\"\"\"\n\n    def __init__(\n        self,\n        schema=None,\n        data_model=None,\n        language_model=None,\n        streaming=False,\n        name=None,\n        description=None,\n        **kwargs,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n        )\n        if not schema and data_model:\n            schema = data_model.get_schema()\n        self.schema = schema\n        self.data_model = data_model\n        self.language_model = language_model\n        if schema and streaming:\n            streaming = False\n        self.streaming = streaming\n        self.lm_kwargs = kwargs\n\n    async def call(self, x):\n        value = await self.language_model(\n            x,\n            schema=self.schema,\n            streaming=self.streaming,\n            **self.lm_kwargs,\n        )\n        if isinstance(value, StreamingIterator):\n            return value\n        if not value:\n            return None\n        if self.schema:\n            return JsonDataModel(json=value, schema=self.schema, name=self.name)\n        else:\n            return JsonDataModel(\n                json=value, schema=ChatMessage.get_schema(), name=self.name\n            )\n\n    async def compute_output_spec(self, x):\n        if self.schema:\n            return SymbolicDataModel(schema=self.schema, name=self.name)\n        else:\n            return SymbolicDataModel(schema=ChatMessage.get_schema(), name=self.name)\n\n    def get_config(self):\n        config = {\n            \"schema\": self.schema,\n            \"streaming\": self.streaming,\n            \"name\": self.name,\n            \"description\": self.description,\n        }\n        language_model_config = serialization_lib.serialize_synalinks_object(\n            self.language_model\n        )\n        config.update({\"lm_kwargs\": self.lm_kwargs})\n        return {\"language_model\": language_model_config, **config}\n\n    @classmethod\n    def from_config(cls, config):\n        language_model = serialization_lib.deserialize_synalinks_object(\n            config.pop(\"language_model\")\n        )\n        lm_kwargs = config.pop(\"lm_kwargs\")\n        return cls(language_model=language_model, **config, **lm_kwargs)\n</code></pre>"},{"location":"Synalinks%20API/Ops%20API/Language%20Models%20Ops/#synalinks.src.ops.language_models.predict","title":"<code>predict(x, schema=None, data_model=None, language_model=None, streaming=False, name=None, description=None, **kwargs)</code>  <code>async</code>","text":"<p>Perform a prediction using a <code>LanguageModel</code>.</p> <p>Predict consist in predicting a target data_model from an input data_model. This function uses a backend DataModel to get the target schema.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>JsonDataModel | SymbolicDataModel</code> <p>the input data model.</p> required <code>data_model</code> <code>DataModel</code> <p>The target data model.</p> <code>None</code> <code>language_model</code> <code>LanguageModel</code> <p>The language model to use</p> <code>None</code> <code>streaming</code> <code>bool</code> <p>Enable streaming if True (Default to False)</p> <code>False</code> <code>name</code> <code>str</code> <p>Optional. The name of the operation.</p> <code>None</code> <code>description</code> <code>str</code> <p>Optional. The description of the operation.</p> <code>None</code> <code>**kwargs</code> <code>keyword arguments</code> <p>Additional keywords forwarded to the LanguageModel call.</p> <code>{}</code> <p>Returns:</p> Type Description <code>JsonDataModel | SymbolicDataModel</code> <p>The resulting data model.</p> Source code in <code>synalinks/src/ops/language_models.py</code> <pre><code>@synalinks_export([\"synalinks.ops.predict\", \"synalinks.ops.json.predict\"])\nasync def predict(\n    x,\n    schema=None,\n    data_model=None,\n    language_model=None,\n    streaming=False,\n    name=None,\n    description=None,\n    **kwargs,\n):\n    \"\"\"Perform a prediction using a `LanguageModel`.\n\n    Predict consist in predicting a target data_model from an input data_model.\n    This function uses a backend DataModel to get the target schema.\n\n    Args:\n        x (JsonDataModel | SymbolicDataModel): the input data model.\n        data_model (DataModel): The target data model.\n        language_model (LanguageModel): The language model to use\n        streaming (bool): Enable streaming if True (Default to False)\n        name (str): Optional. The name of the operation.\n        description (str): Optional. The description of the operation.\n        **kwargs (keyword arguments): Additional keywords forwarded to the\n            LanguageModel call.\n\n    Returns:\n        (JsonDataModel | SymbolicDataModel): The resulting data model.\n    \"\"\"\n    if language_model is None:\n        raise ValueError(\"You should provide the `language_model` argument\")\n    if any_symbolic_data_models(x):\n        return await Predict(\n            schema=schema,\n            data_model=data_model,\n            language_model=language_model,\n            streaming=False,\n            name=name,\n            description=description,\n        ).symbolic_call(x)\n    return await Predict(\n        schema=schema,\n        data_model=data_model,\n        language_model=language_model,\n        streaming=streaming,\n        name=name,\n        description=description,\n        **kwargs,\n    )(x)\n</code></pre>"},{"location":"Synalinks%20API/Optimizers%20API/","title":"Optimizers API","text":"<p>The <code>Optimizer</code>s are a key element in Synalinks, they updates the variables and backpropagate the rewards.</p> <p>They are in charge of modifying and optimizing the variables (including the prompts) of each individual module composing a synalinks program.</p> <pre><code>graph LR\nA[Training Data] --&gt;|Provide x:DataModel| B[Program];\nB --&gt;|Generate y_pred:JsonDataModel| C[Reward];\nA --&gt;|Provide y_true:DataModel| C;\nC --&gt;|Compute reward:Float| D[Optimizer];\nD --&gt;|Update trainable_variable:Variable| B;</code></pre> <p>This reinforcement loop is what makes possible for the system to learn by repeatedly making predictions and refining its knowledge/methodology in order  to maximize the reward.</p>"},{"location":"Synalinks%20API/Optimizers%20API/#optimizers-api-overview","title":"Optimizers API overview","text":"<ul> <li>Base Optimizer class</li> <li>RandomFewShot optimizer</li> <li>OPRO optimizer</li> <li>FewShotOPRO optimizer</li> </ul>"},{"location":"Synalinks%20API/Optimizers%20API/Base%20Optimizer%20class/","title":"Base Optimizer class","text":"<p>               Bases: <code>SynalinksSaveable</code></p> <p>Optimizer base class: all Synalinks optimizers inherit from this class.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>dict</code> <p>The schema of the variables that the optimizer can act upon.</p> <code>None</code> <code>data_model</code> <code>DataModel</code> <p>The backend data model that the optimizer can act upon, if no schema is specified, uses the data model to infer it.</p> <code>None</code> <code>name</code> <code>str</code> <p>The name of the optimizer.</p> <code>None</code> <code>description</code> <code>str</code> <p>The description of the optimizer.</p> <code>None</code> Source code in <code>synalinks/src/optimizers/optimizer.py</code> <pre><code>class Optimizer(SynalinksSaveable):\n    \"\"\"Optimizer base class: all Synalinks optimizers inherit from this class.\n\n    Args:\n        schema (dict): The schema of the variables that the optimizer can act upon.\n        data_model (DataModel): The backend data model that the optimizer can act upon,\n            if no schema is specified, uses the data model to infer it.\n        name (str): The name of the optimizer.\n        description (str): The description of the optimizer.\n    \"\"\"\n\n    def __init__(\n        self,\n        schema=None,\n        data_model=None,\n        name=None,\n        description=None,\n        **kwargs,\n    ):\n        self._lock = False\n\n        if kwargs:\n            raise ValueError(f\"Argument(s) not recognized: {kwargs}\")\n\n        if name is None:\n            name = auto_name(self.__class__.__name__)\n        self.name = name\n\n        if description is None:\n            if self.__class__.__doc__:\n                description = docstring_parser.parse(\n                    self.__class__.__doc__\n                ).short_description\n            else:\n                description = \"\"\n        self.description = description\n\n        if not data_model and not schema:\n            raise ValueError(\n                \"You should provide at least one argument \"\n                \"between `data_model` or `schema`\"\n            )\n        if not schema and data_model:\n            schema = standardize_schema(data_model.get_schema())\n        self._schema = schema\n\n        self.built = False\n        self._variables = []\n        self._tracker = Tracker(\n            {\n                \"variables\": (\n                    lambda x: isinstance(x, backend.Variable),\n                    self._variables,\n                ),\n            }\n        )\n        with backend.name_scope(self.name, caller=self):\n            iterations = backend.Variable(\n                initializer=Empty(data_model=Iteration),\n                data_model=Iteration,\n                trainable=False,\n                name=\"iteration\",\n            )\n        self._track_variable(iterations)\n        self._iteration = iterations\n\n    def get_schema(self):\n        return self._schema\n\n    @property\n    def variables(self):\n        return self._variables[:]\n\n    @property\n    def iterations(self):\n        return self._iteration\n\n    def _track_variable(self, variable):\n        self._tracker.add_to_store(\"variables\", variable)\n\n    def save_own_variables(self, store):\n        \"\"\"Get the state of this optimizer object.\"\"\"\n        for i, variable in enumerate(self.variables):\n            store[str(i)] = variable.numpy()\n\n    def load_own_variables(self, store):\n        \"\"\"Set the state of this optimizer object.\"\"\"\n        if len(store.keys()) != len(self.variables):\n            msg = (\n                f\"Skipping variable loading for optimizer '{self.name}', \"\n                f\"because it has {len(self.variables)} variables whereas \"\n                f\"the saved optimizer has {len(store.keys())} variables. \"\n            )\n            if len(self.variables) == 0:\n                msg += (\n                    \"This is likely because the optimizer has not been called/built yet.\"\n                )\n            warnings.warn(msg, stacklevel=2)\n            return\n        for i, variable in enumerate(self.variables):\n            variable.assign(store[str(i)])\n\n    def _check_super_called(self):\n        if not hasattr(self, \"_lock\"):\n            raise RuntimeError(\n                f\"In optimizer '{self.__class__.__name__}', you forgot to call \"\n                \"`super().__init__()` as the first statement \"\n                \"in the `__init__()` method. \"\n                \"Go add it!\"\n            )\n\n    async def apply_optimization(self, trainable_variables, reward=None):\n        \"\"\"Apply the backprop/optimization for each trainable variables\n        that match the optimizer schema.\n        \"\"\"\n        if not self.built:\n            asyncio.get_event_loop().run_until_complete(self.build(trainable_variables))\n        iteration = self._iteration.get(\"iteration\")\n        self._iteration.update({\"iteration\": iteration + 1})\n        for variable in trainable_variables:\n            if contains_schema(variable.get_schema(), self.get_schema()):\n                await self.optimize(variable, reward=reward)\n\n    async def finalize_variable_values(self, trainable_variables):\n        \"\"\"Finalize the optimization of the variables (cleanup/scaling etc.).\"\"\"\n        for variable in trainable_variables:\n            if contains_schema(variable.get_schema(), self.get_schema()):\n                await self.finalize(variable)\n\n    async def optimize(self, trainable_variable, reward=None):\n        \"\"\"Perform a backprop/optimization on a single variable.\n\n        This function needs to be implemented by subclassed Optimizer.\n        \"\"\"\n        raise NotImplementedError(\n            \"Optimizer subclasses must implement the `optimize()` method.\"\n        )\n\n    async def finalize(self, trainable_variable):\n        \"\"\"Finalize the optimization of the variable (cleanup/scaling etc.).\n\n        This function needs to be implemented by subclassed Optimizer.\n        \"\"\"\n        raise NotImplementedError(\n            \"Optimizer subclasses must implement the `finalize()` method.\"\n        )\n\n    def get_config(self):\n        return {\n            \"name\": self.name,\n            \"description\": self.description,\n            \"schema\": self.schema,\n        }\n\n    @classmethod\n    def from_config(cls, config):\n        return cls(**config)\n\n    def __repr__(self):\n        return f\"&lt;Optimizer name={self.name} description={self.description}&gt;\"\n</code></pre>"},{"location":"Synalinks%20API/Optimizers%20API/Base%20Optimizer%20class/#synalinks.src.optimizers.optimizer.Optimizer.apply_optimization","title":"<code>apply_optimization(trainable_variables, reward=None)</code>  <code>async</code>","text":"<p>Apply the backprop/optimization for each trainable variables that match the optimizer schema.</p> Source code in <code>synalinks/src/optimizers/optimizer.py</code> <pre><code>async def apply_optimization(self, trainable_variables, reward=None):\n    \"\"\"Apply the backprop/optimization for each trainable variables\n    that match the optimizer schema.\n    \"\"\"\n    if not self.built:\n        asyncio.get_event_loop().run_until_complete(self.build(trainable_variables))\n    iteration = self._iteration.get(\"iteration\")\n    self._iteration.update({\"iteration\": iteration + 1})\n    for variable in trainable_variables:\n        if contains_schema(variable.get_schema(), self.get_schema()):\n            await self.optimize(variable, reward=reward)\n</code></pre>"},{"location":"Synalinks%20API/Optimizers%20API/Base%20Optimizer%20class/#synalinks.src.optimizers.optimizer.Optimizer.finalize","title":"<code>finalize(trainable_variable)</code>  <code>async</code>","text":"<p>Finalize the optimization of the variable (cleanup/scaling etc.).</p> <p>This function needs to be implemented by subclassed Optimizer.</p> Source code in <code>synalinks/src/optimizers/optimizer.py</code> <pre><code>async def finalize(self, trainable_variable):\n    \"\"\"Finalize the optimization of the variable (cleanup/scaling etc.).\n\n    This function needs to be implemented by subclassed Optimizer.\n    \"\"\"\n    raise NotImplementedError(\n        \"Optimizer subclasses must implement the `finalize()` method.\"\n    )\n</code></pre>"},{"location":"Synalinks%20API/Optimizers%20API/Base%20Optimizer%20class/#synalinks.src.optimizers.optimizer.Optimizer.finalize_variable_values","title":"<code>finalize_variable_values(trainable_variables)</code>  <code>async</code>","text":"<p>Finalize the optimization of the variables (cleanup/scaling etc.).</p> Source code in <code>synalinks/src/optimizers/optimizer.py</code> <pre><code>async def finalize_variable_values(self, trainable_variables):\n    \"\"\"Finalize the optimization of the variables (cleanup/scaling etc.).\"\"\"\n    for variable in trainable_variables:\n        if contains_schema(variable.get_schema(), self.get_schema()):\n            await self.finalize(variable)\n</code></pre>"},{"location":"Synalinks%20API/Optimizers%20API/Base%20Optimizer%20class/#synalinks.src.optimizers.optimizer.Optimizer.load_own_variables","title":"<code>load_own_variables(store)</code>","text":"<p>Set the state of this optimizer object.</p> Source code in <code>synalinks/src/optimizers/optimizer.py</code> <pre><code>def load_own_variables(self, store):\n    \"\"\"Set the state of this optimizer object.\"\"\"\n    if len(store.keys()) != len(self.variables):\n        msg = (\n            f\"Skipping variable loading for optimizer '{self.name}', \"\n            f\"because it has {len(self.variables)} variables whereas \"\n            f\"the saved optimizer has {len(store.keys())} variables. \"\n        )\n        if len(self.variables) == 0:\n            msg += (\n                \"This is likely because the optimizer has not been called/built yet.\"\n            )\n        warnings.warn(msg, stacklevel=2)\n        return\n    for i, variable in enumerate(self.variables):\n        variable.assign(store[str(i)])\n</code></pre>"},{"location":"Synalinks%20API/Optimizers%20API/Base%20Optimizer%20class/#synalinks.src.optimizers.optimizer.Optimizer.optimize","title":"<code>optimize(trainable_variable, reward=None)</code>  <code>async</code>","text":"<p>Perform a backprop/optimization on a single variable.</p> <p>This function needs to be implemented by subclassed Optimizer.</p> Source code in <code>synalinks/src/optimizers/optimizer.py</code> <pre><code>async def optimize(self, trainable_variable, reward=None):\n    \"\"\"Perform a backprop/optimization on a single variable.\n\n    This function needs to be implemented by subclassed Optimizer.\n    \"\"\"\n    raise NotImplementedError(\n        \"Optimizer subclasses must implement the `optimize()` method.\"\n    )\n</code></pre>"},{"location":"Synalinks%20API/Optimizers%20API/Base%20Optimizer%20class/#synalinks.src.optimizers.optimizer.Optimizer.save_own_variables","title":"<code>save_own_variables(store)</code>","text":"<p>Get the state of this optimizer object.</p> Source code in <code>synalinks/src/optimizers/optimizer.py</code> <pre><code>def save_own_variables(self, store):\n    \"\"\"Get the state of this optimizer object.\"\"\"\n    for i, variable in enumerate(self.variables):\n        store[str(i)] = variable.numpy()\n</code></pre>"},{"location":"Synalinks%20API/Optimizers%20API/FewShotOPRO/","title":"FewShotOPRO","text":""},{"location":"Synalinks%20API/Optimizers%20API/FewShotOPRO/#synalinks.src.optimizers.few_shot_opro.FewShotOPRO","title":"<code>FewShotOPRO</code>","text":"<p>               Bases: <code>Optimizer</code></p> <p>Sample randomly among the best examples to populate the LM's prompt to make it     learn using Few Shot Learning while generating instructions with OPRO.</p> <p>Example:</p> <pre><code>import synalinks\nimport asyncio\n\nasync def main():\n    # ... your program definition\n\n    program.compile(\n        reward=synalinks.rewards.ExactMatch(),\n        optimizer=synalinks.optimizers.FewShotOPRO(\n            language_model=language_model,\n            k=3, # The number of examples to provide to the prompt\n            k_best=10, # The number of best examples to select from\n        ),\n    )\n\n    history = await program.fit(...)\n</code></pre> References <ul> <li>Language Models are Few-Shot Learners</li> <li>Large Language Models as Optimizers</li> </ul> <p>Parameters:</p> Name Type Description Default <code>language_model</code> <code>LanguageModel</code> <p>The language model to use.</p> <code>None</code> <code>k</code> <code>int</code> <p>The number of examples to select (default 3) among the best predictions.</p> <code>3</code> <code>k_best</code> <code>int</code> <p>The max number of best predictions/instructions to select from (default 10).</p> <code>10</code> <code>program</code> <code>Program</code> <p>The program to use. Optional. If None create one (non-trained) at start.</p> <code>None</code> <code>name</code> <code>str</code> <p>The name of the optimizer.</p> <code>None</code> <code>description</code> <code>str</code> <p>The description of the optimizer.</p> <code>None</code> Source code in <code>synalinks/src/optimizers/few_shot_opro.py</code> <pre><code>@synalinks_export(\"synalinks.optimizers.FewShotOPRO\")\nclass FewShotOPRO(Optimizer):\n    \"\"\"Sample randomly among the best examples to populate the LM's prompt to make it\n        learn using Few Shot Learning while generating instructions with OPRO.\n\n    Example:\n\n    ```python\n    import synalinks\n    import asyncio\n\n    async def main():\n        # ... your program definition\n\n        program.compile(\n            reward=synalinks.rewards.ExactMatch(),\n            optimizer=synalinks.optimizers.FewShotOPRO(\n                language_model=language_model,\n                k=3, # The number of examples to provide to the prompt\n                k_best=10, # The number of best examples to select from\n            ),\n        )\n\n        history = await program.fit(...)\n    ```\n\n    References:\n        - [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165)\n        - [Large Language Models as Optimizers](https://arxiv.org/abs/2309.03409)\n\n    Args:\n        language_model (LanguageModel): The language model to use.\n        k (int): The number of examples to select (default 3) among the best predictions.\n        k_best (int): The max number of best predictions/instructions to select from\n            (default 10).\n        program (Program): The program to use. Optional.\n            If None create one (non-trained) at start.\n        name (str): The name of the optimizer.\n        description (str): The description of the optimizer.\n    \"\"\"\n\n    def __init__(\n        self,\n        language_model=None,\n        k=3,\n        k_best=10,\n        program=None,\n        name=None,\n        description=None,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n            data_model=FewShotOPROOptimizedVariables,\n        )\n        self.language_model = language_model\n        self.k = k\n        self.k_best = k_best\n        self.program = program\n\n    async def build(self, variables):\n        if not self.program:\n            opro_inputs = Input(data_model=OPROInputs)\n            opro_outputs = await Generator(\n                language_model=self.language_model,\n                data_model=Instructions,\n                instructions=[\n                    \"Your task is to generate instructions that maximize rewards.\",\n                    \"Below are some previous instructions with their reward.\",\n                    \"Generate instructions that is different from all the instructions.\",\n                    (\n                        \"The instructions should be concise, effective and generally\"\n                        \" applicable to all predictions below.\"\n                    ),\n                ],\n            )(opro_inputs)\n\n            self.program = Program(\n                inputs=opro_inputs,\n                outputs=opro_outputs,\n                name=\"opro\",\n                description=\"OPRO Program\",\n            )\n        self.built = True\n\n    async def optimize(self, trainable_variable, reward=None):\n        \"\"\"Perform a backprop/optimization on a single variable.\"\"\"\n        # Reward backpropagation\n        predictions = trainable_variable.get(\"predictions\")\n        backpropagated_predictions = []\n        backprop_pred_nb = 0\n        for p in predictions:\n            if p[\"reward\"] is None:\n                p[\"reward\"] = reward\n                backprop_pred_nb += 1\n            backpropagated_predictions.append(p)\n        if backprop_pred_nb &gt; 0:\n            trainable_variable.update({\"predictions\": backpropagated_predictions})\n            # Get the k best predictions (sorted by reward)\n            sorted_predictions = sorted(\n                backpropagated_predictions,\n                key=lambda x: x[\"reward\"] if x[\"reward\"] is not None else float(\"-inf\"),\n                reverse=True,\n            )\n            top_k_predictions = sorted_predictions[: self.k_best]\n            if len(top_k_predictions) &gt; self.k:\n                selected_predictions = random.sample(top_k_predictions, self.k)\n            else:\n                selected_predictions = top_k_predictions\n            # Get the k best instructions candidates (sorted by reward)\n            sorted_instructions_candidates = sorted(\n                trainable_variable.get(\"instructions_candidates\"),\n                key=lambda x: x[\"reward\"] if x[\"reward\"] is not None else float(\"-inf\"),\n                reverse=True,\n            )\n            top_k_instructions_candidates = sorted_instructions_candidates[: self.k_best]\n            # Prepare inputs for OPRO\n            inputs = OPROInputs(\n                predictions=top_k_predictions,\n                instructions_candidates=top_k_instructions_candidates,\n            )\n            new_instructions = await self.program(inputs)\n            trainable_variable.update(\n                {\n                    \"instructions\": new_instructions.get_json(),\n                    \"examples\": selected_predictions,\n                }\n            )\n\n    async def finalize(self, trainable_variable):\n        \"\"\"Finalize the optimization of a single variable (cleanup/scaling etc.).\"\"\"\n        trainable_variable.update({\"predictions\": []})\n        trainable_variable.update({\"instructions_candidates\": []})\n\n    def get_config(self):\n        config = {\n            \"k\": self.k,\n            \"k_best\": self.k_best,\n            \"name\": self.name,\n            \"description\": self.description,\n        }\n        language_model_config = {\n            \"language_model\": serialization_lib.serialize_synalinks_object(\n                self.language_model,\n            )\n        }\n        program_config = {\n            \"program\": serialization_lib.serialize_synalinks_object(\n                self.program,\n            )\n        }\n        return {**config, **language_model_config, **program_config}\n\n    @classmethod\n    def from_config(cls, config):\n        language_model = serialization_lib.deserialize_synalinks_object(\n            config.pop(\"language_model\"),\n        )\n        program = serialization_lib.deserialize_synalinks_object(\n            config.pop(\"program\"),\n        )\n        return cls(language_model=language_model, program=program, **config)\n</code></pre>"},{"location":"Synalinks%20API/Optimizers%20API/FewShotOPRO/#synalinks.src.optimizers.few_shot_opro.FewShotOPRO.finalize","title":"<code>finalize(trainable_variable)</code>  <code>async</code>","text":"<p>Finalize the optimization of a single variable (cleanup/scaling etc.).</p> Source code in <code>synalinks/src/optimizers/few_shot_opro.py</code> <pre><code>async def finalize(self, trainable_variable):\n    \"\"\"Finalize the optimization of a single variable (cleanup/scaling etc.).\"\"\"\n    trainable_variable.update({\"predictions\": []})\n    trainable_variable.update({\"instructions_candidates\": []})\n</code></pre>"},{"location":"Synalinks%20API/Optimizers%20API/FewShotOPRO/#synalinks.src.optimizers.few_shot_opro.FewShotOPRO.optimize","title":"<code>optimize(trainable_variable, reward=None)</code>  <code>async</code>","text":"<p>Perform a backprop/optimization on a single variable.</p> Source code in <code>synalinks/src/optimizers/few_shot_opro.py</code> <pre><code>async def optimize(self, trainable_variable, reward=None):\n    \"\"\"Perform a backprop/optimization on a single variable.\"\"\"\n    # Reward backpropagation\n    predictions = trainable_variable.get(\"predictions\")\n    backpropagated_predictions = []\n    backprop_pred_nb = 0\n    for p in predictions:\n        if p[\"reward\"] is None:\n            p[\"reward\"] = reward\n            backprop_pred_nb += 1\n        backpropagated_predictions.append(p)\n    if backprop_pred_nb &gt; 0:\n        trainable_variable.update({\"predictions\": backpropagated_predictions})\n        # Get the k best predictions (sorted by reward)\n        sorted_predictions = sorted(\n            backpropagated_predictions,\n            key=lambda x: x[\"reward\"] if x[\"reward\"] is not None else float(\"-inf\"),\n            reverse=True,\n        )\n        top_k_predictions = sorted_predictions[: self.k_best]\n        if len(top_k_predictions) &gt; self.k:\n            selected_predictions = random.sample(top_k_predictions, self.k)\n        else:\n            selected_predictions = top_k_predictions\n        # Get the k best instructions candidates (sorted by reward)\n        sorted_instructions_candidates = sorted(\n            trainable_variable.get(\"instructions_candidates\"),\n            key=lambda x: x[\"reward\"] if x[\"reward\"] is not None else float(\"-inf\"),\n            reverse=True,\n        )\n        top_k_instructions_candidates = sorted_instructions_candidates[: self.k_best]\n        # Prepare inputs for OPRO\n        inputs = OPROInputs(\n            predictions=top_k_predictions,\n            instructions_candidates=top_k_instructions_candidates,\n        )\n        new_instructions = await self.program(inputs)\n        trainable_variable.update(\n            {\n                \"instructions\": new_instructions.get_json(),\n                \"examples\": selected_predictions,\n            }\n        )\n</code></pre>"},{"location":"Synalinks%20API/Optimizers%20API/OPRO/","title":"OPRO","text":""},{"location":"Synalinks%20API/Optimizers%20API/OPRO/#synalinks.src.optimizers.opro.OPRO","title":"<code>OPRO</code>","text":"<p>               Bases: <code>Optimizer</code></p> <p>Optimization by PROmpting (OPRO) optimizer</p> <p>Use a language model to optimize the prompt's instructions.</p> <p>Example:</p> <pre><code>import synalinks\nimport asyncio\n\nasync def main():\n    # ... your program definition\n\n    program.compile(\n        reward=synalinks.rewards.ExactMatch(),\n        optimizer=synalinks.optimizers.OPRO(\n            language_model=language_model, # The language model to use\n            k_best=10, # The number of best examples/instructions to provide to the LM\n        ),\n    )\n\n    history = await program.fit(...)\n</code></pre> References <ul> <li>Large Language Models as Optimizers</li> </ul> <p>Parameters:</p> Name Type Description Default <code>language_model</code> <code>LanguageModel</code> <p>The language model to use.</p> <code>None</code> <code>k_best</code> <code>int</code> <p>The max number of best predictions and instructions to provide to the optimizer (default 10).</p> <code>10</code> <code>program</code> <code>Program</code> <p>The program to use. Optional. If None create one (non-trained) at start.</p> <code>None</code> <code>name</code> <code>str</code> <p>The name of the optimizer.</p> <code>None</code> <code>description</code> <code>str</code> <p>The description of the optimizer.</p> <code>None</code> Source code in <code>synalinks/src/optimizers/opro.py</code> <pre><code>@synalinks_export(\"synalinks.optimizers.OPRO\")\nclass OPRO(Optimizer):\n    \"\"\"Optimization by PROmpting (OPRO) optimizer\n\n    Use a language model to optimize the prompt's instructions.\n\n    Example:\n\n    ```python\n    import synalinks\n    import asyncio\n\n    async def main():\n        # ... your program definition\n\n        program.compile(\n            reward=synalinks.rewards.ExactMatch(),\n            optimizer=synalinks.optimizers.OPRO(\n                language_model=language_model, # The language model to use\n                k_best=10, # The number of best examples/instructions to provide to the LM\n            ),\n        )\n\n        history = await program.fit(...)\n    ```\n\n    References:\n        - [Large Language Models as Optimizers](https://arxiv.org/abs/2309.03409)\n\n    Args:\n        language_model (LanguageModel): The language model to use.\n        k_best (int): The max number of best predictions and instructions\n            to provide to the optimizer (default 10).\n        program (Program): The program to use. Optional.\n            If None create one (non-trained) at start.\n        name (str): The name of the optimizer.\n        description (str): The description of the optimizer.\n    \"\"\"\n\n    def __init__(\n        self,\n        language_model=None,\n        k_best=10,\n        program=None,\n        name=None,\n        description=None,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n            data_model=OPROOptimizedVariable,\n        )\n        self.language_model = language_model\n        self.k_best = k_best\n        self.program = program\n\n    async def build(self, variables):\n        if not self.program:\n            opro_inputs = Input(data_model=OPROInputs)\n            opro_outputs = await Generator(\n                language_model=self.language_model,\n                data_model=Instructions,\n                instructions=[\n                    \"Your task is to generate instructions that maximize rewards.\",\n                    \"Below are some previous instructions with their reward.\",\n                    \"Generate instructions that is different from all the instructions.\",\n                    (\n                        \"The instructions should be concise, effective and generally\"\n                        \" applicable to all predictions below.\"\n                    ),\n                ],\n            )(opro_inputs)\n\n            self.program = Program(\n                inputs=opro_inputs,\n                outputs=opro_outputs,\n                name=\"opro\",\n                description=\"OPRO Program\",\n            )\n        self.built = True\n\n    async def optimize(self, trainable_variable, reward=None):\n        \"\"\"Perform a backprop/optimization on a single variable.\"\"\"\n        # Backpropagate predictions reward\n        predictions = trainable_variable.get(\"predictions\")\n        backpropagated_predictions = []\n        backprop_pred_nb = 0\n        for p in predictions:\n            if p[\"reward\"] is None:\n                p[\"reward\"] = reward\n                backprop_pred_nb += 1\n            backpropagated_predictions.append(p)\n        if backprop_pred_nb &gt; 0:\n            trainable_variable.update({\"predictions\": backpropagated_predictions})\n            # Backpropagate instructions reward\n            instructions_predictions = trainable_variable.get(\"instructions_candidates\")\n            instructions = trainable_variable.get(\"instructions\")\n            instructions.update({\"reward\": reward})\n            instructions_predictions.append(instructions)\n            # Get the k best predictions (sorted by reward)\n            sorted_predictions = sorted(\n                backpropagated_predictions,\n                key=lambda x: x[\"reward\"] if x[\"reward\"] is not None else float(\"-inf\"),\n                reverse=True,\n            )\n            top_k_predictions = sorted_predictions[: self.k_best]\n            # Get the k best instructions candidates (sorted by reward)\n            sorted_instructions_candidates = sorted(\n                trainable_variable.get(\"instructions_candidates\"),\n                key=lambda x: x[\"reward\"] if x[\"reward\"] is not None else float(\"-inf\"),\n                reverse=True,\n            )\n            top_k_instructions_candidates = sorted_instructions_candidates[: self.k_best]\n            # Prepare inputs for OPRO\n            inputs = OPROInputs(\n                predictions=top_k_predictions,\n                instructions_candidates=top_k_instructions_candidates,\n            )\n            new_instructions = await self.program(inputs)\n            trainable_variable.update({\"instructions\": new_instructions.get_json()})\n\n    async def finalize(self, trainable_variable):\n        \"\"\"Finalize the optimization of a single variable (cleanup/scaling etc.).\"\"\"\n        trainable_variable.update({\"instructions_candidates\": []})\n\n    def get_config(self):\n        config = {\n            \"k_best\": self.k_best,\n            \"name\": self.name,\n            \"description\": self.description,\n        }\n        language_model_config = {\n            \"language_model\": serialization_lib.serialize_synalinks_object(\n                self.language_model,\n            )\n        }\n        program_config = {\n            \"program\": serialization_lib.serialize_synalinks_object(\n                self.program,\n            )\n        }\n        return {**config, **language_model_config, **program_config}\n\n    @classmethod\n    def from_config(cls, config):\n        language_model = serialization_lib.deserialize_synalinks_object(\n            config.pop(\"language_model\"),\n        )\n        return cls(language_model=language_model, **config)\n</code></pre>"},{"location":"Synalinks%20API/Optimizers%20API/OPRO/#synalinks.src.optimizers.opro.OPRO.finalize","title":"<code>finalize(trainable_variable)</code>  <code>async</code>","text":"<p>Finalize the optimization of a single variable (cleanup/scaling etc.).</p> Source code in <code>synalinks/src/optimizers/opro.py</code> <pre><code>async def finalize(self, trainable_variable):\n    \"\"\"Finalize the optimization of a single variable (cleanup/scaling etc.).\"\"\"\n    trainable_variable.update({\"instructions_candidates\": []})\n</code></pre>"},{"location":"Synalinks%20API/Optimizers%20API/OPRO/#synalinks.src.optimizers.opro.OPRO.optimize","title":"<code>optimize(trainable_variable, reward=None)</code>  <code>async</code>","text":"<p>Perform a backprop/optimization on a single variable.</p> Source code in <code>synalinks/src/optimizers/opro.py</code> <pre><code>async def optimize(self, trainable_variable, reward=None):\n    \"\"\"Perform a backprop/optimization on a single variable.\"\"\"\n    # Backpropagate predictions reward\n    predictions = trainable_variable.get(\"predictions\")\n    backpropagated_predictions = []\n    backprop_pred_nb = 0\n    for p in predictions:\n        if p[\"reward\"] is None:\n            p[\"reward\"] = reward\n            backprop_pred_nb += 1\n        backpropagated_predictions.append(p)\n    if backprop_pred_nb &gt; 0:\n        trainable_variable.update({\"predictions\": backpropagated_predictions})\n        # Backpropagate instructions reward\n        instructions_predictions = trainable_variable.get(\"instructions_candidates\")\n        instructions = trainable_variable.get(\"instructions\")\n        instructions.update({\"reward\": reward})\n        instructions_predictions.append(instructions)\n        # Get the k best predictions (sorted by reward)\n        sorted_predictions = sorted(\n            backpropagated_predictions,\n            key=lambda x: x[\"reward\"] if x[\"reward\"] is not None else float(\"-inf\"),\n            reverse=True,\n        )\n        top_k_predictions = sorted_predictions[: self.k_best]\n        # Get the k best instructions candidates (sorted by reward)\n        sorted_instructions_candidates = sorted(\n            trainable_variable.get(\"instructions_candidates\"),\n            key=lambda x: x[\"reward\"] if x[\"reward\"] is not None else float(\"-inf\"),\n            reverse=True,\n        )\n        top_k_instructions_candidates = sorted_instructions_candidates[: self.k_best]\n        # Prepare inputs for OPRO\n        inputs = OPROInputs(\n            predictions=top_k_predictions,\n            instructions_candidates=top_k_instructions_candidates,\n        )\n        new_instructions = await self.program(inputs)\n        trainable_variable.update({\"instructions\": new_instructions.get_json()})\n</code></pre>"},{"location":"Synalinks%20API/Optimizers%20API/RandomFewShot/","title":"RandomFewShot","text":""},{"location":"Synalinks%20API/Optimizers%20API/RandomFewShot/#synalinks.src.optimizers.random_few_shot.RandomFewShot","title":"<code>RandomFewShot</code>","text":"<p>               Bases: <code>Optimizer</code></p> <p>Sample randomly among the best examples to populate the LM's prompt to make it     learn using Few Shot Learning.</p> <p>Example:</p> <pre><code>import synalinks\nimport asyncio\n\nasync def main():\n    # ... your program definition\n\n    program.compile(\n        reward=synalinks.rewards.ExactMatch(),\n        optimizer=synalinks.optimizers.RandomFewShot(\n            k=3, # The number of examples to provide to the prompt\n            k_best=10, # The number of best examples to select from\n        ),\n    )\n\n    history = await program.fit(...)\n</code></pre> References <ul> <li>Language Models are Few-Shot Learners</li> </ul> <p>Parameters:</p> Name Type Description Default <code>k</code> <code>int</code> <p>The number of examples to select (default 3) among the best predictions.</p> <code>3</code> <code>k_best</code> <code>int</code> <p>The max number of best predictions to select from (default 10).</p> <code>10</code> Source code in <code>synalinks/src/optimizers/random_few_shot.py</code> <pre><code>@synalinks_export(\"synalinks.optimizers.RandomFewShot\")\nclass RandomFewShot(Optimizer):\n    \"\"\"Sample randomly among the best examples to populate the LM's prompt to make it\n        learn using Few Shot Learning.\n\n    Example:\n\n    ```python\n    import synalinks\n    import asyncio\n\n    async def main():\n        # ... your program definition\n\n        program.compile(\n            reward=synalinks.rewards.ExactMatch(),\n            optimizer=synalinks.optimizers.RandomFewShot(\n                k=3, # The number of examples to provide to the prompt\n                k_best=10, # The number of best examples to select from\n            ),\n        )\n\n        history = await program.fit(...)\n    ```\n\n    References:\n        - [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165)\n\n    Args:\n        k (int): The number of examples to select (default 3) among the best predictions.\n        k_best (int): The max number of best predictions to select from (default 10).\n    \"\"\"\n\n    def __init__(\n        self,\n        k=3,\n        k_best=10,\n        name=None,\n        description=None,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n            data_model=FewShotOptimizedVariable,\n        )\n        self.k = k\n        self.k_best = k_best\n\n    async def build(self, variables):\n        self.built = True\n\n    async def optimize(self, trainable_variable, reward=None):\n        \"\"\"Perform a backprop/optimization on a single variable.\"\"\"\n        # Reward backpropagation\n        predictions = trainable_variable.get(\"predictions\")\n        backpropagated_predictions = []\n        backprop_pred_nb = 0\n        for p in predictions:\n            if p[\"reward\"] is None:\n                p[\"reward\"] = reward\n                backprop_pred_nb += 1\n            backpropagated_predictions.append(p)\n        if backprop_pred_nb &gt; 0:\n            trainable_variable.update({\"predictions\": backpropagated_predictions})\n            # Get the k best predictions (sorted by reward)\n            sorted_predictions = sorted(\n                backpropagated_predictions,\n                key=lambda x: x[\"reward\"] if x[\"reward\"] is not None else float(\"-inf\"),\n                reverse=True,\n            )\n            top_k_predictions = sorted_predictions[: self.k_best]\n            if len(top_k_predictions) &gt; self.k:\n                selected_predictions = random.sample(top_k_predictions, self.k)\n            else:\n                selected_predictions = top_k_predictions\n            trainable_variable.update({\"examples\": selected_predictions})\n\n    async def finalize(self, trainable_variable):\n        \"\"\"Finalize the optimization of a single variable (cleanup/scaling etc.).\"\"\"\n        trainable_variable.update({\"predictions\": []})\n\n    def get_config(self):\n        return {\n            \"k\": self.k,\n            \"k_best\": self.k_best,\n            \"name\": self.name,\n            \"description\": self.description,\n        }\n</code></pre>"},{"location":"Synalinks%20API/Optimizers%20API/RandomFewShot/#synalinks.src.optimizers.random_few_shot.RandomFewShot.finalize","title":"<code>finalize(trainable_variable)</code>  <code>async</code>","text":"<p>Finalize the optimization of a single variable (cleanup/scaling etc.).</p> Source code in <code>synalinks/src/optimizers/random_few_shot.py</code> <pre><code>async def finalize(self, trainable_variable):\n    \"\"\"Finalize the optimization of a single variable (cleanup/scaling etc.).\"\"\"\n    trainable_variable.update({\"predictions\": []})\n</code></pre>"},{"location":"Synalinks%20API/Optimizers%20API/RandomFewShot/#synalinks.src.optimizers.random_few_shot.RandomFewShot.optimize","title":"<code>optimize(trainable_variable, reward=None)</code>  <code>async</code>","text":"<p>Perform a backprop/optimization on a single variable.</p> Source code in <code>synalinks/src/optimizers/random_few_shot.py</code> <pre><code>async def optimize(self, trainable_variable, reward=None):\n    \"\"\"Perform a backprop/optimization on a single variable.\"\"\"\n    # Reward backpropagation\n    predictions = trainable_variable.get(\"predictions\")\n    backpropagated_predictions = []\n    backprop_pred_nb = 0\n    for p in predictions:\n        if p[\"reward\"] is None:\n            p[\"reward\"] = reward\n            backprop_pred_nb += 1\n        backpropagated_predictions.append(p)\n    if backprop_pred_nb &gt; 0:\n        trainable_variable.update({\"predictions\": backpropagated_predictions})\n        # Get the k best predictions (sorted by reward)\n        sorted_predictions = sorted(\n            backpropagated_predictions,\n            key=lambda x: x[\"reward\"] if x[\"reward\"] is not None else float(\"-inf\"),\n            reverse=True,\n        )\n        top_k_predictions = sorted_predictions[: self.k_best]\n        if len(top_k_predictions) &gt; self.k:\n            selected_predictions = random.sample(top_k_predictions, self.k)\n        else:\n            selected_predictions = top_k_predictions\n        trainable_variable.update({\"examples\": selected_predictions})\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/","title":"Programs API","text":"<p>Synalinks offers three methods to create programs, each tailored to different levels of complexity and use cases:</p> <ul> <li> <p>Sequential Program: This is the simplest method, involving a straightforward list of modules. Ideal for single-input, single-output stacks of modules. However, it is limited in flexibility compared to other methods.</p> </li> <li> <p>Functional Program: This is a fully-featured API that supports arbitrary program architectures. Easy to use and suitable for most users, offering greater flexibility than the Sequential program.</p> </li> <li> <p>Program Subclassing: This method allows you to implement everything from scratch. Ideal for complex or research use cases. It is also the preferred method for contributing.</p> </li> </ul>"},{"location":"Synalinks%20API/Programs%20API/#programs-api-overview","title":"Programs API Overview","text":""},{"location":"Synalinks%20API/Programs%20API/#the-program-class","title":"The Program class","text":"<ul> <li>Program class</li> <li>summary method</li> <li>get_module method</li> </ul>"},{"location":"Synalinks%20API/Programs%20API/#the-sequential-class","title":"The Sequential class","text":"<ul> <li>Sequential class</li> <li>add method</li> <li>pop method</li> </ul>"},{"location":"Synalinks%20API/Programs%20API/#program-training-apis","title":"Program training APIs","text":"<ul> <li>compile method</li> <li>fit method</li> <li>evaluate method</li> <li>predict method</li> <li>train_on_batch method</li> <li>test_on_batch method</li> <li>predict_on_batch method</li> </ul>"},{"location":"Synalinks%20API/Programs%20API/#saving-serialization","title":"Saving &amp; Serialization","text":"<ul> <li>Whole program saving and loading</li> <li>Variables-only saving and loading</li> </ul>"},{"location":"Synalinks%20API/Programs%20API/Program%20training%20API/","title":"Program training API","text":"Source code in <code>synalinks/src/trainers/trainer.py</code> <pre><code>class Trainer:\n    def __init__(self):\n        self._lock = False\n        self._run_eagerly = False\n        self.compiled = False\n        self.reward = None\n        self.steps_per_execution = 1\n        # Can be set by callbacks in on_train_begin\n        self._initial_epoch = None\n        self._compute_reward_has_training_arg = (\n            \"training\" in inspect.signature(self.compute_reward).parameters\n        )\n        # Placeholders used in `compile`\n        self._optimizer = None\n        self._compile_reward = None\n        self._compile_metrics = None\n        self._reward_tracker = None\n\n    @tracking.no_automatic_dependency_tracking\n    def compile(\n        self,\n        optimizer=None,\n        reward=None,\n        reward_weights=None,\n        metrics=None,\n        run_eagerly=False,\n        steps_per_execution=1,\n    ):\n        \"\"\"Configures the program for training.\n\n        Example:\n\n        ```python\n        program.compile(\n            optimizer=synalinks.optimizers.RandomFewShot(),\n            reward=synalinks.rewards.ExactMatch(),\n            metrics=[\n                synalinks.metrics.MeanMetricWrapper(synalinks.rewards.exact_match),\n            ],\n        )\n        ```\n\n        Args:\n            optimizer (Optimizer): Optimizer instance. See `synalinks.optimizers`.\n            reward (Reward): Reward function. A `synalinks.rewards.Reward`\n                instance. See `synalinks.rewards`. A reward function is\n                any callable with the signature `reward = fn(y_true, y_pred)`,\n                where `y_true` are the ground truth values, and `y_pred`\n                are the program's predictions.\n                `y_true` should be a list of batch size length `[d0, .. dN]`.\n                `y_pred` should be a list of batch size length `[d0, .. dN]`.\n                The reward function should return a float.\n            reward_weights (list): Optional list specifying scalar coefficients\n                (Python floats) to weight the reward contributions of\n                different program outputs. The reward value that will be maximized\n                by the program will then be the *weighted sum* of all individual\n                rewards, weighted by the `reward_weights` coefficients. It is\n                expected to have a 1:1 mapping to the program's outputs.\n            metrics (list): List of metrics to be evaluated by the program during\n                training and testing. Each of it is a `synalinks.metrics.Metric`\n                instance. See `synalinks.metrics`. A function is any callable with the\n                signature `result = fn(y_true, y_pred)`.\n            run_eagerly (bool): If `True`, this program's forward pass\n                 will never be compiled. It is recommended to leave this\n                 as `False` when training (for best performance),\n                 and to set it to `True` when debugging.\n            steps_per_execution (int): The number of batches to run\n                during each a single compiled function call. Running multiple\n                batches inside a single compiled function call can\n                greatly improve performance on TPUs or small programs with a large\n                Python overhead. At most, one full epoch will be run each\n                execution. If a number larger than the size of the epoch is\n                passed, the execution will be truncated to the size of the\n                epoch. Note that if `steps_per_execution` is set to `N`,\n                `Callback.on_batch_begin` and `Callback.on_batch_end` methods\n                will only be called every `N` batches (i.e. before/after\n                each compiled function execution).\n        \"\"\"\n        self._clear_previous_trainer_metrics()\n        self._optimizer = optimizer\n\n        if hasattr(self, \"output_names\"):\n            output_names = self.output_names\n        else:\n            output_names = None\n        if reward is not None:\n            self._compile_reward = CompileReward(\n                reward, reward_weights, output_names=output_names\n            )\n            self.reward = reward\n        if metrics is not None:\n            self._compile_metrics = CompileMetrics(metrics, output_names=output_names)\n        self.run_eagerly = run_eagerly\n        self.stop_training = False\n        self.compiled = True\n        self._reward_tracker = metrics_module.Mean(name=\"reward\")\n        self.steps_per_execution = steps_per_execution\n\n        self._compile_config = serialization_lib.SerializableDict(\n            optimizer=optimizer,\n            reward=reward,\n            reward_weights=reward_weights,\n            metrics=metrics,\n            run_eagerly=run_eagerly,\n            steps_per_execution=steps_per_execution,\n        )\n\n    @property\n    def optimizer(self):\n        return self._optimizer\n\n    @property\n    def metrics(self):\n        # Order: reward tracker, individual reward trackers, compiled metrics,\n        # custom metrcis, submodule metrics.\n        metrics = []\n        if self.compiled:\n            if self._reward_tracker is not None:\n                metrics.append(self._reward_tracker)\n            if self._compile_metrics is not None:\n                metrics.append(self._compile_metrics)\n            if self._compile_reward is not None:\n                metrics.extend(self._compile_reward.metrics)\n        metrics.extend(self._metrics)\n        for module in self._flatten_modules(include_self=False):\n            if isinstance(module, Trainer):\n                # All Trainer-related metrics in submodules should be ignored\n                # because a new Trainer has been instantiated.\n                continue\n            metrics.extend(module.metrics)\n        return metrics\n\n    @property\n    def metrics_names(self):\n        return [m.name for m in self.metrics]\n\n    def reset_metrics(self):\n        for m in self.metrics:\n            m.reset_state()\n\n    def _get_own_metrics(self):\n        metrics = []\n        if self._reward_tracker is not None:\n            metrics.append(self._reward_tracker)\n        if self._compile_metrics is not None:\n            metrics.append(self._compile_metrics)\n        if self._compile_reward is not None:\n            metrics.extend(self._compile_reward.metrics)\n        metrics.extend(self._metrics)\n        return metrics\n\n    def _clear_previous_trainer_metrics(self):\n        for module in self._flatten_modules(include_self=False):\n            if not isinstance(module, Trainer):\n                continue\n            # A submodule might be a Trainer. In that case, we need to clear\n            # the Trainer-related metrics, as they are not usable when a\n            # new Trainer is instantiated.\n            for m in self._get_own_metrics():\n                module._tracker.untrack(m)\n            module._reward_tracker = None\n            module._compile_metrics = None\n            if module._compile_reward is not None:\n                module._compile_reward._metrics.clear()\n            module._metrics.clear()\n\n    @property\n    def run_eagerly(self):\n        return self._run_eagerly\n\n    @run_eagerly.setter\n    def run_eagerly(self, value):\n        self._run_eagerly = value\n\n    async def compute_reward(\n        self,\n        x=None,\n        y=None,\n        y_pred=None,\n        sample_weight=None,\n        training=True,\n    ):\n        \"\"\"Compute the total reward, validate it, and return it.\n\n        Subclasses can optionally override this method to provide custom reward\n        computation logic.\n\n        Args:\n            x (list): Input data.\n            y (list): Target data.\n            y_pred (list): Predictions returned by the program (output of `program(x)`).\n            training (bool): Whether we are training or evaluating the program.\n\n        Returns:\n            (float | None): The total reward as a scalar, or `None` if no reward results\n                (which is the case when called by `Program.test_step`).\n        \"\"\"\n        # The default implementation does not use `x` or `training`.\n        del x\n        del training\n        rewards = []\n        if self._compile_reward is not None:\n            for y_t, y_p in zip(y, y_pred):\n                reward = await self._compile_reward(y_t, y_p)\n                if reward is not None:\n                    rewards.append(reward)\n        for reward in self.rewards:\n            rewards.append(numpy.sum(reward))\n        if len(rewards) == 1:\n            total_reward = rewards[0]\n        elif len(rewards) == 0:\n            total_reward = numpy.zeros(())\n        else:\n            total_reward = numpy.mean(rewards)\n        return float(total_reward)\n\n    def stateless_compute_reward(\n        self,\n        trainable_variables,\n        non_trainable_variables,\n        metrics_variables,\n        x=None,\n        y=None,\n        y_pred=None,\n        sample_weight=None,\n        training=True,\n    ):\n        var_mapping = list(zip(self.trainable_variables, trainable_variables))\n        var_mapping.extend(zip(self.non_trainable_variables, non_trainable_variables))\n        var_mapping.extend(zip(self.metrics_variables, metrics_variables))\n        with backend.StatelessScope(state_mapping=var_mapping) as scope:\n            # Note that this is needed for the regularization reward, which need\n            # the latest value of train/non-trainable variables.\n            reward = self._compute_reward(\n                x,\n                y,\n                y_pred,\n                sample_weight=sample_weight,\n                training=training,\n            )\n\n        # Update non trainable vars (may have been updated in compute_reward)\n        non_trainable_variables = []\n        for v in self.non_trainable_variables:\n            new_v = scope.get_current_value(v)\n            non_trainable_variables.append(new_v)\n\n        # Update metrics vars (may have been updated in compute_reward)\n        metrics_variables = []\n        for v in self.metrics_variables:\n            new_v = scope.get_current_value(v)\n            metrics_variables.append(new_v)\n        return reward, (\n            trainable_variables,\n            non_trainable_variables,\n            metrics_variables,\n        )\n\n    async def compute_metrics(self, x, y, y_pred):\n        \"\"\"Update metric states and collect all metrics to be returned.\n\n        Subclasses can optionally override this method to provide custom metric\n        updating and collection logic. Custom metrics are not passed in\n        `compile()`, they can be created in `__init__` or `build`. They are\n        automatically tracked and returned by `self.metrics`.\n        ```\n\n        Args:\n            x: Input data.\n            y: Target data.\n            y_pred: Predictions returned by the program output of `program.call(x)`.\n\n        Returns:\n            A `dict` containing values that will be passed to\n                `synalinks.callbacks.CallbackList.on_train_batch_end()`. Typically,\n                the values of the metrics listed in `self.metrics` are returned.\n                Example: `{'reward': 0.2, 'accuracy': 0.7}`.\n        \"\"\"\n        del x  # The default implementation does not use `x`.\n        if self._compile_metrics is not None:\n            for y_t, y_p in zip(y, y_pred):\n                await self._compile_metrics.update_state(y_t, y_p)\n        return self.get_metrics_result()\n\n    def get_metrics_result(self):\n        \"\"\"Returns the program's metrics values as a dict.\n\n        If any of the metric result is a dict (containing multiple metrics),\n        each of them gets added to the top level returned dict of this method.\n\n        Returns:\n            (dict): A `dict` containing values of the metrics listed in `self.metrics`.\n                Example: `{'reward': 0.2, 'accuracy': 0.7}`.\n        \"\"\"\n        return_metrics = {}\n        for metric in self.metrics:\n            result = metric.result()\n            if isinstance(result, dict):\n                return_metrics.update(result)\n            else:\n                return_metrics[metric.name] = result\n        return python_utils.pythonify_logs(return_metrics)\n\n    async def fit(\n        self,\n        x=None,\n        y=None,\n        batch_size=None,\n        epochs=1,\n        verbose=\"auto\",\n        callbacks=None,\n        validation_split=0.0,\n        validation_data=None,\n        shuffle=True,\n        initial_epoch=0,\n        steps_per_epoch=None,\n        validation_steps=None,\n        validation_batch_size=None,\n        validation_freq=1,\n    ):\n        \"\"\"Trains the program for a fixed number of epochs (dataset iterations).\n\n        Args:\n            x (np.ndarray | generator): Input data. It can be:\n                - A NumPy array (or array-like), or a list of `DataModel` arrays\n                    (in case the model has multiple inputs).\n                - A list of dict mapping input names to the corresponding `DataModel`s,\n                    if the program has named inputs.\n                - A Python generator function yielding `(inputs, targets)`.\n            y (np.ndarray): Target data. Like the input data `x`, it can be either NumPy\n                array(s) of `DataModel`(s). If `x` is a Python generator function,\n                `y` should not be specified since targets will be obtained from\n                `x`.\n            batch_size (int): Integer or `None`.\n                Number of samples per batch of computation.\n                If unspecified, `batch_size` will default to 32.\n                Do not specify the `batch_size` if your input data `x` is a\n                Python generator function since they generate batches.\n            epochs (int): Integer. Number of epochs to train the program.\n                An epoch is an iteration over the entire `x` and `y`\n                data provided (unless the `steps_per_epoch` flag is set to\n                something other than None).\n                Note that in conjunction with `initial_epoch`,\n                `epochs` is to be understood as \"final epoch\".\n                The program is not trained for a number of iterations\n                given by `epochs`, but merely until the epoch\n                of index `epochs` is reached.\n            verbose (int): `\"auto\"`, 0, 1, or 2. Verbosity mode.\n                0 = silent, 1 = progress bar, 2 = one line per epoch.\n                \"auto\" becomes 1 for most cases.\n                Note that the progress bar is not\n                particularly useful when logged to a file,\n                so `verbose=2` is recommended when not running interactively\n                (e.g., in a production environment). Defaults to `\"auto\"`.\n            callbacks (list): List of `synalinks.callbacks.Callback` instances.\n                List of callbacks to apply during training.\n                See `synalinks.callbacks`. Note\n                `synalinks.callbacks.ProgbarLogger` and\n                `synalinks.callbacks.History` callbacks are created\n                automatically and need not be passed to `program.fit()`.\n                `synalinks.callbacks.ProgbarLogger` is created\n                or not based on the `verbose` argument in `program.fit()`.\n            validation_split (float): Float between 0 and 1.\n                Fraction of the training data to be used as validation data.\n                The program will set apart this fraction of the training data,\n                will not train on it, and will evaluate the reward and any program\n                metrics on this data at the end of each epoch. The validation\n                data is selected from the last samples in the `x` and `y` data\n                provided, before shuffling.\n                This argument is only supported when `x` and `y` are made of\n                data_models.\n                If both `validation_data` and `validation_split` are provided,\n                `validation_data` will override `validation_split`.\n            validation_data (tuple | iterator): Data on which to evaluate\n                the reward and any program metrics at the end of each epoch.\n                The program will not be trained on this data.\n                `validation_data` will override `validation_split`.\n                It can be:\n                - A tuple `(x_val, y_val)` of `DataModel`s lists.\n            shuffle (bool): Whether to shuffle the training data before each\n                epoch. This argument is ignored when `x` is a Python generator function.\n            initial_epoch (int): Integer.\n                Epoch at which to start training\n                (useful for resuming a previous training run).\n            steps_per_epoch (int): Integer or `None`.\n                Total number of steps (batches of samples) before declaring one\n                epoch finished and starting the next epoch. When training with\n                input data_models arrays, the default `None` means that the\n                value used is the number of samples in your dataset divided by\n                the batch size, or 1 if that cannot be determined.\n                If `x` is a Python generator function, the\n                epoch will run until the input dataset is exhausted. When\n                passing an infinitely repeating dataset, you must specify the\n                `steps_per_epoch` argument, otherwise the training will run\n                indefinitely.\n            validation_steps (int): Integer or `None`.\n                Only relevant if `validation_data` is provided.\n                Total number of steps (batches of samples) to draw before\n                stopping when performing validation at the end of every epoch.\n                If `validation_steps` is `None`, validation will run until the\n                `validation_data` dataset is exhausted. In the case of an\n                infinitely repeating dataset, it will run indefinitely. If\n                `validation_steps` is specified and only part of the dataset\n                is consumed, the evaluation will start from the beginning of the\n                dataset at each epoch. This ensures that the same validation\n                samples are used every time.\n            validation_batch_size (int): Integer or `None`.\n                Number of samples per validation batch.\n                If unspecified, will default to `batch_size`.\n                Do not specify the `validation_batch_size` if your data is a\n                `synalinks.utils.PyDataset`, `tf.data.Dataset`,\n                `torch.utils.data.DataLoader` or Python generator function\n                since they generate batches.\n            validation_freq (int): Only relevant if validation data is provided.\n                Specifies how many training epochs to run\n                before a new validation run is performed,\n                e.g. `validation_freq=2` runs validation every 2 epochs.\n\n        Returns:\n            (History): A `History` object. Its `History.history` attribute is\n                a record of training reward values and metrics values\n                at successive epochs, as well as validation reward values\n                and validation metrics values (if applicable).\n        \"\"\"\n        self._assert_compile_called(\"fit\")\n        # TODO: respect compiled trainable state\n        self._eval_epoch_iterator = None\n        if validation_split and validation_data is None:\n            # Create the validation data using the training data. Only supported\n            # for numpy arrays.\n            (x, y), validation_data = array_slicing.train_validation_split(\n                (x, y), validation_split=validation_split\n            )\n\n        if validation_data is not None:\n            (val_x, val_y) = data_adapter_utils.unpack_x_y(validation_data)\n        # Create an iterator that yields batches of input/target data.\n        epoch_iterator = EpochIterator(\n            x=x,\n            y=y,\n            batch_size=batch_size,\n            steps_per_epoch=steps_per_epoch,\n            shuffle=False,\n            steps_per_execution=self.steps_per_execution,\n        )\n\n        if not all(module.built for module in self._flatten_modules()):\n            # Build the model on one batch of data.\n            for _, data in epoch_iterator:\n                data_batch = data[0]\n                self._auto_build(\n                    iterator=epoch_iterator,\n                    data_batch=data_batch,\n                )\n                break\n        epoch_iterator.reset()\n\n        # Container that configures and calls callbacks.\n        if not isinstance(callbacks, callbacks_module.CallbackList):\n            callbacks = callbacks_module.CallbackList(\n                callbacks,\n                add_history=True,\n                add_progbar=verbose != 0,\n                verbose=verbose,\n                epochs=epochs,\n                steps=steps_per_epoch,\n                program=self,\n            )\n\n        self.stop_training = False\n        callbacks.on_train_begin()\n        training_logs = None\n        logs = {}\n        initial_epoch = self._initial_epoch or initial_epoch\n\n        for epoch in range(initial_epoch, epochs):\n            self.reset_metrics()\n            callbacks.on_epoch_begin(epoch)\n            with epoch_iterator.catch_stop_iteration():\n                for step, iterator in epoch_iterator:\n                    data = iterator[0]\n                    x_batch, y_batch = data_adapter_utils.unpack_x_y(data)\n                    callbacks.on_train_batch_begin(step)\n                    logs = await self.train_on_batch(\n                        x=x_batch,\n                        y=y_batch,\n                        return_dict=True,\n                    )\n                    callbacks.on_train_batch_end(step, logs)\n                    if self.stop_training:\n                        break\n\n            # Override with model metrics instead of last step logs if needed.\n            epoch_logs = dict(self._get_metrics_result_or_logs(logs))\n\n            # Run validation.\n            if validation_data is not None and self._should_eval(epoch, validation_freq):\n                # Create EpochIterator for evaluation and cache it.\n                if getattr(self, \"_eval_epoch_iterator\", None) is None:\n                    self._eval_epoch_iterator = EpochIterator(\n                        x=val_x,\n                        y=val_y,\n                        batch_size=validation_batch_size or batch_size,\n                        steps_per_execution=self.steps_per_execution,\n                        steps_per_epoch=validation_steps,\n                        shuffle=False,\n                    )\n                val_logs = await self.evaluate(\n                    x=val_x,\n                    y=val_y,\n                    batch_size=validation_batch_size or batch_size,\n                    steps=validation_steps,\n                    callbacks=callbacks,\n                    _use_cached_eval_dataset=True,\n                )\n                val_logs = {\"val_\" + name: val for name, val in val_logs.items()}\n                epoch_logs.update(val_logs)\n\n            callbacks.on_epoch_end(epoch, epoch_logs)\n            training_logs = epoch_logs\n            if self.stop_training:\n                break\n\n        if isinstance(self.optimizer, optimizers_module.Optimizer) and epochs &gt; 0:\n            await self.optimizer.finalize_variable_values(self.trainable_variables)\n\n        # If _eval_epoch_iterator exists, delete it after all epochs are done.\n        if getattr(self, \"_eval_epoch_iterator\", None) is not None:\n            del self._eval_epoch_iterator\n        callbacks.on_train_end(logs=training_logs)\n        return self.history\n\n    async def evaluate(\n        self,\n        x=None,\n        y=None,\n        batch_size=None,\n        verbose=\"auto\",\n        steps=None,\n        callbacks=None,\n        return_dict=True,\n        **kwargs,\n    ):\n        \"\"\"Returns the reward value &amp; metrics values for the program in test mode.\n\n        Computation is done in batches (see the `batch_size` arg.)\n\n        Args:\n            x (np.ndarray | generator): Input data. It can be:\n                - A NumPy array (or array-like), or a list of `DataModel` arrays\n                    (in case the model has multiple inputs).\n                - A list of dict mapping input names to the corresponding `DataModel`s,\n                    if the program has named inputs.\n                - A Python generator function yielding `(inputs, targets)`.\n            y (np.ndarray): Target data. Like the input data `x`, it can be either NumPy\n                array(s) of `DataModel`(s). If `x` is a Python generator function,\n                `y` should not be specified since targets will be obtained from\n                `x`.\n            batch_size (int): Integer or `None`.\n                Number of samples per batch of computation.\n                If unspecified, `batch_size` will default to 32.\n                Do not specify the `batch_size` if your input data `x` is a\n                Python generator function since they generate batches.\n            verbose (int | str): `\"auto\"`, 0, 1, or 2. Verbosity mode.\n                0 = silent, 1 = progress bar, 2 = single line.\n                `\"auto\"` becomes 1 for most cases.\n                Note that the progress bar is not\n                particularly useful when logged to a file, so `verbose=2` is\n                recommended when not running interactively\n                (e.g. in a production environment). Defaults to `\"auto\"`.\n            steps (int): Integer or `None`.\n                Total number of steps (batches of samples) to draw before\n                declaring the evaluation round finished. If `steps` is `None`,\n                it will run until `x` is exhausted. In the case of an infinitely\n                repeating dataset, it will run indefinitely.\n            callbacks (list): List of `synalinks.callbacks.Callback` instances.\n                List of callbacks to apply during evaluation.\n            return_dict (bool): If `True`, reward and metric results are returned as a\n                dict, with each key being the name of the metric.\n                If `False`, they are returned as a list.\n\n        Returns:\n            (float | list | dict): Scalar test reward\n                (if the program has a single output and no metrics)\n                or list of scalars (if the program has multiple outputs\n                and/or metrics). The attribute `program.metrics_names` will give you\n                the display labels for the scalar outputs.\n        \"\"\"\n        self._assert_compile_called(\"evaluate\")\n        use_cached_eval_dataset = kwargs.pop(\"_use_cached_eval_dataset\", False)\n        if kwargs:\n            raise ValueError(f\"Arguments not recognized: {kwargs}\")\n        # Create an iterator that yields batches of input/target data.\n        if use_cached_eval_dataset:\n            epoch_iterator = self._eval_epoch_iterator\n        else:\n            epoch_iterator = EpochIterator(\n                x=x,\n                y=y,\n                batch_size=batch_size,\n                steps_per_epoch=steps,\n                shuffle=False,\n                steps_per_execution=self.steps_per_execution,\n            )\n\n        if not all(module.built for module in self._flatten_modules()):\n            # Build the model on one batch of data.\n            for _, data in epoch_iterator:\n                data_batch = data[0]\n                self._auto_build(\n                    iterator=epoch_iterator,\n                    data_batch=data_batch,\n                )\n                break\n        epoch_iterator.reset()\n\n        # Container that configures and calls callbacks.\n        if not isinstance(callbacks, callbacks_module.CallbackList):\n            callbacks = callbacks_module.CallbackList(\n                callbacks,\n                add_history=False,\n                add_progbar=verbose != 0,\n                verbose=verbose,\n                epochs=1,\n                steps=epoch_iterator.num_batches,\n                program=self,\n            )\n\n        self.stop_evaluating = False\n        callbacks.on_test_begin()\n        logs = {}\n        self.reset_metrics()\n        for step, iterator in epoch_iterator:\n            callbacks.on_test_batch_begin(step)\n            data = iterator[0]\n            x_batch, y_batch = data_adapter_utils.unpack_x_y(data)\n            logs = await self.test_on_batch(\n                x=x_batch,\n                y=y_batch,\n                return_dict=True,\n            )\n            callbacks.on_test_batch_end(step, logs)\n            if self.stop_evaluating:\n                break\n        logs = self._get_metrics_result_or_logs(logs)\n        callbacks.on_test_end(logs)\n\n        if return_dict:\n            return logs\n        return self._flatten_metrics_in_order(logs)\n\n    async def predict(\n        self, x, batch_size=None, verbose=\"auto\", steps=None, callbacks=None\n    ):\n        \"\"\"Generates output predictions for the input samples.\n\n        Computation is done in batches. This method is designed for batch\n        processing of large numbers of inputs. It is not intended for use inside\n        of loops that iterate over your data and process small numbers of inputs\n        at a time.\n\n        For small numbers of inputs that fit in one batch,\n        directly use `__call__()` for faster execution, e.g.,\n        `program(x)`, or `program(x, training=False)` if you have modules\n        that behave differently during inference.\n\n        Args:\n            x (np.ndarray | generator): Input data. It can be:\n                - A NumPy array (or array-like), or a list of `DataModel` arrays\n                    (in case the model has multiple inputs).\n                - A list of dict mapping input names to the corresponding `DataModel`s,\n                    if the program has named inputs.\n                - A Python generator function yielding `(inputs, targets)`.\n            batch_size (int): Integer or `None`.\n                Number of samples per batch of computation.\n                If unspecified, `batch_size` will default to 32.\n                Do not specify the `batch_size` if your input data `x` is a\n                `synalinks.utils.PyDataset`, `tf.data.Dataset`,\n                `torch.utils.data.DataLoader` or Python generator function\n                since they generate batches.\n            verbose (int): `\"auto\"`, 0, 1, or 2. Verbosity mode.\n                0 = silent, 1 = progress bar, 2 = single line.\n                `\"auto\"` becomes 1 for most cases. Note that the progress bar\n                is not particularly useful when logged to a file,\n                so `verbose=2` is recommended when not running interactively\n                (e.g. in a production environment). Defaults to `\"auto\"`.\n            steps (int): Total number of steps (batches of samples) to draw before\n                declaring the prediction round finished. If `steps` is `None`,\n                it will run until `x` is exhausted. In the case of an infinitely\n                repeating dataset, it will run indefinitely.\n            callbacks (list): List of `synalinks.callbacks.Callback` instances.\n                List of callbacks to apply during prediction.\n\n        Returns:\n            (list): `JsonDataModel` array(s) of predictions.\n                If the pipeline failed, a None is added to the predictions.\n        \"\"\"\n        # Create an iterator that yields batches of input data.\n        epoch_iterator = EpochIterator(\n            x=x,\n            batch_size=batch_size,\n            steps_per_epoch=steps,\n            shuffle=False,\n            steps_per_execution=self.steps_per_execution,\n        )\n\n        # Container that configures and calls callbacks.\n        if not isinstance(callbacks, callbacks_module.CallbackList):\n            callbacks = callbacks_module.CallbackList(\n                callbacks,\n                add_history=True,\n                add_progbar=verbose != 0,\n                verbose=verbose,\n                epochs=1,\n                steps=epoch_iterator.num_batches,\n                model=self,\n            )\n\n        self.stop_predicting = False\n        callbacks.on_test_begin()\n        outputs = []\n        for step, iterator in epoch_iterator:\n            callbacks.on_predict_batch_begin(step)\n            data = iterator[0]\n            x_batch, _ = data_adapter_utils.unpack_x_y(data)\n            batch_outputs = await self.predict_on_batch(x_batch)\n            outputs.extend(batch_outputs)\n            callbacks.on_predict_batch_end(step, {\"outputs\": batch_outputs})\n            if self.stop_predicting:\n                break\n        callbacks.on_predict_end()\n        return np.array(outputs, dtype=\"object\")\n\n    async def train_on_batch(\n        self,\n        x,\n        y=None,\n        return_dict=False,\n    ):\n        \"\"\"Runs a single backpropagation/optimization update on a single batch of data.\n\n        Args:\n            x (np.ndarray): Input data. Must be array-like.\n            y (np.ndarray): Target data. Must be array-like.\n            return_dict (bool): If `True`, reward and metric results are returned as a\n                dict, with each key being the name of the metric. If `False`,\n                they are returned as a list.\n\n        Returns:\n            (float | list | dict): A scalar reward value\n                (when no metrics and `return_dict=False`), a list of reward\n                and metric values (if there are metrics and `return_dict=False`),\n                or a dict of metric and reward values (if `return_dict=True`).\n        \"\"\"\n        y_pred = await self.predict_on_batch(x, training=True)\n\n        reward = await self.compute_reward(\n            x=x,\n            y=y,\n            y_pred=y_pred,\n            training=True,\n        )\n\n        await self._reward_tracker.update_state(reward)\n\n        # Perform training/optimization\n        if self.trainable_variables:\n            await self.optimizer.apply_optimization(\n                self.trainable_variables,\n                reward=reward,\n            )\n        else:\n            warnings.warn(\"The program does not have any trainable variables.\")\n\n        metrics = await self.compute_metrics(x, y, y_pred)\n\n        if return_dict:\n            return metrics\n        return self._flatten_metrics_in_order(metrics)\n\n    async def test_on_batch(\n        self,\n        x,\n        y=None,\n        return_dict=False,\n    ):\n        \"\"\"Test the program on a single batch of samples.\n\n        Args:\n            x (np.ndarray): Input data. Must be array-like.\n            y (np.ndarray): Target data. Must be array-like.\n            return_dict (bool): If `True`, reward and metric results are returned as a\n                dict, with each key being the name of the metric. If `False`,\n                they are returned as a list.\n\n        Returns:\n            (float | list | dict): A scalar reward value\n                (when no metrics and `return_dict=False`), a list of reward\n                and metric values (if there are metrics and `return_dict=False`),\n                or a dict of metric and reward values (if `return_dict=True`).\n        \"\"\"\n        y_pred = await self.predict_on_batch(x, training=False)\n\n        reward = await self.compute_reward(\n            x=x,\n            y=y,\n            y_pred=y_pred,\n            training=False,\n        )\n\n        await self._reward_tracker.update_state(reward)\n\n        metrics = await self.compute_metrics(x, y, y_pred)\n\n        if return_dict:\n            return metrics\n        return self._flatten_metrics_in_order(metrics)\n\n    async def predict_on_batch(self, x, training=False):\n        \"\"\"Returns predictions for a single batch of samples.\n\n        Args:\n            x (np.ndarray): Input data. Must be array-like.\n            training (bool): Boolean. True if training.\n\n        Returns:\n            (list): list(s) of JsonDataModel predictions.\n        \"\"\"\n        tasks = []\n        for inputs in x:\n            tasks.append(self(inputs, training=training))\n        y_pred = await asyncio.gather(*tasks)\n        return y_pred\n\n    def get_compile_config(self):\n        \"\"\"Returns a serialized config with information for compiling the program.\n\n        This method returns a config dictionary containing all the information\n        (optimizer, reward, metrics, etc.) with which the program was compiled.\n\n        Returns:\n            (dict): A dict containing information for compiling the program.\n        \"\"\"\n        if self.compiled and hasattr(self, \"_compile_config\"):\n            return self._compile_config.serialize()\n\n    def compile_from_config(self, config):\n        \"\"\"Compiles the program with the information given in config.\n\n        This method uses the information in the config (optimizer, reward,\n        metrics, etc.) to compile the program.\n\n        Args:\n            config (dict): Dict containing information for compiling the program.\n        \"\"\"\n        has_overridden_compile = self.__class__.compile != Trainer.compile\n        if has_overridden_compile:\n            warnings.warn(\n                \"`compile()` was not called as part of program loading \"\n                \"because the program's `compile()` method is custom. \"\n                \"All subclassed Models that have `compile()` \"\n                \"overridden should also override \"\n                \"`get_compile_config()` and `compile_from_config(config)`. \"\n                \"Alternatively, you can \"\n                \"call `compile()` manually after loading.\",\n                stacklevel=2,\n            )\n            return\n        config = serialization_lib.deserialize_synalinks_object(config)\n        self.compile(**config)\n        if hasattr(self, \"optimizer\") and self.built:\n            # Create optimizer variables/programs.\n            if not self.optimizer.built:\n                asyncio.get_event_loop().run_until_complete(\n                    self.optimizer.build(self.trainable_variables)\n                )\n\n    def _should_reward(self, epoch, validation_freq):\n        epoch = epoch + 1  # one-index the user-facing epoch.\n        if isinstance(validation_freq, int):\n            return epoch % validation_freq == 0\n        elif isinstance(validation_freq, list):\n            return epoch in validation_freq\n        else:\n            raise ValueError(\n                \"Expected `validation_freq` to be a list or int. \"\n                f\"Received: validation_freq={validation_freq} of the \"\n                f\"type {type(validation_freq)}.\"\n            )\n\n    def _get_metrics_result_or_logs(self, logs):\n        \"\"\"Returns program metrics as a dict if the keys match with input logs.\n\n        When the training / evaluation is performed with an asynchronous steps,\n        the last scheduled `train / test_step` may not give the latest metrics\n        because it is not guaranteed to be executed the last. This method gets\n        metrics from the program directly instead of relying on the return from\n        last step function.\n\n        When the user has custom train / test step functions, the metrics\n        returned may be different from `Program.metrics`. In those instances,\n        this function will be no-op and return the logs passed in.\n\n        Args:\n            logs (dict): A `dict` of metrics returned by train / test step function.\n\n        Returns:\n            (dict): A `dict` containing values of the metrics listed in `self.metrics`\n                when logs and program metrics keys match. Otherwise it returns input\n                `logs`.\n        \"\"\"\n        metric_logs = self.get_metrics_result()\n        # Verify that train / test step logs passed and metric logs have\n        # matching keys. It could be different when using custom step functions,\n        # in which case we return the logs from the last step.\n        if isinstance(logs, dict) and set(logs.keys()) == set(metric_logs.keys()):\n            return metric_logs\n        return logs\n\n    def _flatten_metrics_in_order(self, logs):\n        \"\"\"Turns `logs` dict into a list as per key order of `metrics_names`.\"\"\"\n        metric_names = []\n        for metric in self.metrics:\n            if isinstance(metric, CompileMetrics):\n                metric_names += [sub_metric.name for sub_metric in metric.metrics]\n            else:\n                metric_names.append(metric.name)\n        results = []\n        for name in metric_names:\n            if name in logs:\n                results.append(logs[name])\n        for key in sorted(logs.keys()):\n            if key not in metric_names:\n                results.append(logs[key])\n        if len(results) == 1:\n            return results[0]\n        return results\n\n    def _assert_compile_called(self, method_name=None):\n        if not self.compiled:\n            msg = \"You must call `compile()` before \"\n            if metrics_module:\n                msg += \"using the program.\"\n            else:\n                msg += f\"calling `{method_name}()`.\"\n            raise ValueError(msg)\n\n    def _auto_build(self, iterator=None, data_batch=None):\n        program_unbuilt = not all(module.built for module in self._flatten_modules())\n        compile_metrics_unbuilt = (\n            self._compile_metrics is not None and not self._compile_metrics.built\n        )\n        compile_reward_unbuilt = (\n            self._compile_reward is not None and not self._compile_reward.built\n        )\n        optimizer_unbuilt = self.optimizer is not None and not self.optimizer.built\n        if program_unbuilt or compile_metrics_unbuilt or compile_reward_unbuilt:\n            if data_batch is None:\n                for _, data_or_iterator in iterator:\n                    if isinstance(data_or_iterator, (list, tuple)):\n                        data_batch = data_or_iterator[0]\n                    else:\n                        data_batch = next(data_or_iterator)\n                    break\n            (x, y) = data_batch\n            try:\n                y_pred = asyncio.get_event_loop().run_until_complete(\n                    self.predict_on_batch(x, training=False)\n                )\n            except Exception as e:\n                raise RuntimeError(\n                    \"Unable to automatically build the program. \"\n                    \"Please build it yourself before calling \"\n                    \"fit/evaluate/predict. \"\n                    \"A program is 'built' when its variables have \"\n                    \"been created and its `self.built` attribute \"\n                    \"is True. Usually, calling the program on a batch \"\n                    \"of data is the right way to build it.\\n\"\n                    \"Exception encountered:\\n\"\n                    f\"'{e}'\"\n                )\n            if compile_metrics_unbuilt:\n                # Build all metric state with `backend.compute_output_spec`.\n                asyncio.get_event_loop().run_until_complete(\n                    backend.compute_output_spec(\n                        self.compute_metrics,\n                        x,\n                        y,\n                        y_pred,\n                    )\n                )\n            if compile_reward_unbuilt:\n                # Build `CompileReward` state with `backend.compute_output_spec`.\n                asyncio.get_event_loop().run_until_complete(\n                    backend.compute_output_spec(\n                        self.compute_reward,\n                        x,\n                        y,\n                        y_pred,\n                        training=False,\n                    )\n                )\n        if optimizer_unbuilt:\n            # Build optimizer\n            asyncio.get_event_loop().run_until_complete(\n                self.optimizer.build(self.trainable_variables)\n            )\n        self._post_build()\n\n    def _assert_compile_called(self, method_name=None):\n        if not self.compiled:\n            msg = \"You must call `compile()` before \"\n            if metrics_module:\n                msg += \"using the model.\"\n            else:\n                msg += f\"calling `{method_name}()`.\"\n            raise ValueError(msg)\n\n    def _should_eval(self, epoch, validation_freq):\n        epoch = epoch + 1  # one-index the user-facing epoch.\n        if isinstance(validation_freq, int):\n            return epoch % validation_freq == 0\n        elif isinstance(validation_freq, list):\n            return epoch in validation_freq\n        else:\n            raise ValueError(\n                \"Expected `validation_freq` to be a list or int. \"\n                f\"Received: validation_freq={validation_freq} of the \"\n                f\"type {type(validation_freq)}.\"\n            )\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/Program%20training%20API/#synalinks.src.trainers.trainer.Trainer.compile","title":"<code>compile(optimizer=None, reward=None, reward_weights=None, metrics=None, run_eagerly=False, steps_per_execution=1)</code>","text":"<p>Configures the program for training.</p> <p>Example:</p> <pre><code>program.compile(\n    optimizer=synalinks.optimizers.RandomFewShot(),\n    reward=synalinks.rewards.ExactMatch(),\n    metrics=[\n        synalinks.metrics.MeanMetricWrapper(synalinks.rewards.exact_match),\n    ],\n)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>optimizer</code> <code>Optimizer</code> <p>Optimizer instance. See <code>synalinks.optimizers</code>.</p> <code>None</code> <code>reward</code> <code>Reward</code> <p>Reward function. A <code>synalinks.rewards.Reward</code> instance. See <code>synalinks.rewards</code>. A reward function is any callable with the signature <code>reward = fn(y_true, y_pred)</code>, where <code>y_true</code> are the ground truth values, and <code>y_pred</code> are the program's predictions. <code>y_true</code> should be a list of batch size length <code>[d0, .. dN]</code>. <code>y_pred</code> should be a list of batch size length <code>[d0, .. dN]</code>. The reward function should return a float.</p> <code>None</code> <code>reward_weights</code> <code>list</code> <p>Optional list specifying scalar coefficients (Python floats) to weight the reward contributions of different program outputs. The reward value that will be maximized by the program will then be the weighted sum of all individual rewards, weighted by the <code>reward_weights</code> coefficients. It is expected to have a 1:1 mapping to the program's outputs.</p> <code>None</code> <code>metrics</code> <code>list</code> <p>List of metrics to be evaluated by the program during training and testing. Each of it is a <code>synalinks.metrics.Metric</code> instance. See <code>synalinks.metrics</code>. A function is any callable with the signature <code>result = fn(y_true, y_pred)</code>.</p> <code>None</code> <code>run_eagerly</code> <code>bool</code> <p>If <code>True</code>, this program's forward pass  will never be compiled. It is recommended to leave this  as <code>False</code> when training (for best performance),  and to set it to <code>True</code> when debugging.</p> <code>False</code> <code>steps_per_execution</code> <code>int</code> <p>The number of batches to run during each a single compiled function call. Running multiple batches inside a single compiled function call can greatly improve performance on TPUs or small programs with a large Python overhead. At most, one full epoch will be run each execution. If a number larger than the size of the epoch is passed, the execution will be truncated to the size of the epoch. Note that if <code>steps_per_execution</code> is set to <code>N</code>, <code>Callback.on_batch_begin</code> and <code>Callback.on_batch_end</code> methods will only be called every <code>N</code> batches (i.e. before/after each compiled function execution).</p> <code>1</code> Source code in <code>synalinks/src/trainers/trainer.py</code> <pre><code>@tracking.no_automatic_dependency_tracking\ndef compile(\n    self,\n    optimizer=None,\n    reward=None,\n    reward_weights=None,\n    metrics=None,\n    run_eagerly=False,\n    steps_per_execution=1,\n):\n    \"\"\"Configures the program for training.\n\n    Example:\n\n    ```python\n    program.compile(\n        optimizer=synalinks.optimizers.RandomFewShot(),\n        reward=synalinks.rewards.ExactMatch(),\n        metrics=[\n            synalinks.metrics.MeanMetricWrapper(synalinks.rewards.exact_match),\n        ],\n    )\n    ```\n\n    Args:\n        optimizer (Optimizer): Optimizer instance. See `synalinks.optimizers`.\n        reward (Reward): Reward function. A `synalinks.rewards.Reward`\n            instance. See `synalinks.rewards`. A reward function is\n            any callable with the signature `reward = fn(y_true, y_pred)`,\n            where `y_true` are the ground truth values, and `y_pred`\n            are the program's predictions.\n            `y_true` should be a list of batch size length `[d0, .. dN]`.\n            `y_pred` should be a list of batch size length `[d0, .. dN]`.\n            The reward function should return a float.\n        reward_weights (list): Optional list specifying scalar coefficients\n            (Python floats) to weight the reward contributions of\n            different program outputs. The reward value that will be maximized\n            by the program will then be the *weighted sum* of all individual\n            rewards, weighted by the `reward_weights` coefficients. It is\n            expected to have a 1:1 mapping to the program's outputs.\n        metrics (list): List of metrics to be evaluated by the program during\n            training and testing. Each of it is a `synalinks.metrics.Metric`\n            instance. See `synalinks.metrics`. A function is any callable with the\n            signature `result = fn(y_true, y_pred)`.\n        run_eagerly (bool): If `True`, this program's forward pass\n             will never be compiled. It is recommended to leave this\n             as `False` when training (for best performance),\n             and to set it to `True` when debugging.\n        steps_per_execution (int): The number of batches to run\n            during each a single compiled function call. Running multiple\n            batches inside a single compiled function call can\n            greatly improve performance on TPUs or small programs with a large\n            Python overhead. At most, one full epoch will be run each\n            execution. If a number larger than the size of the epoch is\n            passed, the execution will be truncated to the size of the\n            epoch. Note that if `steps_per_execution` is set to `N`,\n            `Callback.on_batch_begin` and `Callback.on_batch_end` methods\n            will only be called every `N` batches (i.e. before/after\n            each compiled function execution).\n    \"\"\"\n    self._clear_previous_trainer_metrics()\n    self._optimizer = optimizer\n\n    if hasattr(self, \"output_names\"):\n        output_names = self.output_names\n    else:\n        output_names = None\n    if reward is not None:\n        self._compile_reward = CompileReward(\n            reward, reward_weights, output_names=output_names\n        )\n        self.reward = reward\n    if metrics is not None:\n        self._compile_metrics = CompileMetrics(metrics, output_names=output_names)\n    self.run_eagerly = run_eagerly\n    self.stop_training = False\n    self.compiled = True\n    self._reward_tracker = metrics_module.Mean(name=\"reward\")\n    self.steps_per_execution = steps_per_execution\n\n    self._compile_config = serialization_lib.SerializableDict(\n        optimizer=optimizer,\n        reward=reward,\n        reward_weights=reward_weights,\n        metrics=metrics,\n        run_eagerly=run_eagerly,\n        steps_per_execution=steps_per_execution,\n    )\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/Program%20training%20API/#synalinks.src.trainers.trainer.Trainer.compile_from_config","title":"<code>compile_from_config(config)</code>","text":"<p>Compiles the program with the information given in config.</p> <p>This method uses the information in the config (optimizer, reward, metrics, etc.) to compile the program.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>Dict containing information for compiling the program.</p> required Source code in <code>synalinks/src/trainers/trainer.py</code> <pre><code>def compile_from_config(self, config):\n    \"\"\"Compiles the program with the information given in config.\n\n    This method uses the information in the config (optimizer, reward,\n    metrics, etc.) to compile the program.\n\n    Args:\n        config (dict): Dict containing information for compiling the program.\n    \"\"\"\n    has_overridden_compile = self.__class__.compile != Trainer.compile\n    if has_overridden_compile:\n        warnings.warn(\n            \"`compile()` was not called as part of program loading \"\n            \"because the program's `compile()` method is custom. \"\n            \"All subclassed Models that have `compile()` \"\n            \"overridden should also override \"\n            \"`get_compile_config()` and `compile_from_config(config)`. \"\n            \"Alternatively, you can \"\n            \"call `compile()` manually after loading.\",\n            stacklevel=2,\n        )\n        return\n    config = serialization_lib.deserialize_synalinks_object(config)\n    self.compile(**config)\n    if hasattr(self, \"optimizer\") and self.built:\n        # Create optimizer variables/programs.\n        if not self.optimizer.built:\n            asyncio.get_event_loop().run_until_complete(\n                self.optimizer.build(self.trainable_variables)\n            )\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/Program%20training%20API/#synalinks.src.trainers.trainer.Trainer.compute_metrics","title":"<code>compute_metrics(x, y, y_pred)</code>  <code>async</code>","text":"<p>Update metric states and collect all metrics to be returned.</p> <p>Subclasses can optionally override this method to provide custom metric updating and collection logic. Custom metrics are not passed in <code>compile()</code>, they can be created in <code>__init__</code> or <code>build</code>. They are automatically tracked and returned by <code>self.metrics</code>. ```</p> <p>Args:     x: Input data.     y: Target data.     y_pred: Predictions returned by the program output of <code>program.call(x)</code>.</p> <p>Returns:     A <code>dict</code> containing values that will be passed to         <code>synalinks.callbacks.CallbackList.on_train_batch_end()</code>. Typically,         the values of the metrics listed in <code>self.metrics</code> are returned.         Example: <code>{'reward': 0.2, 'accuracy': 0.7}</code>.</p> Source code in <code>synalinks/src/trainers/trainer.py</code> <pre><code>async def compute_metrics(self, x, y, y_pred):\n    \"\"\"Update metric states and collect all metrics to be returned.\n\n    Subclasses can optionally override this method to provide custom metric\n    updating and collection logic. Custom metrics are not passed in\n    `compile()`, they can be created in `__init__` or `build`. They are\n    automatically tracked and returned by `self.metrics`.\n    ```\n\n    Args:\n        x: Input data.\n        y: Target data.\n        y_pred: Predictions returned by the program output of `program.call(x)`.\n\n    Returns:\n        A `dict` containing values that will be passed to\n            `synalinks.callbacks.CallbackList.on_train_batch_end()`. Typically,\n            the values of the metrics listed in `self.metrics` are returned.\n            Example: `{'reward': 0.2, 'accuracy': 0.7}`.\n    \"\"\"\n    del x  # The default implementation does not use `x`.\n    if self._compile_metrics is not None:\n        for y_t, y_p in zip(y, y_pred):\n            await self._compile_metrics.update_state(y_t, y_p)\n    return self.get_metrics_result()\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/Program%20training%20API/#synalinks.src.trainers.trainer.Trainer.compute_reward","title":"<code>compute_reward(x=None, y=None, y_pred=None, sample_weight=None, training=True)</code>  <code>async</code>","text":"<p>Compute the total reward, validate it, and return it.</p> <p>Subclasses can optionally override this method to provide custom reward computation logic.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>list</code> <p>Input data.</p> <code>None</code> <code>y</code> <code>list</code> <p>Target data.</p> <code>None</code> <code>y_pred</code> <code>list</code> <p>Predictions returned by the program (output of <code>program(x)</code>).</p> <code>None</code> <code>training</code> <code>bool</code> <p>Whether we are training or evaluating the program.</p> <code>True</code> <p>Returns:</p> Type Description <code>float | None</code> <p>The total reward as a scalar, or <code>None</code> if no reward results (which is the case when called by <code>Program.test_step</code>).</p> Source code in <code>synalinks/src/trainers/trainer.py</code> <pre><code>async def compute_reward(\n    self,\n    x=None,\n    y=None,\n    y_pred=None,\n    sample_weight=None,\n    training=True,\n):\n    \"\"\"Compute the total reward, validate it, and return it.\n\n    Subclasses can optionally override this method to provide custom reward\n    computation logic.\n\n    Args:\n        x (list): Input data.\n        y (list): Target data.\n        y_pred (list): Predictions returned by the program (output of `program(x)`).\n        training (bool): Whether we are training or evaluating the program.\n\n    Returns:\n        (float | None): The total reward as a scalar, or `None` if no reward results\n            (which is the case when called by `Program.test_step`).\n    \"\"\"\n    # The default implementation does not use `x` or `training`.\n    del x\n    del training\n    rewards = []\n    if self._compile_reward is not None:\n        for y_t, y_p in zip(y, y_pred):\n            reward = await self._compile_reward(y_t, y_p)\n            if reward is not None:\n                rewards.append(reward)\n    for reward in self.rewards:\n        rewards.append(numpy.sum(reward))\n    if len(rewards) == 1:\n        total_reward = rewards[0]\n    elif len(rewards) == 0:\n        total_reward = numpy.zeros(())\n    else:\n        total_reward = numpy.mean(rewards)\n    return float(total_reward)\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/Program%20training%20API/#synalinks.src.trainers.trainer.Trainer.evaluate","title":"<code>evaluate(x=None, y=None, batch_size=None, verbose='auto', steps=None, callbacks=None, return_dict=True, **kwargs)</code>  <code>async</code>","text":"<p>Returns the reward value &amp; metrics values for the program in test mode.</p> <p>Computation is done in batches (see the <code>batch_size</code> arg.)</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray | generator</code> <p>Input data. It can be: - A NumPy array (or array-like), or a list of <code>DataModel</code> arrays     (in case the model has multiple inputs). - A list of dict mapping input names to the corresponding <code>DataModel</code>s,     if the program has named inputs. - A Python generator function yielding <code>(inputs, targets)</code>.</p> <code>None</code> <code>y</code> <code>ndarray</code> <p>Target data. Like the input data <code>x</code>, it can be either NumPy array(s) of <code>DataModel</code>(s). If <code>x</code> is a Python generator function, <code>y</code> should not be specified since targets will be obtained from <code>x</code>.</p> <code>None</code> <code>batch_size</code> <code>int</code> <p>Integer or <code>None</code>. Number of samples per batch of computation. If unspecified, <code>batch_size</code> will default to 32. Do not specify the <code>batch_size</code> if your input data <code>x</code> is a Python generator function since they generate batches.</p> <code>None</code> <code>verbose</code> <code>int | str</code> <p><code>\"auto\"</code>, 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = single line. <code>\"auto\"</code> becomes 1 for most cases. Note that the progress bar is not particularly useful when logged to a file, so <code>verbose=2</code> is recommended when not running interactively (e.g. in a production environment). Defaults to <code>\"auto\"</code>.</p> <code>'auto'</code> <code>steps</code> <code>int</code> <p>Integer or <code>None</code>. Total number of steps (batches of samples) to draw before declaring the evaluation round finished. If <code>steps</code> is <code>None</code>, it will run until <code>x</code> is exhausted. In the case of an infinitely repeating dataset, it will run indefinitely.</p> <code>None</code> <code>callbacks</code> <code>list</code> <p>List of <code>synalinks.callbacks.Callback</code> instances. List of callbacks to apply during evaluation.</p> <code>None</code> <code>return_dict</code> <code>bool</code> <p>If <code>True</code>, reward and metric results are returned as a dict, with each key being the name of the metric. If <code>False</code>, they are returned as a list.</p> <code>True</code> <p>Returns:</p> Type Description <code>float | list | dict</code> <p>Scalar test reward (if the program has a single output and no metrics) or list of scalars (if the program has multiple outputs and/or metrics). The attribute <code>program.metrics_names</code> will give you the display labels for the scalar outputs.</p> Source code in <code>synalinks/src/trainers/trainer.py</code> <pre><code>async def evaluate(\n    self,\n    x=None,\n    y=None,\n    batch_size=None,\n    verbose=\"auto\",\n    steps=None,\n    callbacks=None,\n    return_dict=True,\n    **kwargs,\n):\n    \"\"\"Returns the reward value &amp; metrics values for the program in test mode.\n\n    Computation is done in batches (see the `batch_size` arg.)\n\n    Args:\n        x (np.ndarray | generator): Input data. It can be:\n            - A NumPy array (or array-like), or a list of `DataModel` arrays\n                (in case the model has multiple inputs).\n            - A list of dict mapping input names to the corresponding `DataModel`s,\n                if the program has named inputs.\n            - A Python generator function yielding `(inputs, targets)`.\n        y (np.ndarray): Target data. Like the input data `x`, it can be either NumPy\n            array(s) of `DataModel`(s). If `x` is a Python generator function,\n            `y` should not be specified since targets will be obtained from\n            `x`.\n        batch_size (int): Integer or `None`.\n            Number of samples per batch of computation.\n            If unspecified, `batch_size` will default to 32.\n            Do not specify the `batch_size` if your input data `x` is a\n            Python generator function since they generate batches.\n        verbose (int | str): `\"auto\"`, 0, 1, or 2. Verbosity mode.\n            0 = silent, 1 = progress bar, 2 = single line.\n            `\"auto\"` becomes 1 for most cases.\n            Note that the progress bar is not\n            particularly useful when logged to a file, so `verbose=2` is\n            recommended when not running interactively\n            (e.g. in a production environment). Defaults to `\"auto\"`.\n        steps (int): Integer or `None`.\n            Total number of steps (batches of samples) to draw before\n            declaring the evaluation round finished. If `steps` is `None`,\n            it will run until `x` is exhausted. In the case of an infinitely\n            repeating dataset, it will run indefinitely.\n        callbacks (list): List of `synalinks.callbacks.Callback` instances.\n            List of callbacks to apply during evaluation.\n        return_dict (bool): If `True`, reward and metric results are returned as a\n            dict, with each key being the name of the metric.\n            If `False`, they are returned as a list.\n\n    Returns:\n        (float | list | dict): Scalar test reward\n            (if the program has a single output and no metrics)\n            or list of scalars (if the program has multiple outputs\n            and/or metrics). The attribute `program.metrics_names` will give you\n            the display labels for the scalar outputs.\n    \"\"\"\n    self._assert_compile_called(\"evaluate\")\n    use_cached_eval_dataset = kwargs.pop(\"_use_cached_eval_dataset\", False)\n    if kwargs:\n        raise ValueError(f\"Arguments not recognized: {kwargs}\")\n    # Create an iterator that yields batches of input/target data.\n    if use_cached_eval_dataset:\n        epoch_iterator = self._eval_epoch_iterator\n    else:\n        epoch_iterator = EpochIterator(\n            x=x,\n            y=y,\n            batch_size=batch_size,\n            steps_per_epoch=steps,\n            shuffle=False,\n            steps_per_execution=self.steps_per_execution,\n        )\n\n    if not all(module.built for module in self._flatten_modules()):\n        # Build the model on one batch of data.\n        for _, data in epoch_iterator:\n            data_batch = data[0]\n            self._auto_build(\n                iterator=epoch_iterator,\n                data_batch=data_batch,\n            )\n            break\n    epoch_iterator.reset()\n\n    # Container that configures and calls callbacks.\n    if not isinstance(callbacks, callbacks_module.CallbackList):\n        callbacks = callbacks_module.CallbackList(\n            callbacks,\n            add_history=False,\n            add_progbar=verbose != 0,\n            verbose=verbose,\n            epochs=1,\n            steps=epoch_iterator.num_batches,\n            program=self,\n        )\n\n    self.stop_evaluating = False\n    callbacks.on_test_begin()\n    logs = {}\n    self.reset_metrics()\n    for step, iterator in epoch_iterator:\n        callbacks.on_test_batch_begin(step)\n        data = iterator[0]\n        x_batch, y_batch = data_adapter_utils.unpack_x_y(data)\n        logs = await self.test_on_batch(\n            x=x_batch,\n            y=y_batch,\n            return_dict=True,\n        )\n        callbacks.on_test_batch_end(step, logs)\n        if self.stop_evaluating:\n            break\n    logs = self._get_metrics_result_or_logs(logs)\n    callbacks.on_test_end(logs)\n\n    if return_dict:\n        return logs\n    return self._flatten_metrics_in_order(logs)\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/Program%20training%20API/#synalinks.src.trainers.trainer.Trainer.fit","title":"<code>fit(x=None, y=None, batch_size=None, epochs=1, verbose='auto', callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1)</code>  <code>async</code>","text":"<p>Trains the program for a fixed number of epochs (dataset iterations).</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray | generator</code> <p>Input data. It can be: - A NumPy array (or array-like), or a list of <code>DataModel</code> arrays     (in case the model has multiple inputs). - A list of dict mapping input names to the corresponding <code>DataModel</code>s,     if the program has named inputs. - A Python generator function yielding <code>(inputs, targets)</code>.</p> <code>None</code> <code>y</code> <code>ndarray</code> <p>Target data. Like the input data <code>x</code>, it can be either NumPy array(s) of <code>DataModel</code>(s). If <code>x</code> is a Python generator function, <code>y</code> should not be specified since targets will be obtained from <code>x</code>.</p> <code>None</code> <code>batch_size</code> <code>int</code> <p>Integer or <code>None</code>. Number of samples per batch of computation. If unspecified, <code>batch_size</code> will default to 32. Do not specify the <code>batch_size</code> if your input data <code>x</code> is a Python generator function since they generate batches.</p> <code>None</code> <code>epochs</code> <code>int</code> <p>Integer. Number of epochs to train the program. An epoch is an iteration over the entire <code>x</code> and <code>y</code> data provided (unless the <code>steps_per_epoch</code> flag is set to something other than None). Note that in conjunction with <code>initial_epoch</code>, <code>epochs</code> is to be understood as \"final epoch\". The program is not trained for a number of iterations given by <code>epochs</code>, but merely until the epoch of index <code>epochs</code> is reached.</p> <code>1</code> <code>verbose</code> <code>int</code> <p><code>\"auto\"</code>, 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch. \"auto\" becomes 1 for most cases. Note that the progress bar is not particularly useful when logged to a file, so <code>verbose=2</code> is recommended when not running interactively (e.g., in a production environment). Defaults to <code>\"auto\"</code>.</p> <code>'auto'</code> <code>callbacks</code> <code>list</code> <p>List of <code>synalinks.callbacks.Callback</code> instances. List of callbacks to apply during training. See <code>synalinks.callbacks</code>. Note <code>synalinks.callbacks.ProgbarLogger</code> and <code>synalinks.callbacks.History</code> callbacks are created automatically and need not be passed to <code>program.fit()</code>. <code>synalinks.callbacks.ProgbarLogger</code> is created or not based on the <code>verbose</code> argument in <code>program.fit()</code>.</p> <code>None</code> <code>validation_split</code> <code>float</code> <p>Float between 0 and 1. Fraction of the training data to be used as validation data. The program will set apart this fraction of the training data, will not train on it, and will evaluate the reward and any program metrics on this data at the end of each epoch. The validation data is selected from the last samples in the <code>x</code> and <code>y</code> data provided, before shuffling. This argument is only supported when <code>x</code> and <code>y</code> are made of data_models. If both <code>validation_data</code> and <code>validation_split</code> are provided, <code>validation_data</code> will override <code>validation_split</code>.</p> <code>0.0</code> <code>validation_data</code> <code>tuple | iterator</code> <p>Data on which to evaluate the reward and any program metrics at the end of each epoch. The program will not be trained on this data. <code>validation_data</code> will override <code>validation_split</code>. It can be: - A tuple <code>(x_val, y_val)</code> of <code>DataModel</code>s lists.</p> <code>None</code> <code>shuffle</code> <code>bool</code> <p>Whether to shuffle the training data before each epoch. This argument is ignored when <code>x</code> is a Python generator function.</p> <code>True</code> <code>initial_epoch</code> <code>int</code> <p>Integer. Epoch at which to start training (useful for resuming a previous training run).</p> <code>0</code> <code>steps_per_epoch</code> <code>int</code> <p>Integer or <code>None</code>. Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch. When training with input data_models arrays, the default <code>None</code> means that the value used is the number of samples in your dataset divided by the batch size, or 1 if that cannot be determined. If <code>x</code> is a Python generator function, the epoch will run until the input dataset is exhausted. When passing an infinitely repeating dataset, you must specify the <code>steps_per_epoch</code> argument, otherwise the training will run indefinitely.</p> <code>None</code> <code>validation_steps</code> <code>int</code> <p>Integer or <code>None</code>. Only relevant if <code>validation_data</code> is provided. Total number of steps (batches of samples) to draw before stopping when performing validation at the end of every epoch. If <code>validation_steps</code> is <code>None</code>, validation will run until the <code>validation_data</code> dataset is exhausted. In the case of an infinitely repeating dataset, it will run indefinitely. If <code>validation_steps</code> is specified and only part of the dataset is consumed, the evaluation will start from the beginning of the dataset at each epoch. This ensures that the same validation samples are used every time.</p> <code>None</code> <code>validation_batch_size</code> <code>int</code> <p>Integer or <code>None</code>. Number of samples per validation batch. If unspecified, will default to <code>batch_size</code>. Do not specify the <code>validation_batch_size</code> if your data is a <code>synalinks.utils.PyDataset</code>, <code>tf.data.Dataset</code>, <code>torch.utils.data.DataLoader</code> or Python generator function since they generate batches.</p> <code>None</code> <code>validation_freq</code> <code>int</code> <p>Only relevant if validation data is provided. Specifies how many training epochs to run before a new validation run is performed, e.g. <code>validation_freq=2</code> runs validation every 2 epochs.</p> <code>1</code> <p>Returns:</p> Type Description <code>History</code> <p>A <code>History</code> object. Its <code>History.history</code> attribute is a record of training reward values and metrics values at successive epochs, as well as validation reward values and validation metrics values (if applicable).</p> Source code in <code>synalinks/src/trainers/trainer.py</code> <pre><code>async def fit(\n    self,\n    x=None,\n    y=None,\n    batch_size=None,\n    epochs=1,\n    verbose=\"auto\",\n    callbacks=None,\n    validation_split=0.0,\n    validation_data=None,\n    shuffle=True,\n    initial_epoch=0,\n    steps_per_epoch=None,\n    validation_steps=None,\n    validation_batch_size=None,\n    validation_freq=1,\n):\n    \"\"\"Trains the program for a fixed number of epochs (dataset iterations).\n\n    Args:\n        x (np.ndarray | generator): Input data. It can be:\n            - A NumPy array (or array-like), or a list of `DataModel` arrays\n                (in case the model has multiple inputs).\n            - A list of dict mapping input names to the corresponding `DataModel`s,\n                if the program has named inputs.\n            - A Python generator function yielding `(inputs, targets)`.\n        y (np.ndarray): Target data. Like the input data `x`, it can be either NumPy\n            array(s) of `DataModel`(s). If `x` is a Python generator function,\n            `y` should not be specified since targets will be obtained from\n            `x`.\n        batch_size (int): Integer or `None`.\n            Number of samples per batch of computation.\n            If unspecified, `batch_size` will default to 32.\n            Do not specify the `batch_size` if your input data `x` is a\n            Python generator function since they generate batches.\n        epochs (int): Integer. Number of epochs to train the program.\n            An epoch is an iteration over the entire `x` and `y`\n            data provided (unless the `steps_per_epoch` flag is set to\n            something other than None).\n            Note that in conjunction with `initial_epoch`,\n            `epochs` is to be understood as \"final epoch\".\n            The program is not trained for a number of iterations\n            given by `epochs`, but merely until the epoch\n            of index `epochs` is reached.\n        verbose (int): `\"auto\"`, 0, 1, or 2. Verbosity mode.\n            0 = silent, 1 = progress bar, 2 = one line per epoch.\n            \"auto\" becomes 1 for most cases.\n            Note that the progress bar is not\n            particularly useful when logged to a file,\n            so `verbose=2` is recommended when not running interactively\n            (e.g., in a production environment). Defaults to `\"auto\"`.\n        callbacks (list): List of `synalinks.callbacks.Callback` instances.\n            List of callbacks to apply during training.\n            See `synalinks.callbacks`. Note\n            `synalinks.callbacks.ProgbarLogger` and\n            `synalinks.callbacks.History` callbacks are created\n            automatically and need not be passed to `program.fit()`.\n            `synalinks.callbacks.ProgbarLogger` is created\n            or not based on the `verbose` argument in `program.fit()`.\n        validation_split (float): Float between 0 and 1.\n            Fraction of the training data to be used as validation data.\n            The program will set apart this fraction of the training data,\n            will not train on it, and will evaluate the reward and any program\n            metrics on this data at the end of each epoch. The validation\n            data is selected from the last samples in the `x` and `y` data\n            provided, before shuffling.\n            This argument is only supported when `x` and `y` are made of\n            data_models.\n            If both `validation_data` and `validation_split` are provided,\n            `validation_data` will override `validation_split`.\n        validation_data (tuple | iterator): Data on which to evaluate\n            the reward and any program metrics at the end of each epoch.\n            The program will not be trained on this data.\n            `validation_data` will override `validation_split`.\n            It can be:\n            - A tuple `(x_val, y_val)` of `DataModel`s lists.\n        shuffle (bool): Whether to shuffle the training data before each\n            epoch. This argument is ignored when `x` is a Python generator function.\n        initial_epoch (int): Integer.\n            Epoch at which to start training\n            (useful for resuming a previous training run).\n        steps_per_epoch (int): Integer or `None`.\n            Total number of steps (batches of samples) before declaring one\n            epoch finished and starting the next epoch. When training with\n            input data_models arrays, the default `None` means that the\n            value used is the number of samples in your dataset divided by\n            the batch size, or 1 if that cannot be determined.\n            If `x` is a Python generator function, the\n            epoch will run until the input dataset is exhausted. When\n            passing an infinitely repeating dataset, you must specify the\n            `steps_per_epoch` argument, otherwise the training will run\n            indefinitely.\n        validation_steps (int): Integer or `None`.\n            Only relevant if `validation_data` is provided.\n            Total number of steps (batches of samples) to draw before\n            stopping when performing validation at the end of every epoch.\n            If `validation_steps` is `None`, validation will run until the\n            `validation_data` dataset is exhausted. In the case of an\n            infinitely repeating dataset, it will run indefinitely. If\n            `validation_steps` is specified and only part of the dataset\n            is consumed, the evaluation will start from the beginning of the\n            dataset at each epoch. This ensures that the same validation\n            samples are used every time.\n        validation_batch_size (int): Integer or `None`.\n            Number of samples per validation batch.\n            If unspecified, will default to `batch_size`.\n            Do not specify the `validation_batch_size` if your data is a\n            `synalinks.utils.PyDataset`, `tf.data.Dataset`,\n            `torch.utils.data.DataLoader` or Python generator function\n            since they generate batches.\n        validation_freq (int): Only relevant if validation data is provided.\n            Specifies how many training epochs to run\n            before a new validation run is performed,\n            e.g. `validation_freq=2` runs validation every 2 epochs.\n\n    Returns:\n        (History): A `History` object. Its `History.history` attribute is\n            a record of training reward values and metrics values\n            at successive epochs, as well as validation reward values\n            and validation metrics values (if applicable).\n    \"\"\"\n    self._assert_compile_called(\"fit\")\n    # TODO: respect compiled trainable state\n    self._eval_epoch_iterator = None\n    if validation_split and validation_data is None:\n        # Create the validation data using the training data. Only supported\n        # for numpy arrays.\n        (x, y), validation_data = array_slicing.train_validation_split(\n            (x, y), validation_split=validation_split\n        )\n\n    if validation_data is not None:\n        (val_x, val_y) = data_adapter_utils.unpack_x_y(validation_data)\n    # Create an iterator that yields batches of input/target data.\n    epoch_iterator = EpochIterator(\n        x=x,\n        y=y,\n        batch_size=batch_size,\n        steps_per_epoch=steps_per_epoch,\n        shuffle=False,\n        steps_per_execution=self.steps_per_execution,\n    )\n\n    if not all(module.built for module in self._flatten_modules()):\n        # Build the model on one batch of data.\n        for _, data in epoch_iterator:\n            data_batch = data[0]\n            self._auto_build(\n                iterator=epoch_iterator,\n                data_batch=data_batch,\n            )\n            break\n    epoch_iterator.reset()\n\n    # Container that configures and calls callbacks.\n    if not isinstance(callbacks, callbacks_module.CallbackList):\n        callbacks = callbacks_module.CallbackList(\n            callbacks,\n            add_history=True,\n            add_progbar=verbose != 0,\n            verbose=verbose,\n            epochs=epochs,\n            steps=steps_per_epoch,\n            program=self,\n        )\n\n    self.stop_training = False\n    callbacks.on_train_begin()\n    training_logs = None\n    logs = {}\n    initial_epoch = self._initial_epoch or initial_epoch\n\n    for epoch in range(initial_epoch, epochs):\n        self.reset_metrics()\n        callbacks.on_epoch_begin(epoch)\n        with epoch_iterator.catch_stop_iteration():\n            for step, iterator in epoch_iterator:\n                data = iterator[0]\n                x_batch, y_batch = data_adapter_utils.unpack_x_y(data)\n                callbacks.on_train_batch_begin(step)\n                logs = await self.train_on_batch(\n                    x=x_batch,\n                    y=y_batch,\n                    return_dict=True,\n                )\n                callbacks.on_train_batch_end(step, logs)\n                if self.stop_training:\n                    break\n\n        # Override with model metrics instead of last step logs if needed.\n        epoch_logs = dict(self._get_metrics_result_or_logs(logs))\n\n        # Run validation.\n        if validation_data is not None and self._should_eval(epoch, validation_freq):\n            # Create EpochIterator for evaluation and cache it.\n            if getattr(self, \"_eval_epoch_iterator\", None) is None:\n                self._eval_epoch_iterator = EpochIterator(\n                    x=val_x,\n                    y=val_y,\n                    batch_size=validation_batch_size or batch_size,\n                    steps_per_execution=self.steps_per_execution,\n                    steps_per_epoch=validation_steps,\n                    shuffle=False,\n                )\n            val_logs = await self.evaluate(\n                x=val_x,\n                y=val_y,\n                batch_size=validation_batch_size or batch_size,\n                steps=validation_steps,\n                callbacks=callbacks,\n                _use_cached_eval_dataset=True,\n            )\n            val_logs = {\"val_\" + name: val for name, val in val_logs.items()}\n            epoch_logs.update(val_logs)\n\n        callbacks.on_epoch_end(epoch, epoch_logs)\n        training_logs = epoch_logs\n        if self.stop_training:\n            break\n\n    if isinstance(self.optimizer, optimizers_module.Optimizer) and epochs &gt; 0:\n        await self.optimizer.finalize_variable_values(self.trainable_variables)\n\n    # If _eval_epoch_iterator exists, delete it after all epochs are done.\n    if getattr(self, \"_eval_epoch_iterator\", None) is not None:\n        del self._eval_epoch_iterator\n    callbacks.on_train_end(logs=training_logs)\n    return self.history\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/Program%20training%20API/#synalinks.src.trainers.trainer.Trainer.get_compile_config","title":"<code>get_compile_config()</code>","text":"<p>Returns a serialized config with information for compiling the program.</p> <p>This method returns a config dictionary containing all the information (optimizer, reward, metrics, etc.) with which the program was compiled.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A dict containing information for compiling the program.</p> Source code in <code>synalinks/src/trainers/trainer.py</code> <pre><code>def get_compile_config(self):\n    \"\"\"Returns a serialized config with information for compiling the program.\n\n    This method returns a config dictionary containing all the information\n    (optimizer, reward, metrics, etc.) with which the program was compiled.\n\n    Returns:\n        (dict): A dict containing information for compiling the program.\n    \"\"\"\n    if self.compiled and hasattr(self, \"_compile_config\"):\n        return self._compile_config.serialize()\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/Program%20training%20API/#synalinks.src.trainers.trainer.Trainer.get_metrics_result","title":"<code>get_metrics_result()</code>","text":"<p>Returns the program's metrics values as a dict.</p> <p>If any of the metric result is a dict (containing multiple metrics), each of them gets added to the top level returned dict of this method.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A <code>dict</code> containing values of the metrics listed in <code>self.metrics</code>. Example: <code>{'reward': 0.2, 'accuracy': 0.7}</code>.</p> Source code in <code>synalinks/src/trainers/trainer.py</code> <pre><code>def get_metrics_result(self):\n    \"\"\"Returns the program's metrics values as a dict.\n\n    If any of the metric result is a dict (containing multiple metrics),\n    each of them gets added to the top level returned dict of this method.\n\n    Returns:\n        (dict): A `dict` containing values of the metrics listed in `self.metrics`.\n            Example: `{'reward': 0.2, 'accuracy': 0.7}`.\n    \"\"\"\n    return_metrics = {}\n    for metric in self.metrics:\n        result = metric.result()\n        if isinstance(result, dict):\n            return_metrics.update(result)\n        else:\n            return_metrics[metric.name] = result\n    return python_utils.pythonify_logs(return_metrics)\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/Program%20training%20API/#synalinks.src.trainers.trainer.Trainer.predict","title":"<code>predict(x, batch_size=None, verbose='auto', steps=None, callbacks=None)</code>  <code>async</code>","text":"<p>Generates output predictions for the input samples.</p> <p>Computation is done in batches. This method is designed for batch processing of large numbers of inputs. It is not intended for use inside of loops that iterate over your data and process small numbers of inputs at a time.</p> <p>For small numbers of inputs that fit in one batch, directly use <code>__call__()</code> for faster execution, e.g., <code>program(x)</code>, or <code>program(x, training=False)</code> if you have modules that behave differently during inference.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray | generator</code> <p>Input data. It can be: - A NumPy array (or array-like), or a list of <code>DataModel</code> arrays     (in case the model has multiple inputs). - A list of dict mapping input names to the corresponding <code>DataModel</code>s,     if the program has named inputs. - A Python generator function yielding <code>(inputs, targets)</code>.</p> required <code>batch_size</code> <code>int</code> <p>Integer or <code>None</code>. Number of samples per batch of computation. If unspecified, <code>batch_size</code> will default to 32. Do not specify the <code>batch_size</code> if your input data <code>x</code> is a <code>synalinks.utils.PyDataset</code>, <code>tf.data.Dataset</code>, <code>torch.utils.data.DataLoader</code> or Python generator function since they generate batches.</p> <code>None</code> <code>verbose</code> <code>int</code> <p><code>\"auto\"</code>, 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = single line. <code>\"auto\"</code> becomes 1 for most cases. Note that the progress bar is not particularly useful when logged to a file, so <code>verbose=2</code> is recommended when not running interactively (e.g. in a production environment). Defaults to <code>\"auto\"</code>.</p> <code>'auto'</code> <code>steps</code> <code>int</code> <p>Total number of steps (batches of samples) to draw before declaring the prediction round finished. If <code>steps</code> is <code>None</code>, it will run until <code>x</code> is exhausted. In the case of an infinitely repeating dataset, it will run indefinitely.</p> <code>None</code> <code>callbacks</code> <code>list</code> <p>List of <code>synalinks.callbacks.Callback</code> instances. List of callbacks to apply during prediction.</p> <code>None</code> <p>Returns:</p> Type Description <code>list</code> <p><code>JsonDataModel</code> array(s) of predictions. If the pipeline failed, a None is added to the predictions.</p> Source code in <code>synalinks/src/trainers/trainer.py</code> <pre><code>async def predict(\n    self, x, batch_size=None, verbose=\"auto\", steps=None, callbacks=None\n):\n    \"\"\"Generates output predictions for the input samples.\n\n    Computation is done in batches. This method is designed for batch\n    processing of large numbers of inputs. It is not intended for use inside\n    of loops that iterate over your data and process small numbers of inputs\n    at a time.\n\n    For small numbers of inputs that fit in one batch,\n    directly use `__call__()` for faster execution, e.g.,\n    `program(x)`, or `program(x, training=False)` if you have modules\n    that behave differently during inference.\n\n    Args:\n        x (np.ndarray | generator): Input data. It can be:\n            - A NumPy array (or array-like), or a list of `DataModel` arrays\n                (in case the model has multiple inputs).\n            - A list of dict mapping input names to the corresponding `DataModel`s,\n                if the program has named inputs.\n            - A Python generator function yielding `(inputs, targets)`.\n        batch_size (int): Integer or `None`.\n            Number of samples per batch of computation.\n            If unspecified, `batch_size` will default to 32.\n            Do not specify the `batch_size` if your input data `x` is a\n            `synalinks.utils.PyDataset`, `tf.data.Dataset`,\n            `torch.utils.data.DataLoader` or Python generator function\n            since they generate batches.\n        verbose (int): `\"auto\"`, 0, 1, or 2. Verbosity mode.\n            0 = silent, 1 = progress bar, 2 = single line.\n            `\"auto\"` becomes 1 for most cases. Note that the progress bar\n            is not particularly useful when logged to a file,\n            so `verbose=2` is recommended when not running interactively\n            (e.g. in a production environment). Defaults to `\"auto\"`.\n        steps (int): Total number of steps (batches of samples) to draw before\n            declaring the prediction round finished. If `steps` is `None`,\n            it will run until `x` is exhausted. In the case of an infinitely\n            repeating dataset, it will run indefinitely.\n        callbacks (list): List of `synalinks.callbacks.Callback` instances.\n            List of callbacks to apply during prediction.\n\n    Returns:\n        (list): `JsonDataModel` array(s) of predictions.\n            If the pipeline failed, a None is added to the predictions.\n    \"\"\"\n    # Create an iterator that yields batches of input data.\n    epoch_iterator = EpochIterator(\n        x=x,\n        batch_size=batch_size,\n        steps_per_epoch=steps,\n        shuffle=False,\n        steps_per_execution=self.steps_per_execution,\n    )\n\n    # Container that configures and calls callbacks.\n    if not isinstance(callbacks, callbacks_module.CallbackList):\n        callbacks = callbacks_module.CallbackList(\n            callbacks,\n            add_history=True,\n            add_progbar=verbose != 0,\n            verbose=verbose,\n            epochs=1,\n            steps=epoch_iterator.num_batches,\n            model=self,\n        )\n\n    self.stop_predicting = False\n    callbacks.on_test_begin()\n    outputs = []\n    for step, iterator in epoch_iterator:\n        callbacks.on_predict_batch_begin(step)\n        data = iterator[0]\n        x_batch, _ = data_adapter_utils.unpack_x_y(data)\n        batch_outputs = await self.predict_on_batch(x_batch)\n        outputs.extend(batch_outputs)\n        callbacks.on_predict_batch_end(step, {\"outputs\": batch_outputs})\n        if self.stop_predicting:\n            break\n    callbacks.on_predict_end()\n    return np.array(outputs, dtype=\"object\")\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/Program%20training%20API/#synalinks.src.trainers.trainer.Trainer.predict_on_batch","title":"<code>predict_on_batch(x, training=False)</code>  <code>async</code>","text":"<p>Returns predictions for a single batch of samples.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Input data. Must be array-like.</p> required <code>training</code> <code>bool</code> <p>Boolean. True if training.</p> <code>False</code> <p>Returns:</p> Type Description <code>list</code> <p>list(s) of JsonDataModel predictions.</p> Source code in <code>synalinks/src/trainers/trainer.py</code> <pre><code>async def predict_on_batch(self, x, training=False):\n    \"\"\"Returns predictions for a single batch of samples.\n\n    Args:\n        x (np.ndarray): Input data. Must be array-like.\n        training (bool): Boolean. True if training.\n\n    Returns:\n        (list): list(s) of JsonDataModel predictions.\n    \"\"\"\n    tasks = []\n    for inputs in x:\n        tasks.append(self(inputs, training=training))\n    y_pred = await asyncio.gather(*tasks)\n    return y_pred\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/Program%20training%20API/#synalinks.src.trainers.trainer.Trainer.test_on_batch","title":"<code>test_on_batch(x, y=None, return_dict=False)</code>  <code>async</code>","text":"<p>Test the program on a single batch of samples.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Input data. Must be array-like.</p> required <code>y</code> <code>ndarray</code> <p>Target data. Must be array-like.</p> <code>None</code> <code>return_dict</code> <code>bool</code> <p>If <code>True</code>, reward and metric results are returned as a dict, with each key being the name of the metric. If <code>False</code>, they are returned as a list.</p> <code>False</code> <p>Returns:</p> Type Description <code>float | list | dict</code> <p>A scalar reward value (when no metrics and <code>return_dict=False</code>), a list of reward and metric values (if there are metrics and <code>return_dict=False</code>), or a dict of metric and reward values (if <code>return_dict=True</code>).</p> Source code in <code>synalinks/src/trainers/trainer.py</code> <pre><code>async def test_on_batch(\n    self,\n    x,\n    y=None,\n    return_dict=False,\n):\n    \"\"\"Test the program on a single batch of samples.\n\n    Args:\n        x (np.ndarray): Input data. Must be array-like.\n        y (np.ndarray): Target data. Must be array-like.\n        return_dict (bool): If `True`, reward and metric results are returned as a\n            dict, with each key being the name of the metric. If `False`,\n            they are returned as a list.\n\n    Returns:\n        (float | list | dict): A scalar reward value\n            (when no metrics and `return_dict=False`), a list of reward\n            and metric values (if there are metrics and `return_dict=False`),\n            or a dict of metric and reward values (if `return_dict=True`).\n    \"\"\"\n    y_pred = await self.predict_on_batch(x, training=False)\n\n    reward = await self.compute_reward(\n        x=x,\n        y=y,\n        y_pred=y_pred,\n        training=False,\n    )\n\n    await self._reward_tracker.update_state(reward)\n\n    metrics = await self.compute_metrics(x, y, y_pred)\n\n    if return_dict:\n        return metrics\n    return self._flatten_metrics_in_order(metrics)\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/Program%20training%20API/#synalinks.src.trainers.trainer.Trainer.train_on_batch","title":"<code>train_on_batch(x, y=None, return_dict=False)</code>  <code>async</code>","text":"<p>Runs a single backpropagation/optimization update on a single batch of data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Input data. Must be array-like.</p> required <code>y</code> <code>ndarray</code> <p>Target data. Must be array-like.</p> <code>None</code> <code>return_dict</code> <code>bool</code> <p>If <code>True</code>, reward and metric results are returned as a dict, with each key being the name of the metric. If <code>False</code>, they are returned as a list.</p> <code>False</code> <p>Returns:</p> Type Description <code>float | list | dict</code> <p>A scalar reward value (when no metrics and <code>return_dict=False</code>), a list of reward and metric values (if there are metrics and <code>return_dict=False</code>), or a dict of metric and reward values (if <code>return_dict=True</code>).</p> Source code in <code>synalinks/src/trainers/trainer.py</code> <pre><code>async def train_on_batch(\n    self,\n    x,\n    y=None,\n    return_dict=False,\n):\n    \"\"\"Runs a single backpropagation/optimization update on a single batch of data.\n\n    Args:\n        x (np.ndarray): Input data. Must be array-like.\n        y (np.ndarray): Target data. Must be array-like.\n        return_dict (bool): If `True`, reward and metric results are returned as a\n            dict, with each key being the name of the metric. If `False`,\n            they are returned as a list.\n\n    Returns:\n        (float | list | dict): A scalar reward value\n            (when no metrics and `return_dict=False`), a list of reward\n            and metric values (if there are metrics and `return_dict=False`),\n            or a dict of metric and reward values (if `return_dict=True`).\n    \"\"\"\n    y_pred = await self.predict_on_batch(x, training=True)\n\n    reward = await self.compute_reward(\n        x=x,\n        y=y,\n        y_pred=y_pred,\n        training=True,\n    )\n\n    await self._reward_tracker.update_state(reward)\n\n    # Perform training/optimization\n    if self.trainable_variables:\n        await self.optimizer.apply_optimization(\n            self.trainable_variables,\n            reward=reward,\n        )\n    else:\n        warnings.warn(\"The program does not have any trainable variables.\")\n\n    metrics = await self.compute_metrics(x, y, y_pred)\n\n    if return_dict:\n        return metrics\n    return self._flatten_metrics_in_order(metrics)\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/The%20Program%20class/","title":"The Program class","text":"<p>               Bases: <code>Trainer</code>, <code>Module</code></p> <p>A program grouping modules into an object with training/inference features.</p> <p>There is four ways to instantiate a <code>Program</code>:</p>"},{"location":"Synalinks%20API/Programs%20API/The%20Program%20class/#synalinks.src.programs.program.Program--with-the-functional-api","title":"With the \"Functional API\"","text":"<p>You start from <code>Input</code>, you chain modules calls to specify the program's structure, and finally, you create your program from inputs and outputs:</p> <pre><code>import synalinks\nimport asyncio\n\nclass Query(synalinks.DataModel):\n    query: str = synalinks.Field(\n        description=\"The user query\",\n    )\n\nclass AnswerWithThinking(synalinks.DataModel):\n    thinking: str = synalinks.Field(\n        description=\"Your step by step thinking process\",\n    )\n    answer: float = synalinks.Field(\n        description=\"The correct numerical answer\",\n    )\n\nasync def main():\n\n    language_model = synalinks.LanguageModel(\n        model=\"ollama/mistral\",\n    )\n\n    x0 = synalinks.Input(data_model=Query)\n    x1 = await synalinks.Generator(\n        data_model=AnswerWithThinking,\n        language_model=language_model,\n    )(x0)\n\n    program = synalinks.Program(\n        inputs=x0,\n        outputs=x1,\n        name=\"chain_of_thought\",\n        description=\"Useful to answer in a step by step manner.\",\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>Note: Only dicts, lists, and tuples of input data models are supported. Nested inputs are not supported (e.g. lists of list or dicts of dict).</p>"},{"location":"Synalinks%20API/Programs%20API/The%20Program%20class/#synalinks.src.programs.program.Program--by-subclassing-the-program-class","title":"By subclassing the <code>Program</code> class","text":"<p>In that case, you should define your modules in <code>__init__()</code> and you should implement the program's structure in <code>call()</code> .</p> <pre><code>import synalinks\nimport asyncio\n\nclass Query(synalinks.DataModel):\n    query: str = synalinks.Field(\n        description=\"The user query\",\n    )\n\nclass AnswerWithThinking(synalinks.DataModel):\n    thinking: str = synalinks.Field(\n        description=\"Your step by step thinking process\",\n    )\n    answer: float = synalinks.Field(\n        description=\"The correct numerical answer\",\n    )\n\nclass ChainOfThought(synalinks.Program):\n    \"\"\"Useful to answer in a step by step manner.\n\n    The first line of the docstring is provided as description\n    for the program if not provided in the `super().__init__()`.\n    In a similar way the name is automatically infered based on\n    the class name if not provided.\n    \"\"\"\n\n    def __init__(\n        self,\n        language_model=None,\n        name=None,\n        description=None,\n        trainable=True,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n            trainable=trainable,\n        )\n        self.answer = synalinks.Generator(\n            data_model=AnswerWithThinking,\n            language_model=language_model,\n            name=self.name+\"_generator\",\n        )\n\n    async def call(self, inputs, training=False):\n        if not inputs:\n            return None\n        x = await self.answer(inputs, training=training)\n        return x\n\n    def get_config(self):\n        config = {\n            \"name\": self.name,\n            \"description\": self.description,\n            \"trainable\": self.trainable,\n        }\n        language_model_config =             {\n            \"language_model\": synalinks.saving.serialize_synalinks_object(\n                self.language_model\n            )\n        }\n        return {**config, **language_model_config}\n\n    @classmethod\n    def from_config(cls, config):\n        language_model = synalinks.saving.deserialize_synalinks_object(\n            config.pop(\"language_model\")\n        )\n        return cls(language_model=language_model, **config)\n\nasync def main():\n\n    language_model = synalinks.LanguageModel(\n        model=\"ollama/mistral\",\n    )\n\n    program = ChainOfThought(\n        language_model=language_model,\n    )\n</code></pre> <p>If you subclass <code>Program</code>, you can optionally have a <code>training</code> argument (boolean) in <code>call()</code>, which you can use to specify a different behavior in training and inference.</p> <p>Once the program is created, you can config the program with rewards and metrics with <code>program.compile()</code>, train the program with <code>program.fit()</code>, or use the program to do prediction with <code>program.predict()</code> or <code>program()</code>.</p> <p>To understand the difference between <code>program.predict()</code> or <code>program()</code>, read the FAQ.</p>"},{"location":"Synalinks%20API/Programs%20API/The%20Program%20class/#synalinks.src.programs.program.Program--mixing-the-subclassing-and-the-functional-api","title":"Mixing the subclassing and the <code>Functional</code> API","text":"<p>This way of programming is recommended to encapsulate your application while  providing an easy to use setup. It is the recommended way for most users as  it avoid making your program/agents from scratch. In that case, you should implement only the <code>__init__()</code> and <code>build()</code> methods.</p> <pre><code>import synalinks\nimport asyncio\n\nclass Query(synalinks.DataModel):\n    query: str = synalinks.Field(\n        description=\"The user query\",\n    )\n\nclass AnswerWithThinking(synalinks.DataModel):\n    thinking: str = synalinks.Field(\n        description=\"Your step by step thinking process\",\n    )\n    answer: float = synalinks.Field(\n        description=\"The correct numerical answer\",\n    )\n\nasync def main():\n\n    class ChainOfThought(synalinks.Program):\n        \"\"\"Useful to answer in a step by step manner.\"\"\"\n\n        def __init__(\n            self,\n            language_model=None,\n            name=None,\n            description=None,\n            trainable=True,\n        ):\n            super().__init__(\n                name=name,\n                description=description,\n                trainable=trainable,\n            )\n\n            self.language_model = language_model\n\n        async def build(self, inputs):\n            outputs = await synalinks.Generator(\n                data_model=AnswerWithThinking,\n                language_model=self.language_model,\n            )(inputs)\n\n            # Create your program using the functional API\n            super().__init__(\n                inputs=inputs,\n                outputs=outputs,\n                name=self.name,\n                description=self.description,\n                trainable=self.trainable,\n            )\n\n    language_model = synalinks.LanguageModel(\n        model=\"ollama/mistral\",\n    )\n\n    program = ChainOfThought(\n        language_model=language_model,\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>This allows you to not have to implement the <code>call()</code> and serialization methods (<code>get_config()</code> and <code>from_config()</code>). The program will be built for any inputs  the first time called.</p>"},{"location":"Synalinks%20API/Programs%20API/The%20Program%20class/#synalinks.src.programs.program.Program--with-the-sequential-class","title":"With the <code>Sequential</code> class","text":"<p>In addition, <code>synalinks.Sequential</code> is a special case of program where the program is purely a stack of single-input, single-output modules.</p> <pre><code>import synalinks\nimport asyncio\n\nclass Query(synalinks.DataModel):\n    query: str = synalinks.Field(\n        description=\"The user query\",\n    )\n\nclass AnswerWithThinking(synalinks.DataModel):\n    thinking: str = synalinks.Field(\n        description=\"Your step by step thinking process\",\n    )\n    answer: float = synalinks.Field(\n        description=\"The correct numerical answer\",\n    )\n\nasync def main():\n\n    language_model = synalinks.LanguageModel(model=\"ollama/mistral\")\n\n    program = synalinks.Sequential(\n        [\n            synalinks.Input(\n                data_model=Query,\n            ),\n            synalinks.Generator(\n                data_model=AnswerWithThinking,\n                language_model=language_model,\n            ),\n        ],\n        name=\"chain_of_thought\",\n        description=\"Useful to answer in a step by step manner.\",\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> Source code in <code>synalinks/src/programs/program.py</code> <pre><code>@synalinks_export([\"synalinks.Program\", \"synalinks.programs.Program\"])\nclass Program(Trainer, Module):\n    \"\"\"A program grouping modules into an object with training/inference features.\n\n    There is four ways to instantiate a `Program`:\n\n    ## With the \"Functional API\"\n\n    You start from `Input`, you chain modules calls to specify the program's structure,\n    and finally, you create your program from inputs and outputs:\n\n    ```python\n    import synalinks\n    import asyncio\n\n    class Query(synalinks.DataModel):\n        query: str = synalinks.Field(\n            description=\"The user query\",\n        )\n\n    class AnswerWithThinking(synalinks.DataModel):\n        thinking: str = synalinks.Field(\n            description=\"Your step by step thinking process\",\n        )\n        answer: float = synalinks.Field(\n            description=\"The correct numerical answer\",\n        )\n\n    async def main():\n\n        language_model = synalinks.LanguageModel(\n            model=\"ollama/mistral\",\n        )\n\n        x0 = synalinks.Input(data_model=Query)\n        x1 = await synalinks.Generator(\n            data_model=AnswerWithThinking,\n            language_model=language_model,\n        )(x0)\n\n        program = synalinks.Program(\n            inputs=x0,\n            outputs=x1,\n            name=\"chain_of_thought\",\n            description=\"Useful to answer in a step by step manner.\",\n        )\n\n    if __name__ == \"__main__\":\n        asyncio.run(main())\n    ```\n\n    Note: Only dicts, lists, and tuples of input data models are supported. Nested\n    inputs are not supported (e.g. lists of list or dicts of dict).\n\n    ## By subclassing the `Program` class\n\n    In that case, you should define your\n    modules in `__init__()` and you should implement the program's structure\n    in `call()` .\n\n    ```python\n    import synalinks\n    import asyncio\n\n    class Query(synalinks.DataModel):\n        query: str = synalinks.Field(\n            description=\"The user query\",\n        )\n\n    class AnswerWithThinking(synalinks.DataModel):\n        thinking: str = synalinks.Field(\n            description=\"Your step by step thinking process\",\n        )\n        answer: float = synalinks.Field(\n            description=\"The correct numerical answer\",\n        )\n\n    class ChainOfThought(synalinks.Program):\n        \\\"\\\"\\\"Useful to answer in a step by step manner.\n\n        The first line of the docstring is provided as description\n        for the program if not provided in the `super().__init__()`.\n        In a similar way the name is automatically infered based on\n        the class name if not provided.\n        \\\"\\\"\\\"\n\n        def __init__(\n            self,\n            language_model=None,\n            name=None,\n            description=None,\n            trainable=True,\n        ):\n            super().__init__(\n                name=name,\n                description=description,\n                trainable=trainable,\n            )\n            self.answer = synalinks.Generator(\n                data_model=AnswerWithThinking,\n                language_model=language_model,\n                name=self.name+\"_generator\",\n            )\n\n        async def call(self, inputs, training=False):\n            if not inputs:\n                return None\n            x = await self.answer(inputs, training=training)\n            return x\n\n        def get_config(self):\n            config = {\n                \"name\": self.name,\n                \"description\": self.description,\n                \"trainable\": self.trainable,\n            }\n            language_model_config = \\\n            {\n                \"language_model\": synalinks.saving.serialize_synalinks_object(\n                    self.language_model\n                )\n            }\n            return {**config, **language_model_config}\n\n        @classmethod\n        def from_config(cls, config):\n            language_model = synalinks.saving.deserialize_synalinks_object(\n                config.pop(\"language_model\")\n            )\n            return cls(language_model=language_model, **config)\n\n    async def main():\n\n        language_model = synalinks.LanguageModel(\n            model=\"ollama/mistral\",\n        )\n\n        program = ChainOfThought(\n            language_model=language_model,\n        )\n    ```\n\n    If you subclass `Program`, you can optionally have\n    a `training` argument (boolean) in `call()`, which you can use to specify\n    a different behavior in training and inference.\n\n    Once the program is created, you can config the program with rewards and metrics\n    with `program.compile()`, train the program with `program.fit()`, or use the program\n    to do prediction with `program.predict()` or `program()`.\n\n    To understand the difference between `program.predict()` or `program()`, read the\n    [FAQ](https://synalinks.github.io/synalinks/FAQ/#whats-the-difference-between-program-methods-predict-and-__call__).\n\n    ## Mixing the subclassing and the `Functional` API\n\n    This way of programming is recommended to encapsulate your application while \n    providing an easy to use setup. It is the recommended way for most users as \n    it avoid making your program/agents from scratch.\n    In that case, you should implement only the `__init__()` and `build()` methods.\n\n    ```python\n    import synalinks\n    import asyncio\n\n    class Query(synalinks.DataModel):\n        query: str = synalinks.Field(\n            description=\"The user query\",\n        )\n\n    class AnswerWithThinking(synalinks.DataModel):\n        thinking: str = synalinks.Field(\n            description=\"Your step by step thinking process\",\n        )\n        answer: float = synalinks.Field(\n            description=\"The correct numerical answer\",\n        )\n\n    async def main():\n\n        class ChainOfThought(synalinks.Program):\n            \\\"\\\"\\\"Useful to answer in a step by step manner.\\\"\\\"\\\"\n\n            def __init__(\n                self,\n                language_model=None,\n                name=None,\n                description=None,\n                trainable=True,\n            ):\n                super().__init__(\n                    name=name,\n                    description=description,\n                    trainable=trainable,\n                )\n\n                self.language_model = language_model\n\n            async def build(self, inputs):\n                outputs = await synalinks.Generator(\n                    data_model=AnswerWithThinking,\n                    language_model=self.language_model,\n                )(inputs)\n\n                # Create your program using the functional API\n                super().__init__(\n                    inputs=inputs,\n                    outputs=outputs,\n                    name=self.name,\n                    description=self.description,\n                    trainable=self.trainable,\n                )\n\n        language_model = synalinks.LanguageModel(\n            model=\"ollama/mistral\",\n        )\n\n        program = ChainOfThought(\n            language_model=language_model,\n        )\n\n    if __name__ == \"__main__\":\n        asyncio.run(main())\n    ```\n\n    This allows you to not have to implement the `call()` and serialization methods\n    (`get_config()` and `from_config()`). The program will be built for any inputs \n    the first time called.\n\n    ## With the `Sequential` class\n\n    In addition, `synalinks.Sequential` is a special case of program where\n    the program is purely a stack of single-input, single-output modules.\n\n    ```python\n    import synalinks\n    import asyncio\n\n    class Query(synalinks.DataModel):\n        query: str = synalinks.Field(\n            description=\"The user query\",\n        )\n\n    class AnswerWithThinking(synalinks.DataModel):\n        thinking: str = synalinks.Field(\n            description=\"Your step by step thinking process\",\n        )\n        answer: float = synalinks.Field(\n            description=\"The correct numerical answer\",\n        )\n\n    async def main():\n\n        language_model = synalinks.LanguageModel(model=\"ollama/mistral\")\n\n        program = synalinks.Sequential(\n            [\n                synalinks.Input(\n                    data_model=Query,\n                ),\n                synalinks.Generator(\n                    data_model=AnswerWithThinking,\n                    language_model=language_model,\n                ),\n            ],\n            name=\"chain_of_thought\",\n            description=\"Useful to answer in a step by step manner.\",\n        )\n\n    if __name__ == \"__main__\":\n        asyncio.run(main())\n    ```\n    \"\"\"\n\n    def __new__(cls, *args, **kwargs):\n        # Signature detection for usage of `Program` as a `Functional`\n        if functional_init_arguments(args, kwargs) and cls == Program:\n            from synalinks.src.programs.functional import Functional\n\n            return Functional.__new__(Functional, *args, **kwargs)\n        return typing.cast(cls, super().__new__(cls))\n\n    def __init__(self, *args, **kwargs):\n        Trainer.__init__(self)\n        from synalinks.src.programs import functional\n\n        # Signature detection for usage of a `Program` subclass\n        # as a `Functional` subclass\n        if functional_init_arguments(args, kwargs):\n            inject_functional_program_class(self.__class__)\n            functional.Functional.__init__(self, *args, **kwargs)\n        else:\n            Module.__init__(self, *args, **kwargs)\n\n    async def call(self, *args, **kwargs):\n        raise NotImplementedError(\n            f\"Program {self.__class__.__name__} does not have a `call()` \"\n            \"method implemented.\"\n        )\n\n    @property\n    def modules(self):\n        return list(self._flatten_modules(include_self=False, recursive=False))\n\n    @modules.setter\n    def modules(self, _):\n        raise AttributeError(\n            \"`Program.modules` attribute is reserved and should not be used. \"\n            \"Please use another name.\"\n        )\n\n    def get_module(self, name=None, index=None):\n        \"\"\"Retrieves a module based on either its name (unique) or index.\n\n        If `name` and `index` are both provided, `index` will take precedence.\n        Indices are based on order of horizontal graph traversal (bottom-up).\n\n        Args:\n            name (str): String, name of module.\n            index (int): Integer, index of module.\n\n        Returns:\n            (Module): A module instance.\n        \"\"\"\n        if index is not None and name is not None:\n            raise ValueError(\n                \"Provide only a module name or a module index. Received: \"\n                f\"index={index}, name={name}.\"\n            )\n        if index is not None:\n            if len(self.modules) &lt;= index:\n                raise ValueError(\n                    f\"Was asked to retrieve module at index {index}\"\n                    f\" but program only has {len(self.modules)}\"\n                    \" modules.\"\n                )\n            else:\n                return self.modules[index]\n\n        if name is not None:\n            for module in self.modules:\n                if module.name == name:\n                    return module\n            raise ValueError(\n                f\"No such module: {name}. Existing modules are: \"\n                f\"{list(module.name for module in self.modules)}.\"\n            )\n        raise ValueError(\"Provide either a module name or module index at `get_module`.\")\n\n    def summary(\n        self,\n        line_length=None,\n        positions=None,\n        print_fn=None,\n        expand_nested=False,\n        show_trainable=False,\n        module_range=None,\n    ):\n        \"\"\"Prints a string summary of the program.\n\n        Args:\n            line_length (int): Total length of printed lines\n                (e.g. set this to adapt the display to different\n                terminal window sizes).\n            positions (list): Relative or absolute positions of log elements\n                in each line. If not provided, becomes\n                `[0.3, 0.6, 0.70, 1.]`. Defaults to `None`.\n            print_fn (Callable): Print function to use. By default, prints to `stdout`.\n                If `stdout` doesn't work in your environment, change to `print`.\n                It will be called on each line of the summary.\n                You can set it to a custom function\n                in order to capture the string summary.\n            expand_nested (bool): Whether to expand the nested models.\n                Defaults to `False`.\n            show_trainable (bool): Whether to show if a module is trainable.\n                Defaults to `False`.\n            module_range (list | tuple): a list or tuple of 2 strings,\n                which is the starting module name and ending module name\n                (both inclusive) indicating the range of modules to be printed\n                in summary. It also accepts regex patterns instead of exact\n                names. In this case, the start predicate will be\n                the first element that matches `module_range[0]`\n                and the end predicate will be the last element\n                that matches `module_range[1]`.\n                By default `None` considers all modules of the model.\n\n        Raises:\n            ValueError: if `summary()` is called before the model is built.\n        \"\"\"\n        summary_utils.print_summary(\n            self,\n            line_length=line_length,\n            positions=positions,\n            print_fn=print_fn,\n            expand_nested=expand_nested,\n            show_trainable=show_trainable,\n            module_range=module_range,\n        )\n\n    def save(self, filepath, overwrite=True, **kwargs):\n        \"\"\"Saves a program as a `.json` file.\n\n        Example:\n\n        ```python\n        import synalinks\n\n        class Query(synalinks.DataModel):\n            query: str\n\n        class AnswerWithRationale(synalinks.DataModel):\n            rationale: str\n            answer: str\n\n        language_model = LanguageModel(\"ollama/mistral\")\n\n        program = synalinks.Sequential(\n            [\n                synalinks.Input(data_model=Query),\n                synalinks.Generator(\n                    data_model=AnswerWithRationale,\n                    language_model=language_model,\n                ),\n            ],\n        )\n\n        program.save(\"program.json\")\n        loaded_program = synalinks.programs.program_from_json(\"program.json\")\n        ```\n\n        The saved `.json` file contains:\n\n        - The program's configuration (architecture)\n        - The program's variables\n        - The program's optimizer's state (if any)\n        - The program's reward's state (if any)\n\n        Thus programs can be reinstantiated in the exact same state.\n\n        Args:\n            filepath (str | os.PathLike): `str` or `os.PathLike` object.\n                The path where to save the model. Must end in `.json`.\n            overwrite (bool): Whether we should overwrite any existing program at\n                the target location, or instead ask the user via\n                an interactive prompt. Default to `True`.\n        \"\"\"\n        from synalinks.src.saving import serialization_lib\n\n        filepath = file_utils.path_to_string(filepath)\n        if not filepath.endswith(\".json\"):\n            raise ValueError(\n                f\"The filepath should ends with '.json', received filepath={filepath}\"\n            )\n        program_config = serialization_lib.serialize_synalinks_object(self)\n        variables_config = self.get_state_tree()\n        program_config.update({\"variables\": variables_config})\n        program_config_string = json.dumps(program_config, indent=2)\n        if file_utils.exists(filepath) and not overwrite:\n            io_utils.ask_to_proceed_with_overwrite(filepath)\n        with open(filepath, \"w\") as f:\n            f.write(program_config_string)\n\n    async def build_from_config(self, config):\n        if not config:\n            return\n        status = False\n        if \"input_schema\" in config:\n            # Case: all inputs are in the first arg (possibly nested).\n            if utils.is_default(self.build):\n                status = self._build_by_run_for_single_pos_arg(config[\"input_schema\"])\n            else:\n                try:\n                    await self.build(config[\"input_schema\"])\n                    status = True\n                except:\n                    pass\n            self._build_schemas_dict = config\n\n        elif \"schemas_dict\" in config:\n            # Case: inputs were recorded as multiple keyword arguments.\n            if utils.is_default(self.build):\n                status = self._build_by_run_for_kwargs(config[\"schemas_dict\"])\n            else:\n                try:\n                    await self.build(**config[\"schemas_dict\"])\n                    status = True\n                except:\n                    pass\n            self._build_schemas_dict = config[\"schemas_dict\"]\n\n        if not status:\n            warnings.warn(\n                f\"Program '{self.name}' had a build config, but the program \"\n                \"cannot be built automatically in \"\n                \"`build_from_config(config)`. \"\n                \"You should implement \"\n                \"`def build_from_config(self, config)`, \"\n                \"and you might also want to implement the method \"\n                \" that generates the config at saving time, \"\n                \"`def get_build_config(self)`. \"\n                \"The method `build_from_config()` is meant to \"\n                \"create the state of the model (i.e. its variables) \"\n                \"upon deserialization.\",\n                stacklevel=2,\n            )\n\n    def to_json(self, **kwargs):\n        \"\"\"Returns a JSON string containing the network configuration.\n\n        ```python\n        json_string = program.to_json()\n        ```\n\n        To load a network from a JSON save file, use\n        `synalinks.programs.program_from_json(json_string, custom_objects={...})`.\n\n        Args:\n            **kwargs (keyword arguments): Additional keyword arguments to be passed to\n                `json.dumps()`.\n\n        Returns:\n            (str): A JSON string.\n        \"\"\"\n        from synalinks.src.saving import serialization_lib\n\n        program_config = serialization_lib.serialize_synalinks_object(self)\n        return json.dumps(program_config, **kwargs)\n\n    @classmethod\n    def from_config(cls, config, custom_objects=None):\n        from synalinks.src.programs.functional import Functional\n\n        functional_config_keys = [\n            \"name\",\n            \"modules\",\n            \"input_modules\",\n            \"output_modules\",\n        ]\n        is_functional_config = all(key in config for key in functional_config_keys)\n        argspec = inspect.getfullargspec(cls.__init__)\n        functional_init_args = inspect.getfullargspec(Functional.__init__).args[1:]\n        revivable_as_functional = (\n            cls in {Functional, Program}\n            or argspec.args[1:] == functional_init_args\n            or (argspec.varargs == \"args\" and argspec.varkw == \"kwargs\")\n        )\n        if is_functional_config and revivable_as_functional:\n            # Revive Functional model\n            # (but not Functional subclasses with a custom __init__)\n            from synalinks.src.programs.functional import functional_from_config\n\n            return functional_from_config(cls, config, custom_objects=custom_objects)\n\n        # Either the model has a custom __init__, or the config\n        # does not contain all the information necessary to\n        # revive a Functional model. This happens when the user creates\n        # subclassed models where `get_config()` is returning\n        # insufficient information to be considered a Functional model.\n        # In this case, we fall back to provide all config into the\n        # constructor of the class.\n        try:\n            return cls(**config)\n        except TypeError as e:\n            raise TypeError(\n                \"Unable to revive program from config. When overriding \"\n                \"the `get_config()` method, make sure that the \"\n                \"returned config contains all items used as arguments \"\n                f\"in the  constructor to {cls}, \"\n                \"which is the default behavior. \"\n                \"You can override this default behavior by defining a \"\n                \"`from_config(cls, config)` class method to specify \"\n                \"how to create an \"\n                f\"instance of {cls.__name__} from its config.\\n\\n\"\n                f\"Received config={config}\\n\\n\"\n                f\"Error encountered during deserialization: {e}\"\n            )\n\n    def get_state_tree(self):\n        \"\"\"Retrieves tree-like structure of program variables.\n\n        This method allows retrieval of different program variables (trainable,\n        non-trainable, optimizer, and metrics). The variables are returned in a\n        nested dictionary format, where the keys correspond to the variable\n        names and the values are the nested representations of the variables.\n\n        Example:\n\n        ```python\n        program.compile(\n            optimizer=synalinks.optimizers.RandomFewShot(),\n            reward=synalinks.rewards.ExactMatch(),\n        )\n        program.fit(x=x_train, y=y_train)\n        state_tree = program.get_state_tree()\n        ```\n\n        Returns:\n            (dict): A dictionary containing the nested representations of the\n                requested variables. The keys are the variable names, and the\n                values are the corresponding nested dictionaries.\n        \"\"\"\n        variables = {}\n        variables[\"trainable_variables\"] = self._create_nested_dict(\n            self.trainable_variables\n        )\n        variables[\"non_trainable_variables\"] = self._create_nested_dict(\n            self.non_trainable_variables\n        )\n        if self.optimizer:\n            variables[\"optimizer_variables\"] = self._create_nested_dict(\n                self.optimizer.variables\n            )\n        variables[\"metrics_variables\"] = self._create_nested_dict(self.metrics_variables)\n        return variables\n\n    def _create_nested_dict(self, variables):\n        flat_dict = {}\n        for v in variables:\n            if v.path in flat_dict:\n                raise ValueError(\n                    \"The following variable path is found twice in the program: \"\n                    f\"'{v.path}'. `get_state_tree()` can only be called when \"\n                    \"all variable paths are unique. Make sure to give unique \"\n                    \"names to your modules (and other objects).\"\n                )\n            flat_dict[v.path] = v.get_json()\n\n        nested_dict = {}\n        for path, value in flat_dict.items():\n            parts = path.split(\"/\")\n            current_dict = nested_dict\n            for part in parts[:-1]:\n                if part not in current_dict:\n                    current_dict[part] = {}\n                current_dict = current_dict[part]\n            current_dict[parts[-1]] = value\n\n        return nested_dict\n\n    def set_state_tree(self, state_tree):\n        \"\"\"Assigns values to variables of the program.\n\n        This method takes a dictionary of nested variable values, which\n        represents the state tree of the program, and assigns them to the\n        corresponding variables of the program. The dictionary keys represent the\n        variable names (e.g., `'trainable_variables'`, `'optimizer_variables'`),\n        and the values are nested dictionaries containing the variable\n        paths and their corresponding values.\n\n        Args:\n            state_tree (dict): A dictionary representing the state tree of the program.\n                The keys are the variable names, and the values are nested\n                dictionaries representing the variable paths and their values.\n        \"\"\"\n        for k, v in state_tree.items():\n            path_value_dict = self._flatten_nested_dict(v)\n            if k == \"trainable_variables\":\n                self._assign_variable_values(self.trainable_variables, path_value_dict)\n            elif k == \"non_trainable_variables\":\n                self._assign_variable_values(\n                    self.non_trainable_variables, path_value_dict\n                )\n            elif k == \"optimizer_variables\":\n                if self.optimizer:\n                    self._assign_variable_values(\n                        self.optimizer.variables, path_value_dict\n                    )\n            elif k == \"metrics_variables\":\n                self._assign_variable_values(self.metrics_variables, path_value_dict)\n            else:\n                raise ValueError(f\"Unknown variable name: {k}\")\n\n    def _assign_variable_values(self, variables, path_value_dict):\n        for full_path, value in path_value_dict.items():\n            path_parts = full_path.split(\"/\")\n            field_name = path_parts[-1]\n            parent_path = \"/\".join(path_parts[:-1])\n            for variable in variables:\n                variable_path = remove_numerical_suffix(variable.path)\n                if parent_path == variable_path:\n                    variable.update({field_name: value})\n                    break\n                else:\n                    nested_field_name = parent_path.split(\"/\")[-1]\n                    if parent_path.startswith(variable_path) and variable.get(\n                        nested_field_name, None\n                    ):\n                        variable.get_json()[nested_field_name].update({field_name: value})\n                        break\n\n    def _flatten_nested_dict(self, nested_dict):\n        flat_dict = {}\n\n        def _flatten(current_dict, prefix=\"\"):\n            for key, value in current_dict.items():\n                if isinstance(value, dict):\n                    _flatten(value, prefix + key + \"/\")\n                else:\n                    flat_dict[prefix + key] = value\n\n        _flatten(nested_dict)\n        return flat_dict\n\n    def save_variables(self, filepath, overwrite=True):\n        \"\"\"Saves all module variables to a `.variables.json` file.\n\n        Args:\n            filepath (str | pathlib.Path): `str` or `pathlib.Path` object.\n                Path where to save the program. Must end in `.variables.json`.\n            overwrite (bool): Whether we should overwrite any existing program\n                at the target location, or instead ask the user\n                via an interactive prompt.\n        \"\"\"\n        filepath = file_utils.path_to_string(filepath)\n        if not filepath.endswith(\".variables.json\"):\n            raise ValueError(\n                \"The filepath should ends with '.variables.json', \"\n                f\"received filepath={filepath}\"\n            )\n        config = self.get_state_tree()\n        config_string = json.dumps(config, indent=2)\n        if file_utils.exists(filepath) and not overwrite:\n            io_utils.ask_to_proceed_with_overwrite(filepath)\n        with open(filepath, \"w\") as f:\n            f.write(config_string)\n\n    def load_variables(self, filepath):\n        \"\"\"Load all module variables from a `.variable.json` file.\n\n        Args:\n            filepath (str | pathlib.Path): `str` or `pathlib.Path` object.\n                Path to load the program's variables from.\n                Must end in `.variables.json`.\n        \"\"\"\n        filepath = file_utils.path_to_string(filepath)\n        if not filepath.endswith(\".variables.json\"):\n            raise ValueError(\n                \"The filepath should ends with '.variables.json', \"\n                f\"received filepath={filepath}\"\n            )\n        with open(filepath, \"r\") as f:\n            state_tree_config = json.loads(f.read())\n        self.set_state_tree(state_tree_config)\n\n    @classmethod\n    def load(cls, filepath, custom_objects=None):\n        \"\"\"Load a program from a JSON file.\n\n        Example:\n\n        ```python\n        import synalinks\n\n        loaded_program = synalinks.Program.load(\"program.json\")\n        ```\n\n        Args:\n            filepath (str | pathlib.Path): `str` or `pathlib.Path` object.\n                Path to load the program's variables from.\n                Must end in `.variables.json`.\n            custom_objects (dict): Optional dictionary mapping names\n                (strings) to custom classes or functions to be\n                considered during deserialization.\n\n        Returns:\n            (Program): A Synalinks program instance (uncompiled).\n        \"\"\"\n        filepath = file_utils.path_to_string(filepath)\n        if not filepath.endswith(\".json\"):\n            raise ValueError(\n                f\"The filepath should ends with '.json', received filepath={filepath}\"\n            )\n        with open(filepath, \"r\") as f:\n            json_config = f.read()\n        return program_from_json(json_config, custom_objects=custom_objects)\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/The%20Program%20class/#synalinks.src.programs.program.Program.get_module","title":"<code>get_module(name=None, index=None)</code>","text":"<p>Retrieves a module based on either its name (unique) or index.</p> <p>If <code>name</code> and <code>index</code> are both provided, <code>index</code> will take precedence. Indices are based on order of horizontal graph traversal (bottom-up).</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>String, name of module.</p> <code>None</code> <code>index</code> <code>int</code> <p>Integer, index of module.</p> <code>None</code> <p>Returns:</p> Type Description <code>Module</code> <p>A module instance.</p> Source code in <code>synalinks/src/programs/program.py</code> <pre><code>def get_module(self, name=None, index=None):\n    \"\"\"Retrieves a module based on either its name (unique) or index.\n\n    If `name` and `index` are both provided, `index` will take precedence.\n    Indices are based on order of horizontal graph traversal (bottom-up).\n\n    Args:\n        name (str): String, name of module.\n        index (int): Integer, index of module.\n\n    Returns:\n        (Module): A module instance.\n    \"\"\"\n    if index is not None and name is not None:\n        raise ValueError(\n            \"Provide only a module name or a module index. Received: \"\n            f\"index={index}, name={name}.\"\n        )\n    if index is not None:\n        if len(self.modules) &lt;= index:\n            raise ValueError(\n                f\"Was asked to retrieve module at index {index}\"\n                f\" but program only has {len(self.modules)}\"\n                \" modules.\"\n            )\n        else:\n            return self.modules[index]\n\n    if name is not None:\n        for module in self.modules:\n            if module.name == name:\n                return module\n        raise ValueError(\n            f\"No such module: {name}. Existing modules are: \"\n            f\"{list(module.name for module in self.modules)}.\"\n        )\n    raise ValueError(\"Provide either a module name or module index at `get_module`.\")\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/The%20Program%20class/#synalinks.src.programs.program.Program.get_state_tree","title":"<code>get_state_tree()</code>","text":"<p>Retrieves tree-like structure of program variables.</p> <p>This method allows retrieval of different program variables (trainable, non-trainable, optimizer, and metrics). The variables are returned in a nested dictionary format, where the keys correspond to the variable names and the values are the nested representations of the variables.</p> <p>Example:</p> <pre><code>program.compile(\n    optimizer=synalinks.optimizers.RandomFewShot(),\n    reward=synalinks.rewards.ExactMatch(),\n)\nprogram.fit(x=x_train, y=y_train)\nstate_tree = program.get_state_tree()\n</code></pre> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the nested representations of the requested variables. The keys are the variable names, and the values are the corresponding nested dictionaries.</p> Source code in <code>synalinks/src/programs/program.py</code> <pre><code>def get_state_tree(self):\n    \"\"\"Retrieves tree-like structure of program variables.\n\n    This method allows retrieval of different program variables (trainable,\n    non-trainable, optimizer, and metrics). The variables are returned in a\n    nested dictionary format, where the keys correspond to the variable\n    names and the values are the nested representations of the variables.\n\n    Example:\n\n    ```python\n    program.compile(\n        optimizer=synalinks.optimizers.RandomFewShot(),\n        reward=synalinks.rewards.ExactMatch(),\n    )\n    program.fit(x=x_train, y=y_train)\n    state_tree = program.get_state_tree()\n    ```\n\n    Returns:\n        (dict): A dictionary containing the nested representations of the\n            requested variables. The keys are the variable names, and the\n            values are the corresponding nested dictionaries.\n    \"\"\"\n    variables = {}\n    variables[\"trainable_variables\"] = self._create_nested_dict(\n        self.trainable_variables\n    )\n    variables[\"non_trainable_variables\"] = self._create_nested_dict(\n        self.non_trainable_variables\n    )\n    if self.optimizer:\n        variables[\"optimizer_variables\"] = self._create_nested_dict(\n            self.optimizer.variables\n        )\n    variables[\"metrics_variables\"] = self._create_nested_dict(self.metrics_variables)\n    return variables\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/The%20Program%20class/#synalinks.src.programs.program.Program.load","title":"<code>load(filepath, custom_objects=None)</code>  <code>classmethod</code>","text":"<p>Load a program from a JSON file.</p> <p>Example:</p> <pre><code>import synalinks\n\nloaded_program = synalinks.Program.load(\"program.json\")\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str | Path</code> <p><code>str</code> or <code>pathlib.Path</code> object. Path to load the program's variables from. Must end in <code>.variables.json</code>.</p> required <code>custom_objects</code> <code>dict</code> <p>Optional dictionary mapping names (strings) to custom classes or functions to be considered during deserialization.</p> <code>None</code> <p>Returns:</p> Type Description <code>Program</code> <p>A Synalinks program instance (uncompiled).</p> Source code in <code>synalinks/src/programs/program.py</code> <pre><code>@classmethod\ndef load(cls, filepath, custom_objects=None):\n    \"\"\"Load a program from a JSON file.\n\n    Example:\n\n    ```python\n    import synalinks\n\n    loaded_program = synalinks.Program.load(\"program.json\")\n    ```\n\n    Args:\n        filepath (str | pathlib.Path): `str` or `pathlib.Path` object.\n            Path to load the program's variables from.\n            Must end in `.variables.json`.\n        custom_objects (dict): Optional dictionary mapping names\n            (strings) to custom classes or functions to be\n            considered during deserialization.\n\n    Returns:\n        (Program): A Synalinks program instance (uncompiled).\n    \"\"\"\n    filepath = file_utils.path_to_string(filepath)\n    if not filepath.endswith(\".json\"):\n        raise ValueError(\n            f\"The filepath should ends with '.json', received filepath={filepath}\"\n        )\n    with open(filepath, \"r\") as f:\n        json_config = f.read()\n    return program_from_json(json_config, custom_objects=custom_objects)\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/The%20Program%20class/#synalinks.src.programs.program.Program.load_variables","title":"<code>load_variables(filepath)</code>","text":"<p>Load all module variables from a <code>.variable.json</code> file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str | Path</code> <p><code>str</code> or <code>pathlib.Path</code> object. Path to load the program's variables from. Must end in <code>.variables.json</code>.</p> required Source code in <code>synalinks/src/programs/program.py</code> <pre><code>def load_variables(self, filepath):\n    \"\"\"Load all module variables from a `.variable.json` file.\n\n    Args:\n        filepath (str | pathlib.Path): `str` or `pathlib.Path` object.\n            Path to load the program's variables from.\n            Must end in `.variables.json`.\n    \"\"\"\n    filepath = file_utils.path_to_string(filepath)\n    if not filepath.endswith(\".variables.json\"):\n        raise ValueError(\n            \"The filepath should ends with '.variables.json', \"\n            f\"received filepath={filepath}\"\n        )\n    with open(filepath, \"r\") as f:\n        state_tree_config = json.loads(f.read())\n    self.set_state_tree(state_tree_config)\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/The%20Program%20class/#synalinks.src.programs.program.Program.save","title":"<code>save(filepath, overwrite=True, **kwargs)</code>","text":"<p>Saves a program as a <code>.json</code> file.</p> <p>Example:</p> <pre><code>import synalinks\n\nclass Query(synalinks.DataModel):\n    query: str\n\nclass AnswerWithRationale(synalinks.DataModel):\n    rationale: str\n    answer: str\n\nlanguage_model = LanguageModel(\"ollama/mistral\")\n\nprogram = synalinks.Sequential(\n    [\n        synalinks.Input(data_model=Query),\n        synalinks.Generator(\n            data_model=AnswerWithRationale,\n            language_model=language_model,\n        ),\n    ],\n)\n\nprogram.save(\"program.json\")\nloaded_program = synalinks.programs.program_from_json(\"program.json\")\n</code></pre> <p>The saved <code>.json</code> file contains:</p> <ul> <li>The program's configuration (architecture)</li> <li>The program's variables</li> <li>The program's optimizer's state (if any)</li> <li>The program's reward's state (if any)</li> </ul> <p>Thus programs can be reinstantiated in the exact same state.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str | PathLike</code> <p><code>str</code> or <code>os.PathLike</code> object. The path where to save the model. Must end in <code>.json</code>.</p> required <code>overwrite</code> <code>bool</code> <p>Whether we should overwrite any existing program at the target location, or instead ask the user via an interactive prompt. Default to <code>True</code>.</p> <code>True</code> Source code in <code>synalinks/src/programs/program.py</code> <pre><code>def save(self, filepath, overwrite=True, **kwargs):\n    \"\"\"Saves a program as a `.json` file.\n\n    Example:\n\n    ```python\n    import synalinks\n\n    class Query(synalinks.DataModel):\n        query: str\n\n    class AnswerWithRationale(synalinks.DataModel):\n        rationale: str\n        answer: str\n\n    language_model = LanguageModel(\"ollama/mistral\")\n\n    program = synalinks.Sequential(\n        [\n            synalinks.Input(data_model=Query),\n            synalinks.Generator(\n                data_model=AnswerWithRationale,\n                language_model=language_model,\n            ),\n        ],\n    )\n\n    program.save(\"program.json\")\n    loaded_program = synalinks.programs.program_from_json(\"program.json\")\n    ```\n\n    The saved `.json` file contains:\n\n    - The program's configuration (architecture)\n    - The program's variables\n    - The program's optimizer's state (if any)\n    - The program's reward's state (if any)\n\n    Thus programs can be reinstantiated in the exact same state.\n\n    Args:\n        filepath (str | os.PathLike): `str` or `os.PathLike` object.\n            The path where to save the model. Must end in `.json`.\n        overwrite (bool): Whether we should overwrite any existing program at\n            the target location, or instead ask the user via\n            an interactive prompt. Default to `True`.\n    \"\"\"\n    from synalinks.src.saving import serialization_lib\n\n    filepath = file_utils.path_to_string(filepath)\n    if not filepath.endswith(\".json\"):\n        raise ValueError(\n            f\"The filepath should ends with '.json', received filepath={filepath}\"\n        )\n    program_config = serialization_lib.serialize_synalinks_object(self)\n    variables_config = self.get_state_tree()\n    program_config.update({\"variables\": variables_config})\n    program_config_string = json.dumps(program_config, indent=2)\n    if file_utils.exists(filepath) and not overwrite:\n        io_utils.ask_to_proceed_with_overwrite(filepath)\n    with open(filepath, \"w\") as f:\n        f.write(program_config_string)\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/The%20Program%20class/#synalinks.src.programs.program.Program.save_variables","title":"<code>save_variables(filepath, overwrite=True)</code>","text":"<p>Saves all module variables to a <code>.variables.json</code> file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str | Path</code> <p><code>str</code> or <code>pathlib.Path</code> object. Path where to save the program. Must end in <code>.variables.json</code>.</p> required <code>overwrite</code> <code>bool</code> <p>Whether we should overwrite any existing program at the target location, or instead ask the user via an interactive prompt.</p> <code>True</code> Source code in <code>synalinks/src/programs/program.py</code> <pre><code>def save_variables(self, filepath, overwrite=True):\n    \"\"\"Saves all module variables to a `.variables.json` file.\n\n    Args:\n        filepath (str | pathlib.Path): `str` or `pathlib.Path` object.\n            Path where to save the program. Must end in `.variables.json`.\n        overwrite (bool): Whether we should overwrite any existing program\n            at the target location, or instead ask the user\n            via an interactive prompt.\n    \"\"\"\n    filepath = file_utils.path_to_string(filepath)\n    if not filepath.endswith(\".variables.json\"):\n        raise ValueError(\n            \"The filepath should ends with '.variables.json', \"\n            f\"received filepath={filepath}\"\n        )\n    config = self.get_state_tree()\n    config_string = json.dumps(config, indent=2)\n    if file_utils.exists(filepath) and not overwrite:\n        io_utils.ask_to_proceed_with_overwrite(filepath)\n    with open(filepath, \"w\") as f:\n        f.write(config_string)\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/The%20Program%20class/#synalinks.src.programs.program.Program.set_state_tree","title":"<code>set_state_tree(state_tree)</code>","text":"<p>Assigns values to variables of the program.</p> <p>This method takes a dictionary of nested variable values, which represents the state tree of the program, and assigns them to the corresponding variables of the program. The dictionary keys represent the variable names (e.g., <code>'trainable_variables'</code>, <code>'optimizer_variables'</code>), and the values are nested dictionaries containing the variable paths and their corresponding values.</p> <p>Parameters:</p> Name Type Description Default <code>state_tree</code> <code>dict</code> <p>A dictionary representing the state tree of the program. The keys are the variable names, and the values are nested dictionaries representing the variable paths and their values.</p> required Source code in <code>synalinks/src/programs/program.py</code> <pre><code>def set_state_tree(self, state_tree):\n    \"\"\"Assigns values to variables of the program.\n\n    This method takes a dictionary of nested variable values, which\n    represents the state tree of the program, and assigns them to the\n    corresponding variables of the program. The dictionary keys represent the\n    variable names (e.g., `'trainable_variables'`, `'optimizer_variables'`),\n    and the values are nested dictionaries containing the variable\n    paths and their corresponding values.\n\n    Args:\n        state_tree (dict): A dictionary representing the state tree of the program.\n            The keys are the variable names, and the values are nested\n            dictionaries representing the variable paths and their values.\n    \"\"\"\n    for k, v in state_tree.items():\n        path_value_dict = self._flatten_nested_dict(v)\n        if k == \"trainable_variables\":\n            self._assign_variable_values(self.trainable_variables, path_value_dict)\n        elif k == \"non_trainable_variables\":\n            self._assign_variable_values(\n                self.non_trainable_variables, path_value_dict\n            )\n        elif k == \"optimizer_variables\":\n            if self.optimizer:\n                self._assign_variable_values(\n                    self.optimizer.variables, path_value_dict\n                )\n        elif k == \"metrics_variables\":\n            self._assign_variable_values(self.metrics_variables, path_value_dict)\n        else:\n            raise ValueError(f\"Unknown variable name: {k}\")\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/The%20Program%20class/#synalinks.src.programs.program.Program.summary","title":"<code>summary(line_length=None, positions=None, print_fn=None, expand_nested=False, show_trainable=False, module_range=None)</code>","text":"<p>Prints a string summary of the program.</p> <p>Parameters:</p> Name Type Description Default <code>line_length</code> <code>int</code> <p>Total length of printed lines (e.g. set this to adapt the display to different terminal window sizes).</p> <code>None</code> <code>positions</code> <code>list</code> <p>Relative or absolute positions of log elements in each line. If not provided, becomes <code>[0.3, 0.6, 0.70, 1.]</code>. Defaults to <code>None</code>.</p> <code>None</code> <code>print_fn</code> <code>Callable</code> <p>Print function to use. By default, prints to <code>stdout</code>. If <code>stdout</code> doesn't work in your environment, change to <code>print</code>. It will be called on each line of the summary. You can set it to a custom function in order to capture the string summary.</p> <code>None</code> <code>expand_nested</code> <code>bool</code> <p>Whether to expand the nested models. Defaults to <code>False</code>.</p> <code>False</code> <code>show_trainable</code> <code>bool</code> <p>Whether to show if a module is trainable. Defaults to <code>False</code>.</p> <code>False</code> <code>module_range</code> <code>list | tuple</code> <p>a list or tuple of 2 strings, which is the starting module name and ending module name (both inclusive) indicating the range of modules to be printed in summary. It also accepts regex patterns instead of exact names. In this case, the start predicate will be the first element that matches <code>module_range[0]</code> and the end predicate will be the last element that matches <code>module_range[1]</code>. By default <code>None</code> considers all modules of the model.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>summary()</code> is called before the model is built.</p> Source code in <code>synalinks/src/programs/program.py</code> <pre><code>def summary(\n    self,\n    line_length=None,\n    positions=None,\n    print_fn=None,\n    expand_nested=False,\n    show_trainable=False,\n    module_range=None,\n):\n    \"\"\"Prints a string summary of the program.\n\n    Args:\n        line_length (int): Total length of printed lines\n            (e.g. set this to adapt the display to different\n            terminal window sizes).\n        positions (list): Relative or absolute positions of log elements\n            in each line. If not provided, becomes\n            `[0.3, 0.6, 0.70, 1.]`. Defaults to `None`.\n        print_fn (Callable): Print function to use. By default, prints to `stdout`.\n            If `stdout` doesn't work in your environment, change to `print`.\n            It will be called on each line of the summary.\n            You can set it to a custom function\n            in order to capture the string summary.\n        expand_nested (bool): Whether to expand the nested models.\n            Defaults to `False`.\n        show_trainable (bool): Whether to show if a module is trainable.\n            Defaults to `False`.\n        module_range (list | tuple): a list or tuple of 2 strings,\n            which is the starting module name and ending module name\n            (both inclusive) indicating the range of modules to be printed\n            in summary. It also accepts regex patterns instead of exact\n            names. In this case, the start predicate will be\n            the first element that matches `module_range[0]`\n            and the end predicate will be the last element\n            that matches `module_range[1]`.\n            By default `None` considers all modules of the model.\n\n    Raises:\n        ValueError: if `summary()` is called before the model is built.\n    \"\"\"\n    summary_utils.print_summary(\n        self,\n        line_length=line_length,\n        positions=positions,\n        print_fn=print_fn,\n        expand_nested=expand_nested,\n        show_trainable=show_trainable,\n        module_range=module_range,\n    )\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/The%20Program%20class/#synalinks.src.programs.program.Program.to_json","title":"<code>to_json(**kwargs)</code>","text":"<p>Returns a JSON string containing the network configuration.</p> <pre><code>json_string = program.to_json()\n</code></pre> <p>To load a network from a JSON save file, use <code>synalinks.programs.program_from_json(json_string, custom_objects={...})</code>.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>keyword arguments</code> <p>Additional keyword arguments to be passed to <code>json.dumps()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>str</code> <p>A JSON string.</p> Source code in <code>synalinks/src/programs/program.py</code> <pre><code>def to_json(self, **kwargs):\n    \"\"\"Returns a JSON string containing the network configuration.\n\n    ```python\n    json_string = program.to_json()\n    ```\n\n    To load a network from a JSON save file, use\n    `synalinks.programs.program_from_json(json_string, custom_objects={...})`.\n\n    Args:\n        **kwargs (keyword arguments): Additional keyword arguments to be passed to\n            `json.dumps()`.\n\n    Returns:\n        (str): A JSON string.\n    \"\"\"\n    from synalinks.src.saving import serialization_lib\n\n    program_config = serialization_lib.serialize_synalinks_object(self)\n    return json.dumps(program_config, **kwargs)\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/The%20Sequential%20class/","title":"The Sequential class","text":"<p>               Bases: <code>Program</code></p> <p><code>Sequential</code> groups a linear stack of modules into a <code>Program</code>.</p> <p>Examples:</p> <pre><code>program = synalinks.Sequential(\n    name=\"chain_of_thought\",\n    description=\"Useful to answer in a step by step manner.\"\n)\nprogram.add(\n    synalinks.Input(\n            data_program=Query,\n        )\n)\nprogram.add(\n    synalinks.Generator(\n        data_program=AnswerWithRationale,\n        language_program=language_program,\n    )\n)\n\n# Note that you can also omit the initial `Input`.\n# In that case the program doesn't have any variables until the first call\n# to a training/evaluation method (since it isn't yet built):\n\nprogram = synalinks.Sequential(\n    name=\"chain_of_thought\",\n    description=\"Useful to answer in a step by step manner.\"\n)\nprogram.add(\n    synalinks.Generator(\n        data_program=AnswerWithRationale,\n        language_program=language_program,\n    )\n)\n# program.variables not created yet\n\n# Whereas if you specify an `Input`, the program gets built\n# continuously as you are adding modules:\n\nprogram = synalinks.Sequential(\n    name=\"chain_of_thought\",\n    description=\"Useful to answer in a step by step manner.\"\n)\nprogram.add(\n    synalinks.Input(\n        data_program=Query,\n    )\n)\nprogram.add(\n    synalinks.Generator(\n        data_program=AnswerWithRationale,\n        language_program=language_program,\n    )\n)\n\n# Note that when using the delayed-build pattern (no input specified),\n# the program gets built the first time you call `fit`, `eval`, or `predict`,\n# or the first time you call the program on some input data.\n</code></pre> Source code in <code>synalinks/src/programs/sequential.py</code> <pre><code>@synalinks_export([\"synalinks.Sequential\", \"synalinks.programs.Sequential\"])\nclass Sequential(Program):\n    \"\"\"`Sequential` groups a linear stack of modules into a `Program`.\n\n    Examples:\n\n    ```python\n    program = synalinks.Sequential(\n        name=\"chain_of_thought\",\n        description=\"Useful to answer in a step by step manner.\"\n    )\n    program.add(\n        synalinks.Input(\n                data_program=Query,\n            )\n    )\n    program.add(\n        synalinks.Generator(\n            data_program=AnswerWithRationale,\n            language_program=language_program,\n        )\n    )\n\n    # Note that you can also omit the initial `Input`.\n    # In that case the program doesn't have any variables until the first call\n    # to a training/evaluation method (since it isn't yet built):\n\n    program = synalinks.Sequential(\n        name=\"chain_of_thought\",\n        description=\"Useful to answer in a step by step manner.\"\n    )\n    program.add(\n        synalinks.Generator(\n            data_program=AnswerWithRationale,\n            language_program=language_program,\n        )\n    )\n    # program.variables not created yet\n\n    # Whereas if you specify an `Input`, the program gets built\n    # continuously as you are adding modules:\n\n    program = synalinks.Sequential(\n        name=\"chain_of_thought\",\n        description=\"Useful to answer in a step by step manner.\"\n    )\n    program.add(\n        synalinks.Input(\n            data_program=Query,\n        )\n    )\n    program.add(\n        synalinks.Generator(\n            data_program=AnswerWithRationale,\n            language_program=language_program,\n        )\n    )\n\n    # Note that when using the delayed-build pattern (no input specified),\n    # the program gets built the first time you call `fit`, `eval`, or `predict`,\n    # or the first time you call the program on some input data.\n\n    ```\n    \"\"\"\n\n    def __new__(cls, *args, **kwargs):\n        return typing.cast(cls, super().__new__(cls))\n\n    def __init__(self, modules=None, trainable=True, name=None, description=None):\n        if description is None:\n            raise ValueError(\n                \"All Sequential programs must have a `description`, \"\n                \"please add it to the constructor arguments\"\n            )\n        super().__init__(trainable=trainable, name=name, description=description)\n        self._functional = None\n        self._modules = []\n        if modules:\n            for module in modules:\n                self.add(module, rebuild=False)\n            asyncio.get_event_loop().run_until_complete(self._maybe_rebuild())\n\n    def add(self, module, rebuild=True):\n        \"\"\"Adds a module instance on top of the module stack.\n\n        Args:\n            module (Module): Module instance.\n            rebuild (bool): If `True` rebuild the program.\n        \"\"\"\n        # If we are passed a SymbolicDataModel created by synalinks.Input(), we\n        # extract the input module from its synalinks history and use that.\n        if hasattr(module, \"_synalinks_history\"):\n            origin_module = module._synalinks_history[0]\n            if isinstance(origin_module, InputModule):\n                module = origin_module\n        if not isinstance(module, Module):\n            raise ValueError(\n                \"Only instances of `synalinks.Module` can be \"\n                f\"added to a Sequential program. Received: {module} \"\n                f\"(of type {type(module)})\"\n            )\n        if not self._is_module_name_unique(module):\n            raise ValueError(\n                \"All modules added to a Sequential program \"\n                f\"should have unique names. Name '{module.name}' is already \"\n                \"the name of a module in this program. Update the `name` argument \"\n                \"to pass a unique name.\"\n            )\n        if (\n            isinstance(module, InputModule)\n            and self._modules\n            and isinstance(self._modules[0], InputModule)\n        ):\n            raise ValueError(\n                f\"Sequential program '{self.name}' has already been configured \"\n                f\"to use input schema {self._modules[0].input_schema}. You cannot \"\n                f\"add a different Input module to it.\"\n            )\n\n        self._modules.append(module)\n        if rebuild:\n            asyncio.get_event_loop().run_until_complete(self._maybe_rebuild())\n        else:\n            self.built = False\n            self._functional = None\n\n    def pop(self, rebuild=True):\n        \"\"\"Removes the last module in the program.\n\n        Args:\n            rebuild (bool): If `True` rebuild the program.\n        \"\"\"\n        module = self._modules.pop()\n        self.built = False\n        self._functional = None\n        if rebuild:\n            asyncio.get_event_loop().run_until_complete(self._maybe_rebuild())\n        return module\n\n    async def _maybe_rebuild(self):\n        self.built = False\n        self._functional = None\n        if isinstance(self._modules[0], InputModule) and len(self._modules) &gt; 1:\n            input_schema = self._modules[0].get_schema()\n            await self.build(Input(schema=input_schema))\n        elif hasattr(self._modules[0], \"input_schema\") and len(self._modules) &gt; 1:\n            # We can build the Sequential program if the first module has the\n            # `input_schema` property. This is most commonly found in Functional\n            # program.\n            input_schema = self._modules[0].input_schema\n            await self.build(Input(schema=input_schema))\n\n    def _lock_state(self):\n        # Unlike other modules, Sequential is mutable after build.\n        pass\n\n    def _obj_type(self):\n        return \"Sequential\"\n\n    async def build(self, inputs):\n        try:\n            input_schema = standardize_schema(inputs.get_schema())\n        except Exception:\n            # Do not attempt to build if the program does not have a single\n            # input.\n            return\n        if not self._modules:\n            raise ValueError(\n                f\"Sequential program {self.name} cannot be built because it has \"\n                \"no modules. Call `program.add(module)`.\"\n            )\n        if isinstance(self._modules[0], InputModule):\n            if self._modules[0].get_schema() != input_schema:\n                raise ValueError(\n                    f\"Sequential program '{self.name}' has already been \"\n                    \"configured to use input schema \"\n                    f\"{self._modules[0].get_schema()}. You cannot build it \"\n                    f\"with input_schema {input_schema}\"\n                )\n        else:\n            self._modules = [InputModule(schema=input_schema)] + self._modules\n\n        # Build functional program\n        inputs = self._modules[0].output\n        x = inputs\n        for module in self._modules[1:]:\n            try:\n                x = await module(x)\n            except NotImplementedError:\n                # Can happen if spec inference is not implemented.\n                # TODO: consider reverting inbound nodes on modules processed.\n                return\n            except TypeError as e:\n                signature = inspect.signature(module.call)\n                positional_args = [\n                    param\n                    for param in signature.parameters.values()\n                    if param.default == inspect.Parameter.empty\n                ]\n                if len(positional_args) != 1:\n                    raise ValueError(\n                        \"Modules added to a Sequential program \"\n                        \"can only have a single positional argument, \"\n                        f\"the input data model. Module {module.__class__.__name__} \"\n                        f\"has multiple positional arguments: {positional_args}\"\n                    )\n                raise e\n        outputs = x\n        self._functional = Functional(inputs=inputs, outputs=outputs)\n        self.built = True\n\n    async def call(self, inputs, training=None):\n        if self._functional:\n            return await self._functional.call(inputs, training=training)\n        # Fallback: Just apply the module sequence.\n        # This typically happens if `inputs` is a nested struct.\n        for module in self.modules:\n            # During each iteration, `inputs` are the inputs to `module`, and\n            # `outputs` are the outputs of `module` applied to `inputs`. At the\n            # end of each iteration `inputs` is set to `outputs` to prepare for\n            # the next module.\n            kwargs = {}\n            if module._call_has_training_arg and training is not None:\n                kwargs[\"training\"] = training\n            outputs = await module(inputs, **kwargs)\n            inputs = outputs\n        return outputs\n\n    @property\n    def modules(self):\n        \"\"\"Unlike Keras, also output the potentially auto-generated `InputModule`\"\"\"\n        return self._modules\n\n    @modules.setter\n    def modules(self, _):\n        raise AttributeError(\n            \"`Sequential.modules` attribute is reserved and should not be used. \"\n            \"Use `add()` and `pop()` to change the modules in this program.\"\n        )\n\n    async def compute_output_spec(self, inputs, training=None):\n        if self._functional:\n            return await self._functional.compute_output_spec(\n                inputs,\n                training=training,\n            )\n        # Direct application\n        for module in self.modules:\n            outputs = await module.compute_output_spec(inputs, training=training)\n            inputs = outputs\n        return outputs\n\n    @property\n    def input_schema(self):\n        if self._functional:\n            return self._functional.input_schema\n        raise AttributeError(\n            f\"Sequential program '{self.name}' has no defined input schema yet.\"\n        )\n\n    @property\n    def output_schema(self):\n        if self._functional:\n            return self._functional.output_schema\n        raise AttributeError(\n            f\"Sequential program '{self.name}' has no defined output schema yet.\"\n        )\n\n    @property\n    def inputs(self):\n        if self._functional:\n            return self._functional.inputs\n        raise AttributeError(\n            f\"Sequential program '{self.name}' has no defined inputs yet.\"\n        )\n\n    @property\n    def outputs(self):\n        if self._functional:\n            return self._functional.outputs\n        raise AttributeError(\n            f\"Sequential program '{self.name}' has no defined outputs yet.\"\n        )\n\n    def _is_module_name_unique(self, module):\n        for ref_module in self._modules:\n            if module.name == ref_module.name and ref_module is not module:\n                return False\n        return True\n\n    def get_config(self):\n        serialize_fn = serialization_lib.serialize_synalinks_object\n        module_configs = []\n        for module in self.modules:\n            module_configs.append(serialize_fn(module))\n        config = Program.get_config(self)\n        config[\"name\"] = self.name\n        config[\"description\"] = self.description\n        config[\"modules\"] = copy.deepcopy(module_configs)\n        if self._functional is not None:\n            config[\"build_input_schema\"] = self._modules[0].input_schema\n        return config\n\n    @classmethod\n    def from_config(cls, config, custom_objects=None):\n        if \"name\" in config:\n            name = config[\"name\"]\n            build_input_schema = config.get(\"build_input_schema\")\n            module_configs = config[\"modules\"]\n        else:\n            name = None\n            module_configs = config\n        if \"description\" in config:\n            description = config[\"description\"]\n        else:\n            description = None\n        program = cls(name=name, description=description)\n        for module_config in module_configs:\n            module = serialization_lib.deserialize_synalinks_object(\n                module_config,\n                custom_objects=custom_objects,\n            )\n            program.add(module)\n        if (\n            not program._functional\n            and \"build_input_schema\" in locals()\n            and build_input_schema\n            and isinstance(build_input_schema, (tuple, list))\n        ):\n            program.build(build_input_schema)\n        return program\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/The%20Sequential%20class/#synalinks.src.programs.sequential.Sequential.modules","title":"<code>modules</code>  <code>property</code> <code>writable</code>","text":"<p>Unlike Keras, also output the potentially auto-generated <code>InputModule</code></p>"},{"location":"Synalinks%20API/Programs%20API/The%20Sequential%20class/#synalinks.src.programs.sequential.Sequential.add","title":"<code>add(module, rebuild=True)</code>","text":"<p>Adds a module instance on top of the module stack.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>Module</code> <p>Module instance.</p> required <code>rebuild</code> <code>bool</code> <p>If <code>True</code> rebuild the program.</p> <code>True</code> Source code in <code>synalinks/src/programs/sequential.py</code> <pre><code>def add(self, module, rebuild=True):\n    \"\"\"Adds a module instance on top of the module stack.\n\n    Args:\n        module (Module): Module instance.\n        rebuild (bool): If `True` rebuild the program.\n    \"\"\"\n    # If we are passed a SymbolicDataModel created by synalinks.Input(), we\n    # extract the input module from its synalinks history and use that.\n    if hasattr(module, \"_synalinks_history\"):\n        origin_module = module._synalinks_history[0]\n        if isinstance(origin_module, InputModule):\n            module = origin_module\n    if not isinstance(module, Module):\n        raise ValueError(\n            \"Only instances of `synalinks.Module` can be \"\n            f\"added to a Sequential program. Received: {module} \"\n            f\"(of type {type(module)})\"\n        )\n    if not self._is_module_name_unique(module):\n        raise ValueError(\n            \"All modules added to a Sequential program \"\n            f\"should have unique names. Name '{module.name}' is already \"\n            \"the name of a module in this program. Update the `name` argument \"\n            \"to pass a unique name.\"\n        )\n    if (\n        isinstance(module, InputModule)\n        and self._modules\n        and isinstance(self._modules[0], InputModule)\n    ):\n        raise ValueError(\n            f\"Sequential program '{self.name}' has already been configured \"\n            f\"to use input schema {self._modules[0].input_schema}. You cannot \"\n            f\"add a different Input module to it.\"\n        )\n\n    self._modules.append(module)\n    if rebuild:\n        asyncio.get_event_loop().run_until_complete(self._maybe_rebuild())\n    else:\n        self.built = False\n        self._functional = None\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/The%20Sequential%20class/#synalinks.src.programs.sequential.Sequential.pop","title":"<code>pop(rebuild=True)</code>","text":"<p>Removes the last module in the program.</p> <p>Parameters:</p> Name Type Description Default <code>rebuild</code> <code>bool</code> <p>If <code>True</code> rebuild the program.</p> <code>True</code> Source code in <code>synalinks/src/programs/sequential.py</code> <pre><code>def pop(self, rebuild=True):\n    \"\"\"Removes the last module in the program.\n\n    Args:\n        rebuild (bool): If `True` rebuild the program.\n    \"\"\"\n    module = self._modules.pop()\n    self.built = False\n    self._functional = None\n    if rebuild:\n        asyncio.get_event_loop().run_until_complete(self._maybe_rebuild())\n    return module\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/Program%20Saving%20API/Program%20saving%20and%20loading/","title":"Program saving and loading","text":""},{"location":"Synalinks%20API/Programs%20API/Program%20Saving%20API/Program%20saving%20and%20loading/#saving-programs-into-a-json-file","title":"Saving programs into a JSON file","text":"<p>Saves a program as a <code>.json</code> file.</p> <p>Example:</p> <pre><code>import synalinks\n\nclass Query(synalinks.DataModel):\n    query: str\n\nclass AnswerWithRationale(synalinks.DataModel):\n    rationale: str\n    answer: str\n\nlanguage_model = LanguageModel(\"ollama/mistral\")\n\nprogram = synalinks.Sequential(\n    [\n        synalinks.Input(data_model=Query),\n        synalinks.Generator(\n            data_model=AnswerWithRationale,\n            language_model=language_model,\n        ),\n    ],\n)\n\nprogram.save(\"program.json\")\nloaded_program = synalinks.programs.program_from_json(\"program.json\")\n</code></pre> <p>The saved <code>.json</code> file contains:</p> <ul> <li>The program's configuration (architecture)</li> <li>The program's variables</li> <li>The program's optimizer's state (if any)</li> <li>The program's reward's state (if any)</li> </ul> <p>Thus programs can be reinstantiated in the exact same state.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str | PathLike</code> <p><code>str</code> or <code>os.PathLike</code> object. The path where to save the model. Must end in <code>.json</code>.</p> required <code>overwrite</code> <code>bool</code> <p>Whether we should overwrite any existing program at the target location, or instead ask the user via an interactive prompt. Default to <code>True</code>.</p> <code>True</code> Source code in <code>synalinks/src/programs/program.py</code> <pre><code>def save(self, filepath, overwrite=True, **kwargs):\n    \"\"\"Saves a program as a `.json` file.\n\n    Example:\n\n    ```python\n    import synalinks\n\n    class Query(synalinks.DataModel):\n        query: str\n\n    class AnswerWithRationale(synalinks.DataModel):\n        rationale: str\n        answer: str\n\n    language_model = LanguageModel(\"ollama/mistral\")\n\n    program = synalinks.Sequential(\n        [\n            synalinks.Input(data_model=Query),\n            synalinks.Generator(\n                data_model=AnswerWithRationale,\n                language_model=language_model,\n            ),\n        ],\n    )\n\n    program.save(\"program.json\")\n    loaded_program = synalinks.programs.program_from_json(\"program.json\")\n    ```\n\n    The saved `.json` file contains:\n\n    - The program's configuration (architecture)\n    - The program's variables\n    - The program's optimizer's state (if any)\n    - The program's reward's state (if any)\n\n    Thus programs can be reinstantiated in the exact same state.\n\n    Args:\n        filepath (str | os.PathLike): `str` or `os.PathLike` object.\n            The path where to save the model. Must end in `.json`.\n        overwrite (bool): Whether we should overwrite any existing program at\n            the target location, or instead ask the user via\n            an interactive prompt. Default to `True`.\n    \"\"\"\n    from synalinks.src.saving import serialization_lib\n\n    filepath = file_utils.path_to_string(filepath)\n    if not filepath.endswith(\".json\"):\n        raise ValueError(\n            f\"The filepath should ends with '.json', received filepath={filepath}\"\n        )\n    program_config = serialization_lib.serialize_synalinks_object(self)\n    variables_config = self.get_state_tree()\n    program_config.update({\"variables\": variables_config})\n    program_config_string = json.dumps(program_config, indent=2)\n    if file_utils.exists(filepath) and not overwrite:\n        io_utils.ask_to_proceed_with_overwrite(filepath)\n    with open(filepath, \"w\") as f:\n        f.write(program_config_string)\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/Program%20Saving%20API/Program%20saving%20and%20loading/#saving-programs-into-a-json-string","title":"Saving programs into a JSON string","text":"<p>Returns a JSON string containing the network configuration.</p> <pre><code>json_string = program.to_json()\n</code></pre> <p>To load a network from a JSON save file, use <code>synalinks.programs.program_from_json(json_string, custom_objects={...})</code>.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>keyword arguments</code> <p>Additional keyword arguments to be passed to <code>json.dumps()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>str</code> <p>A JSON string.</p> Source code in <code>synalinks/src/programs/program.py</code> <pre><code>def to_json(self, **kwargs):\n    \"\"\"Returns a JSON string containing the network configuration.\n\n    ```python\n    json_string = program.to_json()\n    ```\n\n    To load a network from a JSON save file, use\n    `synalinks.programs.program_from_json(json_string, custom_objects={...})`.\n\n    Args:\n        **kwargs (keyword arguments): Additional keyword arguments to be passed to\n            `json.dumps()`.\n\n    Returns:\n        (str): A JSON string.\n    \"\"\"\n    from synalinks.src.saving import serialization_lib\n\n    program_config = serialization_lib.serialize_synalinks_object(self)\n    return json.dumps(program_config, **kwargs)\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/Program%20Saving%20API/Program%20saving%20and%20loading/#loading-programs-from-a-json-file","title":"Loading programs from a JSON file","text":"<p>Load a program from a JSON file.</p> <p>Example:</p> <pre><code>import synalinks\n\nloaded_program = synalinks.Program.load(\"program.json\")\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str | Path</code> <p><code>str</code> or <code>pathlib.Path</code> object. Path to load the program's variables from. Must end in <code>.variables.json</code>.</p> required <code>custom_objects</code> <code>dict</code> <p>Optional dictionary mapping names (strings) to custom classes or functions to be considered during deserialization.</p> <code>None</code> <p>Returns:</p> Type Description <code>Program</code> <p>A Synalinks program instance (uncompiled).</p> Source code in <code>synalinks/src/programs/program.py</code> <pre><code>@classmethod\ndef load(cls, filepath, custom_objects=None):\n    \"\"\"Load a program from a JSON file.\n\n    Example:\n\n    ```python\n    import synalinks\n\n    loaded_program = synalinks.Program.load(\"program.json\")\n    ```\n\n    Args:\n        filepath (str | pathlib.Path): `str` or `pathlib.Path` object.\n            Path to load the program's variables from.\n            Must end in `.variables.json`.\n        custom_objects (dict): Optional dictionary mapping names\n            (strings) to custom classes or functions to be\n            considered during deserialization.\n\n    Returns:\n        (Program): A Synalinks program instance (uncompiled).\n    \"\"\"\n    filepath = file_utils.path_to_string(filepath)\n    if not filepath.endswith(\".json\"):\n        raise ValueError(\n            f\"The filepath should ends with '.json', received filepath={filepath}\"\n        )\n    with open(filepath, \"r\") as f:\n        json_config = f.read()\n    return program_from_json(json_config, custom_objects=custom_objects)\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/Program%20Saving%20API/Program%20saving%20and%20loading/#loading-a-program-from-a-json-string","title":"Loading a program from a JSON string","text":"<p>Parses a JSON program configuration string and returns a program instance.</p> <p>Example:</p> <pre><code>import synalinks\n\nclass Query(synalinks.DataModel):\n    query: str\n\nclass AnswerWithRationale(synalinks.DataModel):\n    rationale: str\n    answer: str\n\nlanguage_model = LanguageModel(\"ollama/mistral\")\n\nprogram = synalinks.Sequential(\n    [\n        synalinks.Input(data_model=Query),\n        synalinks.Generator(\n            data_model=AnswerWithRationale,\n            language_model=language_model,\n        ),\n    ],\n)\n\nconfig = program.to_json()\nloaded_program = synalinks.programs.program_from_json(config)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>JSON string encoding a program configuration.</p> required <code>custom_objects</code> <code>dict</code> <p>Optional dictionary mapping names (strings) to custom classes or functions to be considered during deserialization.</p> <code>None</code> <p>Returns:</p> Type Description <code>Program</code> <p>A Synalinks program instance (uncompiled).</p> Source code in <code>synalinks/src/programs/program.py</code> <pre><code>@synalinks_export(\"synalinks.programs.program_from_json\")\ndef program_from_json(json_string, custom_objects=None):\n    \"\"\"Parses a JSON program configuration string and returns a program instance.\n\n    Example:\n\n    ```python\n    import synalinks\n\n    class Query(synalinks.DataModel):\n        query: str\n\n    class AnswerWithRationale(synalinks.DataModel):\n        rationale: str\n        answer: str\n\n    language_model = LanguageModel(\"ollama/mistral\")\n\n    program = synalinks.Sequential(\n        [\n            synalinks.Input(data_model=Query),\n            synalinks.Generator(\n                data_model=AnswerWithRationale,\n                language_model=language_model,\n            ),\n        ],\n    )\n\n    config = program.to_json()\n    loaded_program = synalinks.programs.program_from_json(config)\n    ```\n\n    Args:\n        json_string (str): JSON string encoding a program configuration.\n        custom_objects (dict): Optional dictionary mapping names\n            (strings) to custom classes or functions to be\n            considered during deserialization.\n\n    Returns:\n        (Program): A Synalinks program instance (uncompiled).\n    \"\"\"\n    from synalinks.src.saving import serialization_lib\n\n    program_config = json.loads(json_string)\n    variables_config = program_config.get(\"variables\")\n    program = serialization_lib.deserialize_synalinks_object(\n        program_config, custom_objects=custom_objects\n    )\n    program.set_state_tree(variables_config)\n    return program\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/Program%20Saving%20API/Variable%20saving%20and%20loading/","title":"Variable saving and loading","text":""},{"location":"Synalinks%20API/Programs%20API/Program%20Saving%20API/Variable%20saving%20and%20loading/#saving-variables-into-a-json-file","title":"Saving variables into a JSON file","text":"<p>Saves all module variables to a <code>.variables.json</code> file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str | Path</code> <p><code>str</code> or <code>pathlib.Path</code> object. Path where to save the program. Must end in <code>.variables.json</code>.</p> required <code>overwrite</code> <code>bool</code> <p>Whether we should overwrite any existing program at the target location, or instead ask the user via an interactive prompt.</p> <code>True</code> Source code in <code>synalinks/src/programs/program.py</code> <pre><code>def save_variables(self, filepath, overwrite=True):\n    \"\"\"Saves all module variables to a `.variables.json` file.\n\n    Args:\n        filepath (str | pathlib.Path): `str` or `pathlib.Path` object.\n            Path where to save the program. Must end in `.variables.json`.\n        overwrite (bool): Whether we should overwrite any existing program\n            at the target location, or instead ask the user\n            via an interactive prompt.\n    \"\"\"\n    filepath = file_utils.path_to_string(filepath)\n    if not filepath.endswith(\".variables.json\"):\n        raise ValueError(\n            \"The filepath should ends with '.variables.json', \"\n            f\"received filepath={filepath}\"\n        )\n    config = self.get_state_tree()\n    config_string = json.dumps(config, indent=2)\n    if file_utils.exists(filepath) and not overwrite:\n        io_utils.ask_to_proceed_with_overwrite(filepath)\n    with open(filepath, \"w\") as f:\n        f.write(config_string)\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/Program%20Saving%20API/Variable%20saving%20and%20loading/#saving-variables-into-json-dict","title":"Saving variables into JSON dict","text":"<p>Retrieves tree-like structure of program variables.</p> <p>This method allows retrieval of different program variables (trainable, non-trainable, optimizer, and metrics). The variables are returned in a nested dictionary format, where the keys correspond to the variable names and the values are the nested representations of the variables.</p> <p>Example:</p> <pre><code>program.compile(\n    optimizer=synalinks.optimizers.RandomFewShot(),\n    reward=synalinks.rewards.ExactMatch(),\n)\nprogram.fit(x=x_train, y=y_train)\nstate_tree = program.get_state_tree()\n</code></pre> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the nested representations of the requested variables. The keys are the variable names, and the values are the corresponding nested dictionaries.</p> Source code in <code>synalinks/src/programs/program.py</code> <pre><code>def get_state_tree(self):\n    \"\"\"Retrieves tree-like structure of program variables.\n\n    This method allows retrieval of different program variables (trainable,\n    non-trainable, optimizer, and metrics). The variables are returned in a\n    nested dictionary format, where the keys correspond to the variable\n    names and the values are the nested representations of the variables.\n\n    Example:\n\n    ```python\n    program.compile(\n        optimizer=synalinks.optimizers.RandomFewShot(),\n        reward=synalinks.rewards.ExactMatch(),\n    )\n    program.fit(x=x_train, y=y_train)\n    state_tree = program.get_state_tree()\n    ```\n\n    Returns:\n        (dict): A dictionary containing the nested representations of the\n            requested variables. The keys are the variable names, and the\n            values are the corresponding nested dictionaries.\n    \"\"\"\n    variables = {}\n    variables[\"trainable_variables\"] = self._create_nested_dict(\n        self.trainable_variables\n    )\n    variables[\"non_trainable_variables\"] = self._create_nested_dict(\n        self.non_trainable_variables\n    )\n    if self.optimizer:\n        variables[\"optimizer_variables\"] = self._create_nested_dict(\n            self.optimizer.variables\n        )\n    variables[\"metrics_variables\"] = self._create_nested_dict(self.metrics_variables)\n    return variables\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/Program%20Saving%20API/Variable%20saving%20and%20loading/#loading-variables-from-a-json-file","title":"Loading variables from a JSON file","text":"<p>Load all module variables from a <code>.variable.json</code> file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str | Path</code> <p><code>str</code> or <code>pathlib.Path</code> object. Path to load the program's variables from. Must end in <code>.variables.json</code>.</p> required Source code in <code>synalinks/src/programs/program.py</code> <pre><code>def load_variables(self, filepath):\n    \"\"\"Load all module variables from a `.variable.json` file.\n\n    Args:\n        filepath (str | pathlib.Path): `str` or `pathlib.Path` object.\n            Path to load the program's variables from.\n            Must end in `.variables.json`.\n    \"\"\"\n    filepath = file_utils.path_to_string(filepath)\n    if not filepath.endswith(\".variables.json\"):\n        raise ValueError(\n            \"The filepath should ends with '.variables.json', \"\n            f\"received filepath={filepath}\"\n        )\n    with open(filepath, \"r\") as f:\n        state_tree_config = json.loads(f.read())\n    self.set_state_tree(state_tree_config)\n</code></pre>"},{"location":"Synalinks%20API/Programs%20API/Program%20Saving%20API/Variable%20saving%20and%20loading/#load-variables-from-a-json-dict","title":"Load variables from a JSON dict","text":"<p>Assigns values to variables of the program.</p> <p>This method takes a dictionary of nested variable values, which represents the state tree of the program, and assigns them to the corresponding variables of the program. The dictionary keys represent the variable names (e.g., <code>'trainable_variables'</code>, <code>'optimizer_variables'</code>), and the values are nested dictionaries containing the variable paths and their corresponding values.</p> <p>Parameters:</p> Name Type Description Default <code>state_tree</code> <code>dict</code> <p>A dictionary representing the state tree of the program. The keys are the variable names, and the values are nested dictionaries representing the variable paths and their values.</p> required Source code in <code>synalinks/src/programs/program.py</code> <pre><code>def set_state_tree(self, state_tree):\n    \"\"\"Assigns values to variables of the program.\n\n    This method takes a dictionary of nested variable values, which\n    represents the state tree of the program, and assigns them to the\n    corresponding variables of the program. The dictionary keys represent the\n    variable names (e.g., `'trainable_variables'`, `'optimizer_variables'`),\n    and the values are nested dictionaries containing the variable\n    paths and their corresponding values.\n\n    Args:\n        state_tree (dict): A dictionary representing the state tree of the program.\n            The keys are the variable names, and the values are nested\n            dictionaries representing the variable paths and their values.\n    \"\"\"\n    for k, v in state_tree.items():\n        path_value_dict = self._flatten_nested_dict(v)\n        if k == \"trainable_variables\":\n            self._assign_variable_values(self.trainable_variables, path_value_dict)\n        elif k == \"non_trainable_variables\":\n            self._assign_variable_values(\n                self.non_trainable_variables, path_value_dict\n            )\n        elif k == \"optimizer_variables\":\n            if self.optimizer:\n                self._assign_variable_values(\n                    self.optimizer.variables, path_value_dict\n                )\n        elif k == \"metrics_variables\":\n            self._assign_variable_values(self.metrics_variables, path_value_dict)\n        else:\n            raise ValueError(f\"Unknown variable name: {k}\")\n</code></pre>"},{"location":"Synalinks%20API/Rewards/","title":"Rewards","text":"<p><code>Reward</code>s are an essential part of reinforcement learning frameworks.  They are typically float values (usually between 0.0 and 1.0, but they can be  negative also) that guide the process into making more efficient decisions or  predictions. During training, the goal is to maximize the reward function.  The reward gives the system an indication of how well it performed for that task.</p> <p>The purpose of a reward function is to compute the quantity that the program should maximize during training.</p>"},{"location":"Synalinks%20API/Rewards/#rewards-overview","title":"Rewards Overview","text":"<ul> <li>ExactMatch reward</li> <li>CosineSimilarity reward</li> <li>LMAsJudge reward</li> <li>ProgramAsJudge reward</li> </ul>"},{"location":"Synalinks%20API/Rewards/CosineSimilarity%20reward/","title":"CosineSimilarity reward","text":""},{"location":"Synalinks%20API/Rewards/CosineSimilarity%20reward/#synalinks.src.rewards.cosine_similarity.CosineSimilarity","title":"<code>CosineSimilarity</code>","text":"<p>               Bases: <code>RewardFunctionWrapper</code></p> <p>Computes the cosine similarity between <code>y_true</code> and <code>y_pred</code>.</p> <p>Formula:</p> <pre><code>reward = (sum(l2_norm(y_true) * l2_norm(y_pred))+1) / 2\n</code></pre> <p>The formula is similar to the classic cosine similarity used in deep learning, but scaled to [0.0, 1.0] and adjusted to have a reward that tend towards 1.0 if the two objects are similar (and 0.0 otherwise).</p> <p>Example:</p> <pre><code>program.compile(\n    reward=synalinks.rewards.CosineSimilarity(\n        embedding_model=embedding_model\n    )\n    optimizer=synalinks.optimizers.RandomFewShot(),\n)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>embedding_model</code> <code>EmbeddingModel</code> <p>The embedding model to use to compute the cosine similarity.</p> <code>None</code> <code>axis</code> <code>int</code> <p>(Optional) Defaults to <code>-1</code>. The dimension along which the cosine similarity is computed.</p> <code>-1</code> <code>name</code> <code>str</code> <p>(Optional) string name of the reward instance.</p> <code>'cosine_similarity'</code> <code>in_mask</code> <code>list</code> <p>(Optional) list of keys to keep to compute the reward.</p> <code>None</code> <code>out_mask</code> <code>list</code> <p>(Optional) list of keys to remove to compute the reward.</p> <code>None</code> Source code in <code>synalinks/src/rewards/cosine_similarity.py</code> <pre><code>@synalinks_export(\"synalinks.rewards.CosineSimilarity\")\nclass CosineSimilarity(RewardFunctionWrapper):\n    \"\"\"\n    Computes the cosine similarity between `y_true` and `y_pred`.\n\n    Formula:\n\n    ```\n    reward = (sum(l2_norm(y_true) * l2_norm(y_pred))+1) / 2\n    ```\n\n    The formula is similar to the classic cosine similarity used in deep learning,\n    but scaled to [0.0, 1.0] and adjusted to have a reward that tend\n    towards 1.0 if the two objects are similar (and 0.0 otherwise).\n\n    Example:\n\n    ```python\n    program.compile(\n        reward=synalinks.rewards.CosineSimilarity(\n            embedding_model=embedding_model\n        )\n        optimizer=synalinks.optimizers.RandomFewShot(),\n    )\n    ```\n\n    Args:\n        embedding_model (EmbeddingModel): The embedding model to use to compute the\n            cosine similarity.\n        axis (int): (Optional) Defaults to `-1`. The dimension along which the cosine\n            similarity is computed.\n        name (str): (Optional) string name of the reward instance.\n        in_mask (list): (Optional) list of keys to keep to compute the reward.\n        out_mask (list): (Optional) list of keys to remove to compute the reward.\n    \"\"\"\n\n    def __init__(\n        self,\n        embedding_model=None,\n        axis=-1,\n        name=\"cosine_similarity\",\n        in_mask=None,\n        out_mask=None,\n    ):\n        super().__init__(\n            fn=cosine_similarity,\n            name=name,\n            in_mask=in_mask,\n            out_mask=out_mask,\n            axis=axis,\n            embedding_model=embedding_model,\n        )\n\n    def get_config(self):\n        config = Reward.get_config()\n        from synalinks.src.saving.serialization_lib import serialize_synalinks_object\n\n        embedding_model_config = {\n            \"embedding_model\": serialize_synalinks_object(self.embedding_model)\n        }\n        return {**config, **embedding_model_config}\n\n    @classmethod\n    def from_config(cls, config):\n        from synalinks.saving.serialization_lib import deserialize_synalinks_object\n\n        embedding_model = deserialize_synalinks_object(config.pop(\"embedding_model\"))\n        return cls(embedding_model=embedding_model, **config)\n</code></pre>"},{"location":"Synalinks%20API/Rewards/CosineSimilarity%20reward/#synalinks.src.rewards.cosine_similarity.cosine_similarity","title":"<code>cosine_similarity(y_true, y_pred, embedding_model=None, axis=-1)</code>  <code>async</code>","text":"<p>Computes the cosine similarity between <code>y_true</code> and <code>y_pred</code>.</p> <p>Formula:</p> <pre><code>reward = (sum(l2_norm(y_true) * l2_norm(y_pred))+1) / 2\n</code></pre> <p>The formula is similar to the classic cosine similarity used in deep learning, but scaled to [0.0, 1.0] and adjusted to have a reward that tend towards 1.0 if the two objects are similar (and 0.0 otherwise).</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>JsonDataModel</code> <p>The ground truth JSON data_model.</p> required <code>y_pred</code> <code>JsonDataModel</code> <p>The predicted JSON data_model.</p> required <code>embedding_model</code> <code>EmbeddingModel</code> <p>The embedding model to use to compute the cosine similarity.</p> <code>None</code> <code>axis</code> <code>int</code> <p>(Optional) Defaults to <code>-1</code>. The dimension along which the cosine similarity is computed.</p> <code>-1</code> <p>Returns:</p> Type Description <code>float</code> <p>The reward value, which tend to 1.0 if the values are similar, and towards 0.0 otherwise.</p> Source code in <code>synalinks/src/rewards/cosine_similarity.py</code> <pre><code>@synalinks_export(\"synalinks.rewards.cosine_similarity\")\nasync def cosine_similarity(y_true, y_pred, embedding_model=None, axis=-1):\n    \"\"\"\n    Computes the cosine similarity between `y_true` and `y_pred`.\n\n    Formula:\n\n    ```\n    reward = (sum(l2_norm(y_true) * l2_norm(y_pred))+1) / 2\n    ```\n\n    The formula is similar to the classic cosine similarity used in deep learning,\n    but scaled to [0.0, 1.0] and adjusted to have a reward that tend\n    towards 1.0 if the two objects are similar (and 0.0 otherwise).\n\n    Args:\n        y_true (JsonDataModel): The ground truth JSON data_model.\n        y_pred (JsonDataModel): The predicted JSON data_model.\n        embedding_model (EmbeddingModel): The embedding model to use to compute the\n            cosine similarity.\n        axis (int): (Optional) Defaults to `-1`. The dimension along which the cosine\n            similarity is computed.\n\n    Returns:\n        (float): The reward value, which tend to 1.0 if the values are similar,\n            and towards 0.0 otherwise.\n    \"\"\"\n    reward = 0.0\n    if y_pred is not None:\n        y_true = await ops.embedding(y_true, embedding_model=embedding_model)\n        y_pred = await ops.embedding(y_pred, embedding_model=embedding_model)\n        y_true = np.convert_to_tensor(y_true.get(\"embeddings\"))\n        y_pred = np.convert_to_tensor(y_pred.get(\"embeddings\"))\n        y_true, y_pred = squeeze_or_expand_to_same_rank(y_true, y_pred)\n        y_pred = np.normalize(y_pred, axis=axis)\n        y_true = np.normalize(y_true, axis=axis)\n        reward = (np.sum(y_true * y_pred, axis=axis) + 1) / 2\n    return reward\n</code></pre>"},{"location":"Synalinks%20API/Rewards/ExactMatch%20reward/","title":"ExactMatch reward","text":""},{"location":"Synalinks%20API/Rewards/ExactMatch%20reward/#synalinks.src.rewards.exact_match.ExactMatch","title":"<code>ExactMatch</code>","text":"<p>               Bases: <code>RewardFunctionWrapper</code></p> <p>Computes the exact match between <code>y_true</code> and <code>y_pred</code>.</p> <p>Example:</p> <pre><code>program.compile(\n    reward=synalinks.rewards.ExactMatch(),\n    optimizer=synalinks.optimizers.RandomFewShot(),\n)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Optional. string name of the reward instance.</p> <code>'exact_match'</code> <code>in_mask</code> <code>list</code> <p>Optional. list of keys to keep to compute the reward.</p> <code>None</code> <code>out_mask</code> <code>list</code> <p>Optional. list of keys to remove to compute the reward.</p> <code>None</code> Source code in <code>synalinks/src/rewards/exact_match.py</code> <pre><code>@synalinks_export(\"synalinks.rewards.ExactMatch\")\nclass ExactMatch(RewardFunctionWrapper):\n    \"\"\"Computes the exact match between `y_true` and `y_pred`.\n\n    Example:\n\n    ```python\n    program.compile(\n        reward=synalinks.rewards.ExactMatch(),\n        optimizer=synalinks.optimizers.RandomFewShot(),\n    )\n    ```\n\n    Args:\n        name (str): Optional. string name of the reward instance.\n        in_mask (list): Optional. list of keys to keep to compute the reward.\n        out_mask (list): Optional. list of keys to remove to compute the reward.\n    \"\"\"\n\n    def __init__(\n        self,\n        name=\"exact_match\",\n        in_mask=None,\n        out_mask=None,\n    ):\n        super().__init__(\n            fn=exact_match,\n            name=name,\n            in_mask=in_mask,\n            out_mask=out_mask,\n        )\n\n    def get_config(self):\n        return {\n            \"name\": self.name,\n            \"in_mask\": self.in_mask,\n            \"out_mask\": self.out_mask,\n        }\n\n    @classmethod\n    def from_config(cls, config):\n        return cls(**config)\n</code></pre>"},{"location":"Synalinks%20API/Rewards/ExactMatch%20reward/#synalinks.src.rewards.exact_match.exact_match","title":"<code>exact_match(y_true, y_pred)</code>  <code>async</code>","text":"<p>Computes the exact match between <code>y_true</code> and <code>y_pred</code>.</p> <p>If their values are equal, it returns a reward of 1.0; otherwise, it returns 0.0.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>JsonDataModel</code> <p>The ground truth JSON data_model.</p> required <code>y_pred</code> <code>JsonDataModel</code> <p>The predicted JSON data_model.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The reward value, which is 1.0 if the values match exactly, and 0.0 otherwise.</p> Source code in <code>synalinks/src/rewards/exact_match.py</code> <pre><code>@synalinks_export(\"synalinks.rewards.exact_match\")\nasync def exact_match(y_true, y_pred):\n    \"\"\"\n    Computes the exact match between `y_true` and `y_pred`.\n\n    If their values are equal, it returns a reward of 1.0; otherwise, it returns 0.0.\n\n    Args:\n        y_true (JsonDataModel): The ground truth JSON data_model.\n        y_pred (JsonDataModel): The predicted JSON data_model.\n\n    Returns:\n        (float): The reward value, which is 1.0 if the values match exactly,\n            and 0.0 otherwise.\n    \"\"\"\n    reward = 0.0\n    if y_pred is not None:\n        if y_pred.get_json() == y_true.get_json():\n            reward = 1.0\n    return reward\n</code></pre>"},{"location":"Synalinks%20API/Rewards/LMAsJudge%20reward/","title":"LMAsJudge reward","text":""},{"location":"Synalinks%20API/Rewards/LMAsJudge%20reward/#synalinks.src.rewards.lm_as_judge.LMAsJudge","title":"<code>LMAsJudge</code>","text":"<p>               Bases: <code>ProgramAsJudge</code></p> <p>Evaluate the output of a program using a <code>LanguageModel</code>.</p> <p>Example:</p> <pre><code>program.compile(\n    reward=synalinks.rewards.LMAsJudge()\n    optimizer=synalinks.optimizers.RandomFewShot(),\n)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>language_model</code> <code>LanguageModel</code> <p>The language model to use.</p> <code>None</code> <code>prompt_template</code> <code>str</code> <p>The default jinja2 prompt template to use (see <code>Generator</code>).</p> <code>None</code> <code>examples</code> <code>list</code> <p>The default examples to use in the prompt (see <code>Generator</code>).</p> <code>None</code> <code>instructions</code> <code>list</code> <p>The default instructions to use (see <code>Generator</code>).</p> <code>None</code> <code>name</code> <code>str</code> <p>Optional. string name of the reward instance.</p> <code>'lm_as_judge'</code> <code>in_mask</code> <code>list</code> <p>Optional. list of keys to keep to compute the reward.</p> <code>None</code> <code>out_mask</code> <code>list</code> <p>Optional. list of keys to remove to compute the reward.</p> <code>None</code> Source code in <code>synalinks/src/rewards/lm_as_judge.py</code> <pre><code>class LMAsJudge(ProgramAsJudge):\n    \"\"\"Evaluate the output of a program using a `LanguageModel`.\n\n    Example:\n\n    ```python\n    program.compile(\n        reward=synalinks.rewards.LMAsJudge()\n        optimizer=synalinks.optimizers.RandomFewShot(),\n    )\n    ```\n\n    Args:\n        language_model (LanguageModel): The language model to use.\n        prompt_template (str): The default jinja2 prompt template\n            to use (see `Generator`).\n        examples (list): The default examples to use in the prompt\n            (see `Generator`).\n        instructions (list): The default instructions to use (see `Generator`).\n        name (str): Optional. string name of the reward instance.\n        in_mask (list): Optional. list of keys to keep to compute the reward.\n        out_mask (list): Optional. list of keys to remove to compute the reward.\n    \"\"\"\n\n    def __init__(\n        self,\n        language_model=None,\n        prompt_template=None,\n        examples=None,\n        instructions=None,\n        name=\"lm_as_judge\",\n        in_mask=None,\n        out_mask=None,\n    ):\n        program = LMAsJudgeProgram(\n            language_model=language_model,\n            prompt_template=prompt_template,\n            examples=examples,\n            instructions=instructions,\n        )\n        super().__init__(\n            program=program,\n            name=name,\n            in_mask=in_mask,\n            out_mask=out_mask,\n        )\n</code></pre>"},{"location":"Synalinks%20API/Rewards/LMAsJudge%20reward/#synalinks.src.rewards.lm_as_judge.LMAsJudgeProgram","title":"<code>LMAsJudgeProgram</code>","text":"<p>               Bases: <code>Program</code></p> <p>Evaluate the output of a program using a <code>LanguageModel</code>.</p> <p>Parameters:</p> Name Type Description Default <code>language_model</code> <code>LanguageModel</code> <p>The language model to use.</p> <code>None</code> <code>prompt_template</code> <code>str</code> <p>The default jinja2 prompt template to use (see <code>Generator</code>).</p> <code>None</code> <code>examples</code> <code>list</code> <p>The default examples to use in the prompt (see <code>Generator</code>).</p> <code>None</code> <code>instructions</code> <code>list</code> <p>The default instructions to use (see <code>Generator</code>).</p> <code>None</code> <code>name</code> <code>str</code> <p>Optional. The name of the program.</p> <code>None</code> <code>description</code> <code>str</code> <p>Optional. The description of the program.</p> <code>None</code> <code>trainable</code> <code>bool</code> <p>Whether the program's variables should be trainable.</p> <code>True</code> Source code in <code>synalinks/src/rewards/lm_as_judge.py</code> <pre><code>class LMAsJudgeProgram(Program):\n    \"\"\"Evaluate the output of a program using a `LanguageModel`.\n\n    Args:\n        language_model (LanguageModel): The language model to use.\n        prompt_template (str): The default jinja2 prompt template\n            to use (see `Generator`).\n        examples (list): The default examples to use in the prompt\n            (see `Generator`).\n        instructions (list): The default instructions to use (see `Generator`).\n        name (str): Optional. The name of the program.\n        description (str): Optional. The description of the program.\n        trainable (bool): Whether the program's variables should be trainable.\n    \"\"\"\n\n    def __init__(\n        self,\n        language_model=None,\n        prompt_template=None,\n        examples=None,\n        instructions=None,\n        name=None,\n        description=None,\n        trainable=True,\n    ):\n        super().__init__(\n            name=name,\n            description=description,\n            trainable=trainable,\n        )\n        self.critique = SelfCritique(\n            language_model=language_model,\n            prompt_template=prompt_template,\n            examples=examples,\n            instructions=instructions,\n            name=self.name + \"_self_critique\",\n        )\n        self.language_model = language_model\n        self.prompt_template = prompt_template\n        self.examples = examples\n        self.instructions = instructions\n\n    async def call(self, inputs):\n        if not isinstance(inputs, (list, tuple)):\n            raise ValueError(\"The inputs should be a list or tuple.\")\n        if len(inputs) != 2:\n            raise ValueError(\"The inputs of the program should have a length of 2.\")\n        y_true = inputs[0]\n        y_pred = inputs[1]\n        if y_true:\n            y_true = await ops.prefix(\n                y_true,\n                prefix=\"gold\",\n                name=\"gold_y_true\",\n            )\n            return await self.critique(\n                await ops.concat(\n                    y_true,\n                    y_pred,\n                    name=\"y_true_with_y_pred\",\n                )\n            )\n        else:\n            return await self.critique(y_pred)\n\n    def get_config(self):\n        config = {\n            \"prompt_template\": self.prompt_template,\n            \"examples\": self.examples,\n            \"instructions\": self.instructions,\n            \"name\": self.name,\n            \"description\": self.description,\n            \"trainable\": self.trainable,\n        }\n        language_model_config = {\n            \"language_model\": serialization_lib.serialize_synalinks_object(\n                self.language_model\n            )\n        }\n        return {**language_model_config, **config}\n\n    @classmethod\n    def from_config(cls, config):\n        language_model = serialization_lib.deserialize_synalinks_object(\n            config.pop(\"language_model\")\n        )\n        return cls(language_model=language_model, **config)\n</code></pre>"},{"location":"Synalinks%20API/Rewards/Reward%20wrappers/","title":"Reward wrappers","text":""},{"location":"Synalinks%20API/Rewards/Reward%20wrappers/#synalinks.src.rewards.reward_wrappers.ProgramAsJudge","title":"<code>ProgramAsJudge</code>","text":"<p>               Bases: <code>Reward</code></p> <p>Wrap a <code>Program</code> into a <code>Reward</code>.</p> <p>You can use this to create advanced reward functions that use a Synalinks <code>Program</code>. The program should have two inputs and one output.</p> <p>Note: The output data model/schema should have a field named <code>reward</code>.</p> <p>Example:</p> <pre><code># ... your program declaration\n\nprogram = synalinks.Program(\n    inputs=x0,\n    outputs=xn,\n)\n\nprogram.compile(\n    reward=synalinks.rewards.ProgramAsJudge(program=program)\n    optimizer=synalinks.optimizers.RandomFewShot(),\n)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>program</code> <code>Program</code> <p>The reward program to wrap.</p> required <code>name</code> <code>str</code> <p>Optional. string name of the reward instance.</p> <code>None</code> <code>in_mask</code> <code>list</code> <p>Optional. list of keys to keep to compute the reward.</p> <code>None</code> <code>out_mask</code> <code>list</code> <p>Optional. list of keys to remove to compute the reward.</p> <code>None</code> Source code in <code>synalinks/src/rewards/reward_wrappers.py</code> <pre><code>@synalinks_export(\"synalinks.rewards.ProgramAsJudge\")\nclass ProgramAsJudge(Reward):\n    \"\"\"Wrap a `Program` into a `Reward`.\n\n    You can use this to create advanced reward functions that use a Synalinks `Program`.\n    The program should have two inputs and one output.\n\n    **Note:** The output data model/schema should have a field named `reward`.\n\n    Example:\n\n    ```python\n    # ... your program declaration\n\n    program = synalinks.Program(\n        inputs=x0,\n        outputs=xn,\n    )\n\n    program.compile(\n        reward=synalinks.rewards.ProgramAsJudge(program=program)\n        optimizer=synalinks.optimizers.RandomFewShot(),\n    )\n    ```\n\n    Args:\n        program (Program): The reward program to wrap.\n        name (str): Optional. string name of the reward instance.\n        in_mask (list): Optional. list of keys to keep to compute the reward.\n        out_mask (list): Optional. list of keys to remove to compute the reward.\n    \"\"\"\n\n    def __init__(\n        self,\n        program,\n        reduction=\"mean\",\n        name=None,\n        in_mask=None,\n        out_mask=None,\n    ):\n        super().__init__(\n            name=name,\n            reduction=reduction,\n            in_mask=in_mask,\n            out_mask=out_mask,\n        )\n        self.program = program\n\n    async def call(self, y_true, y_pred):\n        result = await self.program([y_true, y_pred])\n        return float(result.get(\"reward\", 0.0))\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\"program\": self.program})\n        return config\n\n    def __repr__(self):\n        return f\"&lt;ProgramAsJudge({self.program})&gt;\"\n</code></pre>"},{"location":"Synalinks%20API/Rewards/Reward%20wrappers/#synalinks.src.rewards.reward_wrappers.RewardFunctionWrapper","title":"<code>RewardFunctionWrapper</code>","text":"<p>               Bases: <code>Reward</code></p> <p>Wrap a stateless function into a <code>Reward</code>.</p> <p>You can use this to quickly build a reward from a function. The function needs to have the signature <code>fn(y_true, y_pred)</code>.</p> <p>Example:</p> <pre><code>def my_reward(y_true, y_pred):\n    # ...\n    return reward\n\nprogram.compile(\n    reward=synalinks.rewards.RewardFunctionWrapper,\n    optimizer=synalinks.optimizers.RandomFewShot()\n)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>callable</code> <p>The reward function to wrap, with signature <code>fn(y_true, y_pred, **kwargs)</code>.</p> required <code>name</code> <code>str</code> <p>Optional. string name of the reward instance.</p> <code>None</code> <code>in_mask</code> <code>list</code> <p>Optional. list of keys to keep to compute the reward.</p> <code>None</code> <code>out_mask</code> <code>list</code> <p>Optional. list of keys to remove to compute the reward.</p> <code>None</code> <code>**kwargs</code> <code>keyword arguments</code> <p>Keyword arguments to pass on to <code>fn</code>.</p> <code>{}</code> Source code in <code>synalinks/src/rewards/reward_wrappers.py</code> <pre><code>@synalinks_export(\"synalinks.rewards.RewardFunctionWrapper\")\nclass RewardFunctionWrapper(Reward):\n    \"\"\"Wrap a stateless function into a `Reward`.\n\n    You can use this to quickly build a reward from a function. The function needs\n    to have the signature `fn(y_true, y_pred)`.\n\n    Example:\n\n    ```python\n\n    def my_reward(y_true, y_pred):\n        # ...\n        return reward\n\n    program.compile(\n        reward=synalinks.rewards.RewardFunctionWrapper,\n        optimizer=synalinks.optimizers.RandomFewShot()\n    )\n    ```\n\n    Args:\n        fn (callable): The reward function to wrap, with signature\n            `fn(y_true, y_pred, **kwargs)`.\n        name (str): Optional. string name of the reward instance.\n        in_mask (list): Optional. list of keys to keep to compute the reward.\n        out_mask (list): Optional. list of keys to remove to compute the reward.\n        **kwargs (keyword arguments): Keyword arguments to pass on to `fn`.\n    \"\"\"\n\n    def __init__(\n        self,\n        fn,\n        reduction=\"mean\",\n        name=None,\n        in_mask=None,\n        out_mask=None,\n        **kwargs,\n    ):\n        super().__init__(\n            name=name,\n            reduction=reduction,\n            in_mask=in_mask,\n            out_mask=out_mask,\n        )\n        self.fn = fn\n        self._fn_kwargs = kwargs\n\n    async def call(self, y_true, y_pred):\n        return await self.fn(y_true, y_pred, **self._fn_kwargs)\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\"fn\": serialization_lib.serialize_synalinks_object(self.fn)})\n        config.update(serialization_lib.serialize_synalinks_object(self._fn_kwargs))\n        return config\n\n    @classmethod\n    def from_config(cls, config):\n        if \"fn\" in config:\n            config = serialization_lib.deserialize_synalinks_object(config)\n        return cls(**config)\n\n    def __repr__(self):\n        return f\"&lt;RewardFunctionWrapper({self.fn}, kwargs={self._fn_kwargs})&gt;\"\n</code></pre>"},{"location":"Synalinks%20API/Utilities/More%20plotting%20utilities/","title":"More plotting utilities","text":""},{"location":"Synalinks%20API/Utilities/More%20plotting%20utilities/#synalinks.src.utils.plot_history.plot_history","title":"<code>plot_history(history, to_file='training_history.png', to_folder=None, xlabel='Epochs', ylabel='Scores', title='Training history', grid=True, metrics_filter=None, **kwargs)</code>","text":"<p>Plots the training history of a program and saves it to a file.</p> <p>Code Example:</p> <pre><code>program.compile(...)\nhistory = await program.fit(...)\n\nsynalinks.utils.plot_history(history)\n</code></pre> <p>Example:</p> <p></p> <p>Parameters:</p> Name Type Description Default <code>history</code> <code>History</code> <p>The training history.</p> required <code>to_file</code> <code>str</code> <p>The file path where the plot will be saved. Default to \"training_history.png\".</p> <code>'training_history.png'</code> <code>to_folder</code> <code>str</code> <p>The folder where the plot will be saved. If provided, will be combined with to_file.</p> <code>None</code> <code>xlabel</code> <code>str</code> <p>Optional. The label for the x-axis. Default to \"Epochs\".</p> <code>'Epochs'</code> <code>ylabel</code> <code>str</code> <p>Optional. The label for the y-axis. Default to \"Scores\".</p> <code>'Scores'</code> <code>title</code> <code>str</code> <p>Optional. The title of the plot. Default to \"Training history\".</p> <code>'Training history'</code> <code>grid</code> <code>bool</code> <p>Whether to display the grid on the plot. Default to True.</p> <code>True</code> <code>metrics_filter</code> <code>list</code> <p>List of specific metrics to plot. If None, all metrics will be plotted.</p> <code>None</code> <code>**kwargs</code> <code>keyword arguments</code> <p>Additional keyword arguments forwarded to <code>plt.plot()</code></p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If there are unrecognized keyword arguments.</p> <p>Returns:</p> Type Description <code>Image | Image | str</code> <p>If running in a Jupyter notebook, returns an IPython Image object for inline display. If running in a Marimo notebook returns a marimo image. Otherwise returns the filepath where the image has been saved.</p> Source code in <code>synalinks/src/utils/plot_history.py</code> <pre><code>@synalinks_export(\"synalinks.utils.plot_history\")\ndef plot_history(\n    history,\n    to_file=\"training_history.png\",\n    to_folder=None,\n    xlabel=\"Epochs\",\n    ylabel=\"Scores\",\n    title=\"Training history\",\n    grid=True,\n    metrics_filter=None,\n    **kwargs,\n):\n    \"\"\"Plots the training history of a program and saves it to a file.\n\n    Code Example:\n\n    ```python\n    program.compile(...)\n    history = await program.fit(...)\n\n    synalinks.utils.plot_history(history)\n    ```\n\n    Example:\n\n    ![training_history.png](../../assets/training_history.png)\n\n    Args:\n        history (History): The training history.\n        to_file (str): The file path where the plot will be saved.\n            Default to \"training_history.png\".\n        to_folder (str, optional): The folder where the plot will be saved.\n            If provided, will be combined with to_file.\n        xlabel (str): Optional. The label for the x-axis. Default to \"Epochs\".\n        ylabel (str): Optional. The label for the y-axis. Default to \"Scores\".\n        title (str): Optional. The title of the plot. Default to \"Training history\".\n        grid (bool): Whether to display the grid on the plot. Default to True.\n        metrics_filter (list, optional): List of specific metrics to plot.\n            If None, all metrics will be plotted.\n        **kwargs (keyword arguments): Additional keyword arguments\n            forwarded to `plt.plot()`\n\n    Raises:\n        ValueError: If there are unrecognized keyword arguments.\n\n    Returns:\n        (IPython.display.Image | marimo.Image | str):\n            If running in a Jupyter notebook, returns an IPython Image object\n            for inline display. If running in a Marimo notebook returns a marimo image.\n            Otherwise returns the filepath where the image has been saved.\n    \"\"\"\n    all_metrics = list(history.history.keys())\n\n    if metrics_filter is not None:\n        if not all(metric in all_metrics for metric in metrics_filter):\n            raise ValueError(f\"Requested metrics {metrics_filter} not found in history\")\n        all_metrics = metrics_filter\n\n    colors = generate_distinct_colors(len(all_metrics))\n\n    for i, metric in enumerate(all_metrics):\n        plt.plot(history.history[metric], label=metric, color=colors[i], **kwargs)\n\n    if xlabel:\n        plt.xlabel(xlabel)\n\n    plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n\n    if ylabel:\n        plt.ylabel(ylabel)\n    if title:\n        plt.title(title)\n\n    # Set y-axis limits: minimum 0.0, maximum 1.0 but allow exceeding if needed\n    all_values = [val for metric in all_metrics for val in history.history[metric]]\n    max_value = max(all_values) if all_values else 1.0\n    plt.ylim(0.0, max(1.0, max_value * 1.05))  # 5% padding above max value\n\n    plt.legend()\n    plt.grid(grid)\n    plt.tight_layout()\n\n    if to_folder:\n        to_file = os.path.join(to_folder, to_file)\n\n    plt.savefig(to_file, dpi=300, bbox_inches=\"tight\")\n    plt.close()\n\n    try:\n        import marimo as mo\n\n        if mo.running_in_notebook():\n            return mo.image(src=to_file).center()\n    except ImportError:\n        pass\n\n    try:\n        from IPython import display\n\n        return display.Image(filename=to_file)\n    except ImportError:\n        pass\n\n    return to_file\n</code></pre>"},{"location":"Synalinks%20API/Utilities/More%20plotting%20utilities/#synalinks.src.utils.plot_history.plot_history_comparison","title":"<code>plot_history_comparison(history_dict, to_file='training_history_comparison.png', to_folder=None, xlabel='Epochs', ylabel='Scores', title='Training History Comparison', grid=True, metrics_filter=None, linestyle_cycle=None, **kwargs)</code>","text":"<p>Plots comparison of training histories across different conditions/models.</p> <p>Code Example:</p> <pre><code>import synalinks\nimport asyncio\n\nNB_RUN = 5\n\nasync def main():\n\n    # ... program definition\n\n    program.compile(...)\n\n    history_list = []\n    for i in range(NB_RUN):\n        history = await program.fit(...)\n        history_list.append(history)\n\n    # ... program_1 definition\n\n    program_1.compile(...)\n\n    history_list_1 = []\n    for i in range(NB_RUN):\n        history = await program.fit(...)\n        history_list_1.append(history)\n\n    history_comparaison = {\n        \"program_a\": history_list\n        \"program_b: history_list_1\n    }\n\n    synalinks.utils.plot_history_comparison(history_comparison)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>history_dict</code> <code>dict</code> <p>Dictionary where keys are condition names (e.g., model names) and values are History objects. Format: {\"condition1\": history1, \"condition2\": history2, ...}</p> required <code>to_file</code> <code>str</code> <p>The file path where the plot will be saved. Default to \"training_history_comparison.png\".</p> <code>'training_history_comparison.png'</code> <code>to_folder</code> <code>str</code> <p>The folder where the plot will be saved. If provided, will be combined with to_file.</p> <code>None</code> <code>xlabel</code> <code>str</code> <p>Optional. The label for the x-axis. Default to \"Epochs\".</p> <code>'Epochs'</code> <code>ylabel</code> <code>str</code> <p>Optional. The label for the y-axis. Default to \"Scores\".</p> <code>'Scores'</code> <code>title</code> <code>str</code> <p>Optional. The title of the plot (Default to \"Training History Comparison\").</p> <code>'Training History Comparison'</code> <code>grid</code> <code>bool</code> <p>Whether to display the grid on the plot. Default to True.</p> <code>True</code> <code>metrics_filter</code> <code>list</code> <p>List of specific metrics to plot. If None, all metrics will be plotted.</p> <code>None</code> <code>linestyle_cycle</code> <code>list</code> <p>List of line styles to cycle through for conditions (Default to ['-', '--', '-.', ':']).</p> <code>None</code> <code>**kwargs</code> <code>keyword arguments</code> <p>Additional keyword arguments forwarded to <code>plt.plot()</code></p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If history_dict is empty, has inconsistent metric names, or if there are unrecognized keyword arguments.</p> <p>Returns:</p> Type Description <code>Image | Image | str</code> <p>If running in a Jupyter notebook, returns an IPython Image object for inline display. If running in a Marimo notebook returns a marimo image. Otherwise returns the filepath where the image has been saved.</p> Source code in <code>synalinks/src/utils/plot_history.py</code> <pre><code>@synalinks_export(\"synalinks.utils.plot_history_comparison\")\ndef plot_history_comparison(\n    history_dict,\n    to_file=\"training_history_comparison.png\",\n    to_folder=None,\n    xlabel=\"Epochs\",\n    ylabel=\"Scores\",\n    title=\"Training History Comparison\",\n    grid=True,\n    metrics_filter=None,\n    linestyle_cycle=None,\n    **kwargs,\n):\n    \"\"\"Plots comparison of training histories across different conditions/models.\n\n    Code Example:\n\n    ```python\n    import synalinks\n    import asyncio\n\n    NB_RUN = 5\n\n    async def main():\n\n        # ... program definition\n\n        program.compile(...)\n\n        history_list = []\n        for i in range(NB_RUN):\n            history = await program.fit(...)\n            history_list.append(history)\n\n        # ... program_1 definition\n\n        program_1.compile(...)\n\n        history_list_1 = []\n        for i in range(NB_RUN):\n            history = await program.fit(...)\n            history_list_1.append(history)\n\n        history_comparaison = {\n            \"program_a\": history_list\n            \"program_b: history_list_1\n        }\n\n        synalinks.utils.plot_history_comparison(history_comparison)\n    ```\n\n    Args:\n        history_dict (dict): Dictionary where keys are condition names (e.g., model names)\n            and values are History objects. Format:\n            {\"condition1\": history1, \"condition2\": history2, ...}\n        to_file (str): The file path where the plot will be saved.\n            Default to \"training_history_comparison.png\".\n        to_folder (str, optional): The folder where the plot will be saved.\n            If provided, will be combined with to_file.\n        xlabel (str): Optional. The label for the x-axis. Default to \"Epochs\".\n        ylabel (str): Optional. The label for the y-axis. Default to \"Scores\".\n        title (str): Optional. The title of the plot\n            (Default to \"Training History Comparison\").\n        grid (bool): Whether to display the grid on the plot. Default to True.\n        metrics_filter (list, optional): List of specific metrics to plot.\n            If None, all metrics will be plotted.\n        linestyle_cycle (list, optional): List of line styles to cycle through\n            for conditions (Default to ['-', '--', '-.', ':']).\n        **kwargs (keyword arguments): Additional keyword arguments\n            forwarded to `plt.plot()`\n\n    Raises:\n        ValueError: If history_dict is empty, has inconsistent metric names,\n            or if there are unrecognized keyword arguments.\n\n    Returns:\n        (IPython.display.Image | marimo.Image | str):\n            If running in a Jupyter notebook, returns an IPython Image object\n            for inline display. If running in a Marimo notebook returns a marimo image.\n            Otherwise returns the filepath where the image has been saved.\n    \"\"\"\n    if not history_dict:\n        raise ValueError(\"history_dict cannot be empty\")\n\n    # Get all metric names and validate consistency\n    condition_names = list(history_dict.keys())\n    all_metric_names = list(history_dict[condition_names[0]].history.keys())\n\n    # Validate that all conditions have the same metrics\n    for condition in condition_names:\n        if set(history_dict[condition].history.keys()) != set(all_metric_names):\n            raise ValueError(\n                f\"Condition '{condition}' has inconsistent metric names. \"\n                f\"Expected: {all_metric_names}, \"\n                f\"Got: {list(history_dict[condition].history.keys())}\"\n            )\n\n    if metrics_filter is not None:\n        if not all(metric in all_metric_names for metric in metrics_filter):\n            raise ValueError(f\"Requested metrics {metrics_filter} not found in history\")\n        metric_names = metrics_filter\n    else:\n        metric_names = all_metric_names\n\n    if linestyle_cycle is None:\n        linestyle_cycle = [\"-\", \"--\", \"-.\", \":\"]\n\n    # Get colors for metrics and line styles for conditions\n    colors = generate_distinct_colors(len(metric_names))\n\n    plt.figure(figsize=(12, 8))\n\n    # Plot each metric for each condition\n    for metric_idx, metric in enumerate(metric_names):\n        for cond_idx, condition in enumerate(condition_names):\n            history = history_dict[condition]\n            linestyle = linestyle_cycle[cond_idx % len(linestyle_cycle)]\n\n            plt.plot(\n                history.history[metric],\n                label=f\"{condition} - {metric}\",\n                color=colors[metric_idx],\n                linestyle=linestyle,\n                **kwargs,\n            )\n\n    if xlabel:\n        plt.xlabel(xlabel)\n\n    plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n\n    if ylabel:\n        plt.ylabel(ylabel)\n    if title:\n        plt.title(title)\n\n    # Set y-axis limits: minimum 0.0, maximum 1.0 but allow exceeding if needed\n    all_values = []\n    for condition in condition_names:\n        for metric in metric_names:\n            all_values.extend(history_dict[condition].history[metric])\n    max_value = max(all_values) if all_values else 1.0\n    plt.ylim(0.0, max(1.0, max_value * 1.05))  # 5% padding above max value\n\n    plt.legend()\n    plt.grid(grid)\n    plt.tight_layout()\n\n    if to_folder:\n        to_file = os.path.join(to_folder, to_file)\n\n    plt.savefig(to_file, dpi=300, bbox_inches=\"tight\")\n    plt.close()\n\n    try:\n        import marimo as mo\n\n        if mo.running_in_notebook():\n            return mo.image(src=to_file).center()\n    except ImportError:\n        pass\n\n    try:\n        from IPython import display\n\n        return display.Image(filename=to_file)\n    except ImportError:\n        pass\n\n    return to_file\n</code></pre>"},{"location":"Synalinks%20API/Utilities/More%20plotting%20utilities/#synalinks.src.utils.plot_history.plot_history_comparison_with_mean_and_std","title":"<code>plot_history_comparison_with_mean_and_std(history_comparison_dict, to_file='training_history_comparison_with_mean_and_std.png', to_folder=None, xlabel='Epochs', ylabel='Scores', title='Training History Comparison with Mean and Std', grid=True, alpha=0.2, metrics_filter=None, linestyle_cycle=None, **kwargs)</code>","text":"<p>Plots comparison of training histories with mean and standard deviation     across conditions.</p> <p>Calculates mean and standard deviation for each condition across multiple runs and displays them as line plots with error bands for comparison.</p> <p>Code Example: <pre><code># Compare training histories from different models with multiple runs each\nhistory_comparison = {\n    \"Model A\": [history_a1, history_a2, history_a3],\n    \"Model B\": [history_b1, history_b2, history_b3]\n}\n\nsynalinks.utils.plot_history_comparison_with_mean_and_std(history_comparison)\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>history_comparison_dict</code> <code>dict</code> <p>Dictionary where keys are condition names and values are lists of History objects. Format: {\"condition1\": [history1, history2, ...], ...}</p> required <code>to_file</code> <code>str</code> <p>The file path where the plot will be saved. Default to \"training_history_comparison_with_mean_and_std.png\".</p> <code>'training_history_comparison_with_mean_and_std.png'</code> <code>to_folder</code> <code>str</code> <p>The folder where the plot will be saved. If provided, will be combined with to_file.</p> <code>None</code> <code>xlabel</code> <code>str</code> <p>Optional. The label for the x-axis. Default to \"Epochs\".</p> <code>'Epochs'</code> <code>ylabel</code> <code>str</code> <p>Optional. The label for the y-axis. Default to \"Scores\".</p> <code>'Scores'</code> <code>title</code> <code>str</code> <p>Optional. The title of the plot. Default to \"Training History Comparison with Mean and Std\".</p> <code>'Training History Comparison with Mean and Std'</code> <code>grid</code> <code>bool</code> <p>Whether to display the grid on the plot. Default to True.</p> <code>True</code> <code>alpha</code> <code>float</code> <p>The transparency of the standard deviation area. Default to 0.2.</p> <code>0.2</code> <code>metrics_filter</code> <code>list</code> <p>List of specific metrics to plot. If None, all metrics will be plotted.</p> <code>None</code> <code>linestyle_cycle</code> <code>list</code> <p>List of line styles to cycle through for conditions (Default to ['-', '--', '-.', ':']).</p> <code>None</code> <code>**kwargs</code> <code>keyword arguments</code> <p>Additional keyword arguments forwarded to <code>plt.plot()</code> for the mean lines.</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If history_comparison_dict is empty, has inconsistent structures, or if there are unrecognized keyword arguments.</p> <p>Returns:</p> Type Description <code>Image | Image | str</code> <p>If running in a Jupyter notebook, returns an IPython Image object for inline display. If running in a Marimo notebook returns a marimo image. Otherwise returns the filepath where the image has been saved.</p> Source code in <code>synalinks/src/utils/plot_history.py</code> <pre><code>@synalinks_export(\"synalinks.utils.plot_history_comparison_with_mean_and_std\")\ndef plot_history_comparison_with_mean_and_std(\n    history_comparison_dict,\n    to_file=\"training_history_comparison_with_mean_and_std.png\",\n    to_folder=None,\n    xlabel=\"Epochs\",\n    ylabel=\"Scores\",\n    title=\"Training History Comparison with Mean and Std\",\n    grid=True,\n    alpha=0.2,\n    metrics_filter=None,\n    linestyle_cycle=None,\n    **kwargs,\n):\n    \"\"\"Plots comparison of training histories with mean and standard deviation\n        across conditions.\n\n    Calculates mean and standard deviation for each condition across multiple runs and\n    displays them as line plots with error bands for comparison.\n\n    Code Example:\n    ```python\n    # Compare training histories from different models with multiple runs each\n    history_comparison = {\n        \"Model A\": [history_a1, history_a2, history_a3],\n        \"Model B\": [history_b1, history_b2, history_b3]\n    }\n\n    synalinks.utils.plot_history_comparison_with_mean_and_std(history_comparison)\n    ```\n\n    Args:\n        history_comparison_dict (dict): Dictionary where keys are condition names and\n            values are lists of History objects. Format:\n            {\"condition1\": [history1, history2, ...], ...}\n        to_file (str): The file path where the plot will be saved.\n            Default to \"training_history_comparison_with_mean_and_std.png\".\n        to_folder (str, optional): The folder where the plot will be saved.\n            If provided, will be combined with to_file.\n        xlabel (str): Optional. The label for the x-axis. Default to \"Epochs\".\n        ylabel (str): Optional. The label for the y-axis. Default to \"Scores\".\n        title (str): Optional. The title of the plot.\n            Default to \"Training History Comparison with Mean and Std\".\n        grid (bool): Whether to display the grid on the plot. Default to True.\n        alpha (float): The transparency of the standard deviation area. Default to 0.2.\n        metrics_filter (list, optional): List of specific metrics to plot.\n            If None, all metrics will be plotted.\n        linestyle_cycle (list, optional): List of line styles to cycle through\n            for conditions (Default to ['-', '--', '-.', ':']).\n        **kwargs (keyword arguments): Additional keyword arguments\n            forwarded to `plt.plot()` for the mean lines.\n\n    Raises:\n        ValueError: If history_comparison_dict is empty, has inconsistent structures,\n            or if there are unrecognized keyword arguments.\n\n    Returns:\n        (IPython.display.Image | marimo.Image | str):\n            If running in a Jupyter notebook, returns an IPython Image object\n            for inline display. If running in a Marimo notebook returns a marimo image.\n            Otherwise returns the filepath where the image has been saved.\n    \"\"\"\n    if not history_comparison_dict:\n        raise ValueError(\"history_comparison_dict cannot be empty\")\n\n    condition_names = list(history_comparison_dict.keys())\n\n    # Validate structure and get metric names\n    for condition in condition_names:\n        if not isinstance(history_comparison_dict[condition], list):\n            raise ValueError(\n                f\"Values for condition '{condition}' must be a list of History objects\"\n            )\n        if not history_comparison_dict[condition]:\n            raise ValueError(f\"History list for condition '{condition}' cannot be empty\")\n\n    # Get metric names from first condition's first history\n    all_metric_names = list(history_comparison_dict[condition_names[0]][0].history.keys())\n\n    # Validate consistency across all conditions and histories\n    for condition in condition_names:\n        for i, history in enumerate(history_comparison_dict[condition]):\n            if set(history.history.keys()) != set(all_metric_names):\n                raise ValueError(\n                    f\"History {i} for condition '{condition}' has inconsistent \"\n                    \"metric names. \"\n                    f\"Expected: {all_metric_names}, Got: {list(history.history.keys())}\"\n                )\n\n    if metrics_filter is not None:\n        if not all(metric in all_metric_names for metric in metrics_filter):\n            raise ValueError(f\"Requested metrics {metrics_filter} not found in history\")\n        metric_names = metrics_filter\n    else:\n        metric_names = all_metric_names\n\n    if linestyle_cycle is None:\n        linestyle_cycle = [\"-\", \"--\", \"-.\", \":\"]\n\n    # Calculate statistics for each condition and metric\n    condition_stats = {}\n    min_epochs = float(\"inf\")\n\n    for condition in condition_names:\n        # Find minimum epochs across all histories for this condition\n        cond_min_epochs = min(\n            len(history.history[metric_names[0]])\n            for history in history_comparison_dict[condition]\n        )\n        min_epochs = min(min_epochs, cond_min_epochs)\n\n        condition_stats[condition] = {}\n        for metric in metric_names:\n            # Collect all values for this metric across runs\n            all_values = []\n            for history in history_comparison_dict[condition]:\n                all_values.append(history.history[metric][:cond_min_epochs])\n\n            # Calculate mean and std across runs\n            values_array = np.array(all_values)\n            mean_vals = np.mean(values_array, axis=0)[:min_epochs]\n            std_vals = (\n                np.std(values_array, axis=0, ddof=1)[:min_epochs]\n                if len(all_values) &gt; 1\n                else np.zeros_like(mean_vals)\n            )\n\n            condition_stats[condition][metric] = {\"mean\": mean_vals, \"std\": std_vals}\n\n    # Get colors for metrics\n    colors = generate_distinct_colors(len(metric_names))\n\n    plt.figure(figsize=(12, 8))\n\n    # Plot each metric for each condition\n    x = range(min_epochs)\n    for metric_idx, metric in enumerate(metric_names):\n        for cond_idx, condition in enumerate(condition_names):\n            mean_vals = condition_stats[condition][metric][\"mean\"]\n            std_vals = condition_stats[condition][metric][\"std\"]\n\n            linestyle = linestyle_cycle[cond_idx % len(linestyle_cycle)]\n            color = colors[metric_idx]\n\n            # Plot mean line\n            plt.plot(\n                x,\n                mean_vals,\n                label=f\"{condition} - {metric}\",\n                color=color,\n                linestyle=linestyle,\n                **kwargs,\n            )\n\n            # Plot std band\n            plt.fill_between(\n                x, mean_vals - std_vals, mean_vals + std_vals, color=color, alpha=alpha\n            )\n\n    if xlabel:\n        plt.xlabel(xlabel)\n\n    plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n\n    if ylabel:\n        plt.ylabel(ylabel)\n    if title:\n        plt.title(title)\n\n    # Set y-axis limits: minimum 0.0, maximum 1.0 but allow exceeding if needed\n    all_values = []\n    for condition in condition_names:\n        for metric in metric_names:\n            mean_vals = condition_stats[condition][metric][\"mean\"]\n            std_vals = condition_stats[condition][metric][\"std\"]\n            all_values.extend(mean_vals + std_vals)\n    max_value = max(all_values) if all_values else 1.0\n    plt.ylim(0.0, max(1.0, max_value * 1.05))  # 5% padding above max value\n\n    plt.legend()\n    plt.grid(grid)\n    plt.tight_layout()\n\n    if to_folder:\n        to_file = os.path.join(to_folder, to_file)\n\n    plt.savefig(to_file, dpi=300, bbox_inches=\"tight\")\n    plt.close()\n\n    try:\n        import marimo as mo\n\n        if mo.running_in_notebook():\n            return mo.image(src=to_file).center()\n    except ImportError:\n        pass\n\n    try:\n        from IPython import display\n\n        return display.Image(filename=to_file)\n    except ImportError:\n        pass\n\n    return to_file\n</code></pre>"},{"location":"Synalinks%20API/Utilities/More%20plotting%20utilities/#synalinks.src.utils.plot_history.plot_history_with_mean_and_std","title":"<code>plot_history_with_mean_and_std(history_list, to_file='training_history_with_mean_and_std.png', to_folder=None, xlabel='Epochs', ylabel='Scores', title='Training history with mean and std', grid=True, alpha=0.2, metrics_filter=None, **kwargs)</code>","text":"<p>Plots the mean and standard deviation of multiple training history list.</p> <p>This function takes a list of history objects from multiple runs of the same model and plots the mean and standard deviation for each metric.</p> <p>Code Example:</p> <pre><code>program.compile(...)\nhistory_list = []\nfor i in range(5):  # run 5 times\n    history = await program.fit(...)\n    history_list.append(history)\n\nsynalinks.utils.plot_history_with_mean_and_std(history_list)\n</code></pre> <p>Example:</p> <p></p> <p>Parameters:</p> Name Type Description Default <code>history_list</code> <code>list</code> <p>A list of History objects from multiple runs.</p> required <code>to_file</code> <code>str</code> <p>The file path where the plot will be saved. Default to \"training_history_with_mean_and_std.png\".</p> <code>'training_history_with_mean_and_std.png'</code> <code>to_folder</code> <code>str</code> <p>The folder where the plot will be saved. If provided, will be combined with to_file.</p> <code>None</code> <code>xlabel</code> <code>str</code> <p>Optional. The label for the x-axis. Default to \"Epochs\".</p> <code>'Epochs'</code> <code>ylabel</code> <code>str</code> <p>Optional. The label for the y-axis. Default to \"Scores\".</p> <code>'Scores'</code> <code>title</code> <code>str</code> <p>Optional. The title of the plot. Default to \"Training history with mean and std\".</p> <code>'Training history with mean and std'</code> <code>grid</code> <code>bool</code> <p>Whether to display the grid on the plot. Default to True.</p> <code>True</code> <code>alpha</code> <code>float</code> <p>The transparency of the standard deviation area. Default to 0.2.</p> <code>0.2</code> <code>metrics_filter</code> <code>list</code> <p>List of specific metrics to plot. If None, all metrics will be plotted.</p> <code>None</code> <code>**kwargs</code> <code>keyword arguments</code> <p>Additional keyword arguments forwarded to <code>plt.plot()</code> for the mean lines.</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>history_list</code> is empty, not a list, or if metrics_filter don't match across <code>history_list</code>.</p> <p>Returns:</p> Type Description <code>Image | Image | str</code> <p>If running in a Jupyter notebook, returns an IPython Image object for inline display. If running in a Marimo notebook returns a marimo image. Otherwise returns the filepath where the image has been saved.</p> Source code in <code>synalinks/src/utils/plot_history.py</code> <pre><code>@synalinks_export(\"synalinks.utils.plot_history_with_mean_and_std\")\ndef plot_history_with_mean_and_std(\n    history_list,\n    to_file=\"training_history_with_mean_and_std.png\",\n    to_folder=None,\n    xlabel=\"Epochs\",\n    ylabel=\"Scores\",\n    title=\"Training history with mean and std\",\n    grid=True,\n    alpha=0.2,\n    metrics_filter=None,\n    **kwargs,\n):\n    \"\"\"Plots the mean and standard deviation of multiple training history list.\n\n    This function takes a list of history objects from multiple runs of the same model\n    and plots the mean and standard deviation for each metric.\n\n    Code Example:\n\n    ```python\n    program.compile(...)\n    history_list = []\n    for i in range(5):  # run 5 times\n        history = await program.fit(...)\n        history_list.append(history)\n\n    synalinks.utils.plot_history_with_mean_and_std(history_list)\n    ```\n\n    Example:\n\n    ![training_history_with_mean_and_std.png](../../assets/training_history_with_mean_and_std.png)\n\n    Args:\n        history_list (list): A list of History objects from multiple runs.\n        to_file (str): The file path where the plot will be saved.\n            Default to \"training_history_with_mean_and_std.png\".\n        to_folder (str, optional): The folder where the plot will be saved.\n            If provided, will be combined with to_file.\n        xlabel (str): Optional. The label for the x-axis. Default to \"Epochs\".\n        ylabel (str): Optional. The label for the y-axis. Default to \"Scores\".\n        title (str): Optional. The title of the plot.\n            Default to \"Training history with mean and std\".\n        grid (bool): Whether to display the grid on the plot. Default to True.\n        alpha (float): The transparency of the standard deviation area. Default to 0.2.\n        metrics_filter (list, optional): List of specific metrics to plot.\n            If None, all metrics will be plotted.\n        **kwargs (keyword arguments): Additional keyword arguments\n            forwarded to `plt.plot()` for the mean lines.\n\n    Raises:\n        ValueError: If `history_list` is empty, not a list, or if metrics_filter\n            don't match across `history_list`.\n\n    Returns:\n        (IPython.display.Image | marimo.Image | str):\n            If running in a Jupyter notebook, returns an IPython Image object\n            for inline display. If running in a Marimo notebook returns a marimo image.\n            Otherwise returns the filepath where the image has been saved.\n    \"\"\"\n    if not history_list:\n        raise ValueError(\"history_list cannot be empty\")\n\n    if not isinstance(history_list, list):\n        raise ValueError(\"history_list must be a list of History objects\")\n\n    all_metrics = list(history_list[0].history.keys())\n\n    if metrics_filter is not None:\n        if not all(metric in all_metrics for metric in metrics_filter):\n            raise ValueError(\n                f\"Requested metrics {metrics_filter} not found in history_list\"\n            )\n        all_metrics = metrics_filter\n\n    for i, history in enumerate(history_list):\n        if not all(metric in history.history for metric in all_metrics):\n            raise ValueError(\n                f\"Entry {i}: All history objects must contain the same metrics\"\n            )\n\n    min_epochs = min(len(history.history[all_metrics[0]]) for history in history_list)\n\n    all_values = {metric: [] for metric in all_metrics}\n\n    for history in history_list:\n        for metric in all_metrics:\n            all_values[metric].append(history.history[metric][:min_epochs])\n\n    mean_values = {}\n    std_values = {}\n    for metric in all_metrics:\n        values_array = np.array(all_values[metric])\n        mean_values[metric] = np.mean(values_array, axis=0)\n        std_values[metric] = (\n            np.std(values_array, axis=0, ddof=1)\n            if len(all_values[metric]) &gt; 1\n            else np.zeros_like(np.mean(values_array, axis=0))\n        )\n\n    colors = generate_distinct_colors(len(all_metrics))\n\n    plt.figure(figsize=(10, 6))\n\n    for i, metric in enumerate(all_metrics):\n        color = colors[i]\n        x = range(min_epochs)\n        mean = mean_values[metric]\n        std = std_values[metric]\n\n        plt.plot(x, mean, label=f\"{metric} (mean)\", color=color, **kwargs)\n\n        plt.fill_between(\n            x, mean - std, mean + std, color=color, alpha=alpha, label=f\"{metric} (\u00b1std)\"\n        )\n\n    if xlabel:\n        plt.xlabel(xlabel)\n\n    plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n\n    if ylabel:\n        plt.ylabel(ylabel)\n    if title:\n        plt.title(title)\n\n    # Set y-axis limits: minimum 0.0, maximum 1.0 but allow exceeding if needed\n    all_vals = []\n    for metric in all_metrics:\n        all_vals.extend(mean_values[metric] + std_values[metric])\n    max_value = max(all_vals) if all_vals else 1.0\n    plt.ylim(0.0, max(1.0, max_value * 1.05))  # 5% padding above max value\n\n    plt.legend()\n    plt.grid(grid)\n    plt.tight_layout()\n\n    if to_folder:\n        to_file = os.path.join(to_folder, to_file)\n\n    plt.savefig(to_file, dpi=300, bbox_inches=\"tight\")\n    plt.close()\n\n    try:\n        import marimo as mo\n\n        if mo.running_in_notebook():\n            return mo.image(src=to_file).center()\n    except ImportError:\n        pass\n\n    try:\n        from IPython import display\n\n        return display.Image(filename=to_file)\n    except ImportError:\n        pass\n\n    return to_file\n</code></pre>"},{"location":"Synalinks%20API/Utilities/More%20plotting%20utilities/#synalinks.src.utils.plot_metrics.plot_metrics","title":"<code>plot_metrics(metrics, to_file='evaluation_metrics.png', to_folder=None, xlabel='Metrics', ylabel='Scores', title='Evaluation metrics', grid=True, metrics_filter=None, **kwargs)</code>","text":"<p>Plots the evaluation metrics of a program and saves it to a file.</p> <p>Code Example:</p> <pre><code>program.compile(...)\nmetrics = await program.evaluate(...)\n\nsynalinks.utils.plot_metrics(metrics)\n</code></pre> <p>Example:</p> <p></p> <p>Parameters:</p> Name Type Description Default <code>metrics</code> <code>dict</code> <p>The metrics from a program evaluation.</p> required <code>to_file</code> <code>str</code> <p>The file path where the plot will be saved. Default to \"evaluation_metrics.png\".</p> <code>'evaluation_metrics.png'</code> <code>to_folder</code> <code>str</code> <p>The folder where the plot will be saved. If provided, will be combined with to_file.</p> <code>None</code> <code>xlabel</code> <code>str</code> <p>Optional. The label for the x-axis. Default to \"Metrics\".</p> <code>'Metrics'</code> <code>ylabel</code> <code>str</code> <p>Optional. The label for the y-axis. Default to \"Scores\".</p> <code>'Scores'</code> <code>title</code> <code>str</code> <p>Optional. The title of the plot. Default to \"Evaluation metrics\".</p> <code>'Evaluation metrics'</code> <code>grid</code> <code>bool</code> <p>Whether to display the grid on the plot. Default to True.</p> <code>True</code> <code>metrics_filter</code> <code>list</code> <p>List of specific metrics to plot. If None, all metrics will be plotted.</p> <code>None</code> <code>**kwargs</code> <code>keyword arguments</code> <p>Additional keyword arguments forwarded to <code>plt.bar()</code></p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If there are unrecognized keyword arguments.</p> <p>Returns:</p> Type Description <code>Image | Image | str</code> <p>If running in a Jupyter notebook, returns an IPython Image object for inline display. If running in a Marimo notebook returns a marimo image. Otherwise returns the filepath where the image has been saved.</p> Source code in <code>synalinks/src/utils/plot_metrics.py</code> <pre><code>@synalinks_export(\"synalinks.utils.plot_metrics\")\ndef plot_metrics(\n    metrics,\n    to_file=\"evaluation_metrics.png\",\n    to_folder=None,\n    xlabel=\"Metrics\",\n    ylabel=\"Scores\",\n    title=\"Evaluation metrics\",\n    grid=True,\n    metrics_filter=None,\n    **kwargs,\n):\n    \"\"\"Plots the evaluation metrics of a program and saves it to a file.\n\n    Code Example:\n\n    ```python\n    program.compile(...)\n    metrics = await program.evaluate(...)\n\n    synalinks.utils.plot_metrics(metrics)\n    ```\n\n    Example:\n\n    ![evaluation_metrics.png](../../assets/evaluation_metrics.png)\n\n    Args:\n        metrics (dict): The metrics from a program evaluation.\n        to_file (str): The file path where the plot will be saved.\n            Default to \"evaluation_metrics.png\".\n        to_folder (str, optional): The folder where the plot will be saved.\n            If provided, will be combined with to_file.\n        xlabel (str): Optional. The label for the x-axis. Default to \"Metrics\".\n        ylabel (str): Optional. The label for the y-axis. Default to \"Scores\".\n        title (str): Optional. The title of the plot. Default to \"Evaluation metrics\".\n        grid (bool): Whether to display the grid on the plot. Default to True.\n        metrics_filter (list, optional): List of specific metrics to plot.\n            If None, all metrics will be plotted.\n        **kwargs (keyword arguments): Additional keyword arguments\n            forwarded to `plt.bar()`\n\n    Raises:\n        ValueError: If there are unrecognized keyword arguments.\n\n    Returns:\n        (IPython.display.Image | marimo.Image | str):\n            If running in a Jupyter notebook, returns an IPython Image object\n            for inline display. If running in a Marimo notebook returns a marimo image.\n            Otherwise returns the filepath where the image has been saved.\n    \"\"\"\n    all_metrics = list(metrics.keys())\n\n    if metrics_filter is not None:\n        if not all(metric in all_metrics for metric in metrics_filter):\n            raise ValueError(f\"Requested metrics {metrics_filter} not found in metrics\")\n        filtered_metrics = {k: v for k, v in metrics.items() if k in metrics_filter}\n    else:\n        filtered_metrics = metrics\n\n    metric_names = list(filtered_metrics.keys())\n    metric_values = list(filtered_metrics.values())\n\n    colors = generate_distinct_colors(len(metric_names))\n\n    plt.bar(metric_names, metric_values, color=colors, **kwargs)\n\n    if xlabel:\n        plt.xlabel(xlabel)\n    if ylabel:\n        plt.ylabel(ylabel)\n    if title:\n        plt.title(title)\n\n    # Set y-axis limits: minimum 0.0, maximum 1.0 but allow exceeding if needed\n    max_value = max(metric_values) if metric_values else 1.0\n    plt.ylim(0.0, max(1.0, max_value * 1.05))  # 5% padding above max value\n    plt.grid(grid)\n\n    # Rotate x-axis labels if there are many metrics\n    if len(metric_names) &gt; 5:\n        plt.xticks(rotation=45, ha=\"right\")\n\n    plt.tight_layout()\n\n    if to_folder:\n        to_file = os.path.join(to_folder, to_file)\n\n    plt.savefig(to_file, dpi=300, bbox_inches=\"tight\")\n    plt.close()\n\n    try:\n        import marimo as mo\n\n        if mo.running_in_notebook():\n            return mo.image(src=to_file).center()\n    except ImportError:\n        pass\n\n    try:\n        from IPython import display\n\n        return display.Image(filename=to_file)\n    except ImportError:\n        pass\n\n    return to_file\n</code></pre>"},{"location":"Synalinks%20API/Utilities/More%20plotting%20utilities/#synalinks.src.utils.plot_metrics.plot_metrics_comparison","title":"<code>plot_metrics_comparison(metrics_dict, to_file='evaluation_metrics_comparison.png', to_folder=None, xlabel='Metrics', ylabel='Scores', title='Metrics Comparison', grid=True, metrics_filter=None, bar_width=0.35, **kwargs)</code>","text":"<p>Plots comparison of evaluation metrics across different runs/models/conditions.</p> <p>Code Example:</p> <pre><code># Compare metrics from different models\nmetrics_comparison = {\n    \"Program A\": metrics_a,\n    \"Program B\": metrics_b,\n    \"Program C\": metrics_c,\n}\n\nsynalinks.utils.plot_metrics_comparison(metrics_comparison)\n</code></pre> <p></p> <p>Parameters:</p> Name Type Description Default <code>metrics_dict</code> <code>dict</code> <p>Dictionary where keys are condition names (e.g., model names) and values are metrics dictionaries. Format: {\"condition1\": {\"metric1\": value1, \"metric2\": value2}, ...}</p> required <code>to_file</code> <code>str</code> <p>The file path where the plot will be saved. Default to \"evaluation_metrics_comparison.png\".</p> <code>'evaluation_metrics_comparison.png'</code> <code>to_folder</code> <code>str</code> <p>The folder where the plot will be saved. If provided, will be combined with to_file.</p> <code>None</code> <code>xlabel</code> <code>str</code> <p>Optional. The label for the x-axis. Default to \"Metrics\".</p> <code>'Metrics'</code> <code>ylabel</code> <code>str</code> <p>Optional. The label for the y-axis. Default to \"Scores\".</p> <code>'Scores'</code> <code>title</code> <code>str</code> <p>Optional. The title of the plot. Default to \"Metrics Comparison\".</p> <code>'Metrics Comparison'</code> <code>grid</code> <code>bool</code> <p>Whether to display the grid on the plot. Default to True.</p> <code>True</code> <code>metrics_filter</code> <code>list</code> <p>List of specific metrics to plot. If None, all metrics will be plotted.</p> <code>None</code> <code>bar_width</code> <code>float</code> <p>Width of the bars. Default to 0.35.</p> <code>0.35</code> <code>**kwargs</code> <code>keyword arguments</code> <p>Additional keyword arguments forwarded to <code>plt.bar()</code></p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If metrics_dict is empty, has inconsistent metric names, or if there are unrecognized keyword arguments.</p> <p>Returns:</p> Type Description <code>Image | Image | str</code> <p>If running in a Jupyter notebook, returns an IPython Image object for inline display. If running in a Marimo notebook returns a marimo image. Otherwise returns the filepath where the image has been saved.</p> Source code in <code>synalinks/src/utils/plot_metrics.py</code> <pre><code>@synalinks_export(\"synalinks.utils.plot_metrics_comparison\")\ndef plot_metrics_comparison(\n    metrics_dict,\n    to_file=\"evaluation_metrics_comparison.png\",\n    to_folder=None,\n    xlabel=\"Metrics\",\n    ylabel=\"Scores\",\n    title=\"Metrics Comparison\",\n    grid=True,\n    metrics_filter=None,\n    bar_width=0.35,\n    **kwargs,\n):\n    \"\"\"Plots comparison of evaluation metrics across different runs/models/conditions.\n\n    Code Example:\n\n    ```python\n    # Compare metrics from different models\n    metrics_comparison = {\n        \"Program A\": metrics_a,\n        \"Program B\": metrics_b,\n        \"Program C\": metrics_c,\n    }\n\n    synalinks.utils.plot_metrics_comparison(metrics_comparison)\n    ```\n\n    ![evaluation_metrics_comparison.png](../../assets/evaluation_metrics_comparison.png)\n\n    Args:\n        metrics_dict (dict): Dictionary where keys are condition names (e.g., model names)\n            and values are metrics dictionaries. Format:\n            {\"condition1\": {\"metric1\": value1, \"metric2\": value2}, ...}\n        to_file (str): The file path where the plot will be saved.\n            Default to \"evaluation_metrics_comparison.png\".\n        to_folder (str, optional): The folder where the plot will be saved.\n            If provided, will be combined with to_file.\n        xlabel (str): Optional. The label for the x-axis. Default to \"Metrics\".\n        ylabel (str): Optional. The label for the y-axis. Default to \"Scores\".\n        title (str): Optional. The title of the plot. Default to \"Metrics Comparison\".\n        grid (bool): Whether to display the grid on the plot. Default to True.\n        metrics_filter (list, optional): List of specific metrics to plot.\n            If None, all metrics will be plotted.\n        bar_width (float): Width of the bars. Default to 0.35.\n        **kwargs (keyword arguments): Additional keyword arguments\n            forwarded to `plt.bar()`\n\n    Raises:\n        ValueError: If metrics_dict is empty, has inconsistent metric names,\n            or if there are unrecognized keyword arguments.\n\n    Returns:\n        (IPython.display.Image | marimo.Image | str):\n            If running in a Jupyter notebook, returns an IPython Image object\n            for inline display. If running in a Marimo notebook returns a marimo image.\n            Otherwise returns the filepath where the image has been saved.\n    \"\"\"\n    if not metrics_dict:\n        raise ValueError(\"metrics_dict cannot be empty\")\n\n    # Get all metric names and validate consistency\n    condition_names = list(metrics_dict.keys())\n    all_metric_names = list(metrics_dict[condition_names[0]].keys())\n\n    # Validate that all conditions have the same metrics\n    for condition in condition_names:\n        if set(metrics_dict[condition].keys()) != set(all_metric_names):\n            raise ValueError(\n                f\"Condition '{condition}' has inconsistent metric names. \"\n                f\"Expected: {all_metric_names}, \"\n                f\"Got: {list(metrics_dict[condition].keys())}\"\n            )\n\n    if metrics_filter is not None:\n        if not all(metric in all_metric_names for metric in metrics_filter):\n            raise ValueError(f\"Requested metrics {metrics_filter} not found in metrics\")\n        metric_names = metrics_filter\n    else:\n        metric_names = all_metric_names\n\n    # Set up the plot\n    x = np.arange(len(metric_names))\n    num_conditions = len(condition_names)\n    colors = generate_distinct_colors(num_conditions)\n\n    # Calculate bar positions\n    bar_positions = []\n    for i in range(num_conditions):\n        pos = x + (i - num_conditions / 2 + 0.5) * bar_width\n        bar_positions.append(pos)\n\n    # Plot bars for each condition\n    for i, condition in enumerate(condition_names):\n        values = [metrics_dict[condition][metric] for metric in metric_names]\n        plt.bar(\n            bar_positions[i],\n            values,\n            bar_width,\n            label=condition,\n            color=colors[i],\n            **kwargs,\n        )\n\n    if xlabel:\n        plt.xlabel(xlabel)\n    if ylabel:\n        plt.ylabel(ylabel)\n    if title:\n        plt.title(title)\n\n    # Set y-axis limits: minimum 0.0, maximum 1.0 but allow exceeding if needed\n    all_values = [\n        metrics_dict[cond][metric] for cond in condition_names for metric in metric_names\n    ]\n    max_value = max(all_values) if all_values else 1.0\n    plt.ylim(0.0, max(1.0, max_value * 1.05))  # 5% padding above max value\n\n    plt.grid(grid)\n    plt.xticks(x, metric_names)\n    plt.legend()\n\n    # Rotate x-axis labels if there are many metrics\n    if len(metric_names) &gt; 5:\n        plt.xticks(x, metric_names, rotation=45, ha=\"right\")\n\n    plt.tight_layout()\n\n    if to_folder:\n        to_file = os.path.join(to_folder, to_file)\n\n    plt.savefig(to_file, dpi=300, bbox_inches=\"tight\")\n    plt.close()\n\n    try:\n        import marimo as mo\n\n        if mo.running_in_notebook():\n            return mo.image(src=to_file).center()\n    except ImportError:\n        pass\n\n    try:\n        from IPython import display\n\n        return display.Image(filename=to_file)\n    except ImportError:\n        pass\n\n    return to_file\n</code></pre>"},{"location":"Synalinks%20API/Utilities/More%20plotting%20utilities/#synalinks.src.utils.plot_metrics.plot_metrics_comparison_with_mean_and_std","title":"<code>plot_metrics_comparison_with_mean_and_std(metrics_comparison_dict, to_file='evaluation_metrics_comparison_with_mean_and_std.png', to_folder=None, xlabel='Metrics', ylabel='Scores', title='Metrics Comparison with Mean and Std', grid=True, show_values=False, capsize=5, metrics_filter=None, bar_width=0.35, **kwargs)</code>","text":"<p>Plots comparison of evaluation metrics with mean and standard deviation     across conditions.</p> <p>Calculates mean and standard deviation for each condition across multiple runs and displays them as grouped bar plots with error bars for comparison.</p> <p>Code Example: <pre><code># Compare metrics from different models with multiple runs each\nmetrics_comparison = {\n    \"Program A\": metrics_list_a,\n    \"Program B\": metrics_list_b\n}\n\nsynalinks.utils.plot_metrics_comparison_with_mean_and_std(\n    metrics_comparison,\n    show_values=True,\n)\n</code></pre></p> <p></p> <p>Parameters:</p> Name Type Description Default <code>metrics_comparison_dict</code> <code>dict</code> <p>Dictionary where keys are condition names and values are lists of metrics dictionaries. Format: {\"condition1\": [{\"metric1\": val, \"metric2\": val}, ...], ...}</p> required <code>to_file</code> <code>str</code> <p>The file path where the plot will be saved. Default to \"evaluation_metrics_comparison_with_mean_and_std.png\".</p> <code>'evaluation_metrics_comparison_with_mean_and_std.png'</code> <code>to_folder</code> <code>str</code> <p>The folder where the plot will be saved. If provided, will be combined with to_file.</p> <code>None</code> <code>xlabel</code> <code>str</code> <p>Optional. The label for the x-axis. Default to \"Metrics\".</p> <code>'Metrics'</code> <code>ylabel</code> <code>str</code> <p>Optional. The label for the y-axis. Default to \"Scores\".</p> <code>'Scores'</code> <code>title</code> <code>str</code> <p>Optional. The title of the plot. Default to \"Metrics Comparison with Mean and Std\".</p> <code>'Metrics Comparison with Mean and Std'</code> <code>grid</code> <code>bool</code> <p>Whether to display the grid on the plot. Default to True.</p> <code>True</code> <code>show_values</code> <code>bool</code> <p>Whether to display mean values on top of bars (Default to False).</p> <code>False</code> <code>capsize</code> <code>float</code> <p>Size of the error bar caps. Default to 5.</p> <code>5</code> <code>metrics_filter</code> <code>list</code> <p>List of specific metrics to plot. If None, all metrics will be plotted.</p> <code>None</code> <code>bar_width</code> <code>float</code> <p>Width of the bars. Default to 0.35.</p> <code>0.35</code> <code>**kwargs</code> <code>keyword arguments</code> <p>Additional keyword arguments forwarded to <code>plt.bar()</code></p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If metrics_comparison_dict is empty, has inconsistent structures, or if there are unrecognized keyword arguments.</p> <p>Returns:</p> Type Description <code>Image | Image | str</code> <p>If running in a Jupyter notebook, returns an IPython Image object for inline display. If running in a Marimo notebook returns a marimo image. Otherwise returns the filepath where the image has been saved.</p> Source code in <code>synalinks/src/utils/plot_metrics.py</code> <pre><code>@synalinks_export(\"synalinks.utils.plot_metrics_comparison_with_mean_and_std\")\ndef plot_metrics_comparison_with_mean_and_std(\n    metrics_comparison_dict,\n    to_file=\"evaluation_metrics_comparison_with_mean_and_std.png\",\n    to_folder=None,\n    xlabel=\"Metrics\",\n    ylabel=\"Scores\",\n    title=\"Metrics Comparison with Mean and Std\",\n    grid=True,\n    show_values=False,\n    capsize=5,\n    metrics_filter=None,\n    bar_width=0.35,\n    **kwargs,\n):\n    \"\"\"Plots comparison of evaluation metrics with mean and standard deviation\n        across conditions.\n\n    Calculates mean and standard deviation for each condition across multiple runs and\n    displays them as grouped bar plots with error bars for comparison.\n\n    Code Example:\n    ```python\n    # Compare metrics from different models with multiple runs each\n    metrics_comparison = {\n        \"Program A\": metrics_list_a,\n        \"Program B\": metrics_list_b\n    }\n\n    synalinks.utils.plot_metrics_comparison_with_mean_and_std(\n        metrics_comparison,\n        show_values=True,\n    )\n    ```\n\n    ![evaluation_comparaison_with_mean_and_std.png](../../assets/evaluation_comparaison_with_mean_and_std.png)\n\n    Args:\n        metrics_comparison_dict (dict): Dictionary where keys are condition names and\n            values are lists of metrics dictionaries. Format:\n            {\"condition1\": [{\"metric1\": val, \"metric2\": val}, ...], ...}\n        to_file (str): The file path where the plot will be saved.\n            Default to \"evaluation_metrics_comparison_with_mean_and_std.png\".\n        to_folder (str, optional): The folder where the plot will be saved.\n            If provided, will be combined with to_file.\n        xlabel (str): Optional. The label for the x-axis. Default to \"Metrics\".\n        ylabel (str): Optional. The label for the y-axis. Default to \"Scores\".\n        title (str): Optional. The title of the plot.\n            Default to \"Metrics Comparison with Mean and Std\".\n        grid (bool): Whether to display the grid on the plot. Default to True.\n        show_values (bool): Whether to display mean values on top of bars\n            (Default to False).\n        capsize (float): Size of the error bar caps. Default to 5.\n        metrics_filter (list, optional): List of specific metrics to plot.\n            If None, all metrics will be plotted.\n        bar_width (float): Width of the bars. Default to 0.35.\n        **kwargs (keyword arguments): Additional keyword arguments\n            forwarded to `plt.bar()`\n\n    Raises:\n        ValueError: If metrics_comparison_dict is empty, has inconsistent structures,\n            or if there are unrecognized keyword arguments.\n\n    Returns:\n        (IPython.display.Image | marimo.Image | str):\n            If running in a Jupyter notebook, returns an IPython Image object\n            for inline display. If running in a Marimo notebook returns a marimo image.\n            Otherwise returns the filepath where the image has been saved.\n    \"\"\"\n    if not metrics_comparison_dict:\n        raise ValueError(\"metrics_comparison_dict cannot be empty\")\n\n    condition_names = list(metrics_comparison_dict.keys())\n\n    # Validate structure and get metric names\n    for condition in condition_names:\n        if not isinstance(metrics_comparison_dict[condition], list):\n            raise ValueError(\n                f\"Values for condition '{condition}' must be a list of\"\n                \" metric dictionaries\"\n            )\n        if not metrics_comparison_dict[condition]:\n            raise ValueError(f\"Metrics list for condition '{condition}' cannot be empty\")\n\n    # Get metric names from first condition's first run\n    all_metric_names = list(metrics_comparison_dict[condition_names[0]][0].keys())\n\n    # Validate consistency across all conditions and runs\n    for condition in condition_names:\n        for i, metrics_dict in enumerate(metrics_comparison_dict[condition]):\n            if not isinstance(metrics_dict, dict):\n                raise ValueError(\n                    f\"Entry {i} for condition '{condition}' is not a dictionary\"\n                )\n            if set(metrics_dict.keys()) != set(all_metric_names):\n                raise ValueError(\n                    f\"Entry {i} for condition '{condition}' has inconsistent\"\n                    \" metric names. \"\n                    f\"Expected: {all_metric_names}, Got: {list(metrics_dict.keys())}\"\n                )\n\n    if metrics_filter is not None:\n        if not all(metric in all_metric_names for metric in metrics_filter):\n            raise ValueError(f\"Requested metrics {metrics_filter} not found in metrics\")\n        metric_names = metrics_filter\n    else:\n        metric_names = all_metric_names\n\n    # Calculate means and stds for each condition\n    condition_stats = {}\n    for condition in condition_names:\n        means = []\n        stds = []\n        for metric_name in metric_names:\n            values = [\n                metrics_dict[metric_name]\n                for metrics_dict in metrics_comparison_dict[condition]\n            ]\n            means.append(np.mean(values))\n            stds.append(np.std(values, ddof=1) if len(values) &gt; 1 else 0.0)\n        condition_stats[condition] = {\"means\": means, \"stds\": stds}\n\n    # Set up the plot\n    x = np.arange(len(metric_names))\n    num_conditions = len(condition_names)\n    colors = generate_distinct_colors(num_conditions)\n\n    # Calculate bar positions\n    bar_positions = []\n    for i in range(num_conditions):\n        pos = x + (i - num_conditions / 2 + 0.5) * bar_width\n        bar_positions.append(pos)\n\n    # Plot bars for each condition\n    bars_list = []\n    for i, condition in enumerate(condition_names):\n        means = condition_stats[condition][\"means\"]\n        stds = condition_stats[condition][\"stds\"]\n\n        bars = plt.bar(\n            bar_positions[i],\n            means,\n            bar_width,\n            yerr=stds,\n            label=condition,\n            color=colors[i],\n            capsize=capsize,\n            **kwargs,\n        )\n        bars_list.append(bars)\n\n        # Add value labels on top of bars if requested\n        if show_values:\n            for j, (bar, mean, std) in enumerate(zip(bars, means, stds)):\n                height = bar.get_height()\n                plt.text(\n                    bar.get_x() + bar.get_width() / 2.0,\n                    height + std + 0.01,\n                    f\"{mean:.3f}\u00b1{std:.3f}\",\n                    ha=\"center\",\n                    va=\"bottom\",\n                    fontsize=8,\n                    rotation=90 if num_conditions &gt; 2 else 0,\n                )\n\n    if xlabel:\n        plt.xlabel(xlabel)\n    if ylabel:\n        plt.ylabel(ylabel)\n    if title:\n        plt.title(title)\n\n    # Set y-axis limits: minimum 0.0, maximum 1.0 but allow exceeding if needed\n    all_means = [\n        mean\n        for condition in condition_names\n        for mean in condition_stats[condition][\"means\"]\n    ]\n    all_stds = [\n        std for condition in condition_names for std in condition_stats[condition][\"stds\"]\n    ]\n    max_val = max(np.array(all_means) + np.array(all_stds)) if all_means else 1.0\n    y_padding = 0.15 if show_values else 0.05\n    plt.ylim(0.0, max(1.0, max_val + y_padding))\n\n    plt.grid(grid)\n    plt.xticks(x, metric_names)\n    plt.legend()\n\n    # Rotate x-axis labels if there are many metrics\n    if len(metric_names) &gt; 5:\n        plt.xticks(x, metric_names, rotation=45, ha=\"right\")\n\n    plt.tight_layout()\n\n    if to_folder:\n        to_file = os.path.join(to_folder, to_file)\n\n    plt.savefig(to_file, dpi=300, bbox_inches=\"tight\")\n    plt.close()\n\n    try:\n        import marimo as mo\n\n        if mo.running_in_notebook():\n            return mo.image(src=to_file).center()\n    except ImportError:\n        pass\n\n    try:\n        from IPython import display\n\n        return display.Image(filename=to_file)\n    except ImportError:\n        pass\n\n    return to_file\n</code></pre>"},{"location":"Synalinks%20API/Utilities/More%20plotting%20utilities/#synalinks.src.utils.plot_metrics.plot_metrics_with_mean_and_std","title":"<code>plot_metrics_with_mean_and_std(metrics_list, to_file='evaluation_metrics_with_mean_and_std.png', to_folder=None, xlabel='Metrics', ylabel='Scores', title='Evaluation metrics with mean and std', grid=True, show_values=False, capsize=5, metrics=None, **kwargs)</code>","text":"<p>Plots the evaluation metrics with mean and standard deviation error bars.</p> <p>Calculates mean and standard deviation across multiple evaluation runs and displays them as bar plots with error bars.</p> <p>Code Example: <pre><code>program.compile(...)\nmetrics_list = []\nfor i in range(5):  # Multiple evaluation runs\n    metrics = await program.evaluate(...)\n    metrics_list.append(metrics)\n\nsynalinks.utils.plot_metrics_with_mean_and_std(metrics_list)\n</code></pre></p> <p>Example:</p> <p></p> <p>Parameters:</p> Name Type Description Default <code>metrics_list</code> <code>list[dict]</code> <p>List of metrics dictionaries from multiple program evaluations. Each dict should have format: {'metric_name': float_value, ...}</p> required <code>to_file</code> <code>str</code> <p>The file path where the plot will be saved. Default to \"evaluation_metrics_with_mean_and_std.png\".</p> <code>'evaluation_metrics_with_mean_and_std.png'</code> <code>to_folder</code> <code>str</code> <p>The folder where the plot will be saved. If provided, will be combined with to_file.</p> <code>None</code> <code>xlabel</code> <code>str</code> <p>Optional. The label for the x-axis. Default to \"Metrics\".</p> <code>'Metrics'</code> <code>ylabel</code> <code>str</code> <p>Optional. The label for the y-axis. Default to \"Scores\".</p> <code>'Scores'</code> <code>title</code> <code>str</code> <p>Optional. The title of the plot. Default to \"Evaluation metrics with mean and std\".</p> <code>'Evaluation metrics with mean and std'</code> <code>grid</code> <code>bool</code> <p>Whether to display the grid on the plot. Default to True.</p> <code>True</code> <code>show_values</code> <code>bool</code> <p>Whether to display mean values on top of bars (Default to True).</p> <code>False</code> <code>capsize</code> <code>float</code> <p>Size of the error bar caps. Default to 5.</p> <code>5</code> <code>metrics</code> <code>list</code> <p>List of specific metrics to plot. If None, all metrics will be plotted.</p> <code>None</code> <code>**kwargs</code> <code>keyword arguments</code> <p>Additional keyword arguments forwarded to <code>plt.bar()</code></p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If metrics_list is empty, not a list, contains inconsistent metric names, or if there are unrecognized keyword arguments.</p> <p>Returns:</p> Type Description <code>Image | Image | str</code> <p>If running in a Jupyter notebook, returns an IPython Image object for inline display. If running in a Marimo notebook returns a marimo image. Otherwise returns the filepath where the image has been saved.</p> Source code in <code>synalinks/src/utils/plot_metrics.py</code> <pre><code>@synalinks_export(\"synalinks.utils.plot_metrics_with_mean_and_std\")\ndef plot_metrics_with_mean_and_std(\n    metrics_list,\n    to_file=\"evaluation_metrics_with_mean_and_std.png\",\n    to_folder=None,\n    xlabel=\"Metrics\",\n    ylabel=\"Scores\",\n    title=\"Evaluation metrics with mean and std\",\n    grid=True,\n    show_values=False,\n    capsize=5,\n    metrics=None,\n    **kwargs,\n):\n    \"\"\"Plots the evaluation metrics with mean and standard deviation error bars.\n\n    Calculates mean and standard deviation across multiple evaluation runs and\n    displays them as bar plots with error bars.\n\n    Code Example:\n    ```python\n    program.compile(...)\n    metrics_list = []\n    for i in range(5):  # Multiple evaluation runs\n        metrics = await program.evaluate(...)\n        metrics_list.append(metrics)\n\n    synalinks.utils.plot_metrics_with_mean_and_std(metrics_list)\n    ```\n\n    Example:\n\n    ![evaluation_metrics_with_mean_and_std.png](../../assets/evaluation_metrics_with_mean_and_std.png)\n\n    Args:\n        metrics_list (list[dict]): List of metrics dictionaries from multiple\n            program evaluations. Each dict should have format:\n            {'metric_name': float_value, ...}\n        to_file (str): The file path where the plot will be saved.\n            Default to \"evaluation_metrics_with_mean_and_std.png\".\n        to_folder (str, optional): The folder where the plot will be saved.\n            If provided, will be combined with to_file.\n        xlabel (str): Optional. The label for the x-axis. Default to \"Metrics\".\n        ylabel (str): Optional. The label for the y-axis. Default to \"Scores\".\n        title (str): Optional. The title of the plot.\n            Default to \"Evaluation metrics with mean and std\".\n        grid (bool): Whether to display the grid on the plot. Default to True.\n        show_values (bool): Whether to display mean values on top of bars\n            (Default to True).\n        capsize (float): Size of the error bar caps. Default to 5.\n        metrics (list, optional): List of specific metrics to plot.\n            If None, all metrics will be plotted.\n        **kwargs (keyword arguments): Additional keyword arguments\n            forwarded to `plt.bar()`\n\n    Raises:\n        ValueError: If metrics_list is empty, not a list, contains inconsistent\n            metric names, or if there are unrecognized keyword arguments.\n\n    Returns:\n        (IPython.display.Image | marimo.Image | str):\n            If running in a Jupyter notebook, returns an IPython Image object\n            for inline display. If running in a Marimo notebook returns a marimo image.\n            Otherwise returns the filepath where the image has been saved.\n    \"\"\"\n    if not metrics_list:\n        raise ValueError(\"metrics_list cannot be empty\")\n\n    if not isinstance(metrics_list, list):\n        raise ValueError(\"metrics_list must be a list of metric dictionaries\")\n\n    # Get metric names from first run and validate consistency\n    all_metric_names = list(metrics_list[0].keys())\n\n    if metrics is not None:\n        if not all(metric in all_metric_names for metric in metrics):\n            raise ValueError(f\"Requested metrics {metrics} not found in metrics_list\")\n        metric_names = metrics\n    else:\n        metric_names = all_metric_names\n\n    for i, metrics_dict in enumerate(metrics_list):\n        if not isinstance(metrics_dict, dict):\n            raise ValueError(f\"Entry {i} in metrics_list is not a dictionary\")\n        if set(metrics_dict.keys()) != set(all_metric_names):\n            raise ValueError(\n                f\"Entry {i} has inconsistent metric names. \"\n                f\"Expected: {all_metric_names}, Got: {list(metrics_dict.keys())}\"\n            )\n\n    # Calculate mean and std for each metric\n    means = []\n    stds = []\n\n    for metric_name in metric_names:\n        values = [metrics_dict[metric_name] for metrics_dict in metrics_list]\n        means.append(np.mean(values))\n        stds.append(np.std(values, ddof=1) if len(values) &gt; 1 else 0.0)\n\n    colors = generate_distinct_colors(len(metric_names))\n\n    # Create bar plot with error bars\n    bars = plt.bar(\n        metric_names, means, yerr=stds, color=colors, capsize=capsize, **kwargs\n    )\n\n    # Add value labels on top of bars if requested\n    if show_values:\n        for i, (bar, mean, std) in enumerate(zip(bars, means, stds)):\n            height = bar.get_height()\n            plt.text(\n                bar.get_x() + bar.get_width() / 2.0,\n                height + std + 0.01,\n                f\"{mean:.3f}\u00b1{std:.3f}\",\n                ha=\"center\",\n                va=\"bottom\",\n                fontsize=9,\n            )\n\n    if xlabel:\n        plt.xlabel(xlabel)\n    if ylabel:\n        plt.ylabel(ylabel)\n    if title:\n        plt.title(title)\n\n    # Set y-axis limits: minimum 0.0, maximum 1.0 but allow exceeding if needed\n    max_val = max(np.array(means) + np.array(stds)) if means else 1.0\n    y_padding = 0.1 if show_values else 0.05\n    plt.ylim(0.0, max(1.0, max_val + y_padding))\n\n    plt.grid(grid)\n\n    # Rotate x-axis labels if there are many metrics\n    if len(metric_names) &gt; 5:\n        plt.xticks(rotation=45, ha=\"right\")\n\n    plt.tight_layout()\n\n    if to_folder:\n        to_file = os.path.join(to_folder, to_file)\n\n    plt.savefig(to_file, dpi=300, bbox_inches=\"tight\")\n    plt.close()\n\n    try:\n        import marimo as mo\n\n        if mo.running_in_notebook():\n            return mo.image(src=to_file).center()\n    except ImportError:\n        pass\n\n    try:\n        from IPython import display\n\n        return display.Image(filename=to_file)\n    except ImportError:\n        pass\n\n    return to_file\n</code></pre>"},{"location":"Synalinks%20API/Utilities/NLP%20utilities/","title":"NLP utilities","text":""},{"location":"Synalinks%20API/Utilities/NLP%20utilities/#synalinks.src.utils.nlp_utils.add_suffix","title":"<code>add_suffix(property_key, suffix)</code>","text":"<p>Add a suffix to a property key.</p> <p>Parameters:</p> Name Type Description Default <code>property_key</code> <code>str</code> <p>The property key to process.</p> required <code>suffix</code> <code>int</code> <p>The suffix to add.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The property key with the suffix added.</p> Source code in <code>synalinks/src/utils/nlp_utils.py</code> <pre><code>def add_suffix(property_key, suffix):\n    \"\"\"\n    Add a suffix to a property key.\n\n    Args:\n        property_key (str): The property key to process.\n        suffix (int): The suffix to add.\n\n    Returns:\n        (str): The property key with the suffix added.\n    \"\"\"\n    return f\"{property_key}_{suffix}\"\n</code></pre>"},{"location":"Synalinks%20API/Utilities/NLP%20utilities/#synalinks.src.utils.nlp_utils.is_plural","title":"<code>is_plural(property_key)</code>","text":"<p>Check if the last word of a property key is in plural form.</p> <p>Parameters:</p> Name Type Description Default <code>property_key</code> <code>str</code> <p>The property key to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the last word is plural, False otherwise.</p> Source code in <code>synalinks/src/utils/nlp_utils.py</code> <pre><code>def is_plural(property_key):\n    \"\"\"\n    Check if the last word of a property key is in plural form.\n\n    Args:\n        property_key (str): The property key to check.\n\n    Returns:\n        (bool): True if the last word is plural, False otherwise.\n    \"\"\"\n    words = property_key.split(\"_\")\n    if len(words) &gt; 1:\n        noun = words[-1]\n    else:\n        noun = words[0]\n\n    singular_form = to_singular(noun)\n    return singular_form != noun\n</code></pre>"},{"location":"Synalinks%20API/Utilities/NLP%20utilities/#synalinks.src.utils.nlp_utils.normalize_and_tokenize","title":"<code>normalize_and_tokenize(text)</code>","text":"<p>Normalize the text and tokenize it into words.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text to process.</p> required <p>Returns:</p> Type Description <code>list</code> <p>A list of normalized words.</p> Source code in <code>synalinks/src/utils/nlp_utils.py</code> <pre><code>def normalize_and_tokenize(text):\n    \"\"\"\n    Normalize the text and tokenize it into words.\n\n    Args:\n        text (str): The text to process.\n\n    Returns:\n        (list): A list of normalized words.\n    \"\"\"\n    text = text.lower()\n    text = remove_articles(text)\n    text = remove_punctuation(text)\n    return text.split()\n</code></pre>"},{"location":"Synalinks%20API/Utilities/NLP%20utilities/#synalinks.src.utils.nlp_utils.normalize_text","title":"<code>normalize_text(text)</code>","text":"<p>Normalize the text by converting to lowercase, removing articles,     and removing punctuation.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text to normalize.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The normalized text.</p> Source code in <code>synalinks/src/utils/nlp_utils.py</code> <pre><code>def normalize_text(text):\n    \"\"\"\n    Normalize the text by converting to lowercase, removing articles,\n        and removing punctuation.\n\n    Args:\n        text (str): The text to normalize.\n\n    Returns:\n        (str): The normalized text.\n    \"\"\"\n    return remove_articles(remove_punctuation(text.strip().lower()))\n</code></pre>"},{"location":"Synalinks%20API/Utilities/NLP%20utilities/#synalinks.src.utils.nlp_utils.remove_articles","title":"<code>remove_articles(text)</code>","text":"<p>Remove common English articles from the text.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text to process.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The text with articles removed.</p> Source code in <code>synalinks/src/utils/nlp_utils.py</code> <pre><code>def remove_articles(text):\n    \"\"\"\n    Remove common English articles from the text.\n\n    Args:\n        text (str): The text to process.\n\n    Returns:\n        (str): The text with articles removed.\n    \"\"\"\n    return \" \".join(re.sub(ARTICLE_REGEX, \"\", text).split())\n</code></pre>"},{"location":"Synalinks%20API/Utilities/NLP%20utilities/#synalinks.src.utils.nlp_utils.remove_numerical_suffix","title":"<code>remove_numerical_suffix(property_key)</code>","text":"<p>Remove the numerical suffix from a property key.</p> <p>Parameters:</p> Name Type Description Default <code>property_key</code> <code>str</code> <p>The property key to process.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The property key with the suffix removed.</p> Source code in <code>synalinks/src/utils/nlp_utils.py</code> <pre><code>def remove_numerical_suffix(property_key):\n    \"\"\"\n    Remove the numerical suffix from a property key.\n\n    Args:\n        property_key (str): The property key to process.\n\n    Returns:\n        (str): The property key with the suffix removed.\n    \"\"\"\n    return re.sub(SUFFIX_PATTERN, \"\", property_key)\n</code></pre>"},{"location":"Synalinks%20API/Utilities/NLP%20utilities/#synalinks.src.utils.nlp_utils.remove_punctuation","title":"<code>remove_punctuation(text)</code>","text":"<p>Remove punctuation from the text.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text to process.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The text with punctuation removed.</p> Source code in <code>synalinks/src/utils/nlp_utils.py</code> <pre><code>def remove_punctuation(text):\n    \"\"\"\n    Remove punctuation from the text.\n\n    Args:\n        text (str): The text to process.\n\n    Returns:\n        (str): The text with punctuation removed.\n    \"\"\"\n    return text.translate(PUNCTUATION_TRANSLATOR)\n</code></pre>"},{"location":"Synalinks%20API/Utilities/NLP%20utilities/#synalinks.src.utils.nlp_utils.to_plural","title":"<code>to_plural(word)</code>","text":"<p>Convert a singular word to its plural form.</p> <p>Parameters:</p> Name Type Description Default <code>word</code> <code>str</code> <p>The singular word to convert.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The plural form of the word.</p> Source code in <code>synalinks/src/utils/nlp_utils.py</code> <pre><code>def to_plural(word):\n    \"\"\"\n    Convert a singular word to its plural form.\n\n    Args:\n        word (str): The singular word to convert.\n\n    Returns:\n        (str): The plural form of the word.\n    \"\"\"\n    if word in IRREGULAR_PLURALS:\n        return IRREGULAR_PLURALS.get(word)\n    else:\n        # Use rules for regular plurals\n        if Y_ENDING.search(word):\n            return f\"{word[:-1]}ies\"\n        elif S_ENDING.search(word) or SH_CH_ENDING.search(word):\n            return f\"{word}es\"\n        else:\n            return f\"{word}s\"\n</code></pre>"},{"location":"Synalinks%20API/Utilities/NLP%20utilities/#synalinks.src.utils.nlp_utils.to_plural_property","title":"<code>to_plural_property(property_key)</code>","text":"<p>Convert the last word of a property key to its plural form.</p> <p>Parameters:</p> Name Type Description Default <code>property_key</code> <code>str</code> <p>The property key to convert.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The property key with the last word in plural form.</p> Source code in <code>synalinks/src/utils/nlp_utils.py</code> <pre><code>def to_plural_property(property_key):\n    \"\"\"\n    Convert the last word of a property key to its plural form.\n\n    Args:\n        property_key (str): The property key to convert.\n\n    Returns:\n        (str): The property key with the last word in plural form.\n    \"\"\"\n    words = property_key.split(\"_\")\n    if len(words) &gt; 1:\n        # Assume the last word is the noun\n        words[-1] = to_plural(words[-1])\n    else:\n        words[0] = to_plural(words[0])\n    return \"_\".join(words)\n</code></pre>"},{"location":"Synalinks%20API/Utilities/NLP%20utilities/#synalinks.src.utils.nlp_utils.to_plural_without_numerical_suffix","title":"<code>to_plural_without_numerical_suffix(property_key)</code>","text":"<p>Convert a property key to its list (plural) form by removing     the numerical suffix and converting to plural.</p> <p>Parameters:</p> Name Type Description Default <code>property_key</code> <code>str</code> <p>The property key to convert.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The list (plural) form of the property key.</p> Source code in <code>synalinks/src/utils/nlp_utils.py</code> <pre><code>def to_plural_without_numerical_suffix(property_key):\n    \"\"\"\n    Convert a property key to its list (plural) form by removing\n        the numerical suffix and converting to plural.\n\n    Args:\n        property_key (str): The property key to convert.\n\n    Returns:\n        (str): The list (plural) form of the property key.\n    \"\"\"\n    property_key = remove_numerical_suffix(property_key)\n    return to_plural_property(property_key)\n</code></pre>"},{"location":"Synalinks%20API/Utilities/NLP%20utilities/#synalinks.src.utils.nlp_utils.to_singular","title":"<code>to_singular(word)</code>","text":"<p>Convert a plural word to its singular form.</p> <p>Parameters:</p> Name Type Description Default <code>word</code> <code>str</code> <p>The plural word to convert.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The singular form of the word.</p> Source code in <code>synalinks/src/utils/nlp_utils.py</code> <pre><code>def to_singular(word):\n    \"\"\"\n    Convert a plural word to its singular form.\n\n    Args:\n        word (str): The plural word to convert.\n\n    Returns:\n        (str): The singular form of the word.\n    \"\"\"\n    if word in IRREGULAR_SINGULARS:\n        return IRREGULAR_SINGULARS.get(word)\n    else:\n        # Use rules for regular singulars\n        if IES_ENDING.search(word):\n            return f\"{word[:-3]}y\"\n        elif ES_ENDING.search(word):\n            if S_ENDING.search(word[:-2]) or SH_CH_ENDING.search(word[:-2]):\n                return word[:-2]\n            else:\n                return word[:-1]\n        elif word.endswith(\"s\"):\n            return word[:-1]\n        else:\n            return word\n</code></pre>"},{"location":"Synalinks%20API/Utilities/NLP%20utilities/#synalinks.src.utils.nlp_utils.to_singular_property","title":"<code>to_singular_property(property_key)</code>","text":"<p>Convert the last word of a property key to its singular form.</p> <p>Parameters:</p> Name Type Description Default <code>property_key</code> <code>str</code> <p>The property key to convert.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The property key with the last word in singular form.</p> Source code in <code>synalinks/src/utils/nlp_utils.py</code> <pre><code>def to_singular_property(property_key):\n    \"\"\"\n    Convert the last word of a property key to its singular form.\n\n    Args:\n        property_key (str): The property key to convert.\n\n    Returns:\n        (str): The property key with the last word in singular form.\n    \"\"\"\n    words = property_key.split(\"_\")\n    if len(words) &gt; 1:\n        # Assume the last word is the noun\n        words[-1] = to_singular(words[-1])\n    else:\n        words[0] = to_singular(words[0])\n    return \"_\".join(words)\n</code></pre>"},{"location":"Synalinks%20API/Utilities/NLP%20utilities/#synalinks.src.utils.nlp_utils.to_singular_without_numerical_suffix","title":"<code>to_singular_without_numerical_suffix(property_key)</code>","text":"<p>Convert a property key to its base (singular) form by removing     the numerical suffix and converting to singular.</p> <p>Parameters:</p> Name Type Description Default <code>property_key</code> <code>str</code> <p>The property key to convert.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The base (singular) form of the property key.</p> Source code in <code>synalinks/src/utils/nlp_utils.py</code> <pre><code>def to_singular_without_numerical_suffix(property_key):\n    \"\"\"\n    Convert a property key to its base (singular) form by removing\n        the numerical suffix and converting to singular.\n\n    Args:\n        property_key (str): The property key to convert.\n\n    Returns:\n        (str): The base (singular) form of the property key.\n    \"\"\"\n    property_key = remove_numerical_suffix(property_key)\n    return to_singular_property(property_key)\n</code></pre>"},{"location":"Synalinks%20API/Utilities/Program%20plotting%20utilities/","title":"Program plotting utilities","text":""},{"location":"Synalinks%20API/Utilities/Program%20plotting%20utilities/#synalinks.src.utils.program_visualization.plot_program","title":"<code>plot_program(program, to_file=None, to_folder=None, show_schemas=False, show_module_names=False, rankdir='TB', expand_nested=False, dpi=200, show_trainable=False, **kwargs)</code>","text":"<p>Converts a Synalinks program to dot format and save to a file.</p> <p>Code example:</p> <pre><code>inputs = ...\noutputs = ...\nprogram = synalinks.Program(\n    inputs=inputs,\n    outputs=outputs,\n)\n\nsynalinks.utils.plot_program(\n    program,\n    to_file=\"program_1.png\",\n    to_folder=\"/tmp\",\n    show_schemas=True,\n    show_trainable=True,\n)\n</code></pre> <p>Example:</p> <p></p> <p>Parameters:</p> Name Type Description Default <code>program</code> <code>Program</code> <p>A Synalinks program instance</p> required <code>to_file</code> <code>str | None</code> <p>Optional. File name of the plot image.</p> <code>None</code> <code>show_schemas</code> <code>bool</code> <p>whether to display schema information.</p> <code>False</code> <code>show_module_names</code> <code>bool</code> <p>whether to display module names.</p> <code>False</code> <code>rankdir</code> <code>str</code> <p><code>rankdir</code> argument passed to PyDot, a string specifying the format of the plot: <code>\"TB\"</code> creates a vertical plot; <code>\"LR\"</code> creates a horizontal plot.</p> <code>'TB'</code> <code>expand_nested</code> <code>bool</code> <p>whether to expand nested Functional programs into clusters.</p> <code>False</code> <code>dpi</code> <code>int</code> <p>Image resolution in dots per inch.</p> <code>200</code> <code>show_trainable</code> <code>bool</code> <p>whether to display if a module is trainable.</p> <code>False</code> <p>Returns:</p> Type Description <code>Image | Image | str</code> <p>If running in a Jupyter notebook, returns an IPython Image object for inline display. If running in a Marimo notebook returns a marimo image. Otherwise returns the filepath where the image have been saved.</p> Source code in <code>synalinks/src/utils/program_visualization.py</code> <pre><code>@synalinks_export(\"synalinks.utils.plot_program\")\ndef plot_program(\n    program,\n    to_file=None,\n    to_folder=None,\n    show_schemas=False,\n    show_module_names=False,\n    rankdir=\"TB\",\n    expand_nested=False,\n    dpi=200,\n    show_trainable=False,\n    **kwargs,\n):\n    \"\"\"Converts a Synalinks program to dot format and save to a file.\n\n    Code example:\n\n    ```python\n    inputs = ...\n    outputs = ...\n    program = synalinks.Program(\n        inputs=inputs,\n        outputs=outputs,\n    )\n\n    synalinks.utils.plot_program(\n        program,\n        to_file=\"program_1.png\",\n        to_folder=\"/tmp\",\n        show_schemas=True,\n        show_trainable=True,\n    )\n    ```\n\n    Example:\n\n    ![chain_of_thought.png](../../assets/chain_of_thought.png)\n\n    Args:\n        program (Program): A Synalinks program instance\n        to_file (str | None): Optional. File name of the plot image.\n        show_schemas (bool): whether to display schema information.\n        show_module_names (bool): whether to display module names.\n        rankdir (str): `rankdir` argument passed to PyDot,\n            a string specifying the format of the plot: `\"TB\"`\n            creates a vertical plot; `\"LR\"` creates a horizontal plot.\n        expand_nested (bool): whether to expand nested Functional programs\n            into clusters.\n        dpi (int): Image resolution in dots per inch.\n        show_trainable (bool): whether to display if a module is trainable.\n\n    Returns:\n        (IPython.display.Image | marimo.Image | str):\n            If running in a Jupyter notebook, returns an IPython Image object\n            for inline display. If running in a Marimo notebook returns a marimo image.\n            Otherwise returns the filepath where the image have been saved.\n    \"\"\"\n\n    if not to_file:\n        to_file = f\"{program.name}.png\"\n\n    if not program.built:\n        raise ValueError(\n            \"This program has not yet been built. \"\n            \"Build the program first by calling `build()` or by calling \"\n            \"the program on a batch of data.\"\n        )\n    if not check_pydot():\n        message = (\n            \"You must install pydot (`pip install pydot`) for `plot_program` to work.\"\n        )\n        if \"IPython.core.magics.namespace\" in sys.modules:\n            # We don't raise an exception here in order to avoid crashing\n            # notebook tests where graphviz is not available.\n            io_utils.print_msg(message)\n            return\n        else:\n            raise ImportError(message)\n    if not check_graphviz():\n        message = (\n            \"You must install graphviz \"\n            \"(see instructions at https://graphviz.gitlab.io/download/) \"\n            \"for `plot_program` to work.\"\n        )\n        if \"IPython.core.magics.namespace\" in sys.modules:\n            # We don't raise an exception here in order to avoid crashing\n            # notebook tests where graphviz is not available.\n            io_utils.print_msg(message)\n            return\n        else:\n            raise ImportError(message)\n\n    if kwargs:\n        raise ValueError(f\"Unrecognized keyword arguments: {kwargs}\")\n\n    dot = program_to_dot(\n        program,\n        show_schemas=show_schemas,\n        show_module_names=show_module_names,\n        rankdir=rankdir,\n        expand_nested=expand_nested,\n        dpi=dpi,\n        show_trainable=show_trainable,\n    )\n    to_file = str(to_file)\n    if dot is None:\n        return\n    dot = remove_unused_edges(dot)\n    _, extension = os.path.splitext(to_file)\n    if to_folder:\n        to_file = os.path.join(to_folder, to_file)\n    if not extension:\n        extension = \"png\"\n    else:\n        extension = extension[1:]\n    # Save image to disk.\n    dot.write(to_file, format=extension)\n    # Return the image as a Jupyter Image object or Marimo Image object, to be\n    # displayed in-line. Note that we cannot easily detect whether the code is\n    # running in a Jupyter notebook, and thus we always return the Image if\n    # Jupyter is available.\n    if extension != \"pdf\":\n        try:\n            import marimo as mo\n\n            if mo.running_in_notebook():\n                return mo.image(src=to_file).center()\n        except ImportError:\n            pass\n        try:\n            from IPython import display\n\n            return display.Image(filename=to_file)\n        except ImportError:\n            pass\n    else:\n        try:\n            import marimo as mo\n\n            if mo.running_in_notebook():\n                return mo.pdf(src=to_file)\n        except ImportError:\n            pass\n    return to_file\n</code></pre>"},{"location":"Synalinks%20API/Utilities/Program%20plotting%20utilities/#synalinks.src.utils.program_visualization.program_to_dot","title":"<code>program_to_dot(program, show_schemas=False, show_module_names=True, rankdir='TB', expand_nested=False, dpi=200, subgraph=False, show_trainable=False, **kwargs)</code>","text":"<p>Convert a Synalinks program to dot format.</p> <p>Parameters:</p> Name Type Description Default <code>program</code> <code>Program</code> <p>A Synalinks program instance.</p> required <code>show_schemas</code> <code>bool</code> <p>whether to display schema information.</p> <code>False</code> <code>show_module_names</code> <code>bool</code> <p>whether to display module names.</p> <code>True</code> <code>rankdir</code> <code>str</code> <p><code>rankdir</code> argument passed to PyDot, a string specifying the format of the plot: <code>\"TB\"</code> creates a vertical plot; <code>\"LR\"</code> creates a horizontal plot.</p> <code>'TB'</code> <code>expand_nested</code> <code>bool</code> <p>whether to expand nested Functional programs into clusters.</p> <code>False</code> <code>dpi</code> <code>int</code> <p>Image resolution in dots per inch.</p> <code>200</code> <code>subgraph</code> <code>bool</code> <p>whether to return a <code>pydot.Cluster</code> instance.</p> <code>False</code> <code>show_trainable</code> <code>bool</code> <p>whether to display if a module is trainable.</p> <code>False</code> <p>Returns:</p> Type Description <code>Dot | Cluster</code> <p>A <code>pydot.Dot</code> instance representing the program or a <code>pydot.Cluster</code> instance representing nested program if <code>subgraph=True</code>.</p> Source code in <code>synalinks/src/utils/program_visualization.py</code> <pre><code>@synalinks_export(\"synalinks.utils.program_to_dot\")\ndef program_to_dot(\n    program,\n    show_schemas=False,\n    show_module_names=True,\n    rankdir=\"TB\",\n    expand_nested=False,\n    dpi=200,\n    subgraph=False,\n    show_trainable=False,\n    **kwargs,\n):\n    \"\"\"Convert a Synalinks program to dot format.\n\n    Args:\n        program (Program): A Synalinks program instance.\n        show_schemas (bool): whether to display schema information.\n        show_module_names (bool): whether to display module names.\n        rankdir (str): `rankdir` argument passed to PyDot,\n            a string specifying the format of the plot: `\"TB\"`\n            creates a vertical plot; `\"LR\"` creates a horizontal plot.\n        expand_nested (bool): whether to expand nested Functional programs\n            into clusters.\n        dpi (int): Image resolution in dots per inch.\n        subgraph (bool): whether to return a `pydot.Cluster` instance.\n        show_trainable (bool): whether to display if a module is trainable.\n\n    Returns:\n        (pydot.Dot | pydot.Cluster): A `pydot.Dot` instance representing the\n            program or a `pydot.Cluster` instance representing\n            nested program if `subgraph=True`.\n    \"\"\"\n    from synalinks.src.ops.function import make_node_key\n\n    if not program.built:\n        raise ValueError(\n            \"This program has not yet been built. \"\n            \"Build the program first by calling `build()` or by calling \"\n            \"the program on a batch of data.\"\n        )\n\n    from synalinks.src.programs import functional\n    from synalinks.src.programs import sequential\n\n    if not check_pydot():\n        raise ImportError(\n            \"You must install pydot (`pip install pydot`) for program_to_dot to work.\"\n        )\n\n    if subgraph:\n        dot = pydot.Cluster(style=\"dashed\", graph_name=program.name)\n        dot.set(\"label\", program.name)\n        dot.set(\"labeljust\", \"l\")\n    else:\n        dot = pydot.Dot()\n        dot.set(\"rankdir\", rankdir)\n        dot.set(\"concentrate\", True)\n        dot.set(\"dpi\", dpi)\n        dot.set(\"splines\", \"ortho\")\n        dot.set_node_defaults(schema=\"record\")\n\n    if kwargs.pop(\"module_range\", None) is not None:\n        raise ValueError(\"Argument `module_range` is no longer supported.\")\n    if kwargs:\n        raise ValueError(f\"Unrecognized keyword arguments: {kwargs}\")\n\n    kwargs = {\n        \"show_module_names\": show_module_names,\n        \"show_schemas\": show_schemas,\n        \"show_trainable\": show_trainable,\n    }\n\n    if isinstance(program, sequential.Sequential):\n        modules = program.modules\n    elif not isinstance(program, functional.Functional):\n        # We treat subclassed programs as a single node.\n        node = make_node(program, **kwargs)\n        dot.add_node(node)\n        return dot\n    else:\n        modules = program._operations\n\n    # Create graph nodes.\n    sub_n_first_node = {}\n    sub_n_last_node = {}\n    for i, module in enumerate(modules):\n        # Process nested functional programs.\n        if expand_nested and isinstance(module, functional.Functional):\n            subprogram = program_to_dot(\n                module,\n                show_schemas,\n                show_module_names,\n                rankdir,\n                expand_nested,\n                subgraph=True,\n                show_trainable=show_trainable,\n            )\n            # sub_n : subprogram\n            sub_n_nodes = subprogram.get_nodes()\n            sub_n_first_node[module.name] = sub_n_nodes[0]\n            sub_n_last_node[module.name] = sub_n_nodes[-1]\n            dot.add_subgraph(subprogram)\n\n        else:\n            node = make_node(module, **kwargs)\n            dot.add_node(node)\n\n    # Connect nodes with edges.\n    # Sequential case.\n    if isinstance(program, sequential.Sequential):\n        for i in range(len(modules) - 1):\n            inbound_module_id = str(id(modules[i]))\n            module_id = str(id(modules[i + 1]))\n            add_edge(dot, inbound_module_id, module_id)\n        return dot\n\n    # Functional case.\n    for i, module in enumerate(modules):\n        module_id = str(id(module))\n        for i, node in enumerate(module._inbound_nodes):\n            node_key = make_node_key(module, i)\n            if node_key in program._nodes:\n                for parent_node in node.parent_nodes:\n                    inbound_module = parent_node.operation\n                    inbound_module_id = str(id(inbound_module))\n                    if not expand_nested:\n                        assert dot.get_node(inbound_module_id)\n                        assert dot.get_node(module_id)\n                        add_edge(dot, inbound_module_id, module_id)\n                    else:\n                        # if inbound_module is not Functional\n                        if not isinstance(inbound_module, functional.Functional):\n                            # if current module is not Functional\n                            if not isinstance(module, functional.Functional):\n                                assert dot.get_node(inbound_module_id)\n                                assert dot.get_node(module_id)\n                                add_edge(dot, inbound_module_id, module_id)\n                            # if current module is Functional\n                            elif isinstance(module, functional.Functional):\n                                add_edge(\n                                    dot,\n                                    inbound_module_id,\n                                    sub_n_first_node[module.name].get_name(),\n                                )\n                        # if inbound_module is Functional\n                        elif isinstance(inbound_module, functional.Functional):\n                            name = sub_n_last_node[inbound_module.name].get_name()\n                            if isinstance(module, functional.Functional):\n                                output_name = sub_n_first_node[module.name].get_name()\n                                add_edge(dot, name, output_name)\n                            else:\n                                add_edge(dot, name, module_id)\n    return dot\n</code></pre>"}]}